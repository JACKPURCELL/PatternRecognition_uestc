{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import argparse\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures,StandardScaler,MinMaxScaler\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearNetwork(nn.Module):\n",
    "    def __init__(self, in_dim = 3, n_hidden = 10, n_layer = 3, out_dim = 3, drop_rate=0.1):\n",
    "        super(LinearNetwork, self).__init__()\n",
    "        self.layer1 = nn.Linear(in_dim, n_hidden)\n",
    "        self.layer2 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.layer3 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.layer4 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.layer5 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.out = nn.Linear(n_hidden, out_dim)\n",
    "        self.drop_rate = drop_rate\n",
    "        self.n_layer = n_layer\n",
    "\n",
    "    def forward1(self, x):\n",
    "        x = F.dropout(F.relu(self.layer1(x)), p=self.drop_rate)\n",
    "        y_pred = torch.sigmoid(self.out(x))\n",
    "        return y_pred\n",
    "\n",
    "    def forward3(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = F.dropout(F.relu(self.layer3(x)), p=self.drop_rate)\n",
    "        y_pred = torch.sigmoid(self.out(x))\n",
    "        return y_pred\n",
    "\n",
    "    def forward5(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = F.relu(self.layer3(x))\n",
    "        x = F.relu(self.layer4(x))\n",
    "        x = F.dropout(F.relu(self.layer5(x)), p=self.drop_rate)\n",
    "        y_pred = torch.sigmoid(self.out(x))\n",
    "        return y_pred\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.n_layer == 1:\n",
    "            return self.forward1(x)\n",
    "        elif self.n_layer == 3:\n",
    "            return self.forward3(x)\n",
    "        elif self.n_layer == 5:\n",
    "            return self.forward5(x)\n",
    "        else:\n",
    "            raise AssertionError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(-4.0, 0, ''),\n",
       " Text(-3.0, 0, ''),\n",
       " Text(-2.0, 0, ''),\n",
       " Text(-1.0, 0, ''),\n",
       " Text(0.0, 0, ''),\n",
       " Text(1.0, 0, ''),\n",
       " Text(2.0, 0, ''),\n",
       " Text(3.0, 0, ''),\n",
       " Text(4.0, 0, ''),\n",
       " Text(5.0, 0, '')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb4AAAHOCAYAAADnr2woAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAEAAElEQVR4nOydd3gU19WH39ne1HuvSBQhIQSYZmMw4AbuvduJHdfY+eL4S/I5PXGc2ClOd+ISd8dxN+4GA6YLSSCBEF2o97q9zfeHmPWqSyshQMz7PDzGaHVnZnfn/ubce87vCKIoIiMjIyMjc6agONknICMjIyMjM5HIwicjIyMjc0YhC5+MjIyMzBmFLHwyMjIyMmcUsvDJyMjIyJxRyMInIyMjI3NGIQufjIyMjMwZhSx8MjIBIgjCTwVBePkkn0OlIAjLT+Y5yMicbsjCJyNzhiAIgigIQubJPg8ZmZONLHwyZwyCIKhO9jnIyMicfGThk5nUHF8K/F9BEEoBiyAIjwqCcFgQhG5BEMoFQbjc77W3CYKwSRCEJwVBaBcE4aggCBf6/TxNEIQNx3/3cyCyz7EuEQRhryAIHYIgrBcEYVqf8/ieIAilgiBYBEF4VhCEGEEQPj4+3heCIISN4HpuFgThmCAIrYIg/F+fn80TBGHr8ePXC4LwF0EQNMd/tvH4y3YLgmAWBOFaQRDCBEFYIwhC8/HrXSMIQmJAb7SMzGmELHwyZwLXAxcDocB+4GwgBPgZ8LIgCHF+rz3r+Gsigd8CzwqCIBz/2atA0fGf/QK4VfolQRCygNeAh4Ao4CPgA0l4jnMlsALIAlYDHwM/PD6eAvj2UBchCMJ04O/AzUA8EAH4C5UH+M7x8RYA5wH3AoiieM7x1+SJomgSRfE/x4/5PJACJAM24C9DnYOMzGRAFj6ZM4E/iaJYLYqiTRTF/4qiWCeKovf45H8QmOf32mOiKP5LFEUP8AIQB8QIgpAMzAV+JIqiQxTFjcAHfr93LfChKIqfi6LoAp4E9MBCv9f8WRTFRlEUa4GvgO2iKJaIougA3gHyh7mOq4A1oihuPP47PwK80g9FUSwSRXGbKIpuURQrgaeBJYMNJopiqyiKb4miaBVFsRv41VCvl5GZLMjCJ3MmUC39RRCEWwRB2HV8ObADyKH3kmWD9BdRFK3H/2qiJ8JqF0XR4vfaY35/j/f/f1EUvcePm+D3mka/v9sG+H/TMNcR738tx8+l1e/aso4vVzYIgtAFPNbn2nohCIJBEISnjy+ddgEbgVBBEJTDnIeMzGmNLHwyZwIigCAIKcC/gPuBCFEUQ4E9gDD4r/qoB8IEQTD6/Vuy39/r6Fky5PixBCAJqB3Tmfc/hyS/YxjoWe6U+DtQAUwRRTGYnmXUoa7tu0A2cNbx10vLoSN5P2RkTltk4ZM5kzDSI4LNAIIg3E5PxDcsoigeA3YCPxMEQSMIwmJ69ukk3gAuFgThPEEQ1PSIigPYMo7n/yawShCExcf3Dn9O73s4COgCzIIgTAXu6fP7jUB6n9fbgA5BEMKBn4zjucrInLLIwidzxiCKYjnwO2ArPSIwE9g8iiFuoCf5pY0ekXjRb+z9wE3An4EWekRxtSiKznE5+Z5j7AXuoyfJph5oB2r8XvLw8XPspiey/U+fIX4KvHB8mfca4I/07EO2ANuAT8brXGVkTmUEuQO7jIyMjMyZhBzxycjIyMicUcjCJyNzCiEIwo3HC8z7/tl7ss9NRmayIC91ysjIyMicUcgRn4yMjIzMGcVwpr1yOCgjIyMjczoyaD2qHPHJyMjIyJxRyMInIyMjI3NGIQufjIyMjMwZhSx8MjIyMjJnFLLwycjIyMicUcjCJyMjIyNzRiELn4yMjIzMGYUsfDIyMjIyZxSy8MnIyMjInFHIwicjIyMjc0YhC5+MjIyMzBmFLHwyMjIyMmcUsvDJyMjIyJxRyMInIyMjI3NGIQufjIyMjMwZhSx8MjIyMjJnFLLwycjIyMicUcjCJyMjIyNzRiELn4yMjIzMGYUsfDIyMjIyZxSy8MnIyMjInFHIwicjIyMjc0YhC5+MjIyMzBmFLHwyMjIyMmcUsvDJyMjIyJxRyMInIyMjI3NGIQufjIyMjMwZhSx8MjIyMjJnFLLwycjIyMicUcjCJyMjIyNzRiELn4yMjIzMGYUsfDIyMjIyZxSy8MnIyMjInFHIwicjIyMjc0YhC5+MjIyMzBmFLHwyMjIyMmcUqpN9AjIyMjJjRRRFvF4voiiiVCoRBOFkn5LMKYwsfDIyMqcNXq+31x+32+37O4AgCBgMBlQqlSx+MoMiC5+MjMwphSiKvgjO6/Xi8Xh8AieKou81giD4/igUCgRBQBRF3G43AGq1+mRehswpjCx8MjIyJwVJ4Dwej0/gpD998Re5oSI56edutxtBEFCp5ClOpj/yt0JGRuaE0jd6k/54vV7a29txu91ERkb2i97GgiAIuFwuAFn8ZPohfyNkZGTGhaEEzv81/gLncrlwu93jLk6ScLpcLhQKBQqFnMAu8zWy8MnIyIyYgfbf/AVO2mcbaP9tsPHGMwlF2gOEr8XP4XCg1Wpl8ZPxIQufjIxMP/wFrq+4+YsLfL2vFkgZwXgKX9/zks7N4/Fw+PBhMjMz5UxPGUAWPhmZM5q+0ZvX68Vut9PR0UFYWFgvofCP4Mbz+OM53kDJL16vl4aGBpKTk9FoNLL4ycjCJyNzJjCa/Te73U5TUxNRUVETcl4TcQyFQoHX68XpdMriJyMLn4zMZKHv/ptU4O3xeAZdnhxo/224koHx5kQfy+v1+q5TFj8ZkIVPRua0o6/ASeI21P7baMVsokRhvJNbhjqGdBzpPZPdXc5cZOGTkTlF6StuTqcThUIxZIH3eOyXTcTyo4SUCTpRx5D+K7m7yOJ3ZiILn4zMSWYk+29ms5mamhqmTZs2LgXewzGZljr7JtD4i5/s7nJmIn/iMjITxHAGy/703X+TSgUmohZtIiO+iVrq7Pu++Re4g+zucqYhf9oyMuPIUAXewxksnypMhBidqGMNNNZgy6myu8uZiyx8MjIBcCIMls9EJjK5ZSBkd5czE1n4ZGSGYKj9t7a2NrxeLxEREads9BYIp3PENxBSOcNgSMeXyhxk8Zv8yMInI0NgBstut/uEGCyfCpyOwieVc/TtwzeSY/jX+Gm12tP+4UVmaCbfHSsjMwjjbbAsjTnZONWTW7xeL1arFYvFgsViwWq1YrPZfD+bM2cOer2+1+tHEsXJ7i5nDrLwyUw6AinwDsRgeTJPjKdCxOfxeHzCJomc3W5HoVCg1+sxGo0EBQURGxuLTqdDEAS6u7vZtWsXc+bM8UV+oxFX2d3lzEAWPpnTloEMlpubmwkODh7UhkvevxmeiY74PB4PnZ2dvSI4h8OBUqnEYDBgNBoJDQ0lPj7eJ3CDjRUaGkpGRgYlJSUUFBSgVCpHHPHB14Lv9XpxuVyo1WpZ/CYhsvDJnPKMZv/tyJEjzJo1C6VSOWHnNhk5EZO90+nsF8F1d3fT3d1NcHAwBoOBiIiIMXdRiI6Oxm63U1ZWRl5e3qiXU6XXejweX4G7LH6TC1n4ZE4JTkeD5YmcDCc6ChvL70oC5y9ybrcbtVqN0WjEaDQSFRVFamoqhw4dIjk5GZPJNI5XAMnJyTgcDioqKjCZTAEvY8vuLpMT+dOUmVBOtMGylKAyGTmVbMREUcRut/dLMvF4PGi1Wt8SZWxsLAaDoV+mpf84J6oRbWZmJnv27KGlpYWIiIhRjye7u0xe5E9S5oTQN3qbqALviRS+ySqy/tckiiI2m62XuFmtVrxeLzqdDqPRiMFgICEhAaPROOol5hNZxycIAjNmzGDz5s2DCu9IxgDZ3WWyIQufzJgYbv+tqakJj8dDXFzchBV4T0YxOtFIJQJWq5Xm5mbMZjOtra0A6PV6XwQXGRmJXq8ftz3UE/1ZKRQK4uPjqa2tpbW1dUyRn+zuMnmQhU9mREjZd9J/B0owkfAXOCkqmqhkEzkJYWg8Hs+ANXCCIPjETavVolKpmDJlyoRM8if6M1MoFKSkpFBRUUFubi5BQUGjHkP6Hh86dIjMzExZ/E5zZOGT8XEiDJaluqiJQl7q7MHtdvcSOIvFgsPhQKFQ+AQuJCRkwBKB5uZmLBbLhHWCGM/jDGZSrdfrycvLY/fu3cyePbtXgftoqK2tJTk5WXZ3Oc2Rhe8MxF/g/MXtROy/TbQ4nMpidCJwuVz9MiidTidKpdKXQRkWFkZiYuKIJ+vTJYN0NMcQBAGTycT06dP7FbiPZhylUunLXJUL3E9fZOGbxAwUvdlsNrq6uggPD/e95kQaLMvCN3ZEUcTlcuFwOKipqfEJneQTKglcZGQkKSkp41J0fSo4t4wX/gXsYWFhpKenU1JSwpw5c0YVbUq2drK12emPLHyTgNEUeDscDpqbm4mKipqQczsZQnS6RiyiKOJwOPpFcB6PB4VC4SuojomJwWg0BpypOJLzmChORluimJgYHA4HpaWl5OXljfj4/gIqLeHL7i6nJ7LwnSaMl8GytFQzUUhPxxPFqVTrNhhSiUDfJBOpREDag4uPj8dgMKBSqeju7qampoaEhIRxvoqBz2+yRnwSycnJ2O129u/fz9SpU0c9juzucnojC98pxok2WD4ZQnSmLnV6vd4Ba+CAXjVw4eHhGAyGCct8PZU4mY1op0yZQllZGZWVlaSmpg47Tl8B9Xd3AU5YBC4z/sjCd5IYyGB5uAST8ch+k4VvfJHKO/wFTuoiAPi6CBiNRqKjo9Hr9QF9jpMtCjtRxxosq3Og91wQBHJyciguLkar1RIXFzfsufYdR7Y2Oz2RP6UTzHD7b93d3TQ2NpKZmTkhBd6TXYjgxO1R+ZcIWK1W2tvbsdlstLe3YzAYMBgMvjY5er1eXvoaAScz4oOeB8FZs2ZRWFiIVqv1JX0NhLSl0Bd/dxdpBUbm1EYWvnFgMINl6e/+9N1/U6lUeDyeCbtZzoSIb6y4XK5++28DtckxGAxYLBYyMzPH4cxPHSYy4oMTvy87XFsilUpFfn4+RUVFQxa4DzWOdA1SB3e5wP3URha+URDI/ttwEdzJEKKJPN6pLLQDdRFwuVy9SgSGapPT2tqKxWI5EZdxxjCRdXxDodPpfAXuBQUF6HS6fq8ZTkD9xU+j0cjidwojC98ATKTB8kQLg0KhmNRLnX2P17dNjvTH4/H0apMTHR2NwWBAo9GM6liTkYmO+E40I70eqcBdqvHrm6wyEpcZ6cFSivwm0/s4mTijhW+g/bfOzk4ADAaD7zUnssB7Mqf7S8ebqKd6u92O3W6noaGBuro6LBYLXq8XrVbry6CMi4vDaDTKSQinCOP1ffR6vVgsFpRKZT9xGk0HdqnAfdeuXRQUFPT6vcH2+PoiF7if+pwRd/9oDJY7OjpQKpUBGdkGwkQL30Qz3sLn9Xqx2+29ojebzeargXM6nZhMJl8Ed6L3Tk+V0onxZLz9M4c71miQukj0/fwFQfBFWPn5+b3Of7TXExMTg91u71fgPhoBlcXv1GZSCZ8oilRWVpKQkBCwwbJSqZzUe2ATTaBLq/4TnPRfm80G9G+TYzAYfBPSwYMHCQ8Pn5AHF3kyO3FIJSJms7nX5+/fRaJvBq0oilRXV1NRUcG0adN6CdZoP6uUlJR+Be6jET6Q3V1OZSaV8Lndbq666irWrl0LBLb/plQqfR2XJ4LJlO4/EMNdX982OVINnEKh8NXAmUwmYmJi0Ol0I9pjmYxRGEwu/0x/uru7B/z8pRKR4ODgEZWIiKJIWloa+/bto7KykrS0NN+/B3I9WVlZvQrcAxE+kN1dTkUmlfCpVCq8Xu+YlrcmOuKb7DeC9NTrdrv7ZVBKbXKkBJPB2uSM9ninq1fnZGawBxyr1Up1dfW4fP7SKs706dMpLi5Gp9MRFxc3asHyHy8nJ4eioiJ0Ol1AAiq7u5yaTCrhg7FPRJIZ8GTmRIqtf5sci8WC2Wymq6uL3bt3+wQuPDycpKSk037vYyLP/XQxjpYEzn+J0j+C6ytwO3fuZPr06eN6/v5F6YEKlv9Y+fn5FBYWEhoaislkGvUYsrvLqcek/ATG8kWf6IjvZDDWSdS/RMD/Kd7tdvtKBAwGA1FRUSQlJVFeXk5BQcE4nf3QTOalzlMJj8fTr0SkbwQfGho65gg+UPyL0gPZ4xtorK1bt5KcnBzQGP7uLtKYMiePSfXuj8fNdSZEfDCyh4O+bXIkofN4PGg0Gt8EFxsbi8FgGHAZZ6Di/hPJRArf6RytDoX/d2OoTu6BNrqdKHQ6Hbm5uWzduhWHw4FWqx3TWLGxsVRXV5OQkDBggftw+IufQqGQC9xPIpNK+ODrLMlA9/nOhIhPyrSUbkSpTY5/BOffJkeK4BISEnxtckbKZE/emSzRpSRwZrOZlpYWPB4Px44d62XTdqoK3FAEBQWh0+l8XdfHsv+v0WhISkoatMB9JEjvmyTEsvidHCad8BkMBqxWa8Dp7Ccr4puovmQ2mw23283Ro0ex2Wy+EgFJ4CSbLr1ePy41cCejYF5mcPyTjKQ/TqcTpVLp+/z1er1vH24yvJ8qlYqEhARKS0uZNWtWwNfk9XoJCQnBaDQOWOA+UgRBoLW1FZvNRkZGxqR4j083JqXwWSyWgIVPqVROuPCNNUrti38GnX+CAfS8P16vF4PB4EsRn0xPnfIeXw8jEbjBfEgrKytP+8SjviQmJmKz2Xw1foEgZYdGR0fjcDgoKysjNzc3oPfJ6XTicrnkAveTxKQTPqPR6Gv2GQgno6A8UOHru/9itVr7ZdANVAO1e/duwsPDx7Tncaoy0Xt8J1tkpU4S/lmUIxW4wZioa5ro9y4zM3NUjWf74l8WIRW4HzhwgOzs7IDGkrZVZPGbeCad8On1+jE55p9M4RsMqUTAX+SkyS2Q/ZeJ7tAwkZwKYnQicLvdOBwOamtrfd+BgTpJpKSkjItLyERMwiej/ZFUl6fX64mJiRnV7/e1PsvKyqK0tJRjx46RkpIyqrEkEZXdXU4Ok074jEajb98qEE7GF0/aV+zbRcBqtY6qTc5ojjcZxUHidE5u6VsHKQmcdCxRFImKiiI1NXVUnSRGw0RGfBN9v0k1fjt37kSr1RIaGjri3+1bFiEIAjNnzqSoqAitVktsbOyoxvIXOtndZWKZlMJ3KvdI8y8RkCK4jo4OSktLe2VQxsTEYDQaT4jTw2T2Bz1dGqi6XK5ey5MDRXD+AtfZ2UljYyOJiYnjeAWDMxkjPgm1Ws2sWbMoLi4mPz/f14llOAZygOkrpGFhYaMeS3Z3mXhk4TtBSG1y+kZw/m1yjEYj8fHxeDwekpOTJ6wjxGRdDoRT79oG6gXoX+jfV+BOBSZTxDfYtej1embOnOkrcxjJez+Y9ZlarfYVy+fl5Y3I3aXvWLK7y8Qy6d7dsSa3jBapRKBvkokoir26CISHhw/aJkfyGJ0oJnvEN5HXJi0/DrRE2VfgxhLFT7SYT5aIb6hjBAcHM2XKFF9d3nDJZUN5fkrF8kN1cPfH4/H0G0t2d5k4Jt07K9XxjZW+N0zfPmBWq7VXmxxpcuvbJmcknIwu7JNV+ODEiYQkcNISZUdHB+3t7RQWFo6bwJ0KnK4R30BjDWdQHRUVhd1up6ysrFfvvYEYrq9fUFAQ06ZNo6SkhLlz5w4pXIOdl+zuMjFMOuEzmUy0tLQE/PtS/776+nqfm0nfNjlSH7CRtMkZCSejC/uptBw4nozHROrvRer/p69VW0REBAA5OTljPuapxpkQ8UkkJSVhtVqHLU0YiedneHg4aWlplJSUDFngPlT5kuzucuKZdMJnNBqprq4e9nV9C3ytVisOhwOlUonT6cThcEyYye6Z0Px2ohIZRiPqIxW4uLg4jEZjvyd4s9lMW1vbibiMk8rpGvENxEhbEkmlCVVVVYMaUY90rNjYWOx2O3v27GHmzJkBRaLS7zidztPKIu50YVIKn39yy0BdBPyz5wwGQ78SgdLSUuLi4gIyog2EibZJm+iITzreyRI+SeCkJUrpvx6PB61W69uHHUzghjrWZOV0jPgG+k6P9BhSacLOnTvR6XRER0f3e81o+vqlpqZSUVExaBQ5krGk/Wq5wH38mRTCJy1NlpeX89lnn1FcXMzZZ5/NlClTeOCBB0adPTfZ99wm69KqKIq+SL6qqqpXNwn/TNpAzLbPJE4n5xbp8zabzbhcLjIyMnotIY5GrPqWJoSEhPQ739GIT3Z2Nrt37x4wihzpeUn3qix+48tpf+e/9NJL/P73vycuLo7p06cTEhJCQkICTzzxhG8PZrRMtF+nLHyjY6B2SRaLxbcHo1AoCAsLmxCBk/dKJ+Y4/t0jBvMedbvdVFRUMH369F6dR0ZzLRqNhlmzZlFSUjJgjd9oxhIEgdzcXF+Bu79TzGgEWY78xp/TXvhuuukmbr75Zt//l5aW8stf/jJg0YOTs+cmFa9OBBOd8h+o8PnXQvovVUvtkqQlyoSEBIxGI0qlkubmZsxmM3FxcSfgSnozWSegk7nHN1iDW8mez2QyDeheJJ3zwYMHOXbsmM+LczQCI2EwGMjJyWHXrl3MnTt3TNm5/lGkRqPxFbiPVvik33G73bK7yzhw2gtf3y+AyWQacznDRO+5TfaIb7jjDVXs798uKSwsbNBaSInJmrE6kS4nE3EsSeDsdjuHDx/ulT0daINbQRCYPn16Ly/OQK8lJCSEzMxMX43fWDIrBypwH60g93V3kcVvbJz2wteXsXp1wqknDCfieBMdYUqF3iMRuKGK/Ud6rIliMorseOJf/yotU0oCp1arfT3uxit7WoqwCgsLfclpgY4ZHR2NzWbztR8aC/4F7nPmzAkoEpXdXcaPSffOmUymMVuWTfY9vhO91Cl1dJf2ZLq7uyktLQUYN4Eb7vgTwWR94g4kSpIcjPwFzmazIQiCb0m6r8B1dnbS0NBAZGTkuJ6/5MVZUlJCRkbGmKK1lJQUbDYbBw8eHPN5BQUFMXXqVIqLiwMSPpDdXcaLSfeu6XQ6HA7HmMaY7MI3Xt0ZJIHrG8FJdm2SwBmNRjIzM0fkYThWJqsYnSr4C5z0p6+DkWTw4N8DciBO5JKqwWBgxowZlJWVER4ePqaxsrOz2bVrF06nc8znFRERQWpqKnv27BkX8ZPdXQJj0gnfeEzqZ8JS52iON5jAQe8IbjC7tpaWlgnNEpSXH8eG9P75JxT5f+b+DzXR0dHo9fqAJt8TvZcYGhpKTEwM9fX1AYsMfJ2duW7dOpqbm4mKihrTecXFxVFRUTFkgftIzglkd5dAmXTCJzGWm0qpVE7oHtipUl7gb7gtFXmPRuAGY6Kv70zqwD5W+u67Sm40XV1dvSL2QDxoR3LsE+3VGRYWRkdHB/v27etV5jBaJMvCgwcPotVqCQ4OHtO5arVa1Go1Bw8eJCsrK6Ax/N1dNBqNLH6jYNIJ33jcSJM9q1MQBBwOB01NTYMuV431ab7v8eR9t5NL39pH6cGmb2JRREQEoiiSlpaG0Wg84ec0EZZlYWFhOBwOKisrSUtLC2gcURRRqVS+VkazZ89Gr9eP6dymTp06aIH7SJH262tra0lMTJS//yNk0gnfeDDRe3wnqm5wsP0YyYhbSjoYL4EbjIkWvtM9ChsL/vZsfYv7Jfcak8lEUlLSoIlFk6lsQuqoIJU5SE2eR4tkjmA0Gpk+fbqvj99Yavz6dnAP5LykcQ4dOkR0dLRc4D5CJqXwqdVqXC5XwI09T8ae21iEVkoZ91+iHCqCs1gs1NTUBPz0O1omq/CdTJEdymC7rz2bVNw/mrFPR6/OgZD29vqWOfS1IxvpONCzfJqWlsauXbuG7MAwGP7fGaVSSX5+fr8C90DOTXZ3GTmTUvgMBgMWiyVg4TtVszr79gQcKGV8JC2TTpU9xdP9WBOF0+mku7ub7u5u9u/f72tyO5IOEqcyE92WyL/MYbRLlX2TY0bSgWEk5+R/XsXFxcyaNWvUS8wejwelUulb9nS5XKjValn8huD0uUtGgdShIZCnJzj5WZajEbjhUsYHYqLFYbImt4w3fbu4m81mXxd3aWKLjY3FYDCc0Ca3kzHik5DKHCQ7spE+KAyUFZqSksK+ffs4fPgwmZmZAZ8T9KzM5Obm+pZQtVrtqMaTvh/QI4RSgbssfgMzKYVvrF3YJyri83g82Gw2zGYzDoeDsrIybDbbgE1vAxG4wZjsEd9EEeh1+XcUqK6upqSkhKamJvR6PVOnTmXWrFlER0eTlpbmE7i2tjba2tpGvUR3KjMRWZ0DHSM0NNS3VDl79uwRLVUO1IRWEARfx/WamhoSExNHdJ6DlVZIBe6STdpIRdnj8fjGk91dRsakfFf69uQbLeMtDB6Pp18EJ9k2SRGcUqkkMzPzhDe9hckvfKdKxNe32bHUUUDqBelwONi9ezdTp05l+fLl2Gw29u/fz9GjR1myZMlJO+/JFvENNPnHxsZitVpHXOYgJcn0RRAE8vLyfH38RuJCM1T39YiICJxO56hF2f91srvL8EzKd+RkRXwjEbjBfAmlJ/6J4GQ1op1sx4KeCXGojgL+ZQJ9Owp88cUXZGdnk5KSAvQ88efn57Nlyxba29sDXqofDyaL8A0mWABpaWns3bt3RGUOQxXAK5XKXn38goKChhzLP0IbiLi4OOx2O3v37iUnJ2fY90ja4/NHdncZmkkpfEajcUzCN1xEJAmclEHZV+BMJtO4Gu+ONyd7D/NEc6KEr++DTXd3N11dXZSUlPTqKJCUlIRGo8HpdFJWVkZJSQlarZacnBymTJniG6+xsZH8/Pxex1AqlYSEhNDW1nbShO90akQ73FhDCZ9/N4fhyhyGc37RarXk5eWxe/duCgoKfAbZgYwFX3dwP3ToUK/vzGjGk91dBkcWvgHw3yQe6Enev3VKaGgoCQkJI26dciowViFyOBy0trZiMplG5GBxuu3xSclF/rVwfSP30NBQoqOjOXjwILNnz+43hsPh4JVXXkEURVJTU3E4HHzyySdUVlaycuVK4Osl+b6Rvs1mm7DofzBOtUa0gTLQ3pw//v3yhipzGIlYmUwm357fUIkzIxlLEASmTp3Krl27qK6uJikpadDXDhTx+Y8DsrtLXyat8I1mj0/q7txX5Hbt2uWb6EbbG+xUJtDzF0WRDRs2sGnTJnQ6HTabjezsbC655JIhn3BP1aXO4bJnh4vcpT2UgSgpKUEQBBYsWOD7t6SkJL744gtf8sqMGTMoLCwkODjYV3pTXV2NUqmckEa6gzGREd+JnohHspyqVqvJy8sbssxhpMuy4eHhpKamDrlHN1LfUMkjVCpwj46OHvB1w40nlTk4nc5JMX+NB5NS+Abb45MEzn+J0r+7s7/AlZaWUlBQMKHnPZHNRgNhx44d7Ny5kxUrVmA0GnG73ezcuZO3336bG264YdDfO9nCN1RHgbGUhwz1ugMHDvTbN1KpVMTExHD06FGio6OZMmUKnZ2dbN26laCgIN+S1MqVK0/q9+B0TG7xer2D+s+ORGSGK3MYjcl1XFwcNpuN8vJyZsyY0e8aRzOW//6hRqMhNDS032uGivgk5AL33kxK4VMqlRw4cIA///nPBAcHk5eXh9Pp7JVsEB4e7tuLGehLMNFfDOmLOd696caTr776innz5vkKbFUqFfPmzeP999+ntbWViIiIAX/vRPf/k5AMlyVfRrPZfEI9SIdCpVINGBG63e5ek+qcOXOYPn06ra2tvqzAM2VSCkT4/E21paVoqRWWWq1m7ty5vT7X0RxjqDKH0XZ3SEtLo7y8nCNHjpCRkdHrZ6MdS6PRkJ+fP2iB+2giSFn8epgUwvfVV1/xzjvvUF5eTkNDA06nk8jISBYvXkx+fj7Tpk0L6IOeyAhsooVvtBGY1+uls7OzX28zhUJBcHAwHR0dQwrfeCcyDDb5abVa3G43BoOBqKioMQmcJFxDFYsPdl0zZ85k06ZNxMXF+T5Ts9lMU1MTl156aa/XGgwGDAZDQOd4IjgVIj5/Szb/vVZ/U22TyeTrGgHQ0NDQz0lltCIzWJnDaMfxr/Grq6sjPj7e97NAWiTp9XpmzpzpS57xL3Af6bzhfy1nurvLpBA+k8nEqlWreOSRR4iJieHjjz/m888/5wc/+EHAY060EJ0oo+rxQqFQEBUVRUNDA7Gxsb5/d7vddHZ2Dlm/FKjw9W2ZIwncYJOfQqHA5XKxZ8+eQfdDRkJraytr167l6NGjCIJARkYG5513Xr9lpqEmjRkzZnDkyBHWrVtHbGwsLpeLhoYGVqxYMamK0MeCJHwul6ufqbZkyWYymUbkOer1eklKSmL//v29oqxARHygMofhkmQGQqFQ9Krxkx4aA51XgoODyc7O7lfg7vF4RlyrJ7u79DAphK9vSvhYszph4oVvolshBfJlP/fcc/nwww9ZsGABkZGRWCwWduzYwcyZM4eczIfLIu3bMmegp3tpeXqwjgL+1zWW6NJsNvPKK6+QkpLCxRdfjCiKHDx4kFdffZVvfOMbI7aSUigUXHrppVRXV1NZWYlGo+Giiy4KuERhomsTT8Rk6L/HbrFYaG5uBnp6PUoCFxMTg9FoDNiSberUqRQXF/se0AKJrqQyh+LiYl+ZQ6CJOCqVilmzZlFUVEReXh4mk8knOoEQERHhMz7Iz88PaJ7yd3eBoVc0JiuTQvj6MtYCdpj4CGyia90CITc3F4/Hw9q1a33WanPmzOG8884b8vckMTqRHQX6HitQysrKCAsL69UcdNq0aXR0dFBeXt7vIWs4kpKShkxFHw2ny5O51+vt5zk6UEE/9HQ6GInbyUiRoqzCwkL0en3AIt43WhvLQ7BOpyM3N5fdu3czZ86cMT9Qx8fH9ypwH64gfiDOdGuzSXm1Y7Usg8nfjDZQ8vPzmTVrFlarFZ1ON+gN7C9wLS0tvid8/44C8fHxGAyGcb/pxiJ8DQ0NAy6TRkVF0dTU1OvfTiV7tPFkpGLRN1tWSibqW+84WJ1re3v7CRFz/y4MYzGQ8C9ziIqKwmQyBXxO/j6c0dHRozKhHoi0tDT27dvHoUOHAopqobe7iyAIp3Ri3XgzKYXPZDKNS8Q32YUv0KdhQRB8mWWD7c+o1epeS5RGo3FYB4rxYKwTaVhYGA0NDf06Ynd2dpKZmYnD4WD9+vXs3LkTu92OwWAgJSWFqKioMR33VGawZCL4OlvWZDIRExMzqnKQE2lSbTAYfMuVY3k4kcocSkpKeq0CBIK0THn48OF+mZ6jRUqe2bVrF06ns9e++2jHAXw1fmdKgfukFD6j0ehLYw+UyW7rNdq9gb4tcywWCy6XC5VKNez+THt7Ow6H40RcRj/GGoXl5uZSXFxMbGysz8Kqrq6O5uZmLrnkEl566SXsdjtLlixBo9Gwfft2/vnPf3LPPff0y3gdL3bu3MnatWtpampi+vTpLF26lPT09F6vOXDgALt27cJut5OZmUl+fv6o3V+kpWiXy0VNTc2wmZRjnSRPdPZoWFgYer2e/fv3U1BQEPCxQkNDCQsL49ixY8TFxY3puuPj46mpqaGuro64uLgxXb9U4L5hwwY6OzsHrPEb6ThwZrm7TErhkyO+kR+vr/AN11HAaDQSFRVFamrqiBv9ngzj6EAJDw/n8ssv5+OPP6a0tBToqaO6+uqraWpqorm5mYsuusg3WUyZMoWGhga2bt3KxRdfPC7n78/atWspLi4mJycHnU6H1WrllVde4brrrvNF0J9//jl79uwhKyuL8PBwKioq2L17N7feeuugZRJDZVJKtYZj2WsdCW63m3Xr1lG46QtEr8iS8y9h5cqV47r0LS2tHzhwgOzs7IDHkZKqRtrNYShCQkLo6uoakTn2cCiVSkJDQ6muriY0NDTgjOEzzd1lUgqfRqMZ0k5qJEz2iA+gq6ur117cQAkIKSkpY673Od28OtPS0rj77rtpampCoVAQGhrK7t272bRpk+81Ho+HlpYWGhoa0Ov1HD58eMzH7YvVamXz5s1ceOGFvuXG1NRUlEolX3zxBVOmTKGlpYWSkhJWrlzpexCJj49n+/btFBYWsmjRol6ZlGazedhIvbCwsFfd2YnA6/Xyxyd+hae2iOtzBAQlvPHnjaz9+Gx++8e/jZvYiqJIeno65eXlo+qZN9D5xsXF0dDQMGbBkvxbjx07hk6nGxd7uhkzZrBnz56AOrhLnEnuLpNS+MaDyRLx+XeS8Bc4u91OfX09wcHBw7rYjJWT0QZprCgUCmJjY6mpqeEnD99NorKFCLrYdKCTl+uOkjo1D71ej8fj4dixY1RVVdHV1TUi0+6R0tjYSHBwsM8XVSIxMZEtW7bg8Xg4evQoMTExqNVqHA4HTqcTp9OJyWRi7dq1PnHzf5AZaaR+Itm4cSOWozt47YZgtOoekbtwusgtb3zFl19+yfLly8flONKqRm5uLoWFhRgMhoCWpKVx+pY5BHpOUplDYWEhOp1uTJ04PB4PRqNx0AL30SDNQx0dHYSGhk5a8ZvUi7ljmWxPt4jP4/HQ3d1NQ0MDhw8fprS0lB07dlBSUkJ1dTUul4uwsDCys7OZO3cu4eHhpKenk5ycTHh4+Ald3jhdsx9FUeRff3yM6zK7+e758Xxj+RT+52wdoS1bOXqogpSUFIxGI93d3UyfPp2PPvpoXI9vMpmwWCy93jtRFGlvbwegqqqKY8eOUVdXR21tLR0dHXR2drJ921bWffQ2dVVHsNlsVFZWUlxcTG1t7SkzkW368jMuz/aiVn59PkqFwJVTRb5a+/G4HUfaR5Q8L/ft2xdQxrdUxyeVORw5coTOzs6AzknKwlSpVOTn51NeXj6mLHRpvODgYLKysigpKfHV6AWCIAiUlJTgcrlOy/t2JEzKiG88bu5TNeIbrKPASJrd+jORYnS6lGr05ciRI2isNcyb0rMUpVQqSU5OYk5dCU8VbsQYHE5tbS1Llixh5syZvP/++z6j6bEiiiImkwmTycTWrVtJS0vz7csVFRUxbdo0TCYTS5Ys4fDhwwQFBeHxeHjmT79mTmgrq0NsNFngN4/cwdzzb2B2wRw2b95McXEx119//UmP+pQqFa4Bbi+nR0SpHP20NNj33D/VX6fT+aKiuXPnjqpw29+5ZSTdHIYbS1rK9a/xCzRS8x8vMjKyX4H7aJFEfjK7u0xK4ZMYS9aYQqEY01PTWI83UEcBq9Xqa5kTaEcB/+NNlBidrhGfzWYjRKfo9d7q9QaSE6IIOtBjMF1QUEB6errvu+Z2u0c1eQ3nSblkyRI+//xzNm3ahMFgwOl0Mn36dC6//HLfZLdq1SrWrFlDRVkx54bVcMkMLRpNEHa7g3OnR/C9Tz5l1epLSE9PZ8uWLRQVFfVql3QyOO/8VTz+P69z1Wwvwfqeydnm9PL6XiX3/eKScT2W/+cXHBxMRkYGu3btoqCgYMTC0LdWzr+bw5w5c0Ylon0LzoOCgsjKyvKNNdr9zb7zXEJCAg6HY9DuEMMhCan0fYbJ5+4yaYVPr9f76qwCYaIiPlEUsdlsmM1mX0fvvh0FpBopnU43bqnGCoXilOyRdyqRlpbG851K2s1Owkw9EZJOp2VvnY341DzS0tKora0F4NixY0RERFBTU4PL5SIpKalfhl2gnpSzZs2itLSUhoYGCgoK+pmBz5gxg8TERG678nxWXxJOTHgQLpcTUYToED3Z4R0cPHiQmTNnkpmZyY4dO6itrcVus5I/u2DMWYqBMHfuXDLnXcA1r37OVdN6oql3DiiZtfQKFi5cOOrxRvP9iomJwWq1jkoYBioSl7o57N69e9DeeyMdKzIyErvdTmlpKbNmzRrz5yEVuB8+fJjMzMxR/a7U5mgyu7tMnivpg8FgwGKxBCx84x0RSQLXN4IDfIKmUqlIS0s74S1zYOJaBUnHOh2Fz2g0svzyW3nig6e5Ks9ITIiObftqebUUHIZmXnrpJdLS0mhtbaWsrAytVstXX32FSqXigw8+YOrUqeTk5Iwok3I44uPjMZlMg3bACAkJITg4iKBgDXq9BpfL6fuZx/t11FO0s5BP3niGK/OCCNJ4+f0bKqbMPZ9HHv3ZhNZvCYLAzbffifnq69m2eQNer8j/3rWS2bNnB2yqMJrfS01NZc+ePRw7dozU1NRhXz+YO0psbCw2m21UZQ6DjZWYmIjNZqOiooJp06aN6DoGw7/AfbTZrP4Rqb+7CzBpxG9yXMUASMIXqKNGoBHfUB0F/HvC9S0Cbm9vp6WlJeBU5NFyOi51tra2cuTIEXQ6HdnZ2ROyT3XhqkuIjkvg00/fZf/m3XQ5TKy6+Uaio6MpKSnho48+4rzzzsPtdlNQUEBwcDCCIJCYmEhhYSEJCQnMmjVr1OfqdDr5+MMP2Lr2A9wuF+kz5rDwnKX9Xud2u31P5/OXXsTbxf/lriUxGAwGWltbOdhg4XCXhmuzsmhra+Pj//yLZ64OYVpyj4De4vby8Hsf8cnH87loFHWInZ2dVFRUYLPZSEpKIi0tLSDhnDVr1klZdhUEgRkzZrBz504MBsOw3TyGMqlOTU3t181hKIayGMvMzKSsrIzKysoRCfJQSAXuO3fuRKvVjngu7NvY1l/8pASf051JK3xj7dAwnPCNZ0cBmPgEkNMpuUUURd577z127NhBbGwsdrudN998k1tvvbWfg8mJID8/n6SkJJ588kmuWL7ctx87b948goKCaGpqIj09nezs7F5PxFKpw7x580Z1PK/Xy+8e+wmmxm3clx+CTq3ks9J3+NuOjTz5txcIDg5mX3k5X3zwOi21R1HrTBQsuZBrbriFR7+7lcNvHWZ+koKqNoG3y1pZfPGNVFZW8vHHH7M0VWRq0tfp/BqVgutmaXntk7dHLHwVFRWsWbPGZ1FWVlZGZGQkV1111aj2giay3+VAKBQKX3dzvV5PUFDQoK8dqi2RfzcHvV4/rH3YUMInCAI5OTkUFRWh1+sDLpmQUCqV5Ofn+zq4j6TAfaCO7pPN3WXSCt9YOzRIk3XfjgJmsxmr1dqvo0BiYuKIBG64400Up1PEV1RURFlZGZdddpkvcqqrq+P555/n0UcfHZcsShjak7Kuru74cmIwarXal+nmcDjYv38/OTk5/ZaBDAYDDQ0Noz6P3bt3Y6vcwU8ui0eh6Jlwbl4YQ/e6Oj7/9BNycvP44LnHuTbfxJR5SbSbHXyw83X+smUT4QlTaO2M5sXD1aDS8uBPbker1eJwOMjKyiLiUGG/CTxIq8RuG9m9YrfbWbNmDYsWLfJZZE2fPp3Nmzezc+fOUUVvJ1v4oMfswr9zwmDfpeGMoP27Oej1+iEFZrjr9hdkrVY7pBXZSO4rjUbjM+3Oz88fdvtnIOGDr+/jyeDuMmmFb7QRnyiKvZIPurq6aG1tpbCwsFdHgYSEhBPSUeBkRHyni/Bt27aNvLy8XsuF8fHxhISEBNQqaLTdvRUKBYcPH2b//v0IgoDVakWlUmEwGLDb7URERNDc3Nxvcqyurh7xcpXT6eTAgQN4vV7KdpcwP1H0iZ7E/DQ9H+7aSmvdYa6YaSAroafoOTxIxwXTTXzy7/Xc8OAvfRFHfX09O3bs4OGHH0av15ORkcGvv/Mfbnd50am/Ps/PKqwULBy4tZTL5cJqtWIymVAqlRw5coSwsLBek7G0n7Rnz57TTvigp15y6tSpQ2ZVjqQDwmjKHIa7bqnDRHFx8ZBiNdI+gQaDgZycHN81DrX0PpSHr7+12ens7jKphW+wotCBesJJHQX8kw+cTueoJ9VAORkR3+mS1Wk2mwfc+zQYDMOakY9Hd2/oSRGvrq5m3bp1GI1GX71eVVUVF1xwAd3d3WzevJlp06ah0WiorKyko6OD1atXD3t9RTt38to/f0eCzoIgwMb9HZyf0mPq7T5+/i6Xi5ZOG8bgMOqPHSJzeu/9mpbmJnKTg+nu7vYJX1xcHKGhoZSXl1NQUEBWVhYzl1zKQ+++ww25aoL0Sr44YKPEmszvr7y613gej4ctW7awe/du38Q6d+7cQR38VSrVqMt/xiJ8fR9crFYr2dnZATugREREYLVaKSsrIy8vb8DzGsm5jqXMoS96vZ6ZM2cOKVaj6cUXEhLiK3AfqmxiuDEng7XZpBa+lpYWPvvsM9/mtdRRwL9lzmDZddL+zEQhL3UOTlZWFkePHu2V0eh2u6mvr+fSSy/1/b9kzWa3233OE6PJpPR4POzZs4fqY0cJCg5ldkGBb9+noqKCmJgYCgsLSUtLIzQ0lD179lBfX899991HcnIyRUVFlJaW4nK5yMzM5MILLyQoKAhRFCkrK2PHjh1YrVaysrJYtGgRQUFBNDY28trffsnDSwykRvcI1oVTNXz7X9tZlKbBpLCh02rpsrl49qs2VtyWCC4rDe0WUqK/tkdzOBy02JXk9Nmn6vtw8NDDP2Dt2nm889Fb2OrMFJyznD9cdkU/q7WvvvqKo0ePcs4556DT6TCbzezcuZOpU6fS3NyM3W5Hp9P5Xn/w4EGmTp06qs91JMLn8Xh6CZz0ECDdwyaTibi4OJRKJXv37mXOnDm9zms0JCUlYbFYAioB8CfQMoeBCA4OZsqUKYOK1WDLkoPhX+A+a9asAc9tJGNKkZ/0WZxu4jdphK+8vJwtW7awd+9e35/Q0FBfse+MGTNIS0sb8RPYZBaiiT7eWG+KJUuW8Kc//QlBEMjIyKC7u5uioiIiIiJoaWmhtra2l7m2SqVixowZo8qktFqt/OvPv0XXXsGMGIFmC/z+PT3X3/N9MjMzOXDgAC6Xi/vuu4+Ghgbsdju5ubns2bOHjRs3cuuttzJv3rwBE1k++OADysrKmDFjBgaDgSNHjrBr1y7uvfdeNm9cz5JkD6nRXzc5zUsNZ8WsBO57rYoLZsVh0orsqFWSdc7VNDY2Mi3nLN7f8V9uP1uHSa/B6xXZ2+SlxR3UKxnC6/XS0NDAeed9vYypUChYsWIFK1asAHoeGP77n9f57N1XaG9vZ1rOLKYXLKKjo4Nzzz3Xt+dlMpkoKChgx44dLFy4kPXr15ORkYHRaKSqqgqn0znqJB5/4ZMMG/wFzm63o1AofAI3lNeoKIpMnz6dXbt2MXfuXJRKZUAPW9nZ2RQXF1NXVzcmo26pzCHQInJ/oqKisNvtA0ajgTShTUhIwG63D1qCMVLhk157Orq7TBrh27t3LzabjdWrV/P973+ft99+G7PZzN133x3QeBP9IU7mrM5A8HeuMZvNLF++nC1btrBr1y7fJHzOOecQHBzcb6O9oaFh1OUDn370PqmufVy9Isk31pz6Tp5/5g9872e/p6Ojg7CwMEwmU69ooLm5mcrKykHHbW5uZufOnaxevRqNRkNTUxM6nY6GhgYef/xxYsKMLAzqP8nMStBQ4T6L+GUX43K5uCkpCYPBQF1dHW63h+i5V/DbtR8TZ/TQZvWiiVpElMLBli1byM7ORhAESktLSUpKIiUlZdDz++MTj2Eue5/HlgQTHxrKpoO7+c0/N1Ow/Kp+iR5BQUG43W7y8/NJTExk9+7dNDU1MW3aNPLy8kZk3SVlQ0vCtm/fvl6GDSaTiaCgIOLi4kbdPT0sLIzExESfQASylCoIAnl5eT5D60B73MHoyxyGIikpCZvN1q+90mh6avojdaw4cuRIv6a4UuLecPgXuMPp5e4yaYTv6qt771FIaeanC5M54huKkXT3DgoKoqCggMWLF5+wB5LdW9byyLkxvcbPiA2m65NSvve971FTU4PX6yUxMZGkpCSgZ5/JarUOOTkeOXKE2NhYlEolBw4coL29nejoaObNm8f69etpaWlBpTFz9vSv68hEUeSzvV04TSm+KMdqtdLc3MxnH7xJ9aG9hIUEE5+WTdZZq8hNS6O5uZm6DRvYuXMnn3zyCaGhoVx33XUsX7580PespqaGko0f8tqNkWiPJ7ssnx5Gt9nC09vXc+WVV/Z6gDCbzSiVSnQ6HampqURGRtLZ2Ul0dPSAk57//qr0X4/H40sgEgTBZ/Q9XunxiYmJmM1mDh8+TFpaWkDfF6lzQnFxcUBenBIDlTmM5WFzypQplJaWUlVVRXJyMjC6Pb6Bzq2kpKRfgftolk9PV3eX0+MsA2AkiQ+nEpM9wvSvexxpJuVYjzea99TtcqJV906g+c/mozRYVSw/bw6rV69m7dq1vPTSS1x77bXExMTQ1tZGU1MTF1xwwaDjCoLA7t27KSoqoqWlhYiICObMmUNwcDAxMTHMmjWLN1/4O8nbalmZG0WHxcl3n92Ox+1kuqqQD585gDpmKquvuokX//EHzguv5o+3xRISZOC9bdv5/eNbyJqzjIaGBi666CJuuOEGvF4vJSUl1NXVDShI0s9fe+01kjVtWM0KVMHBvsluXpqJp3a0U1RUxOzZs9FqtdhsNoqLi5kzZw5Op5O//vEJNn3+AcFasHi1rL72NlZecNGgPf/i4uJ8y9ASra2tmEymcf/uS8uV9fX1AX+P9Hq9L0ll7ty5AZ+Lf5mDTqfzGRwEgiAIzJw50zdWdHR0wBGfNJ50bv4F7qMV09PR3eXUP8MAkVq6yAzMiVzqHCiT0mq1sm/fvlFlUo6F0Qpf9qz5bNu/iWW5Pfs6nRYHn+xuYe5ZK8jKykKlUnH++eejVqt58cUXOffcc/F4PERERDB//vxBxy0vL8dqtbJs2TKUSiUOh4PNmzejVqtZtmwZmZmZpM6YS0tCIo+sWce+ffu4doaWb67IpampEbfbzZt7Snn6b08R76ni6tlBRIYFU1NTw9lTgmh3u/jS3MV1113Hzp07CQ8PZ+rUqcyePZsPPviAxsbGfkXQ77zzDocOHSIlJYXde7TYj++txcfHo1Qqqe1wkZScSnJyMuvXr0etVvuWOKdPn87P/u97BNd9yYtXGDFpBKrbbfzs9d/jFUUuu/zKETcvHq3N2EiRHEt27Ngxpgeo0NBQUlNT2b1795juFf/ShNzc3DGdU98av0AjPomBCtwDEdPTzd1l0grfWAvYJU6VWqPxZjwiPv9MyuG6e+/atYtZs2aNz8kPw0g+L6fTyd69e+nu7iYhIYHzV1/J00+W0mWrYVqiie0VjXQLQaRNnel7gg0KCuLiiy+msrKS1atXExMTw9GjRwd9wm1vb6esrIzrr7+eAwcO4PF4CA4OJikpib179zJjxgzMZjMRERHcftd9NF9+DT+69xruvjgapaLH9qy9o4OLsjv4979LuWSxnri4OBwOBx6Pm7CwMHLjrby7uYaIiAhyc3PZtWsXU6dORaFQEBQURFdXVy/hq6urY+/evaxatQqFQsHmz99nc00LCxIUdHV1oTEE88x2Gytuup7c3FwSExNpaWkBep7kCwsL2bdzI+/eGo5Oq0KhUDDNBD85X8ujH77JHd+4c8Sf04ncY1ar1UyfPp2dO3f2y0AdDXFxcVgsloB770lIEWRpaemYIyL/gvTk5OQxi0zfAvfRZopKSPedVOpzKovfpBW+sVqWwddR0WQUvtFEfFIXd3/3GofD0SuT8lTq7j3ctdXU1PDss8/6+t2tX7+emJgY7v7ezynctoVPD+3BHp5OUEQlMTG97ae6urqIjo5mxowZQM8e3mA0NjYSFhZGTEwMYWFhFBYW4vF4mD17NseOHUMURV+NFkB3dzdheiXK44XrgkJBeHg4YWFhRIbbqLaqUCiUuN1uVKqeJcwjLU6CwpIwm82EhYXR3d0N9DyUtLe3ExkZ2eucjhw5Qnx8PCqVClEUWX3tbfzzhX/w+q4WQtXdVNksTMk/l8ysLDo6OnyJJtLyc2FhIdPidBj1vT/naXF6Ghsajp/bxE8rA92jOp2OoKCgXpmegZCWlsaxY8d67a0FQmhoKMnJyT6jgrEIg39B+liyTwcaT6/Xj2n5FDjl3V3G9RsqWXydqOWr0WAymcYsfJJf56n85BIoA0V8fTMpB2pyGxoaSkJCwin9pYbBowmv18uLL75IXl6ez1VFFEU2bNjAjh07uHj1pcCliKLIL37xC3bv3u1LIXe73WzevJlly5aN6BzCw8Pp6OjA6/Wi0WgoKChg//79HDnS0xn9448/JjMzk8WLFwM9iRktTi01rVZiQzQ+AdlbayYlNYPdHR18ua+dBWl6XC4nBxtt/Kdc4KKbVtPQ0IDL5SIyMhKz2cyOHTuYOXOmr6Bbenjp6uqipaWFffv2sW7dOpxOJ/EZOVRWVuIJC+Mfv/sdNTU1gxo3JCQkcKjFjdPtRaP6+r7YV28jKjqapqYmioqK6OjoICEhgYKCgkHtu07090faPw4PD2fPnj3k5uYGfEyj0Uh9fb3vIS9QIiIi0Gq141LmEBISQnR0NPX19WRkZIx5ngoJCfEl0IyF08HdZVyEz+v18uWXX7J161ZcLhfJyclcdNFFxMXFjcfwATGUc8tIORmZjxMRYUr2bFarlcrKykEzKQNtcnuyGSriq6ysxOv19rISEwSB2bNns3btWi4+btQsCAL33nsvf/rTnzhw4AChoaE0NDSQn5/PhRde2Ot3ByM6OtrX/HXBggXodDoyMzN5//33ufDCC1m1alW/rgCxmXnc89zr3DhLSWq4lnZvEG8e1HHFHf+LXq/nlRf/wXMlVdi6vDRYLVx5y73k5uZSVlbGBx98QGxsLJ988gk5OTnMnDmTsrIy38OL0WgkLS2N9evXc+DAAWbPnk1mZiaiKLJ79262b9/Ov//9b6Kiopg+fbrPLWf//v2sX7+etrY2UlJSSJ95Fr/5YivfOTcUk05JbbuTx7+0ctaKa3jxxRdJT08nNjaWmpoaiouLufXWWwfsDDCeS50DjSXdS8nJyZjN5gFT90eCFJ1JiSB5eXmYTKbhf3GQsSRThPEoc5BchMrKysYk7BJRUVFoNBoqKiooKCgIeLxT3d1lXITvN7/5DW+//TZXX301kZGRvP3223zxxRc899xzAacCjxWTyTTmrM6JakYrMd5Lq0N5UqrVapxOJ3q9ftwyKU8Vhnr/pCWYvkiNi/2JjIzkZz/7GYcOHaKzs5OkpKRRu+XfeuutvPzyy7zxxhsYjUbMZjNLly7l4osv7neeL730EnqDieW3/C+fb/uSpkNVWFwit37rbgoKCjCbzfzpmVepqqrCbDZTXl7O9u3b2VteTnBwMNdeey2xsbEEBwcTFBTk22ft+/Ayb9483nnnHYxGI42NjTQ1NaFSqTjnnHOor69Hq9XyyiuvcNNNN1FUVMSHH35IXl4eKSkp1NTU4FboaYs9lyte3kSoTqDLo+GKGx+ktr6JxYsX+6LM+Ph49u/fz9q1a7nuuutG9b6NB/730tSpUykqKvI1dR4NkvBptVpyc3MpLS0d1u9yMKT9s9F0cxju3KKiouju7ubgwYNkZWUFPJaERqMhODiY8vLyMTUpPpUjv3ERvldffZUtW7b4nmTuvvtuZs2ahcvlOmnCNx7lDCerti4QARqtJ6XVauXIkSNjbnsyGiZqv3SoiC8pKYn29nYsFksv/8/BLLcEQWDKlCm+/y8uKmL9R/+lsbaSiOgEIlOmM2fOnEGvy2g08q1vfYu2tjbf/uBAhsMtLS3s2bOH6667DqVSSUFBAQBVVVWUl5dz1lln0dXVxZ49e2hsbESr1ZKVlUVeXh46nY7Q0NARZ8lGRkYyZ84cXydyk8lERkYGHR0dVFdXk5OTQ1NTE9u3b+eTTz7hnHPOoa2tjf3796NUKomLi0OlUvHSe7+go6ODmJgYGhoaeOedd/p5ZWZkZPD+++8P+L222WxUVVURHR0dcPIJDL2sLR1TyoYsLCxEr9f3s2gbCv9xgoKCyMzM9O3NjvZelcbqW+YQaKG8VBeZnZ3N7t27qa6u9tWZBorH4yEzM3PQAveR4u/KI+39niriNy7CN3XqVPbu3cu0adOw2+00NDSQkpLCvn37CAkJISMjY8Kr+pVK5ZhFa6IjvpEIrdvt7iVuA2VSxsbGYjAYhnzPJ7I7g3S8U0H4jEYjK1eu5LPPPiM3N5eQkBCqq6s5evTosC4/27dvY/2rv+PagmAyz4rjWHMX/1r7GmuTEli+cvBaPujZ7wsPDx/05w0NDUREROD1enE4HLhcLp8PYkVFBW1tbWzYsIG9e/f6ork5c+Zw0UUXjfreio+P5/PPP+fss8+mqamJ0NBQFAoF9fX1vu2JlJQUtm3bhlqtprKykvDwcLKysnw2aO+88w7333+/b5Id7F5xu90oFIpen3tPHeCTfPj2K8SH6eh0qrjs+ju49Y47A151GKg0om/nAql7giRaI21n1Xec6OhorFYre/fuJScnZ1TfaX8RHWkHhpGM17fGL9AG3BIKhcJnAVdbW0tCQkJA4/hnejocDp9xwclmXIQvLy+Pa6+9lkWLFhEdHc1HH33EjBkzeOONN2hra+uxZprAyMKfsUy24yGeo8Ff+E50JuVQ3RnsdjvP/OtpPnzrNZwuJ0tXruKe+x8c06b+qWSRdu655xITE8PmzZs5evQoaWlpfPvb3+6XAemP1+vl83de4s4F4SRH9ezvpMcGc9vCCJ778HXy8gvo7OwkLCxs2PdJFMV+vpTV1dVUVlbS2dmJTqdDq9ViMplobm4mIyODN998k71795KXl4fT6aSjo4PS0lJEUeSyyy4b1fVPmTKF8PBwvvrqK9LS0nC5XBw5coTy8nKuv/56nE6nb5Lat28fWVlZPtFWKBSEhYVhsVh49dVXmT17NtOmTfNlivZ1ASkvL2fmzJm97sE/PvEYtrJ3+O/1WhIig2jodPHo+39FrdZw0623j+pahmKg5rFGo5Hs7GxfpudIhHagcVJSUigvLx/1Pl3fyFev15OTk+PrBzjahxj/mjv/mjytVjuqqHYgFAoFubm5FBUVodVqh7w/hkIQBLq7u6mvryc3N/eUKHAflzPIzs7mRz/6kW+p5cILL/QV60rrxRPNeDxVKBSKEx7x+WdSWq1WKioqcDqdJzyTcrDo0uPxcNsNVxPasYvfzfeiVwu8VPQsV676kHc/XhvwksxECt9IjjVt2jSmTZs24jG7u7vxmltJjur95BuiV2FtOsovfvELEhIS6OrqIisri2uuuQadTofT6ewlcFarFa/X6/OllGodc3JyOHToEPv37+ess85CpVJhNpvZsmULSUlJbNy4kRtvvNG3lFhdXU1JSQnFxcWsWLFiwLZNEi6Xi127dmGxWJg6dSqxsbHcc889vP/++6xdu5a9e/f6nDs2btxIfHw8TqeTc889ly+//JLW1lbfg6vUiNZgMFBbW0t9fT2ffPIJd911F1dccQWvvfYa1dXVBAcH09TUhFKp5IorrvCdS3t7O5s+f593bw4Gd8+eamyImh+vMHHXK89w3Y03j9vEONhDb2RkJBaLZcQR20DLtFIPwqKiIgwGw4gf7AcaKyQkhPT0dHbt2kVBQcGoot6+WecajcYX1Y7Fbk1CpVL1KnAPdC73er2oVKpTxt1lXI5+1VVX4XQ6cbvdOJ1O382ekZFBU1PTqPt0nSqM5x7fSDwpNRoNiYmJREREnPDlgMGWOtetW4e9rowXbxRQKHq+Hr+NhXvWNPHKyy9x3/0PBHy8U0n4Roter8eJGrPNhUn/9VN5TW09ta0Wbr99FcHBwTgcPUbRf/jDH1i+fHmvPdak40bTg+3D3XHHHbzyyiv85z//wWg0YrPZWLFiBbt27SIrK6vXJJaUlMTBgwexWq10dnYOKnwHDhzgqV/9gBRdF6E6kTfqReYsv5Lb77yH6667joiICNRqNdHR0URHR9Pa2sp7773HpZdeyrRp0zj77LPZtm0bDQ0NhISEUFxcjEaj4eKLL/ZlbxYXF/POO+9w2223cd9997F37166urrIycnxud5I1NfXkxSqxKRT0t3lxe1yo1SpSA7X4LK38e677/r2MGfOnElBQUHAk+RQ++XJyckjjtgGGyeQfcPBxpL2W0db5jCQy4rRaBy3noAw+g7uA+HxeHx7fKeCu8u4CN8f/vAHNmzYQFBQkO8CGxsb+cc//sHmzZuZOXPmhLl2+CNFbIHeOIHs8QXS3VtiIrOfBlvq3LppA5dm2FAoeicbXJ7l4e8bPgtY+E5249vW1laOHTvmS04Y7Xus0WjIW7SStwvf45p5sXi9Hmw2B3//vJImdxJPP/00RqOR/Px8zj77bNasWcPUqVNH9YRsMpn41re+RUdHB93d3URHR6PVatmxYwcGgwGn09krCUSn09HW1jZoFO5wOHjqVz/g/tkO8lN7yiZsTg+//OgN1qVnsXDRIjZs2OAzo+7o6CA+Pt7n+AJw0UUX0dTURHp6Op2dnajValavXk17e7tvHyk3N5c333wTm82GwWAY0ttSp9Oxr7aLA0fb0Qge3zJ9h0tLh7mn+e78+fNxOBzs3buX+vr6US/lSgy1zeEfsZlMpiH3xIYSUP99w4KCgmGTdIYaKzU1lfLyco4ePUp6evqQ40gMVmcs9QQcbRQ52D06mg7uA+F2u1EqlaeMu8u4CN95553HjBkzCA4ORqPR+D78pKSkYZdhTiSSe0ug4flwwjde3b0lToXmsMEhoTRa+38tGs1egkMHT84YyfEm2hQbeiaaV199lQ0bNhAbG0tXVxcGg4GHHnpoyOUpaR/O/wEmISWDteUZ/O9/y0iL1LDzUDuH7HHcctstxMXF0dHRwdatW312Yd3d3QF990JDQ3uJ2ZQpU6isrKSurg6tVuszjd6zZw+XX355vydws9nMgQMHOHToEGm6DvJTv06X12uUXDs7iJc/fouMzEzffjH01HCJoogoiqxfv97XUHf58uX861//wm6309XVRUVFBbNmzeq1t6RQKIZc2RFFkZf+/SxrXn8GrbuLX39m5555SjJTEmi1wQ/XtJA+Ywk5OTlAz707f/58vvzyy4CTK4bLkO6bWRnUp4mv/7kPNY7RaGTatGkjcogZ6pwkMS4uLsZgMIyozGGo8WJjY7Hb7ezZs6ffPmsg40kF7sN1cB8Ifxs0f3cXjUZzUsRvXIRvxowZJCcn+9z3nU4nXV1dtLa2jqlGZazo9XosFkvAwifdzOOVSTmS453s5rCXXXEVV/zrz9w2y0NmZM8XtdXi5c9FWn70h9vGdLyJjPgkvvjiC0pKSrjpppvQarW+Yu0//OEP/PrXvwYYNEKXlqBNJhPR0dHo9XoWLlxIU1MTjY2NVDzzDOfmhRIeHo4gCISFhbF06VLefvttEhISRpwMVF9fT3NzM/Hx8QMmECxbtownn3wSr9fLgQMHfH3spk2bxjXXXENtbS2NjY3o9Xr2lO5izWv/IjPMS1VjB00tbRwuCCIjpkfcvF4vwRqR9rZmn5F738nOZrOhVqt9tmYHDhxg8eLFxMTE8Mknn5CcnExdXR3BwcFERERQVVVFVFTUkEXdmzZtYvt7T/PcFXo628N4Y7eL73zShttbiyoknti0xcQn9u4bqFAoiIqKor6+PiDhG0lim0ajITc3l927dzN37twBI5mBklv6Eh4eTmJiIqWlpcyaNWvQ1w+3AjXaMofhfDVTU1PZt2/fiLvKDzdeVFQUDodj2OscaFz/LFr/Gr+T4QI1LsL3+OOP88QTT5CYmIggCHg8Ho4ePcrTTz/NrbfeGrDp6VgZrV9n30zKtrY2HA4Hzc3NE+JJeSr0yEtNTeWHP3+ClY9+j+VpoFeJfHRQ4Ibb72Lp0qUBj3uy9vi++OILFi9ejFar9dUTTZkyheLiYt59910SEhLQaDQ+gRtJhC7V4nm9XjIzMyksLMTe3oAgiITHZ2C1WsnJyRl22ctsNvOvv/yO+oodJIUqONruZeq85dx2531oNBqsVqsvKWXlypWUl5fT1taGWq3mm9/8JvPnz+fDDz+kubmZ8PBwysvL2bfuZf50XTKJkUFYrXreWtfIz98o5V/3zKO1qYHGuio2HLJzoDKMd//7GtHR0bz33nvY7XacTifJyck0NjayePFiFAoF1dXVNDU1sXr1agRB4IILLmDdunW+ST48PJyDBw9y++23Dzl5ffLu69ySr8KgBrdWzYPLI7llfii/+dJK4rJvEhISwpYtW/r9ntVqHTBBw+Vy+R5WzGazL/3eX8BHWhNrMpnIysriww8/xGazERISwtKlS32R9EjHSUxMxGKxDFlIPhJLx9GUOYzk3KZOnTpg372BGMlcnZiY2OvhaySiNZDgS/PdWForBcq4CN/3v/99fvCDH/hOvqWlhRdffNFnx3Sy1nENBsOAtmUj9aSUfn8kT0rjwakgfABXXX0NS5edx6efforL5eLOJUt6WXwFwkSXM0ifbW1tLaIo0tLS4muUqVKpiIyMJCYmhnnz5gU0vk6nQ6lUsqtwK9q2Ms6N96JSiBRXlNFR7+G8884bdowX/vkXErq288hVsSgVCpxuD/9c/yn/fT2EWQVn8cKffsn0MCuhWpFtx5xEZi3gJz/5ie9+2rFjB93d3ZxzzjkIgsDmL9Zw5/xgRFsHoteEwWDgnBmxbKqq45lPy8kPaaPBIlDapuOft07h473vsKsjCptbQWZmJuHh4ezdu5e6ujq+973vAT17o1JE6/F4SEpK4pJLLqGwsJDNmzdz7bXXct999w1rT9jV1kxMkga1SonL7QZEjBoFUyMFmm02wsPDfWUUUmTQ2NhIV1cXsbGxNDQ0+O5Vh8OBSqXyPazExsbS3t7OgQMHepkQjLSUyev18tSTj/Ppe6+zNFWk3aXl5z9U88d/vMCCBQtGZSqRlZU1ZO3bSL1/R1rmMBKh8u+7p9PphixLGOn5ZWRksHfv3hHvRw52nicryWVchE+lUuF0OnG5XDgcDl9n5nXr1nHhhReeFEWHHuE7dOgQ+/btIzExkdDQ0FF5UkpJBhPFRJRPjJSIiAhuuOGGcRtvvIRv7969FBUVERkZybJlyxBF0TchdnR0+Lwp8/LyiI2NJSsri9bW1l5p6y6Xi5aWljE90KhUKqZNm8ZXbzzF727KQadVI3q9pEbU43a38+47b3P+BReSnp7uO+7hw4dZs2YNW7ZsxtxYiaW1hgtmxbCn2kBeSigalZKbFkTzvfffo+Srz3hokZrM2J7J8+JcK099tpH1X37JsuOiWl5e3uu6OtuaSM0yIgg27HY7eoOe5NQ0spLc/GVjBwUJamanR/LT61JIitATYxJ4909FPPizP6PVanE6ncybN49169axadMmLr30UiIiImhubmbjxo3s27fP5zWZnJzMihUruPrqq0f0fk3Nn8/mg68xLTYSrUZDV1c3arWazbVK5p8VTmVlJeeeey4fffQRQUFBvlZAixYtoqGhAZPJRFhYGElJSf0SwERRJDQ0lL179/YSnJEsUQL85/XXOfjVf9lylxa14EGhgB3VNu791i2s21Iy7B6fP/6F5AaDoZ+TzWhEdCRlDiMVd6VSyaxZs3w1eYPtZ450rhaErzu419XVDdsh4mSt+g3GuAjfvn37WLNmDTqdDrfbTWVlJSUlJTz00EPAxEV827ZtY+vWrezZs8dnt1NaWkpubi4pKSmkpKSMypPyZFmWTUbGem1ms5mH7ruTPYWbOC/NyycdCn74XTWP/uK3zJ49m02bNvHHx3+CzmtFrVbxqj6c//3Zb7jhhhv43e9+h0ql8tlybd68mbPOOqufQfRoiY+NZVGqmqpjR9FqtTjsdhx2K/NjPHy27gWEukKIyObmu75NY2Mjf/rTn9CqFEQ7K7l7gRedxY1C1cQ/P+jg1vPzmDclklCjBru5jSlhwYSqjRw+0oRKpSbIZOKinGDe+3KNT/hsNhvHjh3D4/GQmJhIQvo0Sqo3siDeTXXVUVwOO0qViqJ6HekpCbx0X2+hd9qtZETpMJvNvijA6/WSkZHBpk2bWLBgAYmJidTW1tLS0sJ5552HyWTi2LFjfPTRR9x111393pOuri6Kioqoq6sjKiqKgoICIiIiuPKaG/ifu9ZgULdw3tRQqmqbeX5rC5XWOEL27aOgoICcnBzy8/Pp6uoiJCSE7Oxs35aC1+tl27Ztvig3NTWVpUuX+pbuJMEpLCz0rdiMtFPMW688w8PzRYxaBaKowOl0claymoJoF1988cWQlnQDoVKpfCLTd6lytJaEIylzGOm5SV6ju3fvHjQDdTQC5b8fqdFohowkpazOU4VxET6r1cqhQ4eIjo5Go9FgsViYN2+ez29wojYujxw5Qnh4OPfeey/Tpk3jscceY/r06axevTqg8U6GZdnpWvM4HCON+PwTiaRIzuVy8fZbb+A5upHCOwV0aiUIAh9X2HnksZ/wk189ya//7yHuneNlXqLArnoHL5RaefzRh/jHy+9x5ZVX8scnHqOx5iiGoFAuu/YWbr311jH3jtPotASHRTFvbhZWq5XSfQeJMdmJDNIxQxHKPSuS+KBwH7/7zS85UlXPlClT2Lv1U356rhaFo5M2i0i01sFdBRpe+uogczMjqGy24FYasbXVUFVlwGQy4XRaqKurRWGIwG41Az0enlu3bvUVT3/++edER0fzYrGbzvoqVk3T0Glx8/IuB6WVSrRBkRxqMJMZ+3UCitsLVZ3eXlHJvn37eOVfT4GtnW8Vfk5kYibq4Gjmz59PbW2tLyV91apVHD58uNf70dDQwLPPPktMTAwxMTHU1tayadMmLr74YiIjI7nt/u/z0bv/5bnXdmEwRJI1ZzV/v+12UlNTh90zX7NmDYcPHyY/P5+goCCqqqp44YUXuO2223zRhiQ4xcXFFBQUjDhS6+zoIC6453WC0JPw4nQ6iTV4fW2lRvvwrtPpfOn/c+fO9S1VBjJWIGUOg2EymZg2bRolJSXMnTu33/d/tJGZVOBeVFQ0ZIH7pIz4CgoKePrpp3v929q1a/nOd77D22+/PWEX3Xdpbqxd2OWIb/zoK3xer7dX93aLxYLdbvdZskm1VdKk+PD9d/LvlT3p+BIXTVXz52IbP/juAzx1gZcrpvf8bFmaSH6cyHc/b+Uff/kju7Zv5Ju5DhYt1lHR1MVv/v17/vvyMwheN7Fxcdxy14Ncetnlo35Ay8+fzS9fUDDtaAevbqqmttWCXqWivaubb63OxmJ3sfNgC0fNNtq6HSgUClSWepzNNhJDFURHq2jrtmLrauNIVQcvvLOWDU0RJOVdyK4t7/ON8xLQaXomSZMpiJfX7iN5yeW43W7+/ve/s3LlSrxer6/Ye926dXQ4BD6v1vOPwm7iTHDxdAP3nK3jt1+2ce/zZbx4Tz6xoTq6bS5eK7Hj0Uf5Hrbq6+t57ekneHh2F+flRGM0mXhr5z5+s2kvN910E9nZ2bjdbrRaLW63m3feeQfoWW5zOBy88cYbxMfHk5ycjMvlIi4uDo1Gw5o1a3jggQc455xzWLFiBYIg4HA4qKioGFE3gba2NkpLS1m1apVvop4yZYqv7ML/vtfr9b7SgsjIyBH5cc5deA4fVvyHh6J6xEkQwCuo+OSgjadnz/Z1Mxkt0lLl7t27mT17dsAm9IGUOQxFeHg4qampPncX//MJZK7WarXDusUMNe7J8O4cF+GTkgfsdrvPU3L9+vW+otCTZUo61i7sp5JJdU1NDf/821Ns3bgOvV7P6qtv5rbb7xizK8OJNo6WHGvsdjv19fXU1tb6PhMpkSgkJIT4+Hh0Ot2g59LZ1U18cP8JI9bgYXdVF2cni1gcXnRqAYUAS9MEFHjZtO4znrhAyeoZPZFOqslOqsbMnWssbP5uOgdb2vnxn/4Ph93GtdffOKpri46OJjlvGf/z6lusWr6I3BAdDq+S2sY23t9ZjtnuwRCZyKKcDLbuOoDBYKC5o5v0MCUhJg2iqELhtmJ3iRxp9bD+gBm76KRwy5ckJufxs7eKWZGlIS4ylAPNbr5sCOGO2ASef/55Kisrfa75UuJHfdUhzE1HaNSruP8sJTfPC8Gg7bnFf7DMwENfKPn2O51EmzoxuxTMW3o1P7qlgNdee42EhASKt2/m4uQO5qX07H0LAlw2K5R1+6vZtm0by5YtQ6lU4nQ6qampAaC4uNgnnEePHuXKK69Er9ejVqsRBIH4+Hhft/lAOzDU19cTERHRLzpJTk7m008/BXrPMeHh4cTHx1NdXT2iCOmu+x7iuks/Ril0c8l0DU1mL7/fKpK3cDkOh6NfKv5oiI2NxWKxUFFRwfTp0wPuvuLvEjOWbg4ScXFx2Gy2fkuogQYpkluMVOPXN4IfrIzjZGnDuAjf7t27WbJkCUlJSb4EjezsbJ544gng5GV1mkwmmpqaAv79UyXiq6+v54YrLuL6zE5eulBNu62dp954nF2FW/nLP58fc7+s8YrG+/pS+jvWOJ1OX72jXq8f8jthsVh4879vsOmLD9BotKy89DrmzpvHu+Ub+Obcr2+oLrvIFwdsiB4noggut4cuOwRpFeg1AhaniMVj5aJpPXt5oujFbO6iIEFBepjI9kNtzE7U8Nh5Su5/+imuvPraUS992l1ull90KanZ2VRXHiYzWsPMzEQ+snfz7vYDrFi+gja7yPTp09mxYwcajY7PDju4IseD1WJBpxLZXisQYVTy0i3xtJud3PBSBY3GCFLTz+M/R/fTVtiEKSqJzPy5fPbZZyiVSqKjo1EqldTX16PX66mqKOGCuBbSEgTeLndzdpLAwboupiWGolEr8HoFlk4NJ+OK/yE/P5/g4GDfk7nkwl+6bR2LsiMIC+v5d7PZTHtrK1OMZl7497PodDrS0tJobGxky5YtXHLJJcycORO1Wu3z8DQajf3ew4EerkaaeAKDr9x0d3cPmqSRnJxMTU0NLS0tw2acpqam8uo7H/OPP/+O6z7YQFBQMFfcege33HobVVVVNDY2jqlhbHp6OmVlZRw7dixg4YPeS7mBWof5k5aW1q/10Fjmg9DQUF/LpoKCgl7jjDRbdKIYt+4MLS0tE956aDgmS8T3/DNPc0VaJw8v+XoJ4fl4kWX/3uTbzwj0eH333Q4ePMi//vI7tm/dhF6vZ0b+AlZccBELFiwgJCQE6PkSS+J29OhRjh07RkREBNHR0b2an37wzpts2/gZKqWK3LPO4ZbbvjGsi4/VauXOW64lxXOAe3OU2Fwiz/+1GDG2gN/u0OP02LgwS0lVh5efbgCNWklBnJbPDjm4MReCRGiyeHlrn4AdPUFBJrodXkL1StxuD0oBED20WcDrsNDVZSdUELB0WGhpaRl0GamlpYUv162ls72VqTNymT9/PiqVipaWFmbPnk18QgJ6vZ7Gqv2olQ4MwSHsreogrdVNfFIoTqcTAJMWvjgMmyotJBmdVHcJRBqVpEf23IpGjcC5qSIbBDXnn38+gnABHo+H9957j127drFkyRIWL17Miy++iNvtJjMzk02bNpEg1HF+tpajdWHUdDbx2h4FOVFegow2QvRqPEodHV494eHhvRxrpEgsJyeHrJmzKa17l1nxapqbm+luaSFCpaSuTcMCD7z31FPYoqMxGI0kJyfz/vvvY7FYfIbcGRkZVFRU+NxXoGcvciBLsNGsNKSmpqJSqTh48KCvN6LL5aKkpITFixcP+nsRERG0tLTQ3Nw8bJue9PR0fvuHv/b797S0NOrq6sZkxiEIAjk5OezcuXPM2z5SmYMkLmOJmKQlVP/MzLGeX3R09KAF7qdCOyKJcRE+QRB6iZ4oiiethMEfyeg3UCb6gxqsDdLOzV/ym3m9PyqVUuCCNCeFhYVjEj7/41VVVXH/7ddyT56Fy5Yq+P57hzm0/iC1W1/jx5ZgLr/+Ns5bcb6v/9e///pXjpSUkKLTUel0svjii3n40Uex2Ww8eNctLI+u4+kLjDhcIs/veJ0ffW8Xz7z85pAPSO+89RZJ7oM8dcnXfbuWZIhc9koJP/jZb9j4xcc8/c42wiMi0CWH8f38Ms5J03Hzy43sqPOQHyuypRo+PKLi6Rdf44uP3+cvW97n/5b1ZPO6PV7e3SeiVCmZnRqCKHqpb7PS0mmjtrZ2wMlt3bp1PPZ/3yFCZSZEJ/DFf7T8J7OAX//+b0RGRlJfX09mZiZh4eEoVTNobqhl294q4pMzcHkFUlJSEEURlUrFZ28f4pqsFlJT0ynavYfbM1zsbVGQHtvz9O5wOjC71Qhapa/LgdvtJigoCJVKxfTp033WURs2bGDBggV0d7SSazCz7YCHj/dZWZamIEzrpbgO3q0w8+1lUVh1sdQ6w0hPT6eurs5X+O1vsXfxJVfys4c/JTvKQbqmA5Og4O39brbWqHl20TyK9u3jaZud/3vsMdRqNTabjTVr1hAREcHy5ctZtWoVzz77LG1tbURHR9Pe3k5zczO33HLLmLIRBUHgxhtv5NVXX+Xw4cMYDAZaW1spKChg7ty5gyZNiaJIRkYGBw4c8C2rQ49odnR0EBYWNmyELwgCERERtLa20traGnBrLmmpcsOGDdhstjE13pV6nO7evXvMc5R/ZqZWq8Xj8YzZnCMpKWnUBe4TzQnpDSEIQi/Rm6gGpH0Za8Q30QwW8QWHhtHQfQzoLRj1VjW5Y2j5JCWcSPtw//zbU1wzpYulGVpWP13Hny4UWZQs0GRx0y14uPXdF1iy9DwWLlzIjx9+mLjyffwsNR2NQoHV4+GJjz/h6ZAQQiLCKQhu4IGzQ2nsdhMdpuKnK4P41juH2LBhA8uXLx/0nLau/5ibp/VuKqpRCazOcFJz7Ch/fvo5378//MCdRCvLyYpW89k98bxdauFwiwvUbi5cfQlLly4lLy+Pu28r56rXK1kU52DjAYE9jQIv3hiOSq3C7hL5a4kGtVHPtm3byM/Pp6GhAZ1OR3h4OO+/+y4//p87MXjdaJxKpii0iCorWw59wh8Tfsvc+Yt44403iImJYcqUKRiNRsqa2+jqtvDoo4/y3nvvsXbtWpKTk2lvb6fTY+CdumRWmJQo9KH8tbCRqGANP7uoZw/ySIubL44IfOvHV6PT6Whvb0etVpOYmEhTUxMOR4+R84oVK2hra6O4uJi9FQeJjXFS3+nip+cqSQ7S0W4XaGi38v4Bgf9bKxIap+Oa22+jpaXFF4GlpaX1ewj5v8f/xq8e/R+aj9agBGKMCs6KV/P9nV9yuS6KcHVPu6SwsDD0ej2LFy/m008/Zfny5URERPDAAw9QWlpKQ0MD06ZN4/rrrx9wOXK0c0JkZCQPPPAAVVVVWK1W4uLifPtckjH8pk2bsNls5OfnExsbiyiKaDQaZs6c6Usw+euf/sBLz/8ThceJQqPnznsf4q577hv2XDIzM30epYF6D0sOQeXl5YPao42UmJgYurq6qKmpGfP86l9+ERoaOqT13EjJzMxkz549w3a/OK33+CT8PwD/v5+sixtrVudEM5jwXXHDHfzpt99hUaqXIF3POnlJrYv1VUr+98ILR3UMyVhb2oOTmpnqdDr27drBHYu1fLrfybmpsDil51h6lReDDu6f6+HNV54jOzubnV9+yQtJKWiOr9sblEruj43jnjfeIDt/KtouM6mP1gAiNhfcNDeYc5L07C7aPqDwWa1WPv3kEyrK91A/owNbkgKdXofb5cZut9NqdiEoeq8gzDt7Be+/sIHVM0RC9ApuPysIr1fk+tetLF98LtCT6PDaOx+xceNGKioqqNj3DAmZRh78uJrMCBf7mz2kZM9m5uwgCgsLWf/RW9i7mui2ukhMn0rtkXKWJXkIqtPxSEwQHlGgwQx7cPPTZ59l+fkX8cgjj/Dcc8+xceNGvF4vJpOJs88+m9DQUG644QYqKiqoqalBp9ORl5fHz372M7Zs3kRNVSVHDr6AubuBZ7Zb6bKLrD/ihcgpJCQkoFariY2Nxe12s337ds455xz27t1Leno6Go2GhQsXcuzYMSwWCyW1bmbqa0kOElAoFEQEqWmzK7hyURy7vtLx/BtrhoxuHA4HH3/0EVvWfoDTZiM5RMHfl4cQF9QjjJuqbDy5oQ5XWFKvRI+IiAja29t9/6/X6znrrLOG/R4GMlkLQk/03JeSkhJ+/v1vkxlkJVQHf6jxcsl132T+4iXs2rWLrq4uvF4vD9xzF5b9a/nkOgXJYWoONtu5/7lfI4oid983eNcR/+VgydMz0G0dQRDIzMz0lROMZd8rISGBurq6cSlzkL6bO3bsGFPDaQlBEHzJLifC3nGsjJvwbdmyhezsbN+b5u/A/emnnwZcSzcWjEbjgJZlpyqDCd/q1aspLS7k7OdeYXm6QLtDwY5aFY8/9XQ/ZwgJ/304f2NttVrtKxfQ6/VkZGT4am/iE1Oo7Wql2ewhLVQEej5Dt1dAq1CQHqHkv/vqaG5uJlqtQd9nKTtCo0HpdnP4WC0N+9v54iaRGdFQ1w33fNhFUbWDa+f0LnLt6uri0KFD/P33j5GhPMYV0+DVXU4WxTeg0agRPS667CKvF4Ox6kXOWrCQBQsW+N6Xt155ju9+eJCbZ6lwebw8vdVKRUcwS1wu7Ha7z1ps6dKlLF26lK1btzJlyhTi4+Npb29ncWQkYWFh/OlPf8LVcoTvzBd5p9BMe5OX/bXNdHm8dKhF3o3vWXpVCRCsFZnt1RDhtnL48GFuuOEGHn/8cdra2nzL1Y8//rjPfmvmzJnMnDmT0tJSX6Ry0cWrALji6ut4+41X2L7pSwxhwXz7sZtobGrinXfe8e1nHTp0iPT0dM455xwAXnjhBRISEnx7KVqtFmN0Gs31VVR2qNDp1Ng9SpLSM1HogtDrLb1E79ChQ3z+0bs011WRPGUG5628iD/99ueEduzixmla5plr2FEt8rvCbn67NAyFILAwUYtS147meE9BicrKShISEnjp38+yY8MneL1e5py9kiuvub5XTVdraysvPfdPtqz/FKVSwVnnnM/ic4e3dRsOs9nMTx6+l9+c52Zeak9k2WnzcNebT7NtZwlnn322L1pe++kHbPuWhsTjyTtTolT87WI3l/3tj3zjrrsHFTMpEUcqTygtLWX27NkBPdCLokhUVNSouyYMdl4hISG0tbWNS5mDyWQiNDSUQ4cOERkZOeZmsf7LqKeKI5XEuAnfnXfeybZt23z/X1ZWRk5ODm63mwcffPCkCJ/JZBqXiG+ilmoHEz5BEHj0p7/gptu+wdatWzEajfxq6VKCgoJ8vqP+Ame321EoFD6BG8xYu6Ojo9cT52XX385fflHErblqXt8ucP9ZIk43OL0CoTod6w7bmTF7PomJiTR6PbQ6nUT4jXnYYkEVFET5/v2suaJH9ADig+Dly0Xifm/n8YKeXm1er5d/P/MP1n/4BrbOVlLUDdyxPJz4hBQ6zE5ufLuJFak2NColaw4K3LPQxMy4bh556E7e/OQr31LbMy//l5deeJ7vvPUq1ceOMD1Ox32zXex6+zd8+ObL/PW5V3slNlx++eW8+eabhIaG+pI8ioqKaK0/xn2znPz5cxt3aIJYFadD9Iq8327nF+1ddHlEoo7fLUqFgNPpJdJgwOFw+Aql/Z+UFy5cyKeffsqsWbMIDg7m6NGjHD58mG9/+9tAj+tKVVUVGo2GO+/5Nnfd+yDQ812zWq2kp6dTVFSEzWajoKCApKQkzGYzF110EWeffTZVVVXodDq++93votPpqKmp4Rff+xa6eCUxwWqMBgMKpYLXtzdRsPAC33lt3bKFl/74Iy6bKrIsXseeA2Xc88rz5EbY+cVVCT1dKboErsvVcfc7Vl7e38zsWAUIatCrEPQ9y68hISEcPXqUTZs2IdraSGhey6PzQ1Ao4MPSl/hx4WZ+/cen0ev1dHV18eBdN7M0opanLwrC7RV5ufBl/rBlA8+//u6gEcH+/fv5z4vPcGjfbqJiE7jk2ttYsmRJr9ds2LCBOdE25qWE+P4tRK/k5ukO/rj3IHPn/o+v7jAtUk+Iyo7Ho/FtxWREqFB6HUMmr/hnYsbGxmI2m9m/f38vX9DRIAgCycnJmM3mXhmVo0XKo8jJyRm3Mge1Wk1cXBy7d+8mPz9/zJmYKpWKnJwctm7dOmAW7mm/1CltkEuce+65tLa2YjAYCAoK6mU+O1GMxx6ftA82UcI32JORKIrExsayYsUKLBaLb68DepaXTCYTQUFBxMXFDVkP1/d4/kK7bNkyDh+4nyee/yvmdhUPfOjiGwUKEmPCea7QxpuHTLz25DcxmUxcfsst/OrfL/DtqGhS9Hr2W8z8oaWFq7/zEP/znW8zu08GeZAWcuL1vnN+843XqNn0Ms9eHckPX6/hzplqtO4u6mur+PkVaVxVZ6bebCY1SssT53uYGmlDKUCOvpN77rydH//8MXQ6HUlJSdx97/18vuZNXrw5jrwYL+2traxI6ODF0hZ+9L/f4R/Pvew7j9WrV3Po0CE2bdpEZGQkXV1dWK1WEmLCae2qZI5Cy+XBx135FSLLjDr2Odw82dTNXxLDEIBuh0idW6BepyczMxNRFKmrq6OtrY3w8HDi4uK49NJLiY+PZ/PmzXR3d5OZmclDDz1EdHQ0G9d/yedvPU+C0Umn1UmXIoLll97ge5DR6/XExcVx3XXX+TJkGxsbsVgs1NbW0tzcTEJCAnl5eb4JPCsri1vu+z6/ePoxrpjmJi7UTWGVg8KOSH76nTsQRRGPx8OLf/stj55n8LUpyksOZkNpEfPCXQhCj/2XTm+gtauDC6cIHOtWkRmrYk+jl3pnEHdffDGvvfYaVVVVAAQHB5OjreaBy9JRHP/O3XOunsc+Ocr6L7/kwosu4sM1H5BnrOeBc79+MHjkvDAeeLuK9evXs3Llyn7fzd27d/OLh+/kG7lu7l1m4GjLHv7++EMcO/oACUkpVFdXExkZSW1tLXHG/vdMqM4DXrfvPoiKiqK+24vZpUDtdiEoBBSCgvouD3avctCVE+jvtiIlloyk28FQTJ06leLiYhoaGgKK1qQMzPEsc/B4PL5z2bdvH9OnTx/z3KdUKgkJCfFFygMVuE804yZ8KpWKPXv2kJKSQk1NDcHBwfz3v/8lPDyckJAQX9+liWQ8Ij5JjCaiBkUSIv8Gt9J/pSJaqVwgIiJiVL6jgx3PPyNOEATuuuc+rrzmOjZv3synH77H7Wu3YXc4WHzOMp577Yc+e6hv3nsvppAQHn3mWbrqaoiKieHGH/+Ii1et4ic/+j7lzV1M98sgt7ngUKuX5ORkRFHkk7de5snzQwnWq1CrFDg9EBespqKpE7fLhUYJt+QriTK6SI9Qo1b23HxTI51UHNjGa7/4BXkZGXyu05FcUECwt4PpYU5aG5sIUbvR6gVuzxFZ8Oz7/O7JJ/nuww8DPd/Thx9+mEOHDnHw4EGCgoKYM2cOd992A3sPHmaF8uubUiEIONwwU6thTbeN59qszFCoOeSC97Q67nnkERQKBX978kn2b91GqFKBLjiY5LPO4upbb2XevHnMmzev17Lzxx9/zFf/+SN3LgwlIliHSmVkf10Xb733Mj987M+DTlqNjY089dRThIeHExERwRdffIFWq+WHP/yh7yl/dsEcjl14M+/t2IypS0VOwSLyLd386n/vweV0EJGQicHVQkZMIm6Pl80H2qmo7cLu9tLebfE9BClVGho7oNEsYnYq2FSt4OVSBVGhBvR6PcHBwXzjG98gLS2N/7z0LDM8e2lsaOhVL7coRc1Xu7Zx4UUXsadoM5em9V4WFwSBJckie0p2DCh8z/7lSb67QOS8qT2ClByuJSPCysVP/pxLbvwWKSkpVFZWUlRUhOWolweXiCiVX0/QmyvdJKR/nVEYEhLCgsXn8sMvPuP3qxQo3G7MLiX/86mX6266Y8i5qa/1mb8vqMFgIDw8sAbN/kuBer3eVy40UvwF2b/MYSx7kJKYpqens3fv3mGTU0Y6plar9XWuGKrbxEQxbsJ33333cd999zF37lwqKir48Y9/zGuvvUZ3dzf333//mIstA0Gr1fqy4AJlsBKD8UCaEP37ipnNZsrKynwCFxcXN2BR8HgwWFf0iIgILrnkEi655JJBf1ehUHDDzTdz/U03+fYOpUnmnnsf4Juv/IG3LrMSFwTdDnjgMzVZWdk0NzX1FDxbuogP7VkLXTItijdKu5iTIKJVCThdLrLigvjwgJkHF6h8omd3efnyqJc7ZxvZ1tzA6vSVNHR28s9330UleOloayHW4EGvEtjTJPLZcSvJV59+khUrV5Kbm+u77ilTpvj20ADOu+gyfvejTUQrnVyJAZGeyM4jKjiAEn1MFK8joFVqmTYvjx/edRezZs3i7jtuQ6wqZVWWHoUA246BtbGelxwO0qZP59ChQ0BPRDZlyhQO7S3i2nlRTM34upZuflgoZc017Nmzh4KCAjZs2ODLUJw1axYrV67khRdeYPr06b79TYCNGzfywgsv8OCDD7Jx40aee+45UlJSiE/J5OjRo7z39n+5fKqH314cg1Ebxlvb9vHysWM0t4fw07cPofeamZ8oEqn08EapkysWdxIVFozH5SAi2MB7B53ERBgQWk1855I4ymosvPHGG6xatcq3PBcVm4C7KZjWtjaioqJQqVQ4HA4O1bRwVKzl8OHDhEXE0NDcPyqrN0NIeP/6OpfLxf7yUs5d0jvJQuXuZnqshpSUFLKzs4GeBI+//qGchz/o4FvzDYQZlHxSbubtI8Gcf0V2r9+/+sbb+MNva1nw7BGSQpUcaXZw1fU3873vPzro9xwGLrb373YwlihLrVaTl5dHSUnJoMbRQ52Xf/a8VOYwVDeH4ZCET+q+UFxcjE6nG9YEYCRjhoaGkpGR4btW6Tgng3GbTW+77TbmzJlDYWEhDzzwAKmpqVx55ZU4HI5hi0dPFOMRpY1HEftQ/f/8G9wmJyf70q5PJHv27OGNl5/jQPluUjOnceud9zFt2rSAxhIEwbdH4/F4eOu/b7C36CtanHqm/NVBaoSW6nYX05MSeWjF2bi+XM+XHjcqnZEDDVay44xcPCuKwiPt3Pl+G9PCPRgauilsMVJdH0aorpNrZnppt4v8Y4ebKRE6pkdr2VTfY5MVGxLCwrAwfrXdybEOD4kmkQfWCHy6T8FStZ4Foocvmm38/reP8e+XXx/0Oi659FI2vvcuazZuJEu0crZWh0appEz08oVWy3/XfOTrSej1ennj1Rd54U+/wHygiP9dpCbG6CEhOJQL0gR+9dUx1r//Pp1OJ9nZ2QiCwIEDB3C5XDgtncQl9U+HjzV66ezs5F//+hfHjh3zLQlVVFTwwx/+kLa2tn6R0VlnncXzzz9PfX09zz77LFdeeaVvn3HKlCm8+K+/oLaZcVi0BOsjuXZRMv/dfIifvLGHaWEuHlykocMm4vW4Odap5fK/HeS2cxJpbHSzvcrDLUszuGnx10t5Xxyw09HR0SsCmFUwj9f/+ik54Qpsdjs2q5WKA4d5p8jN2TPL+MMPvkH0tEW8tkfg3CwXsSE9T/qHm+18eFjF339xcb/3QqlUotFoabe6iTQdN3c+vvdp8eh7LZUlJycze/4SImKieWTjJ1gtFuYuWsU/Xrqd119/ne3btxMXF0d3dzeNjY3849kXMZlM1NbW+upRh3uoHMxtRafTMWPGDF+mZ6APpwaDwdfiZzTjDLQSNZJuDsONKYlpX5u0oZaDh8LfDD46Ohq73U5ZWRl5eXkBjTcejGsYkZOT43NtEEXRl9V1sur4JMZy/NHYlklmvf4CJ2WVjqT/H5z4zd4N69fz5I+/zZ2zPNw0V0FZQx3fu+srfvibv7Nw4cIxjf23p56ktegtfnlOCAmXzGDdvnYeX9vJpWcv5BtnzcPtchMRGUm2w0H50VSeWFfKI+dBVqyR+1ak8qP3NezQTGHZWRfx++8vo66ujkfuvoGNtXaCdCrOTgvmhqlantrmZE76DN9x1aJI/oJl3LvmNRYnQel+Fe+HRqBCgUKA/XoXt3z6BU1NTURHR+N0Onn5xX/z0Vuv0NnZSUxCEvOXnM9ld3yDiNBwXv1qI891d/cYMRh0LFp+Nju2b/N1itjw5Voc+z7krCg74XqBpWlaqrscNNosZEbGcMEUJ7/b0ciiRYt8QpSRkcGGDRvQhcRQUVNDUuTX++GiKLKvRcEMQaC8vJzrrrsOpVKJKIqkpiRTtGML9bW1HNpXRnxKOjExPXswUl+6bdu2kZqa6jtWS0sL+/btw6gR+NsX1by2uZr0KD33XzGP+y7K4f5/buauqzU8t8PKf3Y7KYiHGVFaDre6eeVgOMagFEIij7F69tdR6Z4aMyUtBlJTU+ns7PRNgrGxsSxcfTPffe4pVh5robm+irpukVUzQ7lgpoAhSMuvvtxE/nlXc8t/32Z2nA2PF4rq4bo7vzvgHplCoeC8iy7n6c3/4fvLw7BYehK2PttnxalLISkpqdfrlUol115/A//7gx/2+vcLL7wQjUZDc3MzaWlprFq1yrecGBUVhSiK7N27l2PHjg3ZaHkom7HQ0FBSUlIoLS0lPz8/4Ps3LCxs1OMMZhIylm4OfedK/+4LeXl5AdX49XWDSU5O9pmU+7v8TCQnpIAdek/gJ0v0xuO4g0V8LperX7mAtJYtZVOGh4djNBpPGY86r9fLn3/7U544X8nsJBNOp5OcBD1ZMU5+9fiPWfDe5wG/Z42NjWxf+x6v3BjV0zYIuDA3Aqe5kw/2H0KhWIBIT5Rm1Gq5IGMK+woKeGzTp3S3NaHWGVl+1UNce8NNvqfDlJQUrv/GA+z78nWuzlGicNv4+foOWlwJ3LFyFs3d3fzmw7cprNxPWFgQ7Q4l75V5+EVQEBpBgfb4vTZVo+Y8jZb33nuPO++8k58/+gji4S944mwlgq2JndU1/PXv28makklM9jy+94c/8M4brxDpPMoVsyPRarrZse0F3t0zgwe+92P+++wfeWRlJh9uP4LRrUAEkkPUlNSbcbgjUHgdKPRBvTLslEolycnJdHd3s27bHoJ0jcyZEoXF7uaTXY0oYmbidrtJTk72TRJVx45iaTjMpQun8o9XDxAmdNBecxBEiImN5dChQ8THx6NQKHx7Jm63myNHjrCvZCszNFU8coGS2Ul61h2w8LOXtnD10lyCQ8JoEI2s2V/DC1fpiAtR4XK5WJ7i5eENB5g24woO7jdz7TNVnDs1lG6nyBGziYd+/GuOHTvGpk2buPDCC1GpVMd73qlZsvomKutq0ata+P1NKUSHGHA4HXS2t7A8WcNur51/v/05O3fuRKlUckd6+pArKXfe+20eebCc5b//nPnxLmq7YFeDiDKogfr6et9ec1VVla/Avy9qtZr8/PxBIyhpOa+wsJCgoKBB69eG89eMj4/HbDZz4MAB3xLsYOMMdX/Fx8djsViGHUdisNyDsXZz6HuOOp2O3NxcSktLKSgoGHWuxkA2aFKBe319fb8HmYnghAnfqcRYIj5BEDCbzT3LLMcFzul0olKpfAIXExNDRkbGCdmHG09qamoQrW3MTup5ahMARJF5KXqsnzfS0CdBYTQcPHiQ3FiFT/Qk8hN1/HVTfb+2REpg3lnz+eadd2G1Wn31dn2554HvsG3uAr78+F26bR2YYx1cFZeAx+vlwVeeZXlyE7/+poHiZgU/XeOlG4hVK1ApwOEGjarH+SUKaG5u5uDBg1QUruPNG0001x4jOkRkaoQGtdLF9tZWglt2ULornKkhVn64ap5vYpk3XeQf6w6zs7AQl62LqOBEZqRG88FnGpamujCqVGhV0Ga18NFROxmzVw54PWFhYdzxPz/nk3df5/lXNmOx2olJm8HlF15Ad3c3drsd6JksmmormZ1ooKq2m5x4HWu/3EBe/mwa2iwcqwqnrKzMV87w/vvvs2jRIrq7u2lrayPYWc+V+aAXRWpaLSQY3cyJdPD4exXMPed8Xiv+nBtyVcSHqvF4PNicPcuKN8w2ckQl8PAjP+S1114j5txlTA0LY54gUF1dTXx8POnp6bz66qtER0fT2dlJSEgI9913H9958H6WZ0cQHdqzlKvV6ggLU+CqrcehtBAaGuozL2hubsZsNg/6fTIajcTGxZOQHUFuvIblBgW/iXSzpqSZ3/3y/7j5rgdpbW3l8OHDnH/++dTU1PSL2kZihC0t5+3cuXPQvbqRzB9Tpkxh165dQ3YjH4lBdWZm5ogzRoeyhRzvbg5BQUG9klNGY0c5kPBJBe4nK8nl1J6pxwGNRoPL5Rr2KUUUxX71cDabzddVICIigrCwMJKSknxLTKcber0em8uL2yOiOp4wIgJOt4jDI44p6zYsLIyaTrHfJNHmVvt9uXuEz+V2U+XxsDwxEUEQfLVeWq22X6qzIAgsWLDAl9TR2dnJtvXr+f7LL+N2N3D7fAOmoCAef6WGZy5R8EqJm4/22Zin06AQwOUBQQUfOexcLwi89957FES7cNgsqAU3ClHE5fSyMFHBi3u6+cuqGXznnS+4f2lMv0y+s1KNbNlbjCkijsomMwUZEXwYFMUze9qZG+3itd029rTUYxWMhKoO8PGHH5AxJdtX8lBdXc2KFStITk4m76wldDp6nEiMRiNFRUV4PB5qampobGzEZDKhU4ogeikq3cuNixII0qlYt38f63d3cMFl1/HjH/+Y1NRURFFk7ty5vP3226Snp/c0bDV14faIdDpcpASLxIYLeLzweY2TkOBgilqVXJ7mpdvuwWp30mSB0MhoYswi5ZZujEYjmZmZfPjhhzQeqyBKaCcnRsHHzhBUsTN48Lv/h9lsJiQkhLS0NFpbW4lLSGbTkUoumS2iVPR8B1QqNRuOuCi4cV6vz3W4psR2u50dm9byzk2RiC4rra1teFwaLsgJ5tniZt566y2uvPJKrrnmGuLi4ti3bx8mk6lXF/CRPvBqtVpfRuS8efMCap/TN9NzIKEZifD5j6PX64d0URnOV3O8uzlERkZit9sHNKAeisGMrxUKxUlbDZv0wqfX67FYLL5JXfL18xc4q9Xqq5+SsiljYmLQ6/UcO3YMg8FAdHT0hJ3zidoTjYqKIn3aLF4vKuGmeSE9HTeBV4vMTMubG3BaNvS0thFDU3l/11EumRWBIAhYHR5e3uUh66xlvLRtGxVHyum2m1EZQzj/xjuIiIigYt8+Cj/5BEV3N3YgMTeXc84/f9BaH51Ox7btX1Ffu5ez413gNLO1vJtgtYfcWAUhZ8HKciu/7ILL9AbqnV5e6LbgNai58sorqaur473NL+N0WMHrQqPoySyrbHPjdXpx2MyIHg82d/+J2eZ0ozUYWXnZjbzwym+5bQHctTKbdfs6eODtYhYlqfjVqnDcdgufHSjh85fLqMlI5iNTOtNnLyQ9PZ309HS6urrYsGED5513nu8609LS2LJlC/Pnz+fTTz8lIiKCmqMHKLY3cm6WkXmZEYiiSHpCBLVuM9/+9rd9DxSCIPCtb32LzZs38/nnn1NeXk5MgpogoxKd1sWBLhGvx4XTq2FBdgzd9XtYdf032bz5GfJTvThcSoLCgwgKCmbjsU4SF2fhcDh6OhvUHOaG6W5umpeEw2Gnu7ubtdXlvPHSs/zfzx/3vTd6vZ7Q0FA6kwr45ac7WT1dh0Yp8MV+C2Xdkfzwggt6vZd9v+PSPSn9aW1txWGzgFtFa2sboaGhaDRqQCA5Xk38rFlER0eTmpqK1+tl5syZvqU9aYIfzX0UEhJCamrqmPbq/IVmoHq1kbYk8s8YHcobdCTjjVeZg0RiYiI2m42KiooRJ8RJzYtPJSa18HV0dADwl7/8hcrKSq688kqioqJ8+3BGo5Gk4xZMg4XuJ6M10YlMBvr+Tx/noW/dyuaaZqaH2djVrKZRSOCpfz42pnEFQeAHP3+CX//4e3zwxlESgpWUNXpYdP61pE+ZzgtP/i83TLMzLT6Iwx3dvPKfv6MzmTDv2sXy+AQiomNwezwU7y3nk+5uLr/55gGP85/XXkFbs4EfLA/h+bVNhOsFogxeuh0ePB4I0yt4+Rovb5fb+eEBGzXdcFa2iQhnCN+4/jK62s2Yu8xsLhS5eBp8Z7GXZrOHJzaDUoBv/mMn2YsvY3NVF2dPdRJi7HmitjncrD3oZNXdS5gxYwai+D3+9d4r1FdW0eVUclZGGH+9MYmaY0eIjVOzOFnk+584iDVa6bDs5uihCO6++24EQeDIkSNERUX1mxinTJnCgQMH+O1vf8vu3bv58D0L8bYOrlmYjNflwGJ38XpRGwtW3NBvAhMEgcWLF7N48WIWLFjAr37wbf71VRN1nR5mRIHVLfJlpYJvXRyKoBYInp7D2yUz+OBYNcszBCpbO1hb3EGDMpmVM2fS3NzMsWPHUDo6uKYgGkEQ0On0OB1OVk1Tc8+HX/mWOaFnaXLatGl0xMXh9eTzetEm3C4nmCK4475lvkQ3r9eLxWKhvb0di8VCR0cHTqcTtVqNyWTCZDKRlJREdnY22TPy2XJ0DzMjNb7I5kiLgxaHjuuXLGHLli0+RygpauubYTma+yg+Pp7u7m4OHTrUq9RlJEgipNfrff0N+2ZojqYXn06n85lrDyZYI20hNNIyh5H2SMzMzKSsrIzKysohk4JGcp6nfTnDqcKTTz7JunXrqK2tJTQ0lMbGRtxuN9dddx3z58/v5R84Ek5WM9oTtQSQmJjIK29/xPr16ykvL2dBTAxXXXXVuBjJxsfH86d/vUxFRQUdHR18IzOTsLAwvnHtxfxmdRhJoUoMBgMzgZRoMz/4y294fNV1RBzPFFMplcxLTeXtQwepra31+RBWVFTQ2dlJcHAwH7/1Er86V4dRq6K8USD/D05SwwS6HfBmuZcFyUoSIg3cM9+OSQ8v7NFS0QrfXgIvftnKN1U6FkdH0ubw8Fa5hXP22ogKgcunK7hlloJt1SJPHy5l8e0P8atP32NunAeVAgrrFMxcejXTp08HYMHCRcxfsJDPPvuMl//9LFq3l+LKDhKVHvD2+JxeMFXDuiY1t1+Qy48/qOCrr75i2bJlwMBLfdIDj9FoZOHChRQUFPD6i8/y/XfXEqxy0miBhedfxapLrxzyc7jgggtoanqU53/9II8vE0kIUWDzKLk8V8efdx4lOS2TVXFxPPGX53jt5X/zoy8/pq7OTmhcOhetvpS6ujq2bduGRqMhPFiHVvX1d1GlViPgwaBSYrVaexVdX3zxxbz11ltUV1eTNWsBra2txMfHk5eXx969e2lvb0ehUBAaGorX68VoNPoMtwfizge/zw/vv4XLUm0snKLjULOLf++Gi6+7F41G0++BNCQkhJSUFPbs2RNwqnxWVtao3FS2b9/O+vXr6ejoICIigqVLl1JQUEBycjJlZWW9lgRHe18HBwf3auza93dHM95IyhxGOp7UX7CoqAidTjfs+zTWHn8ngkknfMuWLeP6668nPj4eQRC47bbbuOyyywKujVMqlb4mohPBRAitVqvl/PPPJz8/H6vVOq7u6VJGmcTRo0cximYyooNoamqkuvIwDocDg1aHudWDSqnE5XLhcDhwOBw4nU7czS1s2bKF8PBw9q77klSFgmithjpRxNLdhUIVxlVP7eE8r45ztMG0dnr4h7mb+973cMXcEPLjBDbXGDhsC+XcC+cx17OFji4HS9ByR0QwoijS0OXiu7owqto8XDlL5KIsBR6FimmJai7TCOwp282Sy+/E7XajUCj45syZJCQk9LrWzz77lF/94EEWxVmIUll49K02pkYp+OVyFQa9jnarE6NOg06tJCQ4iNLSUs455xwyMjL49NNPsVgsvZaxDh48yIwZX5dpaLVabr3zXjqvuZH9+/cTHBxMWFgYW7ZsITQ0lJycnEEnqq7Wer59QTpRxgYiQ9WEGtQoFQJbq818Xu/lB8f3kVpqjxIWGsLM2WcRndRT+O5wOJg5cyYqlYoNH1ZzqMlOZnRPYbXL5aTeokLUR/q8Tv2daebOnUtsbCxVVVVkZ2czY8YM2traWLt2LQ0NDQiCQF5eHosWLUKv1w/53cvNzeU3f3+Fhx+8ly/alUTGJXHtvRcxZcoUtm7dSn5+vu87JxEfH09nZydHjx4d6Ve2F4IgkJub69urG+pBeePGjWzatIl58+YRGRlJU1MTH3/8MS6Xi/nz52M2m3tFj4E80EZHR2OxWAYUrNEKynBlDqMZzz8paLjkGVn4JoC+AmcwGMbUoeFkRHwTtbR6oq/NbDZTX19PS6eNunoLtvY6kkNV6MOUNJttdJmdvLbhS244awFarRattsfvVWkxM2/ePDb8903Oj4mm1WxGr9EwJzaWDYYw/u8/B1jqUfNIWCgAHq9IgU7PjTYrYQvv4LDLyVlnp/PUDTfw0J03MH+mjsfeaeMGfc8+gyAI6FUCFpfICoOObpeH9FgjDZ0O9rQYePrjKsLEt6hfu55ahYJHHnusn+i1trbyxE+/x78vVzAlOoKWBjv/s1DgzvecvFcOK6eJvLkPHrg8ji93V/0/e+cdXlV9//HX3Xtm74RMIAlh7ynLAe5qxV1Hq9Vat7Wtq63VqtXWqnXjHiCKiKKCICtAIDuQQPbe4+79+yPcayYkAa0/2/fz8PAQcs8999xzvp/vZ7zfb6T6CZjNZhwOBxqNhsWLF/Pmm28icJqQyBQotEEkJSUxbdq0QddRp9MRFRXFay8+R/6eL5kULqTJ7MOmiOSPjz4zpFVPTeUxuludHHHJMUisLE3yIRODXCZhzsKlfL5pI7vX/ZMrpimJnaggv2Yf736xn8tvfZDQ0FDCw8N59tlnmThjEQ9v/YTrpjqJ1fooqOlhQ5Wes65cQ3FxcUCIwV+mlMlklJWVkZubi8th5eOPNwACVq9ezdKlS3G73Rw6dIjXX3+dG2+88aT30MSJE/nDw4+yceNGUlJSEAqFbNu2DbvdzhXDlMNTU1M5ePAgLpfrpMcfCn41Ff8E41BwuVxs376dJUuWBLhtoaGhzJ07l61btzJjxoxA9tjY2EhERMSYKznx8fFD8g1He7y+jutDZbSjDVASiWREwzM/xlLnj4Ng9j3iVF3Y/xM9vh8q0A6kGJwueL1edu7YwasPPUztunV4LF7e+raKOB0oJL03+sYyWJimZ0/tEaRqNSHBwSiUKvIaG5AnJuJ0OqnIP8SD773Il9lv88aXr/GbV59l6cTJHCy3sVwqx+314fR4sTh9aKRSFiCg8UAO2m4T5o4O1q9fT0NbD18UdxOkFVPv+u579CAEoZhypxuJyEtlu5Nqq4qnNnXye7mO56Jj+Ud4JI+qNDx2551UVFT0+4xff/01i2M9JIVIkEqlaA3BdNh9XJIu5Jk9Ti55105qfDjf7Cnik29bCC2v5dhXX/P15s04HA52b/uceE8Z54RWMV9eiLt6L0qZaNgM6IvNn9Ge9ykfXK7lz2fpePliHWviG3jwnlsG3S/Ze/dyrGAfwd5mlkSZcTld/PkbO15NHLXEkTF5Gh++9k8uT+lA0nGY1spC0oOcXD9VyCfvvQb09pguuOAC1BotwrB0/vytjxs+trHZnMXFNz3AkjPOIDExkenTpzNt2jTS0tKIjo7mgw8+4OtP3iHeUcDq4GPEWg7RdCwfl8uFUChEKpUya9YsvF5vQM7tZJgzZw6/+tWv0Gg0dHd3M336dO64445+Ahl94dfA9ItJjAUqlYrU1FTy8/OHfEY6OzsRiUSDCN0GgwG3243JZApkt1VVVXR3d4858Pn5hq2trbS0tAR+fiI6w3DwX5vKysrADIQfY8nMFAoFGRkZ5OXlDVsZ66vc8mPBj+tsvgecqhntf6rH9//hvfxKNQMnZFtaWji6eTOr4xPQazSEqdTc/95z1JvcpEcIKGoV4Bap+OvPkrnyrVY2dXWhbmvFgYCYSZmsXL6cTz75hIqKbP69WkeIuvc23VNt5ok9X2EwBNGFEKu7V3JKKBEh9nmxCYXMjYpE4/Hw5Et/Z0W6nNWhsCG3A6VCTp7NzRylDC1CHF4hLRoNX7W1kCIPRhMWygc725jtlRAhkqPW9C5oKSoV55h62Lh+PbfddRd2u53q6mqampowyL67dhqtFqVSRbCjG49KhH5cGgcqqlhiTOHurGhs3d1clJzMp59t5o3OTpStB7ll1bjAjneVw80Dm9Yxc84CYmNjB13r7Z+v5/ez5SilvQuTQCDg7Aw97xyq4PbbbycyMpIFCxYwefJkXnr6ER5bZcRa30Ck2sPsKAEfFrm57a1ijOMXMs3jQdp9jESlGINKitPloba5Ar3UwLGSdmpra+nu7katVnPJJZdw2WWXBVSHToTa2lqyd2zhigwPZ2f20goyjVamNQv48MM3GP/HRwO/GxIS0m8RPxni4uKGzGz918J/HV0uFzU1NQiFQmQyGQUFBWOWEwsODsZkMg3a9ECvAL7D4Qjo1Ppht9sDE+LQO+np1+KMj48fc+9+oKC1RqMZs3j+cDSHsQRS6O1FJicnk5ubOyTHb7iA+p+khP3kA9+pmtH+lDO+ge4MJ4Lb7e4npm2xWAJjygMdI7Zu3szi2Diij5dS0iIjiTQYWZbkoEeq5aoMA9PiNfTYPSBVctVvbwu4d/hFegv27eCSTAHBqt4HpsXsZm+1lYa2Lmxoednm4+XIKKRCITaLhQq3m71OB7+NjePmt17gpXOERAZ7CY2MZM1kObd+2ECVTMk5Na1kyORItDpqHHYef/kVSvL2c85rn1JX3YDQ4+Fjm4X5bhu3xyQRIpUSJ5Gyr7aWdR+8x3uvPku4wkVlqxVLVxfXTjEGRrVFYhHfVIu59Kob0QeFUPn6WibLFHhsNuLj4jAajSwQCHh2ywbuXq7v9+ArZGJmR3spyM8bMvB1d3USpe+fDdbW1qJ09+B0OntdIp57jpCQECJlVrS+LsJCldidbkrbHCQHCem0CwkTeNn6xUbwutHKJHg9biQiAVF6KX/Z2kRDvZh//fV+ps5awCVX3TCoxDsUzGYzX335Jdu3fEJdRSnj5n/nLyeRSJgRK+S9gu9sm6B34rpvP/N0IDc3l48++giFQoHH46GxsZGrrrpq0JDJaBAbG0tFRQU1NTX9vhelUklGRgb79+9n1qxZiEQi3G43+/btY+rUqf0yd6VSyfjx4ykuLg70RccCqVTarwR7KkNwQ9EcTsWFxm+u69fgPJVe5A+B/4rAdyoZ30858A3lztDX2NYf4Ox2e6Cs4+c4qlSqYTlB9p4eVH14O0a1momxqZS25XP9cg1GoxaX28u/vu1gwYqfoVAoBo32m7s7GJdkpN1mxe0WcvunzSxNcPHvVWBXqrnzoy5WVlWwSqulyeEk2+3mzhUr+GTLFiYbbSQohXSZbHR1dWE0Grn7bDl3b1dw12uP09PTg1wuZ+bMmYGx8Y0b1vH4mTJWRNuR+oQ8f6idXxVZeDNtMjt7ujhSXETFoU3888IQxoXrcHu0/OyFbta81cK9y8PQKUV8dsTJt+3hvHz5lRQWFqJJSGDGAJNRrVyOy+FkqP2G1/dd+Xn//v1s374di8VCZmYmseNS2FtRxOrJvbtzk6mHtm4L5VYNVy9eTHBwMJmZmbz44ovo7GZM3R3EhktwOn3opSKsTtDLPPRU51NdWUGyRsk3lV5Wpknx+Xw8/FUPNruDv6/Sk5GmJacmm7/ck8sDT718Qkmp9vZ27r31esbL6rkwwkNiqpknNh7h4jnxrMwMRihT8+Y3x2hsdrH2uSeYumAlBoMBk8kUmJAddP8cz5pGQ7iuq6tj3bp1LF68OBBcc3Jy2LRpE+effz7l5eUkJSWN+Hh++Hw+VCoVjY2NARlCP1avXs26devYuHEjOp2O7u5u0tPTOfPMMwcdx2g0YjAYaG1tJTk5eczZjkqlIi0tjby8vDFnaH4MpDmcaoCKiYnBZrMNklwbaOv0Y8BPPvCp1Wo6OzvH/PqfaqnT5/Phdrux2WxUV1cPEtRWq9XodDoiIyNHbGzrR0RyMpVHjxLbR3Xil0vO4qY369m/wcH4iC4Ot7iZMP0Mbvrlr4c8RtLEyZQ21pCWEc5r39QwLdLDL2bIKO/wkRxnZOf90Vz6egNdE87AXl3DG1lZtBcWYhMK6cKDw+1BBphbWnC7XGjkeiQScT9bHz/efP1lLh9v4+fTtLS3ORH4vNwxS8ihBgf3FBdyTCQixtzK5eluXt9aTVkXRAapuHNFJHd/0spTJdFIxSKmL1jGy2uuJCgoqNerzuNmqdeLqM9DX9zexsTZS9hamk1GnAHhcYUTs83F3johN103hbfffpt9+/YxZcoU1Go1R44codXk4tmjIJd2oZQKefrzcoqbXAikXnZ+8yVLlp+NSCQiLS2NrZ8foSLGRbIR7DYbIoGPL456SQ0WUWP1YHW6WZCi4638VrZX+ZAJPRyqc/CHxRLiEyNRSkWsnBSCxdXCJ+ve4de/vWfY7/rdt15jvqGOGxeEAj6ihU2scju4e1s1mbEaHtlQwQSdld/NFSJRl/PRZ0/TKE3mdw/+ZRCpubOzk08++YTDhw8jEAiIiopiwYIFtLe3B0jqw2VM+/btIzk5uV9gCg8Px263Yzab8Xq9AZHy0cAfXDIyMgZZEMlkMtasWUNnZycdHR0EBQWdcLrRYDBgsVhOyXUdem3DrFYrpaWlp1wuDAsLw2azUVxcTHBw8ClnZsnJyRQUFAzKkIfC/0qd3yNOtcf3ffrxDYXvI/D1LVP6/3a73YiOUwlkMtlpFdROz8hg/f79ZFdVknacmJ7b2MDCVRex6tJLaWlp4eqYmBOW0c7/2Rp+9+st6BU2jnV6uSRZQqPJh1CmDgwUXDBRRktKMhkXXsjXL7/MVLsDs8PB3kYf9qkCDEoZMomAbrOZdWVuZi74xZDvVVp4iHNThAgEQgxBQZhNJtrtdrJivLzdKeTdK67i1xve5PFdJs5J8fHryT6qTQ7u+6CLUIOWn193C+ecc06/YxoMBg60NbF4x2eIBAIyw2KZk5BKfWgI199wAx+8KeKxz/cwO06CzeVlR6WPWWdfgVAoZMeOHaxZsyYQGKKjo3G5XLQYjfxhazY9TZXcNQf+tFSFSGXk1QPbef/NRq795W9QKBQsWHo2z+zcyOGmJiaEeNldK6KyU8D1s1U8ne1DKNeR3eDkzrPiaTAJ2FNpZ0FiLSqNGp1Wi8fbW+GYnqDhq+zcE37X+3ds4R8r/Vw+AXEJSVSXHyFO7eCP7xeTrLNzfoaC6IQUpFIpS6cIuPWTHtrb2/tNKLpcLl544QUiIiK4+OKLEQqFbNy4kbvuuouFCxcik8nYuHEjS5cuZdWqVYMWzY6OjiGDmj8TmzVrFjk5OSiVylE5DPjLiSeyIDIYDCOy7PF6vYSHh9Pa2kpzc/MplT1jYmI4evQoFRUVY8pk+yIuLo6SkpLevvUYrYf88Euu+WkOP6Ti1Wjwkw98p+rC/kPSC/zvN9bA17dM6Q9w/jKlSqVCqVTicDgQCoWEhYURHBxMRUXFqNXbTwa5XM55V19N7oEDfJmXT7fFjDwujmCFgrCwsBFZpcTExPDHJ17knVefZ3vFBlLUXuKiwonvc67NVtDpDcyaN4+SkhI2vf8+re3t+OxS5r5uQyH2kBYsJDZExN4OBeuevHbQ+9hsNhQaPYWNTmbFSRAJReh0etBBWXcHV0yfQYRWi8nh4ppJXm6ZKcTjhfkiIQvjfMx9pZMrB5R83W43l6xexjR5OY9dDFKhh0+OlPF8bjNrP/qSkJAQfnXb3RQUFFCcdwCxVM6VF88hMTGRr7/+mqioKHw+X2CD4na7cTmdFO78lBgt3LZIxMJ46LBaCQkJ4p4lWq744BgVFRUUFxdz9913473kEi5ZtZRgBURqPLi9An6/xcKNKyfyUX4PrvCZ/GlHIdGyHlpcKuRWKTcnpQVk7AAaOh3og078XQkEQjx97le1Wk1SWgae/GrKOwT8YraOcSnRyPuUshfGeikpLupHFegrOpGXl4dUKqWqqooLLriAoKAg4uPjsdlsfPjhh6jVaqZPn95v2CYuLo5jx44Fsgy/GEBjYyOZmZlIpVIyMjICwy4jle7q20fT6/VDEtNHCn/2OGnSpIAW52gFNfpCJpPR3d19QmHskcBPc9izZ89pEY0WCoVMnjyZAwcO/Oikyvz4yQe+0zHV+WMLfH69UZPJxNGjR6ksKsJqNqOLiiIpORmDwYBGoyEiIiJQprRYLHy9YQOy5haCxCKOuD2YDHqixmhAezKoVCpmz59PT3s7vtxc4uvqqG5u5p3ychZfdtmIdqnJyck88OhTnHPRGp5/6CYuVCox9ZhwORxUd/v4qkLKc4/0qv0vXraM7tw89pSVsUqm4AJ9ED6fh2/MVp5vd7Bs+ZxBWqS5ublseull4ixunjnkZFKQk6w4NVKplM1HHHxbK+a6mb0Lv8nhZEVir6C3UNgb3DQSH5lhAp546E4aaiq5+robEQgEvP766xjtFTxxgTwg1pwSAd0uC++9/SYPPPwnhEIh6enpJCQkBPqpBw8epLKyku7u7sC0oFwu7+35bd/EX5dLeD7bzrxYAWEqEOOjsb4encFIusHJu+++ywUXXMCkSZM4ePAgUXoRjy2TkGgUIPD5ONQi4rUDVYjFShYuWY5SeR7btm3j5ssu47nH/0h+g40pMUpAQJfFxVuH7Jz360tO+B3NXnIW6/Pe4tbFoYFA0Gjy0egLZ/GyLKTq3H5BD6DL7qOxqZn333+f4ODgXjWht98mKSmJuLg4nE4nX331FZGRkQQHBwdKlQ0NDUilUl599VW2b9/OpEmTWL16NWKxmJkzZ7J3714KCwtJS0vD5XKRn58fkDKDXoeBcePGUVBQwJQpU0YUuAbKB0ZFRWEymcbUM/R6vUgkkkE8wbEGBz9d4kTC2COFUCgkIiKCuro6Ojs7Tznz83P8cnNzvxfK1KniJx/4TnW45Yduyg4srfZVxfD/cbvdSKVSqo8dw1dezrTQUFQRkTR0ddFaUcHEVasG8cGyv/mGuK5uJvTJtopqajh04MCQfa/TgYL8fJyHcrkoORmBACLEEhQGA5vffZfou+4KTHCeDFOnTmXm2Vdz/gt/Y064D49PSG6TgImT5wW+2/j4eNpUSkLcHq43BCEAvIi5QC/HZLVwsL293zVpb29n8wv/5qrwcEITEpig1XDDJ1vQKc34ZGpE2kh+c+81FOw/QILRiFwsBmS025x4fV6EAlBIRSikQn51hpYvtq7lq7hxSCVinv/7o9w00Ynd5umV+BII8LjdLIpxc99nH3L26vMCu38/8Ts8PDzAHfvtb3+LzWYLZDRlZWWECHvISghCl9tIZRfEGMQEa0W02d04HA6OtsM1113DlVdeiUAgYNc3X3LZJCmTwjwo5VK8Pi8rtEL2VlnZ2tLrvHDgwAHOOeccsrKyuPvhp3jqkftQH2pEK/VR3iNl5c9uPKk58WVXXMPvfruP322qYF6sgEaTl88rxNx4xyNIpFLef2Y/M8d5UB43R6xqtfLBwS5mLJcHSN2vvfYaMpkMj8cTCAx6vR6fz4fFYgmIxVutVuLj41Gr1axevZqdO3fyxRdfBAxmb7rpJj7//HPWrVsH9PbCfvnLX/bLYsLDw+np6RmxHudQk5N+gvxoy5V9j+X/rv1TlWNdZ04mjD1aJCQkUFJSclrcHPzTrH4xgaH0Zf9T+F/g+5Ggry2S1Wqlo6MjoIrh9/0LCQkhISEBiURCR0cHjdn7WJyRgUjYu6iE6vXk1VRTfvQo4/uMitvtdtrKypgTF9/vPVMjI9iRva+33HeKD8xQKDtwgJlhx+19fD58QLBGQ2RLC5WVlSNWdwdQC0Q8eNZlmBwOpCIRd66Oo91sZuuHH3LNHXcgEAgIjohgrkZDt8eDTCDotY8SCkmXStk/QMXjUE4OmUIhocf7PWeljWdpcgrvFxRgyZrEb+66C7fbzZ+PHeO6DW+gkLj5xz47v5sLMokAg0LIgQYvlZ1CFo83EK638dcX/06Q2EKywU2zGRRiH3anDR8CZBIhLRYfXnsPWz55n7v+8OchyepqtZobb7yRf//730RFRaFQKMjLy0MgEiGXK1gxXskLOd2khfgIVvUuHjltSuqcUtasWRNYTFrqKrkgOZwuVwsI3Qh9HuxOD8EKL0KFnheef47omFjWrFkD9AoP//PV99i1axddXV38cu5cmpubOXjwIAkJCcPa42i1Wp587jV27NhBQd4B9ONC+evdZxIdHd3rcJ7/c655/z0WxPiwugVsOWIlfd7ZLFu2DLlcjkKhoK6ujtLSUpqbm6moqCAhIYHY2Fi2bduG0Whk8uTJlJaWEhsby9atW8nKykIikTB79mw2b97MsmXLkEqlhIaGctVVVwX4pUVFRUNyD5OTk0esxzlU4BuYaZ2M3zjcsYKDg7FarRQVFZGRkTHmQKBQKJg4ceKQwtijgcfjQavVnlY3B78ZgJ/j92OZ7vzJBz61Wn1KPL7vA30tWPzTlH7Sq0AgQCKRkJCQEPj3UGhtbSVSJAoEPT9i9AYOl5f3C3wulwsR9JsuBBCLxEjw4XK5TjnwlZWVkb99Ox2NjehCQ8lcuBC3w4FUfPzB6fM5ZAIBbrc78O/u7m6KCgqwdnURHh9PWlpavwfOarXSfuwY5yen9LseSqMR79GywERdVEwM2Uolap0em8WMBwEisZgGiYSYpCQ+/OADcnftRh8SjEqjIV3S//aXikRMi4qiUKXqtSqqqsLbVcajV4+npaaCRzdWc/1nbpaO89Js9vFluZBb58lx2W1oxC6OHT7CbZfGUBMVyuMbu7hooo9JoWD3QKsF/n1QwM1njaeho4hDhw4xa9asIa/ltGnTSE5OZv/+/VitVlatWsUDd/yKwroeFiSpsHjlXPFRK8EKNw02BZroWGYs6u80Hp04nurqIjLHJ9DZ2ozL5cDjhbxmC5OCLCwxlnOksYmXnn2SG2+9i+rqar76YhPN9bXoQqPZv38/Go0GhULB+vXrmTFjBuedd96Q96NUKsVgMKBQa/D5fAEzXbvdTnrWNAQSBc3t7aSkpDA7vpRZs2b1K3/5M96wsDAqKyspKipCKBRSVVVFcHAwERERtLe3U1VVBRAoXSoUCkQiERaLpV/w8VNChltk++pxnoyYPxxXTiKRkJmZGRh2GYne7VD0g9jYWEwmE1VVVSQkJJz0GH4MLB/q9Xri4+PJz88fcRl3IPx0hpG6OYz0mEqlEoPBQGFhIZmZmT8KL9OffOD7T2Z8fcuU/r/9Kb+/xBUdHd3PFqmtrY2enp6TlhmEQiFO3+BeoNPtRizt/yCr1WrEBgMt3d2E9lHTbzP14FarR7xjHQ4lxcXkffABc0NDCRuXSKvJxJ733qNeKuXL4hIm6HSog4x4BUIcLhfVHjdTj7tLl5eX88Urr5AK6CVSynbtIic8nJ/dcENAwFkoFOJDgNfnQzTgofEc57653W7GjRvHM24Xu8wm5ihVeFxOKsxmXuzswLfjW9x797JQLqfF5eYDi5nimFhmRMf0exBLe3qIP76wfvvVZ5ydKiItNgRz9RHevSCe94t6eC6nhWuyFHz0My1ugQOX28Xesk4cLg+hCjd6iYcJURqu2mBiSjhIRD721fuYkBDGlQsT2Hm4leLc/cMGPuidRly2bFng39fccg8P/u0PzA3uIj1GS/q4UPY1K7j2rtvRarW0tbX1e/2q8y/mdzdvJD7Iy9ykFGwONy99UYBDrOPF6+cik4jwen289M0+Hv3TQxw98BXnpfpIlnr46LM2WmRJ3H7/IyiVSpxOJ1u2bCEqKooZM/obyrrdbh575A+0lmxnaYIPmwv+vPF15px9BTV1Deh0OoKDg5FIJOTl5aFQKAKlej+P1GKxBIjgl1xySaCHFhkZyfTp08nOzmb//v0sWbKEefPmBTZF3d3dAEMOiJzM2ssfuE427HIiqx61Wk1KSgr5+fkjChDDEcT95UCVSjXiKcihgmhERAQWi2VUXnkDz89/zL40h/T09DEHK//0eFxcHDabjaNHj5KSkgL8r9T5veJUtTpHguHc2/uWKYOCgoiLizvpznCkU53R0dEcEQgx2WxojmdrHq+H8u4uEub079kJBAKmLl3K3g/XMcFqJVijoc1kosRuJ2n69H43oMvlorOzE6lUOqJmudfr5eCXX/V66h0vG4bpdKQ0NpKzNxuJXkdLZyetdXUcaWigRafFMHsOZrMZjUbDl2+9xTlBwYQfX7wygV2VFezaupUVq1cDvVOiERMnUFRZyaTo78jUR5ubUcT0jvo/+8gjaDs6uWzaNB7dsQNpfR3hcgW1Xg8iuYTZPV3caAwmWKNDKpWw2O7gstJS3gkPZ2lCAiKBgJzGRir1OmbExLBx40Y+++AtwtK6ONSpweF0IpbLuW56CNmNVhrM4EKExQV7C9p5KcdDeFQcXrmGKI2UP1+o4vOcGrIrLextgHsunsylc+MQCgWYHB5kYYNH6nt6erBYLAE+VW5uLnk52UhlchJTxvPgUy/z9ptreaumgqwZc/nL4iW0t7eTn5/P+eefz949ezhWkodCrWXarHnc85dneeXZx3lq11HMFhsKgY7nfzUHmUR0/F4TMGucmtf+9SYbb04iXCelq6uLTKOStQUtbP3qC1adewFSqZTJkyezd+/eQYFv27Zt2I5+w78uDEYsEgI+zs5wctGLT7H80ptZsGBB4HeLi4vJz8+nuLiYzMxMTCYTr/7rSWTmambJOyn7qpi7v9zInDPORqPRcPXVVxMWFsaSJUv45ptvyM7Oxmq1IpPJaG9vZ8+ePSxatGjI4TOLxcL6D9/nkftuxWG3M3vRcn5x46+JiIgI/I5arSYxMfGEwy4nI1+HhIRgMpk4cuTIsIR8P4bLHoeSIzsZhgui/s8zEh7dUOfXN5jGxcVx+PDhU+Id9g2mfu3T2traE4oi/BD4yQc+qVTar6w2Fvh3pkKhcJB7e98y5UD39rHsaEYa+BQKBRnLlrL7q6+JwIcUAfVuNyGTJg2paRgTE4Piyis4nJtLZXMz2qQkFk3OCpSPAArz8yn6Zjtajxur14c6IZ75K1eekPdktVrx9nQT1Gen6nA6sNfXk6nTM3fRIj7bl01LfT06mYz5aWmkhIXxzeuvk7JsGTqbjfDI/ny+yZFRvL1/fyDwASw+5xzWvfgiTeXHiJDJaXU4qFbIOfvcc/nLXXcjLi9HJ5WgVmu4Y/oMDpUeoSfIwFRNN9uLG7k6WI9a4KS9pZGg0HAipFLmGw0cDg7iWEMDToeD2MwMli1aRFFBAQfeeptgp4jSeiEJSh9bSkx8bDGRHqUnWqtDJIzlzi+rqLJ4CI0L47JfXUlbSyMv7/mI2xYb0Wu1zErUUt/pJDYuisvmxwPQbXXydTlc//OFgc9msVh4/7XXOLpnL2qRELNEglnkQWuvZlGCAJvLx+ufuJmxcg2P/e1J9uzZw/79+9m8eTMxMTGcffbZfPrBGwTbSpkcLaen0c3bT33K3POu52/PvkpPTw+5ubk0bvsX4Yb+Je3i2i5mRXkJ1/VuyLxeD2KxiPPSFfxx7y5WnXsB0LuBNJvNg77/3V9/yvnpUsQiAZ2dnXR2duJyOZkTaqKhob7f744fP568vDzkcjlff/01FUfymaso5eczxQQFxSOTyXh9dyu7ao7yx5ff7LcIL1q0CIFAwNatWzGZTIhEItLT05HL5eTn55OUlBQIal6vl3t/exPGjv38bb4WlUzIp4UfcN2araz9YBPBwcGB44aFhWEymQapjfgxElmwhIQECgoKTrqgn+hYUql0VKXT4Y7l98rzcxb7ftaTYWAwFQgEpKWl9d47xx0mRou+gW8gx28sxztd+MkHvrHC4/FgtVoDVjJ5eXm4XC6kUmkgwEVFRaFSqU6rDt1oeHzx8fGErrmM+vp6PB4PM0NDMRqNeL1e6urqaG9rQ6lSERsbi1wuJzg4mPl9ymdAIPBVVFRw7PPPWRkbh0omw+fzcbihga0ff8zqPkMTAyGTyfCIxdhdLuTHy0Umkxm5z4dDKEAqFqOy27lz5kw62jto9HiIDwnBB+zIzkbL4OMKhYNdI4KCgrj69tspLi6mo6mJkOBgFqWns/b5FwgtLeW6+HhUIjF1NhsvFRfj9fmorC/mV2fq2VniBQEoxQLweujsaEenN+L1wZRp0zj33HNRKpV4vV6Ki4t58fHHcdbXM1kup6TWwto9rYTLRKTJxOTWd7HX4WPZ1EQEhhimT4igqbsbg8HApEmT+Mxi5uaPthGrh9I6L/LgKQR7vazdWY/P1xtABcZEXn31VZKTk1m2bBkb3nyT0JIj3JuUhFQk4uMjh9nduJPfXTGBoKBeCsaCZBN3fPIWK846h/nz5zN//vxAOW/zp58Q7y7l54u/K9tOiOjm9qcf4LPP56BQKEhMTKSoyYvZ5kKt+K6sd7iuB5niu7K6TCajq6sb6H/9Kysrh5yC9LhdSERCOto76O7pRq/v1SBVSi2UNzf345gJBAJEIhE/+9nP2LlzJwe2buDqK4wE6dVIjvcnr54Xxsevl1FXV4dYLMZqtWK1WnE4HGi12gCx32Aw9FpYHdfIzMvLQ328bL9nzx4c9fn85QINSmXv5PBNC6T0fN3O+++8xc233tbvMyQmJg67uI8k8PmDTXZ2Ns3NzUgkEmJjYwdRAk52LH/p1E9zONHvnkheTCQS9fPKGylhf6hj+rPRAwcOIJfLR01zGHhMkUjE5MmTycnJQaVSnTJtYqz4rwl8w9X8/WXKvpQBf5nSr/IglUpJTk4+5V7YSDBaArtSqey3IDkcDrZv2oS4oYFQiZR2j4cSqZS5551LSEjIsMc5vG8/U4JDAhqbAoGACVFR1FZU0NTUNOzuTCKRkDhjBvv27mVewjhEQiEioZDcjnYi09OxOOyEicRIRCJcHjdiaW/fLtpoxFtZQbtETLvZHCiTAhQ2NJA4hHGwTCbr57fY2tpKw8GDrAoKQiUW4/V60QtgvNvDdlMP8xKEJAkFTI8U8kGdid8adSjlUqwWD234KPR5efiss1CpVDgcDl775z+p2rUbU3k5zxiDMIrE1Mp8XCqW84SphzCBmDx8zNUZ2Hr4CLfNmUO4WEyJxcZn/3yWpddfx+oLL2Hx8rNobGzEs28f11xzDZ2dnTQ1NbF//37ipihYsGABKpWK8vJynnjiCeQ1tVyTkYHw+P15tKOBy8Yr6GxuCgQ+vVLC4jgv+7KzA1mF/34uztnBleONgX87HA7qq48xOUKIPj2diRMnUlBQgEUcwuNbGjhrvAIpLnYWN1DUJsPcLae5x0mYVopEIkUuk/Hvb9uITpob6LdVV1dz6623DvpOpi9YwWcbDnFFqomQkGBEIjE2p4dtNWKmnTWO6upqIiIiAsNCQUFBGI1GgoODMWqVhBi1+LxeHA4nHq8Hr8eDwGXhscceC0wbz5kzhwsuuGDYvrdYLCYjI4PCwkKmT59O3qGDLIl1IRT258edkSzlX/t2ALf1+7l/2GX//v2B4OnHSIWgm5qa+Prrr+nq6iIyMpLOzk5mzZrVT2VmJMcKCQkZ1ni2L052LJlMFuhhTps2bUTDN8MF0+HcHEYCj8czaMpUKpWSlZX1H7Uq+skHvr43jn83NlSZ0t+LCw0NRalU9ntdd3f3D/YlnapkWeGhQxibm8lK+I6v19zVxd7PP+ecyy8f9mExd7SjMxgH/VwvFg1Z4uqLOYsW8Y3Vygd5eQSLxbS7XFRHRzMzIhKlVEaXx4PX56PJYiEmIwOAbqsVndFI5uLFfPLGG2RKpejlCqpNJmp1Oi5dunTY93O5XAHCt8RmpcrUQ6RQhFQipr6riyyVkm9NPZhcIg62etFKJHzktNDU7mWhXM0xi5NNzc1kLFxIa2srer2eHVu3oiopob6mhmUSKWECAW1OB2p8pMvlXOhx0w08FhrKHY0NGGQypkVGInI4iMvQYSwu5sNXXmH8vHk0NjbS2dmJxOnk47/9jRCJhHKTmTqXk9/cfXdgEUpJSSE7Oxt3QwP2pCQEEgkurxePz4NaKsZxfDrSD7EQPJ6hyvb9M+Tm5ubeMXK1D5FIhEwmY/r06XR1dREffyZvfLmRhtJiJsXruHqmng/2O7ns1Rquna1HJ/OxrVzEUV8yGcZgtm3bRmpqKrfcckugbObxeHpVZ4qLEYlElLmiefzbXC6cYsPq9LLhsJdxU5f3mhC3tREcHExnZyfl5eVcfPHFVFZW4vP58IjVZJd1MCWut2oilUo53GCmrtPJqtmzSU1NxWazceDAAf79739z2223Dbt5VavVAXK6Tm+g1ioaVEto7HajDxp68+e3D8rPz+8XKE42JAO9Axyvvvoq6enpgQnU4OBgtm7dSnh4eKAvOtIgGhcXN6TxbF+MRFBao9GQnJw8ogzyZMccys1hJPAPtwyEUqk8LSoxY8VPMvA5HA4OHz5MYWEhBQUFNDc3M3nyZHQ6Hc888wyhoaGjKlP+kA4Npxr4qgsKWR7ePzsL0+uRVVXS1tY27NSYMTqa5oZGEvr8v8/no8XlZoJxcEDsC4lEwvJzz6Vr4UI6OzvR6XT4fD62f7QBVWcHtT4fH1dUEBUSSmRUFE63m/0NDYw/71wmTpxIyB13UHDwIK0dHUSMG8eiSZMCpUd/udm/WXE4HIjFYo4eOcK+TZtwVFXjEAjY2dqGXCKhsbubGJEIiUzGN7Vmqhp7WCyXs0gi5xObk12mDiaptNydmIS1roF7rrySe55+moJvv0VvtuDr6SZeJsPu9eHy+jAKeq2bgoRCGnw+gsUSskRidnl9gQxNo9EQHhtL08EcjM3NxMbGopRKqS8sZH5kFNOjoqmpr+fVgnxyc3KYOWcODQ0NbHjpJTxVVVQ1NfNweztNWi06g56ubgcflpi5YfF3ZSCrw8P2aiF33TJj0PXPmLmEHfte44oQNQKBALPZgkcopajVwyV9hhLCwsKwWCzoBT08cfsClLLex//saTHc+34pB8TpiDxe0lZN5Q8/+9mQAgMul4vnn3+e1tZWEhMTMZvNqIOiKG7uwtcaiVSmZM7Fc0hNTaWmpoa3336b/Px8goKCWLVqFSEhIWg0GsxmM7+8/fc8/uT9XO+0MylaSUmjice/7mLOsnMDU4kqlYqFCxfy0UcfnZR0Hh4eTnd3N2njx/PqPyWsbnIyOb73M3RaPbyaC1fceQ4FBQUEBwcPkvlSqXqJ/X2nNEcSrI4ePRqgIEHvlGlXVxeTJk1iz549ow58fuNZfzlwqErNSI/lzyBHOp15ov8fC83B4/H8KGXLfpKB7/zzzyc0NJSMjAyWLVvGN998w8aNG8dcqvwhhapPNfB53S7EQwRzieDEx82YOZMdb76FTCwmwmDA5nSSX1+PbsL4YcnLA6HX6/tNgp537TU0NDQQtmQJRXv2kFtcjLW6ihaPl+RFC8nIzKSkpIQjOTk4nU4ik5MJCQujqqoqwL1UKpXYbL32QgaDgYyMDMrLy6nfto270sZT6/FSUFnJv9vbOFsmZ6VYwi67nd1uFzOlUm5XqpCLBQgFMMXn4nFTD/cEBUNnF3ank/Pcbm674gpSJk6E8nKmKpQUdnUxXSrDgQ8Q4PR6yXY6maZW9+qher1otBqClUra7XZ8Ph9fNTUxf+FCFq9ejVAo5Mi+/SyIjGL9N98wOSISlULOPJ2Or3fvJjYhgSfvvQ9tRzsGuYJmmYzYCeM5d9w4tEHBNJrN/Pujd3AfEnChqAOrw8NHhTZS56wacrpu0ZIzeKHgAM99XcyUGBlHKi18W2Vizrm/6Nff6enpwWruZk4MgaAHIBYJuXhaEAcFMaw8r1eibDhVnT179tDV1cXq1asDNJKEhARqampQGqMCdIPu7m5KS0u57LLLuPjiiwdtMJuampg7bx6hYS+z7u1XeeObUiJj04mc5GH5ipX9flcgEBAeHk5DQ8NJ1VZSUlI4ePAg1//2D9z05MNMi7KgkvjYXeMlJnUKW7duJSgoiI6ODhISErjuuusCtBmA0NDQwLBLWlraiKx/LBZLv/KfRqPB6XQGZAX9GI2NkFAoJCsrK6DpObBPNxoLIb8I9Wi5gkNhtDSHE53n/+gMpxmbN2/u929/v2Csge+H1Os81cAXkZpKVVUVSX2yPpPNRrdEPGwA8/l8hIeHM/fnl3Jo+w52V1YgkEpJnD2LOTNnjvlcRCIRMTExxMTEMHnyZL788kuSk5OZplTi8Xh49bnnsBw8yASVGqlEQun+/RxOS+OSa68NcLM2f/QRddnZJIjE1OBjr1SK1etjZVAwBqUS8cSJ3LLzW/6uNxItFuMTi5mjUhHZ1UmFx0OcXEWT3Y7J4yZZJCZaIOSB2moe0RtJlclIFIl4s62Fgt27SRUIOCgRccThwORxc55CidnrZq/DQa3HzTVCEfmdHXzpsHNxdEZg/MPmdlPW082CceNQqVT09PQgEwoI1eoQKxU09PQQbTCgFgpprKvj9cceZ7nJxNkRURy22+hSKolKTKQWsLe3ERIdzcXX/or6ujp2eAxIVQqmro6mrbGO39x0LXKZgmmzF7Bs+Qr0ej1yuZyb77if3NxcSo8UYB/vRiMqJ75PubumpoaOjg7Gxccgqh38XUlEQrxu97Dj+263G7PZzPbt24mNjaWtrQ2v14tYLEYikTBz5kw6OzvZtWsXer2erq4uJk+ezEUXXTTkwucvIU6aNIlJk54J/Pyf//wnbW1tg3RVu7q60B3noHq9Xmpra5FIJIH+oX8R9ffrLBYLT/37LTo7O7Hb7UTW1dHR0cHixYsDG9ndu3fz9ttvc8MNN/R7r3HjxpGXl0dDQ0NAX/NEiImJoaWlBbfbHWiJGI1GCgsL+1VYTsQJHAr+Sc+h+nSjMaH1i1AfPHgQpVJ5Sq4QMDqaw4/RhBZ+ooFvIE7Vhf2HdkU/lffKmD6d7TU1WGtrCNdqMVltlNltZJx55pAPsF/lQiAQEB0dTfTla3qVXkSiMSs22Gw2DpeU0FJdg0ipIOI4WV0qldLe3o7dbqezsxN3aRm/mD4DqUSCz+cj1Wrl8/JjVFdXB3hNPXv2cmVyckB1pqGriz9+tonLz+jtAR5ub2ecTE6GTofV5UKi0WDu6eFsuYIrO9qoNJsRCQTESqT4vF7ixWIaPR7eNZu4XShko81Ks9tDuEhEkceF3i1kqUxOhcfNHR3tCBAQIpFwqdHIJoeDzyxmZDIZm4+VUd1Qz9yEBCwqJc1eL/EpvcoyCoUCq8+H2+PB4XQhE4sRCoSoY6Jpqa5intPFZIkEhQDcPh+ToqNQi0TolUoqHA5SMjNxu920t7dzx+8eZt++fbz8+L3Y26qYGeUlWu2j+P3P+XbTu/zmj0+QlJTU63Q+Y0agrJafn8+mTZuQSqUBDcwrr7wSu93Oh3s3cEaGB6lEhN3p5nBdFx/sb2bZL+YEBNBbWloCw159jYh9Pl9gTL6fio5SycyZM5k8eTIdHR2EhIQEAtVQGK53tnjxYtauXUt4eDharRafz8eRI0dwuVyBycmn//J7sLbhcPsIjU3hngcfIy0tLXAMqVRKbGwsVVVVLF68GI/Hw5133smFF14YWISFQiGzZs3i/fffp6enpx8J3j92f+DAAbRa7UlVjcLCwkhPT2fbtm1MnjwZtVpNZWVvayElJaW3HHw8YxttlqPRaAaVX2H0AWVgBnkqrhCjoTkMNdzyY8CP74y+B/x/cmEXCoWnpGau0+lYdumllB0+TFl9PYroaOZMnDgsn2eoPsZom859/f7q6+vZ9sGHxNrtRKjVWLxedkglLL/qKlQqFVOmTEEoFLJ1yxYm6XRIJRLqOjv5qKiQNqcTi8NB9jPP8IeHHqJ4927mh4X1k1oL02oxyhUUVVczb/x4Gnt6cHm9CACPAGRCYa/1EuD2QYhQiAVodbsR4uOg08k/DQbu7Opik9XCZpuNJ/R6IsVibF4vm+12unxeHjIa2eV08JrJzBnTp1PQ2Ul1YyNxMdFMGj8eiVZLbk0Nz1ZXcc8f/8iFzc0cPnyYuXPnIpVKCYmN5aMtW6iqr+APLcdwerz4VEYmpKWRUFpGj9OFSCwmVCZnb1s78YmJdDqdIJEgFoupr68nLCwMp9PJBy8/Ray0nflTBJw9sTeY1HfYyG6p4c0XnuTBvz03aEGdNGkSEyZMoKGhAbFYTERERODeipt2Nn/b8hlqbxfbcysIkruw+hQ8/8SDnHnR1aSmphIcHDzI4QNg4cKF7N69m3HjxuHz+aiqquLIkSMcOnSIhQsXYjQaB2VrQ2G4wJeent7LS/z0U9RqNTabDZ1Ox69//Wuqqqp49N6b+PMZAqbHafD54NPCUu741VW8/+nWfuVA/+h9UVERcXFxCIXCQQFMIpGgUCgwmUyDAoF/2CU7O/uEAdyPiy++mF27drF3714sFgvJycnccsstqNXqgDrMWBEaGorZbO5Hkh9NxudHX8eEqVOn9itnj3bNGSnNYbjhFvhfqfN7x+kwo/0hrYlOFUqlkqypU2Hq1JP+rj/jGwir1crhkhI6GhrQBgeTNnEiWq02oFDjHzix2WwBvz+1Wk1VcTHLQ0NI76OwUt/RQfZXX5E8Y0bgvcQSCS6fjx6bjVdyDjApK4tFUVG0mc0csdl48cUXCRYIUOh7Hyi3x8PWkhIKysrobG3hiZpqHvtmG3Kfj7KeHnaIRGTpDTgcDmTApw47cqGAl60WFspklLhcbLLZWCqXI0SAXAD/Mpu4W6MlQyqj2u0mTizmRo2GG9rbOOZwkCkSg8/H3IQEdjscuIKMnLN4MVqFErNYxMzMSbyzL5sjR47w61//mqeffpoNGzYQFhZGQ0MDBw59y9XpHmbFSBDJ5GS3+vgwv4wkjxujTsuxnh5i1BoEbW3kVFaiiY0lJCQEs9lMTk4Ov/zlLzl27BihEjP1nWYWz/1uSCBcLye8qwdvax319fVEH8+q+0IikRAXFxfQz/R/bxlTZtDU3s2W9c9z/2I1ybGhGA0GShpt/GX9a0z/63PD9oLmzp3ba+e0aRONjY10dXURFhbGhAkTeOWVV1i5cuUgU96hcKJpyUWLFjF79mxqampQKBRERUUhEAj4218eZs1EFzPiDcfvXTh3ko7s+h6+3LKFCy68sN/xdTodNpuNjo4O5HL5IAf27u5unE7nsDQfpVKJ0WikurqayMjIEwYakUjEwoULWbhw4aD/S0xMJD8//5Q2tAkJCRQWFgYUWUbTL+wLv2OCfzrTf4yxBNKR0Bz+V+r8D+L/U6nzh8ZQn62jo4NPXn2NsK4ugiQSmnt62Pruu2SuWEFcXFyA6zQwG3A6nfTU1DJ+QN0/ymhEUH6Mnp6ewMOfNnEiH23+nM6KCsJjYkiMjsbr9dHmcjFp6lQOHz6MuauL0rZWZqtUfJp7CGdVFdcYgtjjdvF0ayu3yRRkqZTslyl4oK2FZU4nSTIZuTYbJS4nz8fEsqWtnTctFjq8HmLFIq7VaDnidFDj8SAB5kplOH0+vPgQIwAfxInEOIVC4pRywk1i3tu7B6vHS1R4GMEaDV12BzKtBoEAJsTGsrOkBI1Gw/33309xcTENDQ3YrSZuWBzNDYsiOT4jQ4bLRfbhfXxmFnNvcgpdLS10mXqIcjp5ff9+JGVlzJs3j6qqKi699FImTpxIaWkpbi/gA1Gfdcnn8yEUCBEJ6Pf9uVwuDh06xIE9O7BZLUTGp5CYmBjgpKrVasLCwti57Qt+vSyWeZO/CwST4qTMCq9h//59Q6qYQG8Z8ZZbbuHtt9/m2LFjrF69mrCwMHQ6HVarlXXr1pGVlTVkIPaft9PpPGm/SyaTDRpkqassY2XMYD5aerCHmqryfj/zHz8tLY2cnByWLFnCF198wZw5c4iMjKSlpYU9e/Zw9tlnn5DjJpfLEYvFlJaWjkn/EnpLoWazmerq6jG9Hno3qBMnTgxMep5KCdFoNBIdHU1BQUHAUHesAepkNIfhjvufFqr+rwh8p8OM1jXA1uangt7xdzNdXV2BjGD75s9JaWslIzoGmUzG+Oho0i0W9lZWkn722cPetH1/7vP5qGlvp7q1BYlYgsXp6JddhoWFMWn1Kl7/+9NMTEmmoaubTq8HbUwMBoOB4OBgZDIZhxsa6D58mMNlZVwTFEyjxcx+u52L5ArmKVWYBQJWxsQwJTqKOyrK2SoSMker5V8GA+6ubs5TKBChYIPVgkAgoMbr5XWrFZlQiNPnY7fLQbxIglQgwOnzIQFqPG6kXh/lLg9mqYQVAiGf2S2onE667Q7cUil6lQqvz0fPcfV56N31Z2Zm9kpPZW9jWtzxHfDxy1JTU8PseBmlNj2vWCxESMT0ANVSKRkpk+ns7OTmm28mJSUlsKglJibSLTCiVinYU2VncUrvwlLfaafdp8ck0OJyuSgsLMRqtbLj6y10H93J0iQpMpmE7H259LTN54Zf395vAepsaSAydPCYeaTax9bsPRzauYWmhloio+NZfem1LFy0KPA7EomEnp4eVqxYERAcht7nLDExkUOHDg0Z+Hbv2sWGt/9Na0MtLi+svvRaLr50zcinE5MnUFhZwMwByWhui5jZZ/UP1P4hnb46mBdffDHbtm1j27ZthIaGcv7555/Ui9Lr9RIZGUlNTQ319fVERUWd8PeHw7hx46isrDylY/RVZDEajafkqBIdHY3FYgmIRo8l4/NDp9ORlJQ0JM3hfxnffxCno8fncDhO4xn9Z9DXDsnv+2e1WgNlIZ1OR2hoKAecDhZlTe7XW4uWyxGVH6OtrW3Y0pBEIiF8fBolVVWU19XRVV1NilhKm91Ovs+DJjOzX7lnzoIFNLW1UZCfz7iEeMYdl6GCXlWW8ePHM/Wii9jw4Yd48/NpVyoxjhtH3cZPWCQQIAfMTieWjg6MWg2XBgezLyuLppyDuD1e5AIBQVIpZU4H6202lAIB79msXBwVzTSRmE/FQl6uq+OJIA06r5dyh4Mv7DbChCJqXS7+1t0NKiUtGg0SiZiCtjay3C7So6OwezzUmM00mkzMmDFj0GZAHxxBfeshphxfpB12Oza7HatIh0yjJyZrcq/snVrNFIWCo0ePEhMTw4EDB/qJHYvFYtb88k6e+ONtPLnrGAX1dsLUcLRTQqFDRcbCqax/441eabq0NGy1B/nThUnIpb2LzcJ0H09u2cmBA/P7uUEYIxP4MvsLJF29PRhjSDghoWGsz+tBKd3DvWfFkLIinJKGNv757O9obfkNF178s8Dn7JtxuFwuOjo6UKlUw05A79m9mw+f/T23zFMzYXk4ZTWtvLftZV7t7uL6mwYrwgyFCy9Zwy1Xf0RSsIkFSSrcXh/r8kyUmIL44wApvr7TqTKZjAkTJlBaWsp99903qoXY5/MFdEEPHDiAWq0eUc9vIPxDTzU1NahUqjG7pctksoDe5ak4rgMBebT6+nr0ev0pBajQ0FCsVusgmsOPNfD9OFwBv2f8fxpuOR3wer2YTCYaGxs5evQoubm57N+/n5KSEjo6OpBIJMTExDBlyhSCg4NJTEwkPj6e4ODg4w3voft+Pk5eopi7bBmft7RSU1TMco2WCKmESJ2WW2fNpmjLln68JoClS5fi9fmw2mwB0npZWRktLS1Mnz4dvV7P2eeeiy41hfFZWThsNuIkUoqdTlwuF0KfD5nbTU9HJ3u6u+mx2wmaOoWrqitZazbxWE8Xf+jp4cHoaD5ISmaZVkuDQkFdWAi//sMfsBmN/NFs4s7ODh4ydZPtcNDm9fCe1cpFajVP6A0019cRFBfP7/76Vz4vKeHNAwfYUlFBfksLJquVzs5Ofv/73/Pkk0+Sk5ODz+djyYpz2FjaO4QCvU3+mk4PuxsVLF22nAMHDmAymejq6mLr1q3o9XrOO+88Dh48SFNTE5WVlRQWFrJ//35cLhfX/OYPTDv3ZvLUK9gpPYuglfcTmzwd+/YdTD9WTsqhPD579FHsrfXIJN891kKhgEVJSgr2fxv4WXNzMwV7t7G73EJFm5NIpZvm2goeXZdHVYuZB1dFkhQqo7GhDk/rUc6Laeb5Jx7i8ccfD5TrpkyZQklJCbt3fsszf7qHjS8+zHN/vovPP/mQpKSkQffFhnde5Oa5KiZGaxAIBITppNy1PIwD2zbS0dFx0vvZ4/EQFRXFHx5/nufKoln2Sg/LXzax3TGVJ59/fRBJemAp1WAwEBkZSUlJyah6bf7j+IddioqKxrQJ9vc0s7KyKC4uDngWjgVarRadTtfrF3kKLRj/9GptbS2dnZ2nHKDi4uIQiURUVFQMep+h3vs/if+ajM/v3TUW/Cd6fCORSvI7TfcdNrFarb0iwcd7OiezQxo43CKRSIicMJ4jlZWkR31Xrqrv6MBrNJ6QzF5RUcG+r7dSd+Qw0WIxR6RSkiMimBgWhkwqJammmtLSUubMmRN4jVar5cYbb2TdunXk5eUBvQocN954Y2DSLjQ0lOCMDLaWHEZXV89ylYqHWlqIFAhYotZg83jYaDaz2+tmans7Vq8Xj1SKzmgkVCDgGoGQmOPlyHCFksiUZGplcubNm8e+JUvIKCxC39pKikxOm8mEGHjS3MPPtTqOOZ2sVqh4saWZs846ixkzZpCdnU13dzcSiYSvv/4ao9HIjBkz6Ozs5OOPP6atrY2VK1dy4Y33c9+LT5CgMWN3utl12MdVN1+PwWCgoqKCiIgIOjs7yczMZMaMGXR0dNDT00NPTw96vb6fy0d9fT2pqamBMtn27dtp/PhTbkn6zpw30uXk6fJciqvbSY7QIJNJAQE+f5OR3oX8qcf/QrroCGlz1Gw/5mBtnhOpWESDXUhyVBA6qZey4nykHjNhcjEakQgVLlQqFS+++CJ33XUXc+bM4d1336F8x7s8uMJAqFZMW4eZzcdsbHj3dTIyngx8x263m8baKtKX9h1796GUiUgwCqirqwtMgnq9Xnw+X+Dvvs+AUChk6tSpvPruJ3R0dCAW93JT/b8vFAoDvz/U8xMTE0N3dze1tbUjtuzpWwJUKpWkpaUFZM1GUxr0H0ehUAw5XDJayOVyZDLZKfUe4bsBlf37959yBnk63Bx+KPxXBD61Wk1jY+OYX/9DZ3z+QNv3ofB4PP0CnNlsxu12I5PJAkMLISEhKBSKUT2QQwX1OcuW8enra+moqCDiuDpJhVDIsiuvGDYYFxcX882LLzFfryNUrUFmNnOovp7gqCiijwddCYIhLaKioqL4zW9+E9icDFVKuvjqq9nwzjt8kHOA2O4uMoKMvGO18WJbK10eN1KZjKuSUzg/bTw2t5sHa2po6+nml5OyaG1opNthx4OA7VYrc1xupl10DkFBQfzit7/ljquuIstuR4CAYqeD/Q47l6u1eH1eHB4viVFROLs68Pl8BAcHk5mZSXZ2Nps3byYiIoLk5OTAwE9wcDAff/wx8+bNY9HixcycNYuCgoJeZZqSEvLz8wNedBKJBKPRSEpKCsHBwZSUlDBr1qx+fTM/Bi7kuTt2ME+n7/cznUZDgs3Hh1sOcGamHplcRnzCOLYftTHrsl5fvLfeeovinF2sOTOc+DANE+LNtLe3k5aayjsHulh/oJnqqkriNW6kQhkymQyzwwteG+1NtURE9JZjly1bhsJr5rplIQQp3Xi9XhLjY7g3XcN17+VQVVUV0JkUiURodAbqOuxEGuR8U9LG1rwaxGIJ+5ukXKRQ9OuhCwSCQBDr+3df9CVh+zdv/rJaXxuxvvBLgR04cACNRjMiZ4CBxwkKChqx/97A4/ifZ6PRSGRkJMXFxWRkZIwp+/F6vcTGxlJZWXnK/nZyuZy4uDjKy8sDRtljxUCaw48V/xWB71RLnT9kxufz+Xo1MltaAiPoAykDoaGhJCQknBaR16E+m16v5+Jf3sjhkhKam5rQGI1cOHHisMo3Pp+PHevXc054OBE6HVU2O/bSUlZpNHxSUMDEiAhcXi/HPG7mDOEV6MeJeicqlYrLr7+eLpuN5jfe4IHkVJRiMQc62nmhpYW5Uikzw8ORiERIRCJunz6TW778AkV1DUv0ehp7unm3s4PI6dM4//7fkXFcLDsxMZF/vPMOV61eTYPTSYnTyVMRUaRIJHQ4HBhDQ2iSSohPSkYgELBjxw42bNhASkoKQUFBmM1m3nvvvYBdjlgsRqFQsGvXLkJDQ3G73QFLqKSkJAoKCti7d2/AW27hwoU4HA6ys7Opr6/ntttuG/YaDMx+vH0ydY/HTU1NDcjU5LRBpluPq83G09/kkLzgEpxOJ08/9jBfbd1OaHgkFrcZkVCI7nhWXd/QgMWjRRuRyMeF+7lrngShSIjb4+O1g04WTIygtCyf1PTJNDc3A9DcWM+MMyL7lVYBkoOFNDY2BgKfz+fjjFWX8u/N/0Lg6MJu6uCcZB89dg+NHQrWvvhP/vjnJwLlyrEMWfjvY3+gGk6BRiQSMWnSJA4dOjSIyzYUhjpOXFwchYWFowo4A73uYmNjMZlMY5YR8/dY/UR7lUo1Iv7kcFAoFBgMBvLz8wNc27FCLBYzefJkDh48eEoUju8T/xWBz6/3OFZ8Xxmfy+XqZ4dksVjweDyBIZSB5a7vA8Px+ORyOZOHsAYaCt3d3Xg7OxGEhfPBvmwq6uoxd3aSqlRiEYvYV13Fwc5ORAkJp/w5li5fzj82fcaHrS2kSKRUWq10mEykJCUi6dPnaTCbiFAo2SkWku9xkTxtKndedhnz588fdA6xsbH88e9/541HHmGCUMQH3V1coFIjEotx6nS82tHOdXfdSU9PD+vXr+fcc89FpVLhdDoRi8V8tfFTHr/vPpIyMpgyZw4Wi4WoqCjS0tIGbU4iIiJYsWIFAPX19ezatYvm5mYSEhK44oorRlxumn7GGXy9/wBZIaGIhULa29vxiERUGI0s/dnPKGxrxit2o81wcLi4EFnzATKNdvTxLXxeIeGN3Q4evkCJUtqryPLNwaOUWqO44NKf8/bTZdy0qYdYrYdqk4e4iCCunp/AH7/oprm5mfT0dAAiY+I43NBIVlxv8PR6vXR0dbO3tBXd4cMkJiYGsqpV555PYUEeR756jSdWSnB7INyo4YUFafx+cw579uzhjDPOGNM94Yc/0/Ofy3D3mkKhCJQsp0+ffsJFfqjj+KkF/mGXsWSO0GvMm5OTE6jWjAb+4/knPQ8ePDhqy6C+8Hg8gY3naLPZoSCXywPXaKgs8n89vh8A/2ken9fr7Uf87usy4De1jYiIQKVSIRaLKSwsJDo6+pTGlUeK05HNymQyOmw23ty6lQUSKStDQjDp9XzR0MCenh6a6+qIlEoJqanh/Uf/StKC+ay6+OIx8ZBSU1PJWr4MRWkZdqmEBKkMzY4d1JpMjBvXyx/cXFbGpzk5nKlQECeVkudyUVJTc0J/s8WLFxMVFcX7a9eydfNmvu3qRqtWkahWcemtt5CQkMCWLVtQKBTY7XZcLhdWq5XsdetYqVCgc7rwllewISeHmDlzApNtHo+H/Px8SouKUGq1zJ4zJ0CijoqK4pJLLhnTNZ85cyYHF8zn8Z27mCmXU9/czLcWC5POO7efSsgnH28gylnG9bPG43CICRV1sXxqFNe/Uc5vP2plSrSENpOLnBop/3ztT3R2diIzRDIvKRKfuYWVs0NIiQ3l28NtKAwRtLa2Mn36dLxeL6t+dg3/+tf93KcUE62XUFxazgd5NgS6FFpbW3n44Ye56aabmDhxIkKhkMiIcGYtGkfkOHVAps7pdLAiRcLu3dtOS+ADApnfiRbXoKAgenp6TrrIDzfmP9rMcajj9JURUyqV/cSyT4a+05JyuZz09PRAIB/Lc+U/XmxsLIWFhVRXVxN3gurMSKBUKlEqlaNyc/ih8F8T+H6oqc6hKAM+ny+gsK7T6YiKikImkw37YP5/0gaF3h20XSwm3W5n6vHei1IsZqExiGyblXlaHasnTqS9vR2FUsnX2fvYbjCwdOXKkxx5MAQCAT+/8UY+X7+estw8pF4vcZMn89WB/ajy8hAIhbxz+DBPGo3oNFoiwiNZLBTwSl0ta198kdvvu2/I4/p8Pmprazm8ezcX6fXodQb22ayYPB5CQkPxeDzo9Xq0Wi2hoaG0tLTw+RtvcKndTrRIjAcBepGIi8QS9rS1Ab32WE89/DDOomKyZFK6PR4eeX0tP7/7rn4DPmOBSCTi13feScHy5eTt20djVRURDgdLjmeT/s+Us/NLrkqxUFVVhdvtprurG6VSycVTjdSHnYncYKDxwAF+c/9FFBccYvvHrzMn0klxaS1NFrC4hHyd38S39VJmnDGPq6++GoVCgcfjYc7cuVitv+OBt/5Nd2MFXVY3k+edxa/P67U0amho4KWXXuLJJ59EKBQiFktx+4RojlNWfIDLbMZkdSA2nD7rGofDERjyOhHi4+PJz88/IbfuRPw2/6DKSDPHof5fKpWSkZEROMZI2xcDj6fT6QKfZ8qUKaPOqPr2R9PT08nJyUGpVI46Ex14TIVCgdFoHLGbww+F/4rAp1arT3uPz+v19jO0NZvNOJ1OJBJJYNgkJiYGpVI56smtHzLwDVfqHC2MajUhYWEUdnSgFgqxeL24VSomSOWEq1S9N/zxIYUlsbG88c03LFm+fEy7QI1Gw8+uvhrLxRYcDgcVx47xVlsbW6qq6OnuJlEgQOD2IJCIAw/amcHB3PflV9x+3314PB6Ki4v5bP16mqqqMEZHkzF1Km8+9RQPhIYRp9EiEos4TyDkpepKivLyuPLaa9HpdHz66adUV1fz8l//SmhnFxcEh+D1+Wh0u+jo6mLyhAns6eyitbWVvbt2oSou5takpMB5zLVYeOrJJ8nMzBxkNTNafOduMAmLxcIDDzxAUVEREyZMQCAQsGXLFixmM3FxccREG/EB7e3t1NbW0NQsobSrFJVKxZIlSwgLC+OrV1/goTON6NUKXO54DpVU8tS3Zlb+/DaeXbKU2NjYQQMn56xazcozz+L666/n6gsv7KcJGxkZiVKp5OjRo0yYMIF5i87g71ve4axMNxqFGAEgkshZX9jK5fcsGPXn93q9mM1mTCZT4G+Xy4VcLg9UUk40He1f5E/EzzsZsdtoNBIeHn5KjularTZgojvSoDWUZFlERARms5mysrJhlXeGg8fjCUx++zPRnJwc5HL5mF1t/MF0KDeH/3QA/K8IfKeS8fl8PlwuFy6Xi+rq6kAW15cyYDQaiY2NPaH00Wjw/8n/zw99cAgRQhEhEil2u42Q43zALbW1qI+XgQQAPh8ahQKPzYbb7R7VNauqqmLXF1/QXFmJPjSMmSuWM2HCBHZ98glrxo9ns6kHp1BIT0c70XI5nV1dtEtl6Ax6bHYnTpeT/fv3k5+Xx1evvcbZCiUzlCp2lZfzzObPmaPRkDJAzPus0DCe2ryZK49bJV188cX87c9/Jr29g3axCKHPh0QgIFmposRhp7aqCkdYKBKJhP1ffsXloWH9HvIIlYpUX697wty5c0/5uvuhUqm4/fbbeeONNzh06BBCoZCjR48ya8nZ7KrMJiO2NwAEBwXR3NHNEYuCNdeuYdKkSQQFBfHC3x/l7PEKNEoZDqcTrVbLwpmZVNjriE5OHZKb54dYLEYqlQ5ZqhOJRIFJ3gkTJjDv3Gv51fpXWT7Oi1gAX1UKmbjkMmQy2QknCv3edv4gZzabEQgE/Saax40bF3i9f0jsZJqWfn5ebm4u06dPH/J+PNkiHRsbS1FR0QlpEicLoOHh4QEfwJEEreECul9BZbQKMQOJ5n5LJH8mOpa1rW8W+WOjOfxXBD61Wj2iHp/H4+k3bNKXMuDxeALTeaOlDIwW/5/8//yYtvQMvn3uOX6emIRO1zvscLipkWMiEZH+nbRAgA+o7uhAFxWF2Wxm744d1JeWoQ4yMm3hwiFH+aHX5fqTZ55hkVrDyqBgmru6+ObZf9F43rl4urs50t3NArGE5Lg4rm9pocnjIUQopLuzE5lczobOdsInTOCZBx6gKDeXaKGQPJmcj+w2xskVxLrd7KivZ1VoCFnG77iKEqEATx8Kxvz58/kwKJjJ8lpKgF1OB0vVvaRsvVDETpMJw5zZGAwG3C4nEsngBUMqYEhax6kiMjKSe++9l46ODrxeL4888giLl5zB1s09PPH1YWbHibA4fKw76GLK8p9xxhlnBLzs7NYejKG91JiO9nacTicKuZwghQ+L2XzS9546dSoFBQXM7OPf2NHRQWdnZ7/v9Kprr2fugsXs3vUtPo+HW6+fy/jx42lubqakpISMjAxsNlsgyJlMJhwOB1KpFI1Gg1qtJi4uLqASMxz69vuAEwY/pVJJSkrKIOufkWIkNImRSIIlJSWRm5tLQ0PDIHf40ZyLf9JTqVSOaPBmuPNTq9WkpqYGNgWjvS59g+lAmsOplFBPB/4rAp9/IMGPgWr1fsqAUCjst4PsSxk4cODAKRs4jhQ/dKnzdLzXpEmTaD3vPF749FNiRWLMXi9mvZ4Lb72Fz3btZnF4OCKPh4bWVvbabEy55Ge8+uijTHK5WWo00llRyZbcXFouuYR5AxTufT4fW9et4yyjkXHGIDweD5FKFSuMHl5+5x2cTiet1TXMDQpCKRJxU0oKvystZb5MilEq52BTI3UqJcFFRaQ6nCSIxERJxGw09XC2WsPPVCo8YglfdHXy94OHeGrBAoKOT4hua2lhxgC3gbCYaDoPHuQCrY6XOtooc7sZJ5GSbbexVyTireOUhKyFC9nzySdc1KekaXI6KfZ4uPj4ZOTphJ/07S9NxcfHU1dXx/mXXkVZWRnZ5YcRq+SIo6r4+eVX9lM7Sc6YycHCt0mO1KE3GGhva0MkEnOoWcjFw2xG+uL888/n0UcfxWKxEBcXR1dXFyUlJaxZs2bQ4EdSUhJJSUkBc9u6urqAio3fyFaj0aDX64mJiTlhP/xE6Bv8+pLbh0JISAjd3d0cPXp01GVCoN905VDDLiMJfH4TXT89YSzSaNDfNWHKlCkjGpIbTlosODgYq9VKUVHRqDmHfY15/eflpzlMnz59zCXU04GffODr7u6moKAAr9fL1VdfTVNTEw8//DAKhSLAi/u+KQOjxQ893HI6sg+BQMCys85i5rx51NTUIJfLSUhIQCQScTApiS+3fEl9fR0RiYmsvO4X5O7ew0wfTD/OYYrU6YgzGHhl/XqmTJ8ekC+zWCy0t7dTXVyCIjqahoYGRCIRUqkUo0pFnEqFcv58cta+gUMkRiqTsSg8HKHdwW6hgHyfl6XXXsuxF16gq7UNoc9HnEjEQbsDvVDI1xYLl6g1+FwuximUJNht/LO4mHNiYzlgNpHt86Hb8S2b33oLoVJJRGoqNSUlyKwWJvp83KPVc9Dp4Ag+cgQCLv/1zYGy4JmrV/PX3bt5o6KcyVodXQ47Wy0Wll599QkVcE4G/73hJ20PvG/9i/x5553H3/72N+RyOePHjyc6Opo9e/Ywa9asQRN7S5at4G+7vkS6v445yUF0OcS89MkR9BPOGjYL74uQkBAefPBBvv32W44ePYrRaOTOO+8kISEhsNHs24vzc1Ptdjsej4fk5GSSk5PJy8sj5rhQ+enAUOT24ZCYmEhubi5NTU2Eh4eP+r3kcjkTJkwYUpVlpCLQfUuv06ZNGyTFNlIoFIp+53KySc8TaWrGxsZisVhG5Lh+smPK5XIyMjL+4xKQP8nA53A4uPjii6murkan05GRkYHb7ebKK69k8uTJp+2h+r7w/22qsy+0Wm2A5+XH1KlTmTp1KlVVVSiVSkJDQ1n3r3+xrI9nn8fjQeTxordY2LZtWyC7VqlUKBQK5Bo1Kp0ObR+ektfrxS4Uct7ZZ9NQV8crn23mwuBgqqw2cswmxHI5UpGQxmPH6Glo4LGgEOI8HjweD+fI5Lx63Ii20eFAKBCgCwkhSyphs17PzuQk2sxmdHv2sryllQgfFLd3sv7wERRyORMNRp7q7CTKa8Hh81HkcjFp+TKWnHVWoP+i1+v5/ZNPsv2bb9i1fz8qo5Erly0bdH2Ggtfr5cCBA2RnZ+NyuYiOjmb69OmDFE5EIlHAhQD6k7+TkpK44447WL9+Pdu3b0etVrNkyRJWrVo16P0MBgN3PPA3vtj0MU/t241UHkTsvOXMmDl7xBtCrVbLWWed1W/gJCcnJzBwotFo0Gg0hIeH43K5+Ne//kVZWRk6nY7Ozk6WL1/OBRdcEJhMHOuiPxADye0nGnbpSwgfS0bi1wQdqMoyGv88vzSaP2j1/U59Ph9ffPEFL774Im63m9TUVK688koyMzOHPBc/PcFvPzQcTiYm7S95jmZTMNwxtVrtaRHfOBX8JAOfTCbj2WefJSYmJvBlZ2VlsXjx4jFndcPJIH0f+P841Qm9D2VHRwcul4uQkJBBN72f12Y2m3F5PDS1tqAQivB6PAhFImRSKQ4ExMXFBbhffkxdtoyd277hzMTEgDLH/ro6ZLGxfPXVV3hcLuyZmbzS1AimHhYrFESHhZE2ZQrvFBcT4/WRLJXisNkQAl6BgLPlCj60WrH7fPR4PaSFhXGku4urb76JjIwMfn/5FVwhlpAmleJw2EnTRSCt97Ld4yY+IoKpegONAmhpacbn9jDFYmPdw48QNmsmv/j1rwM8zTOWLiUqOhq32z2sT93ALO7VV1+lsrKS9PT0ALdz7969PPbYY6PqMaekpHDfffeNSPs1KCiINVf9Aq76ReBc8vLyaG1tHbIn03fgxGQyYbFYAgMnGo1m0MBJXzzyyCMIBAKuueYaRCIRVquVTz/9FL1ez+zZsykqKhrTWP5w8N97cOJ+n0QiITMz85Rc02NjY+np6aGmpiaQWQ9UbjkZ/KpAA2kAa9eu5fPPP2fu3LkkJiZy7Ngxfv/73/PAAw8wdQjj6ajjvfRjx44N8jfsi5MFvr49OoVCMaIy7I/VmQF+ooEPGDRddaqLuz8Y/dQC3+l6r9bWVja++SbmyiqkQiFOrYaFF15IbGxsoI/a2dmJQCDo9e+aNo2DO3dx3vjxgTJMRXs77vBeN++B13nZ2WfzQWsrL+UXECMR0+L2UIWPI+vXk2Z3kCmToXK72evzkh4aSnp8AinJyQiEQjIjwsmViGmw2zACYoEAiUBAl9uFUABykQivUMLbNdW0paYwf/589u3bh9bUQ5PDgdjpYJxSBQLIlEr51uKkrKWFWW43oXY786UyXnbZmaLVkB4by9rsbLalprL8zDMpLCzko+eeJ87rQQZsdnuYc9FFLFm+LDB52BcCgYBjx45x9OhRLrroon6+fOvXr+fjjz9mzZo1o/5+xtoj85ufikSifoFu4MBJfHz8SQdO/Kivr6eyspKrrroqsDAqlUoWL17Mpk2bOOecc+jq6qK8vPyE06Sj/Sz+e30o7c++UKvVAXrBWNcN/7CLXyh+LI7psbGxFBcXU11dTXx8PN3d3axbt45rr70Wj8eDSqVi0qRJSKVSXnnllSEDH/Rufk42NDOS8+tbhh1J79Dj8Qybtf+n20o/2cA3EP6x6rGm2D80xeD7mPobCqcj47Pb7ax96imm2WykBAXhcrlo6Oxi/RNPsPzGG0lKSiImJga1Wo1YLCYyMpKkpCTeNZl4s+Qw48RiOn0+auUyLrnlliEfQJlMxuU33EBDQwMtLS3E+3xk3/97lvoEXBXfK4Xm8nqJr6xkc1MTvpRUBMcXt4zwCBrEYhrFErrsNhReH06fl2ynE6NEyn0WM06BgJhJGTz57LM4nU4+WruW+sYmIoRC9rpc6Mxmrg2PwCQS0ux00tnUhE4hZ7xQjE0oQCgWYSuvwBUeztLwCNZ99RUzZs/mo3/+kytCQgk/PuBicTp59f33iIiJZvz48YFyZd/FuLS0lMTExH59GT9nr6CggBUrVvTjy51O+AdO+lIHfD4fBQUFxMbGYjAYTmngBKCtrQ2DwTDoew4JCQlMpI4bN47c3Nxhs82xoK9HnH+adTiEh4fT3d1NT0/PmN7LnyEdPHiQKVOm4PV6R732DJwWra6uJjg4GJVK1c/eKzU1lY0bNw4aJul7HP/QjFKpHFIWb6TZmVKpHHHv0O12/y/j+0/Dz+Ub66TU/0eKwffxXgOVafwuzuqGRsYnJyOVStFJpYSFh0NdHc11dcyfPx+Anp6eQJCVyWRcdfPNVFRUUF9fT4hazXkTJpxQ+kkgEBAVFUVUVBRff/UV8vY2FhuMgQVMIhSSrFYR0dlJWUcHaccHZ7RyORmpaTzf0sxZOi3qrm6qEHBILue5M84gVKXm4fJjXPv732MwGHj28ceZ0tnNeeHhhJrMhKiEbLCYebu1hT1mM3pgtkSCwOXhdbsZmV3GXYlJyL0emhsbUYaGYu3pJicnhwleX2/QEwgQABq5nPk6PYXZ+5g0adKQn1MikfTr5fnhcrmIiori6NGjaDSaU+qB9R048Qc4/8CJv1QZFRWFWq0OeKx5PJ4xB1yHw8Hnn3/Ozp07MZlMVFdXs3TpUoRCIfX19ZhMJjo6OpDL5YGglJ6ezsGDB1Gr1adNvm80wy5JSUnU1tbS0tISkJkbDfx6lfn5+QQFBY3pM/Qlk+t0Onp6egY9r93d3ScVyuibrQ03dTrSjYzBYCAuLo6CggImT5487Ov+V+r8EUCpVGKxWMYc+H5Ia6IfQ+Dzer1YrdZ+QW4oZRqVSoXFbCY8yDjo2oaq1ZT2sYMaSJ0QCAQkJiaOalLMD7vFggQBAx85jUqNrb2NRrOpl8Ds83Gwvh5tagoJqSm89vXXWMxmtEoFd2ZMotFu583mZuKWLGbixIm9+o279/CrsDB2dHfxaUsLkV4vGWIJz7W1MlOpYnVQMDq3G4lETJhVzGdOJ2EyKQ6HA4vdTllrCxMWLsTlcKCXSGi0WMhrbMTj9ZIeFoZOLsfaM7w/5LRp0/jyyy/7qbu4XC6Kioq44ooriImJobi4+ISLTl94PB5qamo4duxYgGg+cOAkIiLihJPNCQkJ5Obm0tbWNqLgZ7Va2bNnD1VVVYSEhHDw4EHcbjdz585FKpWydu1annvuOaZPnx5wOMjNzUWlUrFx40bOPfdcpFIpEyZMoLCwkKlTp562RXSkwy5AQHlGpVKNSkvTD71eT3R0NFVVVQF/ydFCJpORnp5OUVERISEh7Nu3LzAg5fF42Lp1K6tXrz7pvaBUKk/oBTiaDD4yMhKLxXJCwv2JAt//Sp0/EP4/WRP90MMtHo+Hjo6OQfqifmUaf3lLKpUOecOGhIZyaIhNQZ2ph5CJ3wkAn85BmqS0ND43GtjT3UPM8SwBoN7poCUyEo/RyD/KSvEAythYDu/YwXK3h+vHT6TH6eSN2hr+3dbC/IWLWLFyBXPmzEEgEGCxWOju6uIfR8uYJRAwSywmz27nNZsViUTC0thYdDIZarOFRIMBbXc3OY0NbGxtIU4ipdFmo9po4LfnnUdbWxtPV1dDTTWJiYkIRSJ2Hi5BaLez+o47hv1sUVFRrF69mg0bNhAfH49IJKKqqopp06YFpvM6Ojr6DU/4MXDgpKenh02bNlFWVhYo36WkpHDbbbeNaiEemIGdKDNvbm7m4YcfRqPREBkZyY4dO9i7dy+33XZbYCLw1ltv5ZFHHmHz5s0EBwej1+tZtWoViYmJfPDBByxZsgSNRoNOpyM8PJyysrJTMlwd6vOcjNzu9XoRi8WkpaUFhl3GIgAdHR1NdXU1ra2tY+YC63Q6EhISuPDCC3nrrbfIy8sjKiqK2tpapkyZwlVXXTWi4xiNRqKjoyksLGTSpEmnFICSkpLIz8+nrq5uyKGt/2V8PwKcqkPDD5nxfV/9RL9LhH8Cz1/ecrlcSKXSMeuLpqam8m1EBHuqq5kWFYVYKORYWxsHPR6uOF7mhNMb+FJSUph4xhns+vBDOhrqyVIoqLda2YaPSx94gJDwcBITE5FIJLz3xhsscrv5eUxvkIhSKnlEq+W3VZWc/fNLmThxIl6vF4/Hg9vtpvDYUSZ4vXzt9ZIslrJYLkftclLodBAWEsKkceM4nJdPk9VKuFaDpEPGq52dSDQaZo9L4Nbf/paQkBBMJhONYhHnzJpFvF6PUCAkPCKCdbt2oTmJ/dCKFSvIzMzk0KFDuN1uzj//fOLj4wMLVWJiIvv378fr9eJ2uwcNnGg0GoKCgti4cSNOp5ObbroJqVSKx+Ph22+/5bnnnuPee+8d1TWXSqWkpqYGss2hBkTcbjfPPPMM0dHRzJs3r1cmLTgYtVrNJ598ws033xzoZ2ZmZmI2m7nsssuQSCSBzxYUFERVVVXAMzEmJobCwsLTKnc1EnK7//+0Wm1AlmyswcJgMNDZ2TnijHkoREZGYjKZuPPOOzl69Cg6nY7ExMRR+/lFR0djMplOeXjIT//IyclBoVAM4qb6PQOHet1/Gv81gU+pVP5XZXwul2tQL26gS0R0dDQej4fy8vITjjqfDGKxmDU33cSWDR/zwsEcBD4fxvh4LrzuF/0GE07nNRQKhVx/220kT5rE5x98wDuNjUTPmM69114bmEQ0GAwIhUIK9uzlOr3fpLM38IoEAqYLReTl5QUI2g6Hgz/cdhvLRGIukElQCoVsd9j5yGphkUyGViJh89GjTElMJDUzg/qaWraWH2OXy8Wyn11M1tSp1NfX869//Yv777+fgwcPsnDJEoLi4qhqaMDrcaGPi2Oi2cwzzzzD+vXrSUpK4pxzzhlyxxwREcHZZ58dCGx+hROz2YzX60Umk1FTU0NaWtqggRO3283XX3/Ns88+GxgUmTJlChKJhAULFvDaa6+NqXdlNBrp7OykoqJi0KKZnZ3N2rVrOXToEBdeeCEFBQUkJycjFouJiIigtLSUlpYWwsJ69Uv9pfO+OpA+nw+LxdKvrOgf8sjJyQlMkZ4O9B12Garf13eKOyoqiu7u7jEbx/p8PlJSUigtLQ3Y9YwFKSkp7Nu3j7i4OKZNmzamY8DYeHlDwW/PdPDgQbKysvp9b//L+H4E8Pf4xoofusc30vc6mdefWq0mKioKlUo15E1ot9tPSxam1Wq5+KorcVx6ScCOZCgDz9G8l78PM1x5SSKRsGz5cpYtXz7k/3s8Hnw+HyqdlvauTpLUfXs0AtoFEH2cTCsQCNi9ezfhzS2cI5OTJBIhBNaIVPzLbKJbIECMgDwBPFdayiyjkQqTibc7OpCFhtBSWsoek4n4mBh62tr44333MWXmTKRSKVHR0UQdD2z79u0LlJmmTJlCVVUVDz74IPfeey+JiYmDBk46OjoQCoWEhoYOGjgBaGhooK2trV8JzePx8Oc//5m6ujpmzpxJZGQk+fn5FBUVcdVVVyEWi9FqtXR1dY068DU1NdHW1kZjYyN6vT6QvRw7dozXXnuNJUuWUFdXx7hx4zCbzRw+fJgJEyZQW1uLx+MJbHysVmvvUFNISL8AU1JSgkqlGhRcxGJxoM81bdq0Ie8Jh8PBvn37aG5uJiYmhqlTp550ktJf8hwq8xvovp6WlkZOTg5arXbUyjter/e0+OYJBALi4+MpKSmhp6dnzH1Df8bt5+WdCvxqLAOtlf431fkjgEqlOiUX9h9DxjdUFuf1egO9uJF4/Y30vcaKE00ajjTwOZ1Otnz6KQe+/BKXzUb4uERW/vzSYZvofj6cX43f/152ux25XM6yCy9k/YMPkqk3ohSLEQigrKeHAqGA2xYvDjycxQcOMFunw9rcggtQCYUIgJkyOe9aLSAAr0iMeMliNh47RmFdDWdHR7M6PZ2y2lq25hzEYrdzZkoq6zZvJs/pRKDVMmXKFEQiEQ6Hgx07djBnzhxSU1MxGAyo1Wp8Ph9PP/00a9asCWTkZrOZDz/8kIqKCqC3n3LdddcNGiCKiIigvb293879zTffZM+ePSxfvhy73Y7BYODcc8/lo48+oqioiOTkZLq6ukYlhOxyuXjuuefIzs4mIiKCtrY2NmzYwGOPPUZ4eDhffvklWVlZxMTEEBUVFejJ+UvqSqWS2tpa9u/fj0wmo66ujssuu4z6+nrefvttIiMj6e7uxufzcfvttw95//oFqv1i1n1/p76+nocffhiVSkVwcDA7d+7knXfe4YEHHjhpkBqu3zdw0tFPUcjJyRmxBqYffgK7RqM55bKpUCgkLCyMwsLCU5I1k0gkgUnPUw1QWq024AzhF/oeuHHw43+lzh8Q/596fAKBAJfLRXNz85iyuNHgx6gS884rryDYf4CbY2PRymSUtbfx/l//ymX338+4ceP6Bbm+D1Ffr7j4+HgqKyvJyspi+fLllB8+zC3vf8BUqRSzz8dhoYB7nniiXyDRGAxYAJ1CQbnNRrDXi1wgoMTppMbtQiMWc0lQEGWfbWZX+TFu0RsJFghobWwiUiLlmsgo/nb4MFHh4STrdYQ4HNQrlaxfv560tDQaGhoCwRjAYrEgkUgCMlkzZsxAJBJhMpn461//SkZGBsuWLQOgqKiIhx56iCeeeAKj0djvM6elpXHw4EF0Oh179uzhpZdeYvbs2URFRfX2GRsb8Xg8jB8/nkOHDlFaWspZZ501qGRotVrJzs6mra2N6Ohopk2bFihDfvDBB5SXl/OLX/wCyXH39B07dvCHP/yBF198kaampoBs1ooVK3jzzTfp6OhAqVRSWVlJe3s7//jHP4Dejc3EiRMDn6O6upqamhp0Oh0TJ0484T0dERFBV1fXIAugZ599lgkTJjBlypTAz3bt2sUrr7zC3XfffcL7bTgnh6EEK2QyGRMmTAhkNyN9/voGgaioKHp6eqisrGTcuHEjen1f+CsqYWFh5OfnM23atDELa6hUKpKSkigqKjrl0mRoaCgWiyXgTfhjxo/HC/57xqkGvu8rQLhcLjo7O3vdvw8fJicnh/z8fCwWCzabDZ1OR2pqKtOnT2fKlCmkpKQQGRmJVqs9LWWE0zlwcjreq7Gxkbp9+7goKQmtTIbP5yPJEMQylZqvN3wcKJcJBALEYnHAC04qlSKTyZBKpUgkEkJDQwMu4AKBgJtuu42n131I+l13sviBP/Lm5s3MmDGj33svXLaMzd3dmEVCXEIBbQIodbv4xmFngkzOvOgYlqamcpbNRpYX9EoFYqcLr92OwO1CKRYRKhSx8+AhMpRKwuwONHI5kyZNor6+nu7ubjQaDZMnTyY0NBS9Xh8wS5XL5YHFa/v27YSGhgYyRX8fJTo6mm3btg26ZhKJJKDtuHbtWjIzMxGJRIjF4sBEbmtrKzU1NVRWVrJy5UouvfTSfseoqanhnnvuYceOHTQ1NbFp0ybuv/9+2tvb8fl8fP7555xxxhmBMpZAIGDBggV0dnayZ88e4uPjqa2tBSAsLIwbbrgBg8HQq4Cj1fLnP/+ZmTNnMnPmTObPn98veMfFxTF//vzAeQ9EZWVlgBoBvf2ppqYmurq6gN7ya319PVlZWf1eN2PGDHJzc0fU2/dzB/0OFzC8sLRfj7OkpGTEz85AybLU1FTa29tpbW0d0ev7wn9ewcHBhISEcPjw4VEfoy+0Wi0KhYLi4uJTXgvi4+OB3s3Mjxn/NRmfWq2mqalpzK/3l6rGCp/PN6gXZ7fbh8ziAPLy8gI30feJH0PG539/r9dLdXU1cWIx+MB7/HcFAkgODubLygqkUumId7fJycnk5ORgNBpRKBQB8vtwyMnOxu128WpXFxMAs9PJbocdsUjMkuQULs+aRPGhQwjMFjLEIvZ2tHNdRBR5zU2YZHI6TCaKGhuYk5zKZEMQO009TJ89m+UrVgC998Bdd91FaWlpYEfs8/nYvXs3CxYsCGQeNTU1Q5Yho6Kihl1Q9Ho9Pp8Pp9PJsmXLeP/990lPT0ehUKDRaBCLxfT09PD3v/+dyZMn93utz+fjhRdeYMqUKaSlpQV+np2dzTvvvMMvf/nLITmw/pJbfX09M2fO5B//+Ad6vZ7k5OTAJmTy5Mn87ne/O2k/y+l04nA4UKvVgetgNpt57LHHOHbsGOHh4TQ2NpKcnMy9995LRkZGoKzmdDqRyWSD7gt/73YoMYChMJDcPlypDnonTbu7u09oPtsXA4NoX+1LpVI5Ko5g38wsPj6ewsJCampqRnQew52b/x4Zaxbqh38Q6eDBg8Ne9/+VOn9A/JA8Pr/sU98/Xq830L/xE4blffhnfdG3V/V944e8Cf1DO/6hk6F0Ko1GI60eL0KhoJ+sVEt3N4bQ0FGVdMRiMampqZSUlJxU8Li1tZWv3nyTf06dhsfn41BLC/U1NYiamqn3ecno6mL3li8JFUC4SEy5QEBeVzfm4FCmhYWRU1NDnknArIRx3DF3DrnV1Rx0ubhg1qx+n+83v/kNf/3rXzl69CgGg4GGhgaCg4O55JJLAr8XGRlJbm7uoHNsaWk5Idk/NTUVk8lEcHAwU6ZM4d133yUlJQWfz8e2bdtYuXJlgCzeF42NjXR3dw/qoU6ZMoW1a9fi9XqJjY0dtCharVYaGxux2Wxs3LiRCy64gL1797Jjxw4EAgFTp07l3nvvPWHQs1qtvPLKK+zYsQOfz0d4eDhXXXUVM2bM4Pnnn8fpdHLdddcF7p0vv/ySF154gTvuuIPk5GSKiorIzMxEIBAM0qI8evRooDoyUvQltw9l+eTHQDmxkzm+DJU9SqVSMjIyRs0R7Ct/1ldPVa1W98ukRwp/NuovmavV6jEp1fjhH5zZsWMHJpPpP+q7Nxz+awLfqdIZhurxDZfF+WWf1Go1ERER/abwRoIfw47oVDGUZ5z/evlLlX5Lnb46lWlpaXwWF8ve+nrmHJ+ENDkcbGluYv4tt4z6PAwGAxqN5qQ786KiIiaKxMgFQlweF+Fd3UR7PGQFG7mztpZgqxW5x0MbIJdCnVBAkk7P3VUVzAkKYr/LhdNoZGF4GE8fPYrdoGfJuasHBfeYmBj+/ve/c+jQITo6Oli9ejUTJ07s950vXLiQTz75hNLS0gDVoqKigqNHj3LDDTcM+xmCgoKYOnUq27dvZ8WKFaSnp7Nnz56AzZPD4eCXv/wlZ511Ftdcc00/6kNfHp0f/oXY4/Fw+eWX8/TTT7No0SISEhJoaWlhw4YNdHV1UVdXh8fj4ZVXXuGcc87hzjvvDJSfTwSfz8ef//xn3G431157LQqFgsrKSp566iluu+029u3bFwh60PsMLl68mJdffpkbb7yR4OBgurq6qK6u5tprr+X5558nKyuLiIgIamtrKSws5J577hn18+QveZ7MUcFfgj506NCQMmB9MVzZVKvVEhcXNyLrID88Hk+/9+pLKZg8efKoqRL+DNIvj+af9DyVgOVfAwsKCk5pAOf7wn9N4DvVqU4Am81GXV3dmLK4nzL8fZHhsjg/R8qf4XR3dw+rYCEQCLjmttt46/nnyS4rRScW0wrM//llg3pyJ0J5eTkb3nmXqsMlhMbEkDRpEueeey4qlYru7m527dpFe1sb4RERhIeHc+zYMdrMpt7NkQAsnR2MV6o40t5OiETKK2YT8+Ryalxu3rWYCFGpuVmt5jmHnRqbDYXRyIzFi1l5+RqMRiPx8fHY7fbAg993Ny+VSpnVJxMcCIPBwKJFi3j++ecxmUwolUoSEhJ48MEHT6r8cdttt3H//ffz4osvEhcXx44dO1i+fDkrV65ELBZjs9n48MMPiY6OZvlxGkhUVBQ+n29QxuQXy1YqlUyfPp077riD9957jy+++AKFQoHZbOaee+4JlOkyMzP56KOPyMrKGtIfbiCOHj1KbW1tvyA8btw45s6dywcffIBMJhu0YMrlcmQyGSaTCbVaTWJiIocOHSIpKYnf//73bN68mdzcXOLj4/nTn/40pvKfvzza09Nz0mdZoVCQlpYWGHY5UaAc7liRkZH09PSM2Oh1qCDaVxd0tFSJvqVTvy2T/zgn27yc6JhSqZSEhATy8vKYNm3aj4ra8F8V+EaS8Q2XxUHvlxkUFERERAQqs+MZMgAAeKlJREFUlWpMPJz/z+ibxQ1VivUbog7M4vrCz4UyGAzDPlRBQUHcev/9NDU1YbFYiIyMHNUutqCggEdvvZVzpVKWa7VU5Oby3jfbaW5qIiw8nM2vvEKWUESwWMxXPi+GadP41R13cPemTbS43Tjr63CazPTY7HzZ3cUKlYokgZAar4e9HjdLQkIps1qotNlo9XhIDY7kt5MmUdndzcEdO7jxuByZUqkkNjaWsrIyJkyYcJKz/g7r1q1j8+bN/OIXvyA4OJiamhp27NhBY2PjSafljEYjzz33HJs2baKgoID09HTOOeecwP8rFArmz5/Ppk2bAoFPJBJx1VVX8eKLLzJhwgRCQ0Opq6ujvLy830TklClTAlOTb775Jk1NTf16U0FBQaSmpvLVV1+NKPDV1NQQERExKCDExcWRnZ0NMMidoaWlJcBrhO/UQ/wE6t/85jcnfd++GCjW7XeH92vS+jcFJwqAQUFBvRqvR46M6nvui5SUFA4dOjQiUYHhLIT0ev2IjWf7YuA0p1qtJjU1NRCwxjIx6j9mUFAQVqu1n0TajyEx+K9ZuYea6nS73Vgsln4SXv5R4YFZnM1mo7y8/ITDET8lnCyL6xvchgtyQ0EikZCYmEhpaWlAkmooCASCUctTuVwuTCYT/3jkEdaIxGSpNODxEqLVESOT89D69Ri0Wu4bl0S8rrfvc6HPx0v5Bez69ltu+P3vuevKK5nn9iB2OVlnNiHHxwKhCLFIiMrlJUciYZFWS15XF26JlGCZjMvVGkxlZahkMo5Ze+8jP1UgIiKC1tbWQQuaz+ejuLiYyspKgoKCAsRfh8PBW2+9xWWXXRbgn6Wnp6PX63nllVdYsmTJSa+1QCDgrLPOorq6eshF1Gg00tHR0e9nU6ZM4Xe/+x1bt26lqqqKuLg4rrjiimEzTIfDMYgc7s/qy8vLcTqdJ80WQkJCaGtrG/Tz5uZmoqKiWLRoEe+88w6LFy8mOjqauro6tm3bxhVXXNFvoZZKpYwfP56ioqIAh2woeL3ewPPu/+NyuQJlPb+2aN+qjb/keTInh/j4ePLz86mvrx/TGuHvi+Xk5AR4ucPhRCVYP4VlNHJkQwXS4ODgIY1wR4q+cmUxMTFYLJbT6q94qvivCHxer5eOjg66urq45557cLvdXHLJJYE6tEqlIjw8/IRZ3A/px/dDw9+H8we7gaRdf2DzP2ynasYbGhpKU1PTmL3WhrLUsVqtiMViRCIRrVXVzElJRSwWBz5LilqDoakRXU8PUcrviMdCgYAVEeG88P77BEVHo/N40Go1HLaK6XLYOU+mQCsUcsTtYb3NSoJIzM6GRhrtdj73+bjYGIRWJCRco6emq5v2xkacTmfg+AKBgPHjxwd4djKZDIvFwsMPP0xDQwMxMTF0dnby4osv8sgjjwQW4oGk6+joaCwWCx0dHSPSevT3w7744gvOPPPMfgvbsWPHhhR8jo2N5ZprrhnRdzBlyhReeeUVJk+eHDi2z+ejrKyMpUuXUlxcfNKsIzMzE6VSyZ49e5g5cyYikYiOjg6+/fZbbrrpJmbPno1KpeLDDz9k06ZNREdHc8MNN7Bw4cJBx9Lr9YSGhlJWVkZaWlpA7KHvPQK9G+CTucP3hb83fTInB7+It998diwuMH2HXWbMmDHsWnQyQ+zU1FQOHjxIc3PziESxhwukcXFx/YxwR4OBqi1+ibSGhoYxT5+eTvxkA19zczMPPfQQhYWFmM3mgMJFRkYG06ZNIzU1dVS7mB+SwP59oS9toC/5WygUYrVaUSqVY8rixgL/BJlerz/h4uPxeAbt0t1ud2CX7h8g8kukORwOxHIZTkGvy7ofPp8Pk9tDklFNd3c3QUFBgc/vsto4kpPDqu4eFiiVrFaqSTNbaQoK5t2ODt6ymgmTSLgwIpKa9g7ed9rpxMfPFQr0QFtLK1Ex0ZiFQtp6TIMm/KRSKSkpKZSUlJCVlcXatWvxeDz9elt5eXk8+uijPPTQQ5jNZlwuFxKJBI/Hg8PhwOl0Bly3R4qJEycyadIk3nnnHVasWIFWq+XIkSPs37+fv/zlLyP/soZAVlYWcXFxbNiwgczMTIRCIYWFhRgMBlasWEFVVdVJdS0FAgF//OMf+fvf/85LL72EWq3GYrGwZs0aZs+eDfQO+gwV6Pzw+Xw4HI7AfdHS0kJra2s/yyW/fdZYekzDkduHglgsJjMzM2D7M5b+mEajCbi/D2c7dTKiuUAg6EeVONmQisfjGfIZ7KuRqlKpRrVJHXiOAsF3ZrhjkXw73fjJBj6NRsOaNWvIyMhAq9VitVpZtGgRl19++ZiO90Py3eC7ybKxBh9/9jbUOfvJ3/7glpycTEVFxYj93U4H/I3vsrKyQN/K4XD026VbLBYEAkGg7BwaGhpwXBgOMpmMGUuWsGHnLtbExAY+z9bmJkLSUmkym/GIxJjN5sCC8EVREfMio1gSH8+btbXoZTKSFApEdjsvZGTy79oaDtisvN3Zgd1pJ1ql4lyFkjyHA7xeBECJSESOSEjkuIQhr2FQUBBtbW3U1NTw9ddf9wt6QEAKq6enh6ysLL755hsyMjICPa3t27fj9XpxOBwBqayenh42b95MTk4OMpmMxYsXs7iPBBvAAw88wN///nc2bNiAw+EgIyODP/3pT6dcchIKhdxxxx3s3LmTPXv24PV6OfPMM1mwYEGgnO3f2Jxo1D8kJIS//OUvNDY2YjabiY2NHXYC0O8R2XcT5HQ6+wW5rKwsiouLGT9+/GkXsx6Jf59KpSIlJYX8/PwTll1PhPDwcHp6ejh27NiQ4vEjWRdGM6QycEq0LwZOeo70mg4VnMViMVlZWWMemDmd+MkGPqVSydy5cwP/lslkp0RA/6EDn1/r7mQYjjbQN5s7WRZnNBppbm6msbFxVPqNY4V/AfP5fHR1dZGdnY3P5+tnqRMcHIxSqRzTwnHDbbfxx6oqHqiqJE0opAao12p45PHH2bd7N8+8+hoJDgcRUilHOzr4pLWFxydnEa/TYQgKYl1HG4vlcgQWC+VmM2aFnIdWrKCpqIjXS4/wYHIqVQ0NzNNAns1KtsmExOtmdtpE5MuXDXteSUlJ7Nu3D7vdPkjnUSAQBPrQd911F9deey3ffPMNKSkpNDU1ERkZSVhYGA8//DBPPfUUJpOJ+++/H4PBwPTp07Hb7WzcuJHCwkJuu+22wPcvlUq5/fbbycnJYfLkySccuR8tRCIRixYtYtGiRYP+TygUkp6eHiCZn2yxG9jP9XNh+5YqvV5voFQZFBREfHz8kMc9mZj1WHAiJwe/o4RCoUAkEhESEkJ3dzdHjx4lNTV1TGooycnJHDp0aMhy5UilxdRq9YiC8MmOJ5VKyczMDEwojyRwDXdMhUJx0vLyD4GfbOAbiJPt1H5s8BN2B4rmDhw48Qe5vrQB/2tGEzSSkpLIyckhODj4tO7IBvZa+gpr+8s6FRUVzJgx47Q9EAaDgadffZUDBw5QXV1NalgYs2fPxufzcayqijKRkAKPm47qBmIkEs5Sa/h4335aJ07kF9On81FxMU/W1FBmNqEUC1mVnkG7zcaHVgsxShVhcjnCsDAqmhqZqVASIRSyHgGN0VH88txzhz0vkUhERkYGoaGhHD58OOCiDdDV1UVHRwdJSUmBa3PRRRchlUoJDQ0lPDwcr9fLSy+9REVFBYcOHUKr1Qa0PKG3J/Pmm28OcsX2S5r5hz9+qOdAoVCQlJR00n6fv1Tp/2O1WhEKhYFMf6AjxcngF4L2X+PT9XkHOjkAbNq0iTfffJPu7m5kMhkXXnghl19+OYmJiQHbn5CQkFFv4PqWBlUqVb9MazSVIL8v5IkmTkcSSDUaTcB4diSZrNvtHnbT8WNYh/9rAp8fJxtN/jHA339zu91Dnutw5O9TwUinLYfDcGPhYrE40IuLjo4edgE7evTomEfBh4JIJGLWrFn9+HLPPPMMLS0tXPbzn+NqbETv9fL5zp2Yq2s4WyTi1UMHcfp8nJOWRqTeQEhYCKvXrOFYURFOlYpVS8+g4MmnqOjqIlihICYklKOdnTTqdIRPmcxtDz10UsV+fwn+n//8JxaLhXHjxtHa2sqePXu4/PLLA7SNlpYWLr300n6bAaFQSEhICM3NzeTm5g4aUBGJRIwbN47CwsJBKiwGgwGDwXDKklSjRUhICB0dHb1SdHFxg0qVDocDmUwWuEdCQkJQqVSn/IxGRkYGyPVDqdWMFX2dHD777DPWrl3LqlWriIyMpL29nc2bN2OxWLjpppsC4uNDyamNBH4Bc7+yi/9eGK2YdEJCAgUFBdT+X3vnHedYWbb/K5NkWjLJ9N5777MNdmFd2tJZEaQIvIA/BAURBQVRQXxVRFDRlSK+KihIFRBY2i512WWnl0zvk0mmZEp6Ju38/hifYzKTzKSf0X2+n49/OMw+J5mcnPt57nJdU1Mu/xbuxiPWQkSoidXURp+RzWbbckPrjpw0gS8QwS4YAdPd2EB4eDg0Gg2SkpJC1nCSnJwMpVK5qUu0zWZjZxzJA4zUCUiq0rHhZDNSU1MxMzODhYWFoBW9dTodPvnkE9x4440YGxiAZGUFYQxwZm0t/m9wENssVmSZzTjS0oIXOtqRXN+An919N5KSktDQ0ABg1U2h6513sGRagUGnAz8qEsVlpRjRqHHpDTd4bFNzxhlnwGAwoKOjA++++y6Sk5Nx2223Yfv27ezv5ObmYnx83KnGY7VaoVAokJOT41aJyGQyuW2AycvLQ1tbG+Lj4xG7iQO8v5B7hNwbo6OjmJ6ehlgshkQiQWxs7Drz3EBDuhslEolPXZaucFS7efrpp3HhhReyadqEhAQcOHAATz75JK6++mpIJBK22cXXLEpMTAwKCgrQ1dXFyu55u3lf23G6tua6mUKNI47aoDk5OW5/byub0AInUeAD/u3bxtWJb6OGExLYSLqyqKgI7e3tSE1NDekNVFpaira2NsTGxkIgELBpKPIQ0+v1CAsLY2stKSkpmzacbAZp+e/o6IBUKg2KMIBarUZ0dPTqTKbBgDibHaLwcESGRUEUEYlSIYPPbVbsKilGY1o6/qLXrfu7i0QiXPWd7+Dvv3kUOZGRiObxMKjVovLcc1FYWIjR0VHExsZuqpfI4/Fw9tlnIyUlxa1Z6lVXXYVHHnkEERERyMrKglarxfvvv4/Gxkakp6fj9NNPxzPPPIOCggL2oapSqTA+Po7bb7/d5XXDwsJYdQ9PTFo9xWw2O53i1t4jaWlpyMrKQk9PD8rLy91eV6fTYWhoCLGxscjNzfX7e0pSy57WGT2Fx+OxG7+17uUikYhVKJJIJBCLxcjOzsbw8LDPz56UlBRoNBoMDQ2xEnbersPn81FbW4vW1tZ1XoLeBCnHIEq8D11BA98WgjS4+OM47El+3d3YAOD58HdERAQyMjIwOjrqsrMr0Dh2zEVERODYsWMQCASIiIhgay3+NJxsRmRkJLKysjA8POzkEBAokpKSsLKygqWlJdgYBlrGjgQAC2o1eCYjIiIiMWS1Yl9iIorS01EzPIzW1lanGhoAlJWV4e5f/woymQwrKyvYk5uLzz/6GL//7veQLOBj3mJFzrYmHLj66g0bSSIjI5Gbm4uBgQGnWh/hlFNOgdlsxp///GcsLi6Cz+fj7LPPxg033AAA2LVrF3p7e/HMM88gNzcXZrMZU1NTuOmmmzY8NUdFRSEvLw99fX3rzFw3g6gaOQY5k8kEoVDInvRzc3MhEolc3iMFBQWQyWTrDFgZhsHTTz+Np59+GomJidBoNEhPT8cDDzzgd7OVp3VGbyEp+6WlJcTFxf17NOZfNmOOASEhIQETExN+DXAXFhaira3NL4eZyMhIlJeXo6Ojg/V+BLwPUqTTs6WlBVFRUS4zDButuRVKTSdV4CPpIV8DHxlid/xSO57iXA1/O44NkJ95SmZmJlpaWpyUQAKBu4YTUkTPzs7G6OgoSkpKApYi8gTiSrC4uOiTyvxGhIeH4/zzz8crr7yCguxsiCIicWJuFp8fPYrCFQseNa0gPVqEmH/VJaL+NRPoisjISDb9eej116H94AN8vbAQ4QIBrDYb3m1tw2sCAS6/7jqnf2cwGDA4OAij0YiMjAxkZWVBpVI5uac7snfvXpx++unQarXruuF4PB6++tWv4uyzz0Z3dzfCw8PR1NTkUQozJSUFCwsLUCgUblVGHFVONBrNuvlJiUSCjIwMr7Rpk5OTsbi4uC5N9u677+Lll1/G//t//w9SqRR2ux3Hjh3DHXfcgWeffdbvjVZSUhKWl5cDWt8UCAS4+OKLcejQIVx88cWIjo6G1WrFoUOHsGPHDqfAZ7fbIZVKsbS05JEkmSscm138mScm/oyOEmK+nM4iIiJQVVXFjkusPcW7a27ZCkEPOMkCH2kX96WORAKexWJZd4oDPBsb8BYej4eSkhL09/f71I3nT8MJMab0x93ZW8jALBkADlSqZGFhAc/94Q8YaWnByvw8Xm1tRSTDICUyCikrZqRGR2JbXDyeWV5GSVw8LDYbOq0W3LhJs43VakX7e+/hxtxchP/rSy7g83FGXh4OHj8O7Re/yM4Kjo+P4+0//xk5VhtEPB4+tFgQU1WJcw4cQGdnJ2JjY12eEHk83oa2OtnZ2T4pYZSUlKC5uZlVk3FMZ69VOfFkftJTiouL0dLSgtjYWHZT9fe//x1nnHEG+//DwsJwyimnoK+vD21tbWhsbPT7uqTLMpB15GuuuQZ6vR5PPPEEEhISsLS0hKamJtx5551Ov0eaR8hQuUgk8kqIgEBm8z777DOPJOHckZmZCa1Wy4pi+zovLJFIUFBQgM7OTtTX1zutQVOdWwhPhao3azhJTEwMqITXRkgkEsTExGw6Y+dJw8laHcKNIPn7iYmJDdU3Ak1kZCQyMzMxPDy8rjPRF6xWKx798Y/RsLiEq4uKISgpRZtSifuPfYadqSmoj41FW28ffq+ax9ll5eiamkKrzYqCffs2fN8DAwN4/x//QO9nn2EoLx+ZBQVI/te8VbhAAElYGOtFZrFY8PYzz2B/XBxSJKsP9yaGwbs9MnTm5aGkrAwymWxTz0B/cVQ50Wg0EAgErEO6o8qJWCwO2j1N5vu6urrYOuPs7KzLE29iYiLm5uYCet22traAzTMKBALceuut+MpXvgK5XI7U1FSXEmGkecRX/z1HxGIxIiIi2GYXXz8n0vgTExOzoeHuZqSkpECn02FgYMCpy5gGvi3E2sC3mdvA2rGBoqIidHR0IDU1NWSnIGB1t9rc3MzO2IWi4QRY7eBqbm5GcnKyTztUX8nIyEB7ezuWl5f97j7s7OyERDmDff9qCgCAhvR03FrfgOMpyZjIzoZ0507kjI7i0+Fh8GxWnHfllbjkkkvcBqHu7m6887vf4QuxcViMjUOEVovx1laYq6qQmZUFrckEdRifPVmMjY0heWWFDXrA6r1Vn5aGI59/jh27dkEikfikiegOT1ROiIC2yWQKyCbDU4jNUm9vL6qrq1FcXIzh4WHW+YG8/omJCY9sejwlIiICpaWl6O7u9llVxRXk9Oquec7xRCWRSJCdnY2enp51tU5PsNvtCA8PR2xsLDsg7wvEAb6lpcVvKUYiseY4LkED3xZjYWEBFovF6WeeNpxERkYiNTU1ZKcgx4dXVFQUjh8/DqFQGLKGE+LK3N/fH/TTiCOky5PUD/z5As3OziLHxb8viY9HH5+P0849F0///OdosNmRlpGJIb0eh198ETt37mRP2OPj4zj63ntYmplBWkEB+lpbcXlKKjJjY6GvqsRHrW3YJ47BRF8f+BIJ3lUosOOLX2TnmKxWK8Jd/O0iBAJYDauOIQUFBWhpaUFCQoLXBqD+qJxkZ2ejo6PDZ8FwX0lJScHS0hKmpqZw3XXX4a677kJ0dDSKi4uh1Wrx3nvvoaysLOABOS4uDklJSX4FDVeQMQNXyi5rU4kZGRlQq9Wbapm6gqxVUFCAjo6OdR6K3kBOoMeOHWO1YX3BsdMzOjoaCQkJbgMfrfFxwMrKCt5++23s27fP51pcdnY2Tpw4gdTUVL+6Q9eyUcNJTEwMMjMzMTExgfz8/A21DwONVCqFSCTasBEiGERFRSEjIwMjIyNsC7cvJCUl4VObDZNqNSx2O3KkUgjCwjCp0SCpuAHP/e53uFwiRcG/mmmaACQMDuKPv/0t7v3pT9He1oa3fvc7nBotQmNMDAaPHEHrZ5+horAI0wBEsbGoKivDe1OTaJ9RomRBhX1fuRqn7N7NvoasrCx8bLPDaDYjyiH4DMzOImf7qrluWFgYysvL2bqqu2DvSuWEuIz4onLC4/FQUVHBzrsFe+jYYrHgzTffxOHDh2G325GVlYXrr78eP/nJT3Dw4EG89NJLiIiIwHnnnYebb745KK8hJycHXV1dHrsXeIo7JwdXNTTiS+mtYLNjYCUD8mQ20hdiYmIQERHhsk7nDY7jEnV1dQC2TpBzxUkV+P70pz9hx44dmJ2dRWZmpk9rEFHnoaEhj8w217JZwwkJcq4eXtHR0eju7t7U6TnQFBYWsqnWUKoxZGZmoq2tDWq12ufuUqlUilcmxvH+5AQSxGKYdTrsz8xEbxgfF9TVYeHECeTmF0CpVEKtWoAgXIj65GS8/S+vvDf//GdclZ6B1H+dwnhaLU41m9E1OopbSkuxvLAIrdWCyxoaYM6cx9d/8pN16dmYmBjU7D8H/3zzTdRKYyGOjMTY0iLGxWJc6qAnKxaLkZ6ejuHhYRQXF2+ockKaToijhj8Q9wiZTBZUoXKbzYZ77rkH8/Pz7D3c3NyMW2+9Ff/3f/+Hv/zlLzCZTAgPDw/q/U2aqFpbW1lbskCtC6x3cnAV+BxTjWvn6jbCca1AuEEwDAOhUIi4uLh1dTpviYyMZPVZfdEnDSUnVeCLiIjAAw88gO9///v485//7PMXPCEhAXK5fNMOMUf1CkcVC18bTqKjo5GcnIzJycmA1YI8QSAQoLCwEAMDAz4Fe18hKU9fg71er8f999+PA1/+MmKiorCi1WJpaQlPvP8+vvv97yMzMxM2mx3dLS0I1+oQHy6ExmJF19gojFFR6OjoQKRWi9SM1U2SzWaDYngYp6am4aB8CjbwkBITA4Fej1ePH0f2ZZe5rUnu3L0byenp6Pn8c5i0WqTX7sXlTU0Qi8VO94lWq8Xs7Czm5+fZppO4uLgNXQsCQUJCAist5sm9tby8jNdeew0tLS2QSqU477zzsGPHjg3v488++wxyuRzXXXcd+1kWFBSwM3xf+9rXAiqivRFCoRAVFRWsmHWg6lGunBzcdU1GRESgvLzcq5T+2hSiv24QpCaZn5/vl5EuQSqVIj8/Hz09PS7rnVvlFHhSBT4AOO+88/DYY4/h6NGjOPXUU31eh9xscXFxCAsLc0pB6XS6oDWc5OTkoLm5GSkpKQFNtW5GUlISlEplyGtB0dHRSE1NxejoqNfDv59++imSkpJQW1sLAOwoikAiwcjICM4//3yMaDWoUS2gMj4O/1AoMarVYNlsxphAALvdjvllNRi7HbywMBj0ekTa7chOTIJVNY8/zSqRHR6BWasVzXYbDl72pQ1fT0FBAavCotVqMTY2xt4nJFWZnp7OpuJKS0tDauFCrITi4uI2PGEvLCzg5ptvRnJyMsrLy6HRaPDQQw/h3HPPxY033uj2333++ecoLy93ejjzeDzU1tait7c34Lqam0GyK319faioqAiomLVjvW8jLcy4uDikp6ejt7fXI0FtV0GUCFH7cmJzTJ06KrL401SWmpqK3t5eDAwMBEWMIhCcdIGPx+Ph4YcfxjXXXIP333/f65Zix4YTPp+PY8eOISwsbJ3QbjAbToqKijAwMMA+0EMFMY+Ni4sLiqyYO7Kzs1mvOm9qGbOzs04ncrLpSE1NhUwmA5/PR3xqKt6WT+OFvj6cJhDi6uho6EUizAoEeOeppyBKS8Ox0VHsKiwEXyCAhWFwfHkJZ9U3YE9pKVQ6HSoEApi0Gqdg4U7lxFPrpYKCAvT19aG6ujpku2QiaUbsZ9x9xs8++ywyMzNxzjnnsD8rLS3F448/jvPOO2+dxRAhOjoaS0tL635uNBqRlpYGhUKB2NhYr5t7/CEjIwPLy8uYnp72ufzhCmJjZrfbYbPZNvy+ZGVlQa1WY2pqatOZTHdNI3l5eT6d2BzXI355bW1taGho8Pn0bbfbERkZCZPJBLlcHtC/a6AIXaFoC1FaWordu3fjL3/5y4a/R+SHJicnIZPJcOLECZw4cQJjY2NYWVlh9QTr6upQX1+PoqIipKWlBXUOClj1zxMIBAGbcfKU8PBw5OTkYHh4OKTXJTWZvr4+rzwRc3NzMT09ve7nk5OTbJt8WnIy6ktLkBQZher4OIjj4lCVmYVScQxOC49AXlkZXjca8Le+PpxQKvH6igkf22w4t7oaaRIJKtPSMKxeRsH27ZiZmUF/fz+am5vx+eefY2hoCHq9HlKpFGVlZdixYwcaGhpQXFyMtLQ0REdHQ6VSYX5+fl1NJDk5GUKhEEql0r8/npdER0cjJycH/f39bn/n6NGjbAOD478jJ0Z37Nu3D93d3dBqtezPjEYj2tvbcc4556CyshIymQxWq9X/N+IFpaWlUCgU0Gg0AV2XqKJsJgJN7m+FQuFyY+CIu7QpObFNTk5CrVZ7/BrXBtKoqChWN9fXMQfi6F5VVQW5XO70nmiqk2N++MMf4tRTT8WBAwcgkUigUqnA4/G8bjgBVi11fLHy8Yfi4mK0trayQTBUpKWlYWZmJiAzdt4gEomQkpKCsbExj2e7duzYgWeffRYfffQRtm/fDqFQCJlMht7eXjYlV7V7N95ubsGOWCmK/iUztWK1QQMGNRkZeGthAff+6ld46623MGOzIS49DcNdXfj1ic9RIBJhwrQCfl4uLigvh81m8zilPTk5iWNvvolIrQ42hoE9IR6nnn++0yC3o8oJsSsKBWlpaaykmWOrvFwuZzd9ZrN53b/brCW+pKQEl19+Of74xz+ipKQEPB4Pg4ODuOCCC9immpycnID76G0Gn89fN1TvL0TyTaPRQKVSbZqpIMoum522NkqbCgQC1NTUoL29HY2NjR7VhF2dIOPj45Geng6ZTOa1niuwOl7D5/M3FMbmGt4m3TdbuzXHB4xGI3p6etDZ2Ylnn30Wk5OTAFatYr7+9a+zgc4bDcKOjg7k5OSEdMwAWH0QGQwGv9r9fcFgMHDSXWq329Ha2orS0lKP02ELCwt46qmnWJf34uJi3HjjjezfbGVlBffecQfsH3yIm1NSYLHbobLZkVFaikGzCQPl5Tjv0kvx8nPPQdvaioYYCcKFQrQsLYFXVoqrb7wReXl5Xj0clpaW8M4f/4jd8QlI/NcDUbG4iM9NRlx4441OQW55eZkd7g7l39pqtaKlpQXV1dUICwvDj3/8Y5w4cQIZGRkYGhqCyWTC97//ffZzmJ2dxd/+9je88MILmz7k5XI5Pv30U9jtduzcuXPdLJtMJoNUKg15imxubg7T09Nei1nbbDanlDaZoyR1W7FYjNjYWAiFwk3XXVhYwPDwsNvv1szMDPR6/YabP5VKhdHRUY/kBpeWlqBUKl16YcpkMlZswBt0Oh1GRkZQU1MDYPUe7uvrQ1NTEyIjI0M52O72j31SBb7PP/8c3/zmN1FZWYna2lpUVlbi7rvvxm9/+1u/TFC5CgQMw6ClpcWrQBAoxsfHYbPZAqqs4Qk6nQ69vb1ea4iazWZYrVaXJyedTodvXXstdqgWUBUXD0msFPNmM55bXMSXvnsXRCIRPn78CZwnkSAtJQURERGw2e14ZnAAu2+7zaW7wkYc/+RTCFtaULmmkaN5fBzSs85E1ZrO2ZGREbbzLpSo1WoMDg7iww8/hEwmw4EDByAUCmGz2fDss8+it7cX5557LmsndOedd+ILX/iC39e12WxoaWlBeXl5yO/rwcFBCIVCtw97i8XCinY7qiaRWToS6NY+3Im+79rhdleMjY3BaDS6fCYpFAqsrKxsGow2WsORhYUFzM/Pu2xCsdvtaGlpQV5enlcNbaRe6fi9UCgUmJmZ8VmqzUdo4HPHZ599hh/+8Id49dVX/QpaIyMjEAqFPgkG+4NWq0V/fz8aGxtDmj8nX4ry8vKAOkd4wujoKAD4FAisVuu63TnRsHzv5ZdhmJyEODwc1thYfPGmm9DQ0IA3XnkFoo8+Qn1aOlQqFdLS0sDj8dAxPQ15dRW+dO217PoqlQrtx45hdnwcMQkJqNm1a914wOHXX0euUonMBGcvs0GFArraGuzcs8fp5+SkW1xcHFK3DGA1EFx//fW47bbbnIKQxWLBz3/+cxw4cACZmZnYu3dvQIfBdTodO2oQylS+3W5HW1sb8vLyIBKJnNwpjEajkwWTRCLxqomN1Occh9tdwTAMOjs7kZSUtK5RZWpqCgzDbPqcYRgGXV1dSEhI2PDkPDc3B7Va7db6zGw2o7m5GTU1NR5/zxcXFzE7O7uuw3RwcBDx8fGhFMJw+0c+aWt8hJ07dyItLQ1vvPEGLrzwQp/XIbqWqampIW1Bj4mJgVQqDXhX2mY4ypn54hzhD7m5uWhpaUFycrLbL6OjILNj3dZR5cSxbtvf34+CgkLIeTzEZWXh/EsvXRewwsPD2c7E+Pj4dbtCpVKJfz75JKrDwlAmjcXixCQ+6O5G3Ze+hFoHHcr49HQoB4fWBb65FRMyXQQPx27LQLpWeEJiYiLsdvu6+oxQKERKSgrOPfdcv7Il7iD2WP39/QEdNXAFwzBOYgEAWFNk0mWalpaGqKgov14HmekDsOFnuNYx3XGzs1GNz9UaJ06cYFOtrthMU3OtsLYn9U93XaxFRUUBMz/2l5Oyq9MRHo+HBx98ED/72c9gNBp9XofP5yM/Px9DQ0MBfHWekZ+fj6mpKZcNB8FEIpFAIpFALpeH9LphYWEoKytjuzwZhoFOp4NSqcTQ0BBaW1tx/Phx9Pb2Ynl5GdHR0SgsLMT27dvR1NSEsrIyZGZmQiqVgs/n443XX8dT3/8+0gYHcX1SMuoUSvz9wQfZz7KspgadRhPMViukUilWVlagNxjQodWg3MEy59h772F7eARqM7OQGBOD4tRUnJeVjeP//KfTZ1NSXo7pqEgMKhSw2e2wWK3omZrCcny821NsdHQ0srKyMDg4GNw/7hpiY2ORmJjIOogT1Go11Gp1UIUU0tPTwePxoFAoAram3W6HVqvF9PS0Uwfu8PAwjEYj4uLiUFVVxXat5ufnIyUlJSAKOTwejw1+mymbEFWWnp4ep3vHG/Fn0lwik8lgMplc/o4n60kkElaI2hNFFtLcshby/rcCJ/2JD1j9gn35y1/Gb3/7W9x1110+r5OUlAS5XB7yjkeBQICCggIMDg56XW/yF+IckZSUFBLVDcdGApvNhqNHj0IoFCI6OtprlROj0Yg//+4gjv3tb9glEuGEcgYjSgWu2L4DMcvLeO/FF1F4993Iz89H3pln4M/vvY+66GjYbTZ8NDqCkvPPZ9M5drsd0339OHvNkL0kKgrxVitmZ2fZ4ezo6GicdeWVaPn4Y3QMDAA8HjIrK3H27t0b7ojT09PZ8YdQiQiEhYXh5ptvxiOPPAKLxYKysjIolUq89dZbuOqqq4LebUo0LaVSqdcpdcd7RaPReOUzGBERAbVazcrHBQry4HclZr0WV6os3nrnRUVFobS0lFWHWftvPQ2kqamp0Gq1GBwc3FTce6u7rwO0xseysrKC7du348UXX/QrB63X6yGTydDU1BTSD5nUBbKzswPuXr4ZCwsLkMvlbBdXoDCbzU4PLoPB4KRyIhaLMTAwgKqqKp/0Fv/21FOwHvkAhTOzqIqPg51hcGh+HubMDHypoREP9/fjzt8+isjISDAMg+HhYcja2sDYGcSlrXqvkcDHMAwev/9+XJaaBtGaoPvC8BDOuvVWl55zNpvNK7F0s9nMtoeHUjf18OHD+N3vfge5XI7s7GxcddVVG1o3BRKdTrepeLfjveLYdELqce6aTjaCfKfS09N9ck3fCG+aXYaHh2Gz2VBSUoKBgQEkJCQ4Obx7wvj4OPR6PSoqKpx+PjY2hoiICI8cHhiGQUdHB1JSUjb8/YmJCfD5fJell/Dw8FA+F2mNbzMiIiJw//334wc/+AH++Mc/+vzhiEQixMXFhbzmRtzaOzs7sW3btpB2lyYkJECpVPqsdk9qLI56lWtVTvLz8102EpDBdm/rjHq9HgNHj+JrubkYnpldNePk8bAvIQG/Hp/AYlk5IBSytQrix0iaABiGQXt7OxYXFxEfH7/699+5Ey0ff4LTHE59Q7OzgBuDUmDjWo8rwsPDUVRUhN7eXq/b7v1h37592Lt3L9tF7KsbgC+IxWJkZmaiv78f5eXlWFlZceqsdGw6kUgkAbPqcnSuEIvFAT3dOjo5bHYPEPf4mZkZn93Sc3Jy0N3djcnJSafGGG9Sp46OECKRyG2jlc1mC2mfgy/QwOfAhRdeiMceewzHjx/Hzp07fV4nLy+PNXAN5Q0QFRUVUr9ARxwH6jdK19lsNnaw11G4Oyoqim3UyczMREREhEcPdYlEgtjYWExOTiInJ8fj12swGBAFHmJjYhARF4tZnQ6pMTGI5PMRxQMOj42i8syz3HYUErWNjo4OtvNw5549+KdCgZeGBpEpEGLJbsOiRIILv/zlgAaoxMREqFQqThqaKioq2NGdYDfZODad6PV6qFQqfPrpp+yJ31uRd18QCoUoLy9HT08PGhoagiJmDWze7EICTlRUlE+vgQTx5uZmtiQAeG8Y6zgk727QfiOJNprq3KL09vbi+uuvx3vvvefXTT4zM4PFxcWgdLxthN1uR3NzM6qqqkKq9gGsdjUuLS2x79lisawbHeDxeE4PrpiYGL/b1X15zzabDT+9/XZcLZFCKhCgt60NAoMBBosFT2g12Hf11fjKLbdsqjahUCgwOjqKJbkciv5+8ARCxObmIDM/HwkJCSgoKAhKO77NZmPfc6BsdTxlenoay8vL69Jm/mC3251O/GRDRGq3MTExiI6ORldXFyorK0M+QiOXy6FWqwP6ngGwru0CgWDToKDVanHixAnU19f7LJZhNBqd1GF6e3uRlpbm9XobDdr39fUhJSXFZckllOl50Dk+77j99ttRXFyM6667zuc1GIZBW1sbioqKQpoWAlbVGMbHx0OWCiMegxqNBkNDQwgPD2f1+hwDnEgkCloKljQieOMUf+yzz/DR44/j3ORkZMRIIJuawhszSuz8n//BxQcOeLTO4uIifv3972N3XDx2lZXCbLWiUz4NVVYmDlxzTVBTzhqNhp3hDLVwQnd3N5KTk13WLTeDOMaTdKVj04njELirzIFWq2UFDEI51sEwDGQyGeLi4gI+h+ZNve/48ePg8/l+ze0uLi5iaGgIjY2N6O3tRU5Ojk/PqImJCWg0mnXycj09PcjKylqXCuXxeKFOgdLA5w3Ly8vYvXs33nnnHb+6M3U6Hfr6+kI+XA6syg0lJiYGdKgY+LcGoePO3GKxsKnKiIgITE5OYtu2bSEdPAZWB2SjoqK8srbp6OjAR6+9BpVcjsTMTJx20UUeu14MDg7izw89BOHQMMIYBtkFBThnx3bEiUR4c3gYDddeG3TfxLGxMdhsNq8tm/zFYrGgtbUVNTU1G56K3TUo+dN0IpfLodFoQp5NCaaijKfD7a2trYiMjERERIRfnzkRs7ZarSgqKvLpBE02A2Kx2Ok+7+zsREFBwbo1aeD7D+APf/gDurq68OCDD/q1zsDAAMRicSjVCgD8u/vPH4kgi8XilH5a2w5O/rd2Zz4xMQGLxRLyhzFJ/232MA4ESqUSL/3yYRQolagLDwcfQPvcHIakEly3fz+6pqYQfvbZaHSY8wsGDMOgtbUVhYWFIR2hAZx1RHk8Hkwm0zrBAMcGJXLq93cTSE6cSUlJbi2QgoVer0d3d3fAxKwJJOUZFha24SaApLe7u7uRk5Pjc7cpCVrLy8toaGjw+ftCygwFBQVsp2lbWxvKysrWrbmVAh9tbnHD9ddfj1NPPRV9fX1emzs6QubciM1MqAgPD0d2djZGRkY2nbtxpXJiMBic3CmysrIgEok82plnZ2ejubkZWq02pFqLfD4fpaWl6O3t9Srl6QutR4+iMSoS4sREGFUqJEkkqIqNhXJpCUMzM1i22ZAXgtobaVro7OwMmbwXaToxGo1gGAZHjx6FQCBAZGQk21kZzKYT0ljU0tICiUQS0hqnSCRCXl4eZDIZampqAmpeC/w77ekudU1KCDU1NWx3pS/vn/wNjxw5Ao1G43PgCwsLQ21tLVpaWhAVFQWRSOS2uWWrNLYAVLnFLXw+Hw899BDuvvturzzg1iIQCJCTk4ORkZEAvjrPSE9PZ1NMBNJEoFQqMTg4yKqc9PX1Qa1WQyQSoaioCDt27EBTUxNKS0uRkZEBiUTiVdtzWVkZ+vv7PVJ6CCSxsbEQi8UuffgCyaJ8GikxEiRnZmLGbMaKxQKxOAYSixk9U1OYF4lCJuAdFRWFnJwcDAwMBHxtu90OjUYDmUyGe+65B2eccQYuuOACPPXUUzAYDMjLy0NkZCRKSkpQV1eHwsJCJCcn+y3vtRkCgQDl5eWQyWQ++8b5SkpKCqKiojAxMRHQdYmyic1mc/u9ISnR8PBw1krJV//CsLAwREdHY2hoyC/VqoiICFRWVqKzsxNWq9WtcstWgp74NuCUU05BUlISDh06hPPOO8/ndYi7dKhPQDabDRkZGejq6kJ8fDxrl0JSlQkJCcjNzQ1K+iEmJgaxsbEeuUoHmsLCQjQ3NyMhISFoKc/E7CwoW1pRn52NjKoq9Pf1I9JuQ8fKCoxWK75z9dUhTeukpqZifn7e51lKwLWAN/n5XXfdhZycHJxzzjnQ6/V47bXXMDs7i5/+9KcQi8Vse3so37NEIkFaWhoGBwf9ysr4QlFREVpbWyGVSgNqR0bm+zZSdiE/k0qlyM7ORk9Pj1+nz/LyclbZxdeAJZVKkZeXh66uLp9nDUMJrfFtglwux/nnn48jR474Jcml1WoxMDAQNEFnV6lK0kRgNBohFotRUFAQ0p1YKGtua1lcXMT4+DhrcBpoZmdn8fwvf4kzY+OQm5AAs9mMz0aG0SeV4oxLL0ViYqJHahiBxGKxoKWlBXV1dZveq6TphHRWGgwGJwFviUQCsViMsLAwPPTQQ+ju7sYll1zC/vuVlRU8/PDDePrpp1FWVoa5uTkolUpUV1eHXLHInw5TfzCZTGhvbw+4io5jvW9ts8tnn32GXbt2Of1+b28voqKifJrdJetNTU1haWnJJ+NZRwYHByGXy13aU4WFhYVapJrW+HwlMzMTl156KQ4ePIhvf/vbPq9DutdmZmb8KsivVZLXarVYWVlBREQEW49LTk52EtUlASgnJyekgY/P56O4uBj9/f0hVRkBVl2kZ2dnoVAogtJYlJKSggtuuQVHXn4Z7w30wxYWhsy6OtxwySUQiURoaWlBXFxcSAO+UChESUkJent72YBPRk0cOyvXquKsvV/W8sEHH+Css85y+llERAQqKipw9OhRlJWVITk5mZWu86ar1l9IWr21tZW1CQoVkZGRKC4uRk9PD+rq6gJ2yvFmuB1Y1TNtbm6GRCJBQkKCT9fMysqCRqPBxMSEX53IRUVFmJychFKpXPec20o1Phr4POA73/kOtm/fjiuvvNKvoFVQUICWlhYkJSV51IRgs9nWdVU6DvXGxsYiOzt7U/07Pp/PilhXVVX5/Pp9IT4+npUzC/WOvKioCC0tLUhISAiKgHZeXh5u+M53oNFoIBQKnYIcCUDBbrJxhGEY9l5obW0Fj8eD2WxGZGQkOx/nS9OJSCRyWQMymUxO77m4uJgN+KSVfWlpCQcPHsShQ4dgt9tx5pln4hvf+EZAtS8d1VVCPdOYkJAAtVqNkZERt552vuAY/DYbcXBsMKmvr/d5s1VWVoaWlha2DOLr646KisLY2Bg7l7kV2dqJ2C1CZGQk7rvvPvzwhz/0q1mDGNUSI1VHzGYzFhYWMD4+ju7ubhw/fhytra2Qy+VgGAZpaWmoq6vDjh07UF1dzboieyrtlZSUBLvdjoWFBZ9fv68UFxdjbGws5LZJAoEARUVF6OvrC2qTjUQiWfewIQ//YFk2kaYTuVyOvr4+1l5ndHSUtU7Kz8/Hzp07UVdXh4KCAp+bTg4cOICPPvrIqYlCqVRiYGDA6STI5/NRUVHBNpwYjUZcddVVGBwcxHXXXYcbb7wRCoUCV155Jet7FygkEglSU1NDbtsErG6AdDod5ubmArquJ80uhIiICLZW52uzT1hYGGpqatDf3w+DweDTGgzDgMfjoaamBt3d3VhZWfFpnWBDa3weYrfbsX//fnzve9/D9u3b/VrnxIkTSEtLYyW9SOrJsb4SCJHdtZhMJnR0dITczBRYrYmpVKqASz55Qm9vL+Li4kI+8xUoWTF3TSdr63GOWQSdTscqnPh7H9lsNtx+++1obW1FeXk5DAYD+vr68OMf/xgXXHDBut+fmppiHRX++te/rlNAevbZZ3HeeefhWgfn+kBAXMdTNxAFDxZmsxltbW2orq4OeLrV8dR3/PjxdTU+R8hg+lo1FVcwDINjx46tW295eRl9fX3Ytm2b188Jq9WK1tZWbN++HSqVCqOjo+w9KBAIQv3coQPsgUAmk+HGG2/Eu+++69EHSFROHJXkrVYrhEIhTCYTiouLERMTE1SR3bVMTEzAarWGrNWeQCxesrKyfE6j+App+gi1lQ+wKqU2ODjosXqP2Wx2ul9I08lapRNPgtnk5CR7n/kLsaQ5evQoYmJicM4557gNLiQA/elPf0JERMQ6wfe2tjYsLi7id7/7nd+vay1EUSYYAWgz1Go128AWyAc8aXYhjiAbbbwZhkFPTw/b8bkRjkFqLXK5HCqVyutu0ZWVFXR3d7PCDWNjY6wdklAo3DKBj9b4vKCiogJNTU3429/+hmuuucbpv5HTG9Eg1Ov1ANybXvb29oJhmJB3O2ZlZaGlpQWpqakhHfzl8XgoLS1FR0cHYmNjQ/oFEAqFKCoqQn9/f8i7Dkm7+/j4uFPXnWPTCQl03jadbEZWVpaTdZI/8Hg81NXVsc7km/1uWVkZGIbB0tLSuv++tLQUtM2PUChEWVkZJ/U+qVSKtLQ0DAwMBFROjXz+Kysrm94LZDB9rQuDKzayRMrMzIRGo1l3327GWreH3NxcdHd3Y2pqCvn5+R6vE2xo4POSH/3oR9izZw+sViv6+vpQU1PDKvCTB1Z2dvamu/LCwkK0trYiMTExpEEgLCwMxcXFGBgYCFqrvzsiIyORkZGB0dHRgDYCeEJiYiJmZ2c5abLJy8vDiRMnAKxukDQajZO+qUQi8cqKyVPIQ7C9vR2NjY0hVw669tpr8T//8z+or69n/+YqlQonTpzAH//4x6BdWyqVIiUlBUNDQ5uqFgWazMxM9PT0QKFQ+DXOQhrbNBqNk3t8WloaW0dzB5/PR01NjZMLg7trbPTsKS0tZZtdPDW+XbsmURZqaWmBVCoNuKGvr9BUpwccPnwYhw4dQnt7OxYWFmC325GWloaLL74Ye/fuRVZWlk8PrKmpKaysrIRc0xJYPXHGx8eHPAgwDIOWlhaUlJSEvOOLpDyDOWi9thNXq9XCbrcjPDwcer0epaWlkEqlIR30JgHf3xktX3jyySdx8OBB5Ofng8fjYWJiAt/97ndx2WWXBfW6wXRP3wySQvRUzNqxhkuCXFhYGMRisZNbBZ/P98rJYSPrIGC1DjwyMoKamhq3a6ysrLCzoZ6kjpeWlqBUKtedeE0mEwQCQagttGiNzx8+/PBDWK1W1NTUICkpCVarFaeeeioee+wxv3aUDMOgubkZFRUVIfdUI0Eg1CcBILCNF94yPz/PDlr7y9oHFklvu2s6GR8fh9Vq5WSjI5PJEB8fH/IGH7vdjk8++QQLCwuIiorCrl273Dp3Bxpyj9fW1oa8pKDT6dh0q2PTESmJkPS2Xq93quES7dGNvheeOjkAqzU2o9HoMvWqVqsxNTWFysrKDddQq9Xo7e31SPBepVJhYWHB5XNRKBSG+vtOA1+g+eijj/Dzn/8cL730kl+76OXlZYyNjYV8wBtYbUlXq9UoLS0N6XUBYGRkBHw+P+i2Pa7o7u5GSkqKVycBR2UcjUYDo9Ho9QOLnHaLi4tD9vAnWK1WtLS0cKKiYzQa0dnZGXBHA09YXl7G0NAQGhoaQr7JksvlUCgUSExMdBJ+l0gk7EnOF7cKT50cyO92dnYiKSlpnZDD4uIiZmdnPZJ7UygUmJ2d3fQ5NTs7C61W63JzRwPffwEMw+CKK67AZZddhnPOOcevtXp6epCcnBzylAwxyy0sLAz5g5iMdXDRfUcsm1ylPB1NdUmgI00n5GFF3MB92agYDAZ0dXVxMlJCbISCJZu3ETMzM5ibm+Mk3To+Pg6z2RyQ7lZXOLqbkPuGWDJZLBaIxWLk5eX51ajk6poMw4DP528aTKxWK5qbm1FeXu70PZ+fn8fS0pLHf5e+vj6Eh4dv2BGuUCiwsrLisiFmM6GNIEADXzCYmprChRdeiCNHjvjVJr+ysoL29nZOHoZ6vR4ymQxNTU0hfyAtLS1hbGws5E02wOrOdG5uDnl5eU4PLMemE3KSC3TTydTUFAwGQ8gbLwBgeHgYfD7fJ11Hf5HJZIiNjQ25NyUZxcjMzERSUpLfazlujDQaDSsZSDZGEomEHVGy2+1obW1FUVFRwP0SSfATCASb3p96vZ6d4SWbvdnZWeh0Oo9Hm8h7yc3Ndft3nJqaAsMwLkcpaOD7L+LHP/4x+Hw+vvWtb/m1DlfzdcDqw5D494Wavr4+SKXSoAs6OzadkAYCvV4PsViMpKQkNtCFoumEzGPl5ub6PWbgLXa7HS0tLSgtLQ15c1GgBvpdYbfb8eKLL+If//gHtFotduzYgRtvvJGtaZJTvicC3oS1urgajQZms9mpGzcmJmbTjZHRaERHR0dQmqq8aXaZm5vDxMQEm/bd6HTmDrPZjObmZtTW1rr8DMfGxhAREeHy+0wD338RRqMRO3bswD/+8Q+/OiSJk3F1dXXIazDkgVRbWxsUTcuNCEanJWkgcFQ6CQsLY7UDSZCz2WxobW3lpMGHqOiEyjzWEeIizkWGQaPRoL+/P+CNTffeey+6u7tx+umnIyYmBp2dnZDJZPjb3/7GBr+N6n0Mw0Cv17MBTqPRwGq1Ijo62ukk5+s9qlKpMDExEXDt1o2cHFwxPDwMm82GkpKSDU9nG6HRaNDT04Nt27atu3eHh4cRExPjUtwg1OIRoIEvuLz00kt47bXX8Pjjj/t1Uy8uLmJychK1tbWBe3EeolKpoFAoAtLt6C1zc3Nsu723uKqteNN0MjMzg4WFBU6k1BQKBZaXlwM67OwpcrkcOp2Ok8amiYkJmEymgKV6BwYG8NWvfhXf+ta3nDYw77zzDlJSUnDvvfeyPxsbG4PFYkFaWppTHddms7FiEyTQBXozNDIyAoZhAt7V622zS3t7O9LT02EymSAUCn1KPSuVSiiVynVlioGBASQkJLic+9tKgY+KVAeAAwcOQKlUoqWlxa914uPjERYWBpVKFaBX5jnkRuXi2snJybDb7Rtem6SdZmdnMTw8jLa2Nhw7dgwymQxLS0uIjo5GYWEhtm/f7uQcHxMTs+HJIiUlBVarlZP3nZaWBrPZzMm1MzIyYDQaObl2dnY2DAZDwK7d2tqKkpKSdYGqpqYGx48fh1qthlwuR29vL+bm5iCXyzE4OAibzYaUlBRW/L2qqopNPwcjA5Cfnw+NRoP5+fmArkvErO12+6Zi1jweD1VVVRgdHWXl8HwhLS0NIpEIIyMjTj93NxS/lSyJAKrcEhDCwsLwq1/9Cl/72tfw9ttv+5U+Ki4uRkdHBxsEQwm5dlxcXMhTYKWlpWhra0NsbCzCwsJgMBicduSOTSdSqTRgSidESo1cO5RpRyLt1dbWBqlUGtJ0K1HUID52oRyod7w2qZH5g0QigV6vB8MwsNvtsNlssNvtmJubA8MwkMvlkEgkyMjIgFgsZlPcycnJIU3t83g8VFZWorW1FWKxOKAlDU+c2wlCoRBVVVVobm72q8ZcXFyM1tZWzM3NsR3pNpst5Kl7X6AnvgBRVVWF2tpaPPfcc36tExkZidTUVExMTATolXl37fT0dIyNjYXsmjabDWq1GnNzcxAIBDh69ChOnDjB2hglJSWhpqYGO3fuRG1tLQoKCpCUlBRQYe+IiAjk5ORwYmkTERGB/Px89Pf3h/za4eHhKCwsZHVjQ33t4uJiyGQyn65tsViwuLiIiYkJJCUlYXBwEAMDA7BYLGwQOH78OK677jpUVFQgKysLUqkUfD4f4eHhKC0tRU9PD2v2GirCw8NZLdFAXzssLIwN/pv9TckGcnx83OfPnsfjobq6GsPDw6ykmtVqDfmm2RdojS+ALCws4PTTT8d7773nV8ccmXHjotkkmGoy7ppOiNJJTEwMhoaGOBnwJi3v2dnZIXePAFaH6pOTk0NupwOsdtbGxMQgMzMz5NceHBxEeHj4hkIGZrPZqY7r6FhB6nGdnZ343ve+h6ysLIhEIgwODuK0007D/fff7zZzMjo6CrvdzomSzuTkJPR6vUfD495AAh+fz980AMlkMlitVohEIr/+Blqtlm2W6uzsRFVV1bpTfFhYWMgbyECbW0LH73//e4yMjOCBBx7wa52FhQVMT09z0myiVqsxPDzsVwfaysrKOnsdIuTtqFqx9qGk1+vR09PjVl8wmHDZacmldVIwxww2g4xXlJSUsAa6a+8boVDo1FnpbhBcp9Phww8/hFarRWNj46ZC6KTRIycnJ+SbHYZh0N3djaSkpIDLyHk63N7V1YXc3FwMDAxsOJvnCTMzM5ienobFYnH5/aGB778cq9WKU045BU8++aTfDgTEvy7Us14A0N/fz9qsbATDMDAajU47cjLQ6xjkvHH+Hh0dBY/H42TIenp6GlqtlpNuR5VKBblc7rUHWiAgvoGhkvYiaicajQaLi4tQKBSIjIxEZGQkq4zT3t4OuVyOgoIC7N27NyibkZWVFbS1tXk13xcoiIxcZWUlxGJxQNf2ZLi9vb0dJSUlEAgEG87mecrg4CDkcjn27t277po08J0EfPDBB/jlL3+JF154wa8HmNFoZOWtQn36cSViTYx1HdOVVqvVSenEk4HezSAzjZWVlSE/gXA5XA6sumbExsYGfaDfFaOjo2AYJuAiCu42R5GRkezGyGg0QqPRoKqqCkqlEl/+8pfBMAyysrIwNTUFAHj++eeDIrK9uLiIsbGxgM/YeYI7MetAsNlwe2trKyorKxEREeGVELU7GIbB4cOHUVlZuW6mmQa+kwCGYXD55ZfjyiuvxFlnneXXWqOjo+Dz+cjJyQnQq/MMm82GiYkJqFQqiMVi6HQ62O32dUPgwbqZA5Fu9RUiqszFgDc5BXBV321tbUVhYaHP8lpk7MRR0stisSA6OnqdDNxaenp6kJCQgO985zuIiIjA/v372f/2zjvvQKfT4e9//7uvb29DSFs+F8pJSqUS8/PzQdEx3cjJ4cSJE6ivr2cD3fT0NObn5/3KOBw9epQdmXC0ZOLz+Vx0e9LAF2omJiZwySWX4MiRI361ipP6S11dXdBqP66sUkjTyfLyMrKzs5GWlhbyINDf34+YmJiQazsCqwPeer2eEz3NxcVFjI+Pc6JhSoK+JycQxwwAuXdsNhsb5MgGydP732q14vDhw/jGN76B++67z+nfWSwW3H///fjkk0+CIuZOBNtzc3M5aW7q6+uDSCQKuGzgRsPtx44dw/bt252ySb29vYiKivK5zPDZZ5+hurqazVSRjfFWC3xbf+DiP5ScnBxccMEFePzxx3Hbbbf5vA6fz0dBQQGGhoY29c3aDEcV+bXNA2Q3npub69R0QkSsuUi9FRYWorm5GYmJiSFv+MjIyEBbWxuWl5cDLi68GfHx8Zifn4dcLkdWVlZIrx0VFYXs7GwMDAw4qdnY7XbWEdzRYJdkAJKTk1FQUOBXBkAgECAjIwNCoXBdsBQKhYiKioJOpwtK4CMzdm1tbZw0GJWUlKClpQUSiSSg9xvZOJGTn+NGigRER0pLS9Hc3AyJROLzBkAsFqOgoIC1otpqw+sAPfEFFYPBgB07duC1117zu02d1J3i4uI8+n1SV3F8UK1Vkfe06WRkZAQCgSDk6VYgsMax3sJlypOc9LmwbbJarejo6EB0dDQYhmFntBwNdmNiYoLyN7HZbGhoaMBll13m1Bw2OjqKl156CcePHw/qZ7GwsICJiQnOTtvBErMmz3nHet9nn32GXbt2rftdk8mE1tZW1NfXezVkb7fb8fnnn2Pnzp0AnHVBBQIBF/N9NNXJFc8//zwOHTqEgwcP+vVFMhgM7KzM2l2au5STK3sdX+ByrhBYbbtOTU0NuV8hsDpvZTKZgublthFqtZoVVQ7WQ3itizyZrYyOjsbi4iLKy8tDruTzz3/+E3feeSf279+P/Px8jI+P45133sFPf/pTXHjhhUG//vDwMMLCwpCfnx/0a61lfn4eU1NTQQm8a5td3AU+YNUybGBgwKtNn8ViQXt7O7Zt2wbg341iaWlpyMrKooHvZMJut+OMM87A/fffj4aGBr/WGh4ehlAohFQqdRoCt9vtTkPgwWg6WVhYYFvtQw2xlPGn48xXSMNHUVFRyIfqgdXPXCAQBMSp3rGWq9FonAbBXQl6c3n6+fjjj/GLX/wCi4uLKCgowM033+z2IR1o7HY72tvbkZeXx0ln7/DwMHg8XlC6ax3rfRsFPmB106dWq1FZWenR528ymdDb24v6+nr2Z1arld00e5qtCiA08HFJR0cHvvGNb+Dtt9/2aizBYrE4pSr1ej30ej1SUlIQGxuLmJgYiMXikO2kuru7kZqa6reZpy8oFApoNBpO5uu4HKonA97l5eVezXqZzWanzkrHWq6jgMBmD7SBgQG27hdqSJ2ztrY25IHXZDKhvb09KGnHzQhmo41j8Pv88883DHwMw6CnpwdSqdSjz1+n02FkZGTd5liv1wMAF5sIGvi45uabb0ZDQwOuvPLKdf/NsenE0V7HsemEKFbMz89DpVJxYqPDpVM8SZvk5+eHvNkEWO3StVgsnMhbabVa9PX1ufSwc3fvhIeHO9Vy3amdbIbNZkNLSwsqKioCPmTtCf39/YiOjuYk8KpUKkxOTnJy4vXFONdTiJh1W1sbW49zB6k1l5SUbHpiU6vVmJqactmEJxQKQ75pBA183KNSqbB371688847mJychFarRXJystdNJyQAFBQUcJJ6m5qagslk8luVxhc2qnMGG4ZhWGmtUDuXA6s+cjabDRkZGU4nubX3jkQiCaiAN7Bx4A02xEmhrKzMaS4sVAwNDUEgEHCiIrSRca4vmEwm9t5Rq9UQCAQenaaNRiPa2trQ2Ni4YZ/A4uIiZmdnXeqP0sB3EmE2m9Hb24v29na0t7fjzTffhNVqRUFBAS6++GJcfPHFPtmykBGDpqamkO9ESQAoKyvj5AQwPj4Om83GyaAx+buHIgCQQXDHk9zy8jIkEgni4+PZQBcIayZPGB8fh8Vi4WTDQ9RNuMg02O12tLW1oaCggIsaFSYmJmA0Gr1K8TvKwZH7x2QysRskx/lKoue52T20sLCAkZGRDe/9+fl5LC0tuWwEo4HvJOLxxx/HsWPHUFdXh7q6OlRWVuKcc87B//3f//n94B4aGkJUVBQnivoajYbVdQx14PW15hUoxsbGYLfbAxp47Xb7OrUT0pXreJKzWCysvBUXqea2tjbOGj7kcjk0Gg0nbvVc1/u6urqQkpKyTgaM/HcS5Mj94yrIucoCeOPkAKze+0aj0e1nMDMzA4PB4LIbNjw8nIt5Phr4tgqHDx/Gr3/9a/z973/360awWq1obm520tIMJQMDAxCLxZyoqnAdeFtbW1FaWupT6o2Mnjg2LdlsNohEIqfGE3efKZfjFSQAcHHPETeDlJQUTqybuGy0cRSzFggEGwY5Mrbk6Wv01MmB/G5nZyeSkpJcfu/lcjlsNpvLeV8a+E5yGIbBpZdeiuuuuw779u3zay2lUonl5eWAe3p5Agm8XOyCgVUl+KioqJArmwCrqbfe3t5NU542mw06nc4pXckwDMRisVM915sRDXLyys/P5yT1NjMzw+pKhhoinF5bWxtQ93JP8cQ7MFCsPcktLS1Bo9EgLi7O5yC30bU2c3IgkO99eXn5uh6DiYkJ8Pl8l1koGvgoGB0dxZe+9CUcPnzYr6BBHoJFRUWcNFzMzs5y1mFKus24Gqpfa51ks9mcAhxRO3Hsyg3U6Ik3eprBgIhJB8MpYTOWl5dZ8XIuRkvITGcgO4vXBrm1TUvkfwsLC1hcXPR4rs4bNnNycESv16OjowNNTU1Oz6/R0VFERUW5vC9CLQH3L2jg22r84Ac/gEQiwde//nW/1tFqtejv70djYyMnjS4dHR1eSakFkoWFBUxNTYXcv47MV/b29kIsFmNlZQVhYWHrglwwH8zT09PQaDScnPa5Pnlx6aTgr6yYuyBHfAg3O8n19vYiJiYm4JkOx/k+T5pd5ubmMDk56VRuGBoaglQqdamwRAMfBcDqrmnnzp14/fXX/ZbiGhgYQExMDCdC0lyOGACrp4+kpKSg1X3MZrPTSc5R7SQ8PBxzc3OcnLxIvSUzMxOJiYkhvTawKmk1OjrKiW0UUdPhqtNybm4OCoVi0w2Xv0HOFWS8gzjWB5KNnBxc4ajFCaw6TCQnJ68buufxeJyUQ0AD39bkueeew3vvvYff/e53fq3jyjQ2lIyNjYHH44Wk9rEWMugbiPe+tgWciAg4dlauHQQfGRkBn8/n5L0T93CuPvehoSEIhUJO3juXjTbA6mYzMjKSbeQIRpBzh8FgQFdXF+rr64MiZu1pvY/MFKenpyM1NRU9PT3IyspaF5Bp4KM4Ybfb8YUvfAH/+7//i7q6Or/WUigU0Gq1nPjHERHrmpoaTlJfSqUSS0tLHre6MwwDk8nkdJIj3XGOnZWeOFdw6RYPrNZZ5+fn/bas8gUyWsLVcPns7CxmZmZQXV0d0lMncT5pb29HbGwsVlZW1jnKByrIuWNubg7T09NB6TJ15eTgDovFwrqIjIyMoKCgYN2YEQ18lHW0t7fjm9/8Jt566y2/UoVksNzXNnt/WVxcxMTEBCft3qTWmJOTs27GjDykHINcoB9SGo0GAwMDnNRZAbBzXly0+et0OnaonwP1ffT29kIikQRtnnXtJsnxJBcVFQWVSoXa2lqPdE8DzdDQEPh8flBcJDZybl+LVqtFd3c3wsPDUVFRsW7zGxYWxsmpHDTwbW1uuukm7NixA5dffrlf62g0GgwNDXFSdwFW623Jycmc2AeRpoOKigoniyaLxcI6gvtrz7QRQ0NDCA8P58SzkKS6uRotmZqagsFg4CTbEEgtURLk1krCkU2S4zA4YW5ujvWL5GKmlPh0BlPM2pMNzczMDGQyGU499dR13y8a+CgumZ+fx759+/D+++/7/eXt6+tDXFycS5WHYBNK+yBXHoRGoxECgQDp6elsoAtVICAP4KqqqpAbxwKr95BCoeDkAUxO3NnZ2QF/AHuCVqtl5yo9PXX6EuTcwaWQNqnzBkvM2pvgd+TIEWRlZa2TtaOBj+KWX//611AqlfjRj37k1zpk98+Fdx2wqt5gMBgCqixit9uh0+mc1E5ceRAKBAI0NzdzVnMKhXHsRvT29iI2NpaT7l7yAOby1KnX611qWjoGOVfpbm+CnCtIrTMYnZaesLS0hJGRkaDMNnrT7HL06FF2wN/RuozP53PyLAINfFsfi8WCnTt34umnn/a7S04ul8NoNHIiKOxvrZEMgjs6ggNggxx5SLnbgXI51whwqyhDpK24GurnMu1HxjvIaX+jIBeMdDfptGxoaODkdDM+Po6VlZWgpJs9HW7/7LPP0NjYyApLkGYvGvgoG/Luu+/i97//Pf72t7/59eBgGAbNzc2oqKjgpNPQ0+BjtVrXqZ2EhYU5SXr5onYyNDSEiIgITlJPRFGGqw7XxcVFjI+Pc+IhB4T21Ln2JKdWq6FWqxEbG4vY2NigBTl3cNVlCvw78KelpQWlycmTZhfi6K5Wq9Hb28tmnWjgo2wIwzA4cOAAbrzxRuzdu9evtdRqNUZGRjh7AA4ODiI6OprttnN0kyeO4GQQnJzkRCJRQFI1XAcfLoe7gdUZs+joaE5PndXV1QGtda4NchqNBmazed1JTq/XY2xsjLO/fV9fH8RiMSd/e4vFgtbWVlRVVQV8w+tJvY8EPmBVWWh+fh41NTUQCAQ08FE2ZmRkBJdddhmOHDnid8pEJpMhMTEx5G3uZrMZS0tL6O/vh0QigclkYt3kyUku2O3fXI5XAKsND2KxmBPbKBL4Ax18PMVfA1V3QS4qKmrdMLgrhoeHwefzOTGPJcoqpaWlnOjn+tLo4ykbOTkwDINjx46xgQ9YPf1HRUWhqKiIk1EX0MD3n8U999yD+Ph43HLLLX6tYzab0dbWFjQDT6JW4TjjZDKZEB4eDolEArvdDqPRGHItTYJMJkNCQgInHa5ci2hz3WgzMjICHo+36YyZv0HOFcESk/YUvV6P7u5uzkTEp6ensbS0hIqKiqAMt7tqdrFarWhtbcX27dvZnxFxh5KSEk5mTEED338WOp0Ou3btwhtvvOG3DuPU1BRWVlZQWFjo1zru2r83M7wkbe5cmJdyPd/G9alzeHgYAoGAE0kxEnyKi4vZTsdgBDl3EAcLrppNZmZmMDc3h6qqKs42fVKpNCgZB1fNLisrK2ywd8RkMsFms3Hy/QcNfP95/PWvf8WHH36IRx991K91SKt1ZWWlx2kvhmFgMBicGk/WPqBiYmI8UjshD6Bt27ZxImLNpXUSsFrzkUqlnIwYkB13IIa7vYVhGCwtLUEmkyE5ORk6nY69h9Yq5gQLpVIJlUoVFBsfTwi2qsxGBDPl6srJwWAwYGBgwKX0olAo5OS7Dxr4/vOw2+3Yu3cvfv7zn6OmpsavtZaWlthOP1fXMRgMTic5m8227gHlz4lpfHwcDMNwUnMh3W5ZWVmcDFdzPWKg1WrR19e3qWmuP6yVhXM8yQGr91hFRQUn1jQymQxxcXGcbDyIqEF5eTknc6XBHLFY2+yi1WoxNjaG6urqdb9LAx/FK5qbm3HnnXfijTfe8PvGIfY90dHRTjNOdrsdIpHI6SQX6C8JOXlwpWpiMplY40wuiuxc+QYSxsbGYLfbA+JfR4Kc40bJ8SRH/kc2SgzDoKurC+np6U5DzaGCbDyC0enoCVzX+zy1UPIFx3rf8vIylEqlS6F4GvgoXsEwDL761a9iz549uPTSS736tzabzUntRKPRQK/XIzk5GVKp1EntJBSQUydX9a6pqSmYTCZOhvqB1bRXXFwcJ67lpN5WUlLiVdrL2yDnDiJlV19fz8mpT6PRsHOlXDyAuU65Dg4OQigUBiXjQuLH8vIyFhYWXA7Qh4eHc/K+QQPffy5zc3M444wzcPjwYbc7VqvV6hTkiNrJWkdwuVwOm80WFDV3T+BqvAL4t6KMtw//QEEabbh6+Ov1evT09Lhtc3cMcmvrut4EOXeoVCpMTU1xtvGZmJjAyspKQKX0vEEmkyE2NhYZGRkhv7bdbkdbWxvy8/OD0mRit9uhUqmg0+lcbixp4KP4xCOPPIL5+Xn84Ac/wPz8PMxmM6xWK3uKCwsLWxfkXO1sScqxurqak8HuUIpYu0Kn07EzTlzs/FUqFaanpzlR9gCAyclJ9tTrKsgRFwt/g5w7+vv7IRKJOBnuJqap2dnZnDjWc13vI8a9gdx4EXlBtVqN+fl5pKSkuOwgpoFvC0K6z9RqNfh8PrKzs2Gz2bgauHRCpVKhvb0dJ06cwMGDBxEVFQWxWIx77rkHDQ0NrCO4Nw/xxcVFtt7EBVwa5gLcOqYDq7XWxMTEkM0Wrj3JTU9Ps2ICwQxyriCzjVzV24iQNlenbp1Ox566udj4LS4uYmxsDHV1dV5v/Ox2u1Pzkk6nA4/HWydKIRAI1q1NA98Ww2Aw4A9/+ANGRkbw4YcfIikpCffddx92797NatNxAcMw2LNnD4RCIRoaGlBfXw+dTodDhw7hmWee8fsm6urqQkZGBiddjgzDsPNdXKQciVs8V6omwZwtXBvk1voRkgBHTr1cPHy5rrepVCpMTk5yJuWnUCiwuLiIysrKkF8bWG10slqtG9a6ieWXWq1mgxzDMKyGLgl0rtRbXA23c7HJ+Bc08Lni0UcfRWdnJw4cOIAvfOEL+PTTT/HEE0/goYcewquvvoqvfOUrnKRFgNWbyPHmYRgGF110EW6++Wacdtppfq1Nuhy5mq3T6XRsiz0XD5+lpSV258vF9efm5lgxY19ZO2vpGOQ2G0OZnp6GRqNBWVmZP2/DZ8bGxmCz2fwWVfCVwcFBREREcGIaDKye+uPj4zkZsSDeiRkZGUhOTgbDMNDr9U6bJWL55RjkPM2ArR1u5/F4nIhH/Asa+NYyNTWF66+/Hg8++CDq6+sBrHbe3XHHHaiqqoJOp8NXvvIVJ+05rhkaGsIVV1yBw4cP+z1yMDY2Bh6Px1nKb2hoCJGRkZzUewBuB8sBoLu7GykpKR651fsT5Nytx6VxLDn1FxQUIC4uLuTXJ6IOXOlpBtI13hvIfbS0tITh4WFERUWBYRiIRCKnIOdvJsDRySEsLIwGvq2E1WpFbW0tDh8+jJSUFBw6dAiPPfYYjEYjvvjFL2LPnj0oKyuDQqHgpBPLHd/97neRmpqKm266ya91SMqPq8FqUu+pq6vjJBXCtZwZafRZe33ycHIcIXAMcuTh5O9rJvWuxsZGTiS9iKIPVylXrufrdDodZDJZUMSkAWd5OJKytFqt7H3E5/OhUCiCKmYdFhYGgUBAA99W44UXXsBzzz2HyclJ1NTUoLCwEJdffjkKCgowOzsLu92Ov/71r7jzzju5fqksWq0Wu3btwltvveX3bl2lUkGhUPiVcvOH+fl5zMzMoKqqipPrz83NYXZ2lrPrz8zMYGZmBikpKUENchtdn8yXcYFSqcTCwgJn11coFKyYMxdMT09jeXnZ7+sTsXjHdOXKysqmoyhyuRwajcbl0Lm/kOAnFAppjW8r8qtf/QpdXV244YYbcMopp2B0dBRPPvkkRkdH8cwzz2BhYQFpaWmcNbq44umnn8bRo0fxq1/9yu+1uBSRBoDOzk5kZmZyknIj18/IyAh6LdfxJEdOcxaLBRaLBfHx8UhLSwtqkHNHV1cXUlNTPUq5BhqGYdiUL1eznUTRiAsHD3L9xMREr4QN1gY5k8nkk8M8wzCQyWQBrzcyDAONRoO2tja0t7fjtttu4ySlDBr43KNSqdiHzTPPPINPP/0UxcXFOOuss3DKKadw/OpcY7fbcfrpp+Ohhx7y+7RiNBrR1dWFpqYmToI713JiJOUXyNlCd0HO1UmOpDy5Sjm6S7mGCpJyrqur4yTlTsxbuTIt3kxSzWw2OwU5o9Ho5IhCgpyvTVr+zheSe72zsxOtra1ob29Hf38/oqOjUV9fj8bGRnzpS1/iZHwFNPBtTHt7O+677z7k5ubijDPOwAUXXACr1Yp7770X+/btw5lnnrmuy5JrTpw4ge9973t4/fXX/Q5YIyMjEAgEnHW5TUxMwGq1BkRL0hfkcjn0er1Ps4XeBDl3KJVKLC4ucpZym5+fZ1PeXNzji4uLrIg6F9f31zjXX4h5bE1NDXsvqdVqGAwG1tuS/G+t7VcgIPVOT8SsTSYTenp62CDX09MDoVCI2tpaNDQ0YNu2baioqOBkE+cCGvg2QqfT4YUXXsDFF1+M+Ph4/OUvf8EjjzyChYUF3HLLLbjnnnsArB8x4BKGYXD99dfjjDPOwCWXXOLXWlw3mpAuu4qKCk52hqTLsKioiPWOc/d7mwU5iUTi9ZeeOEhkZmZyNj5DUl5caIkC3I8YhHrEwmq1OnXpLi0tgWEYpKamsvdRdHR0yJ43SqUSTz75JH7wgx+wwd9isaCvrw9tbW1oa2tDV1cX67TR1NSEpqYm1NTUcHJS9xAa+Dzh6NGj+OEPfwidTofvf//7qKiowOOPP464uDjcc889WyrwAavNCWeddRaOHDni9zD23Nwc5ubmOGs0UKvVGBkZ4WzXT7QsScrXVZAjXXGOiieB2tkGI+XqDVzbJxE5Pa4kvRiGQVtbG/Ly8gJe7ybSXo6qJ2FhYU6bpejoaPT09CA5OZmTeqPNZsN1112HiIgIxMbGoqOjA0ajEWVlZWhoaEBTUxPq6+shEom21DNwE2jg84QvfOELOPPMM3H33XezP3viiSfwxhtv4NVXXwWfz99ywe+hhx6CWq1mT6W+Qma78vLyEBsbG5gX5yW9vb2Ij48P+RefBLnh4WGsrKyAx+PBZrMFLci5Q6FQYHl5OShddp7Adcox2C3+m0H0LP2pd7qT9iID4VKpFCKRyGVKNVQWSna7HePj4+xJrr29HcvLyygqKkJbWxtuu+02XHfddZBKpVvqWecDNPB5gtlsZm/4/v5+NDc34+DBgzj99NNx4YUXYteuXVsu8JnNZuzYsQPPPfec38Pger0eMpkMTU1NnLxH0ugQzEYPolTh+HAiQU4sFkOpVKKysnLDlGewIJuPnJwczrps+/v7IRaLOXENB/4tpM2Vi8L8/Dymp6c98q8j0l6OWQFPpL02gki6NTQ0BCT42+12KJVKtLS0oK2tDR0dHZidnUVubi57kmtqakJiYiJ4PB6mpqZw/vnn49133+Wk0zbA0MDnKYuLi3j//ffR1dWFxcVFFBYW4qKLLsJFF12EgwcP4rTTTttywe/NN9/En/70J/zlL3/x+3UNDw8jIiKCM0UVpVIJtVqN0tJSv9faKMg5Kp44Blm1Wo3h4WHU19dz8hmTLleuBqtJvZcrLVPiopCTk8PZiIsrF4lAS3ttxNTUFHQ6ndeScgzDYH5+nj3JtbW1YWpqCunp6WhsbGSDXHp6+ob39nvvvYe2tjZ897vf9fetcA0NfJ6ytLSEO+64A3l5ebjsssvYB/B3vvMdFBYW4mtf+xrHr3A9DMPgggsuwK233ordu3f7tZbNZsOJEyc4a28ntZbCwkKvTl2+BDl39Pf3IyYmhjPFnunpaWi12oAEf19YXl7G8PAwGhoaOAv+7e3tnI14WK1WnDhxAmlpaew4gc1mC7i0lzvIfONG9T6GYbC8vIz29nY2yI2OjiIhIcHpJJebm7ulZpBDDA183jA8PMx2dy0sLOBb3/oW3nnnHbz77ruc2flsxuDgIK666iocPnzY7y/k7OwsFhYWOKs1kZSrOwV/x903CXSOQY48mHx9aFqtVjQ3N3NmX0NOPXl5eZxoWQKrWqrh4eGcdVnOzs6yqjrBDL6O0l6OOqhCoRB6vR5lZWWIjY0NeQC2WCy49tprcc8996CiogJ6vd4pyA0NDUEsFqO+vp4NckVFRVvCTm0LQQOfLzzwwAN45plnsHfvXjz44IOcNX14yp133onMzEx89atf9Wsd8uAtKCjgpNYFrG4+wsPDkZWVFdQg5475+XkolUrO5NyIliVXg/2kyzLUQsqOBHrEwltpL7lcDq1WG1IXCxKIu7u78dZbb+GFF15AbGwsIiMjUVtbi8bGRmzbtg3l5eWcpML/w6CBz1teffVV/PjHP8bvf/977NixAwC2jEGtO9RqNU499VQcOnTI7+YILqyDHE9yarUaSqUSkZGR6+ooodp9e+OgEAympqZgMBg4M+3VarXsPcBFuox0OfqqquKvtBfDMKykW7AaPcxmM3p7e9mB8O7ubgBAVVUVGhsbMTIyApPJhIMHDwbl+v/l0MAXaHQ6HTo7O6HRaLB//36uXw7Ln/70J5w4cQIPP/yw32sNDg5CJBIFpda1tllAq9WuO8mZzWbMzc1xduoicl5czdaRemdBQQFn2YaxsTHY7XbOVHU8rTe6kvYKDw+HVCr1S9orkJJqVqsVg4ODbJDr6OiA2WxGeXk5Ghsb0djYiLq6OqfBdYZh8MUvfhFXX301Dhw44Nf1T0Jo4PMVd07sFosFb731Fu6++24cPXqUs1rMWmw2G/bs2YNf//rXfktgkVqXv00GngQ5dye5rq4upKenc6ZoolAooNFoOGs0MRgMrJYqVynP1tZWlJSUcCU0jOHhYfD5fOTl5QFY/e45NjEZDAYIBAKnk1xUVFTAMhVLS0sYGRnxqtnHbrdjZGSErcl1dHRAq9WiqKiITVfW19dDIpFsuubS0hJeeeUV3HDDDYF4OycTNPAFAkefKZL2/OEPf4jZ2Vk88cQTXL88lmPHjuEHP/gBXn31Vb9TVN6OF9jt9nWKJ/7U5LgWsd4Kp67JyUmsrKygqKiIk+sTVRsuBsutVivUajV6e3shEolgNpvB5/PXqZ4EOx0/MjICo9HoUtnIbrdjenoaLS0tbAOKSqVCfn4+q1/Z2NiI+Pj4LTUGdRJAA58/TE1NYXp6GhUVFYiKinJKe73wwgv45JNP8PDDD3NpuOgEwzC49tprsX//flx00UV+r0V2/GulpNwFOZFIxI4PBKImNzk5CbPZHDIdxbUYDAZ0d3dz5mDhqZZoMAlF8N1I2isiIgIKhQLbt2/nJO1st9uxf/9+fPvb30Z1dTVaW1tZ1ROFQoHMzEynMYLU1FQa5LiHBj5/+MMf/oCbbroJV1xxBebm5pCWloZ9+/ahtbUVzc3N+N73vud3gAk0CoUC+/fvx5EjR/y2W9Fqtejv70dpaSn7YApWkHMFwzBshyFH9iYYHx+HzWbjrNa1Vks01AT65OtK2gsAey+5kvaSy+XQ6XQhSzszDIPFxUW0t7ejtbUVHR0d+PTTT1FRUYGdO3eyKcusrKyTeVZuK0MDn7+cccYZuPLKK3H22Wfj9ddfx+zsLAwGA8477zycdtppXL88lzz44IMwGAxeKzAQKSbHIKfX6xEdHY2UlBT24RTKnTfXiirEQaK8vJyz9v7x8XFYrVbOTr6+jlh4Iu0lFos3XZO4WGRkZCApKcnft7Nuba1Wi46ODrS1taG1tRXDw8OQSCROJ7mOjg689NJLeP755+mJbutDA5+/vP766/jlL3+Jjz/+mOuX4jErKyvYsWMHnn/+ebfai66CnKNKBQlyDMOgpaWFsw5HYFVRRSKRBNQt2hs0Gg0GBwc5UzQhnwGXjSabqcq4a2QKlLRXIIxzGYZhgzhpPunv70dUVBRqa2vZIFdWVubydd50001obGz0e16WEnRo4AsEN998M6655hrs3LkTwNby53PHP//5TzzzzDP405/+BIvFgsXFRadait1u91iKaXp6GjqdjrO5slCIWG/G4OAgoqKiONMyJQ4GXKY8Ozo6kJ2djfj4eKcarytxgWBkBrwRkgZWN4AymczJPDUsLAw1NTVs80llZaXHgdRgMGBoaGjLqjhRWGjgCwR6vR5Wq5WzBgNvsFqt6OvrQ0tLCx544AFERETAZrPh2muvxYEDB3zSGyQnjrKyMs7SfTMzM1hcXORMTo2IOHPlWwdwM1vnKO21uLjIigs4bppCYd1E6OnpwczMDM444wynn1utVvT39zvNytlsNlRUVLA1uerq6oCOO1C2LDTwnUxcccUVGBwcZE0kExMT8fvf/x7vvPOO37tvjUaDoaEhzmptRE4tPz+fs/GChYUFTE1NeXziCDSk3lhWVhYU01ZPpL1MJhOWl5c5My7WarXYs2cP/vd//xdqtZqdldPr9SgpKUFTUxMaGxvR0NAAsVhMg9zJCQ18JxOOvoKEO+64A/n5+bj++uv9Xp8rw1jCZiLWoaCnpwdJSUmceZbpdDr09vYG5G+wmbRXTEzMutMtcRBITU0NiaSb3W7HxMSEk1Cz0WjE+Pg4vvGNb2DHjh1oaGhAXFwcDXIUAg18JzvLy8vYvXs33n77bb9VZriW8gJWB4oFAgFn7gHkb8BlvXF0dBQ8Ho9VNPEEs9m8TvUkPDzcKV0ZGRnpUfAIRKOJKxiGwczMDGue2t7eDqVSiZycHKeB8OTkZPzsZz+D2WzGfffdF7DrU/5roIGPAjz11FPo6OjAL37xC7/XksvlMBqNnKmJ2O12nDhxgtNam1KpxNLSEmf1xs1GLNZKe+n1egiFwoBKe83Pz0OhUKC6utqndRiGgUqlYgNcW1sbJiYmkJqayupXbtu2DZmZmS7Xt9ls2LdvH37zm9/QZhPKWmjgo6w+JHbv3o1HH33U74f1VhgqX1hYgFwu5+yBRzocc3Jy/HbD8BUiLlBbWwudTucU5EIl7eWpfRDDMFCr1ejo6GCbT4aHhxEfH4+GhgY2yOXl5XmVvl1cXIRUKt3SzikUTqCBj7LK0aNHcd999+Ef//iH37Wh5eVljI6Ooq6ujrO6CqkzBXqg2VO48M1bK+21sLCAsLAwJCUlOQW5UNU/LRYLnnrqKZx99tnIz88HsBrkDAYDOxDe1taGgYEBREdHO5mnlpSU0IBFCRY08FFWYRgG11xzDc4//3xccMEFfq8nk8mQlJTEmWfdysoK2tvbOROxBoCJiQlYLJagKKrY7Xank5xWqwWPx3MaCI+OjkZraysqKys5O32//PLLePTRR3HFFVegvb0dMpkMQqGQNU9tampCRUUFZ/VQykkJDXyUfzM9PY1zzz0XH3zwgd/1MbPZjLa2Nk4Dz9TUFEwmE2f1RpL29Xe8wB9pL7VajaGhoZCoylgsFvT19bHpys7OTjAMA7PZjIqKCnzrW99CdXU1Z7VXCuVf0MBHceanP/0pLBYL7rzzTr/XmpychMVi4UzAeSsM1pNam6eO9cGQ9hoaGkJERASys7P9eStO2Gy2deapJpMJ5eXlbF2uvr4eIpEIBoMBe/bswUsvveRVpymFEiRo4KM4YzKZsGPHDrz00kt+a1/a7XY0NzejqqoK0dHRAXqF3sG1jibgPvCQelewpb2Iqkx1dbVPn4PdbsfY2Bhbk2tvb4darWbNU5uamtDQ0ACpVOr2b/zZZ5/hsccewzPPPOPXe6FQAgANfJT1vPrqq3j++efx1FNP+R0slpaWMDExgdra2sC8OB8YGBiAWCxGRkYGJ9e32Ww4ceIESktLYTab2SBnNpvXBblg1bqWl5cxMjKyqbKO3W6HQqFw8pWbm5tDbm6u06xcYmKi1/eGxWKhtTzKVoAGPsp67HY7zj33XNx1113YsWOH3+tx3WFptVrR3Nwc8IFqd7iS9jIYDLDZbMjMzIRUKoVEIgm5QfHhw4cxPDyMm266iX2dc3NzbIBrbW2FXC5HRkaGU5BLT0+nqieU/yZo4KO4RiaT4YYbbsB7773nd3OKyWRCR0cHp40us7OzUKlUqKioCPjarqS9IiIi1qmecCnpxjAMpqensX//flxyySUYHh7G6OgoEhMTnWblcnJyqHkq5b8dGvgo7rn99ttRUlKCa6+91u+1xsfHYbfb2XmuUEOGynNzc/2SZvNH2ovYJwX75MkwDHQ6ndOs3ODgIGJiYpCZmQmZTIYXX3wRxcXFNMhRTkZo4KO4Z2lpCXv27ME777zjt+MBkRKrqalBVFRUYF6glxiNRnR1dXnsWRcMaa9AnzyJLVBXVxcb5Pr6+hAREYGamhp2ILy8vJxtkvnmN7+JyspKaphKOVmhgY+yMU8++SR6enrw85//3O+1uJYSA1Y96wCsa6u32WxO6cpgSXsxDIPOzk5kZWUhISHB639vNpshk8nYINfT0wMAqK6uZjssq6urNzxR6vV6HDhwAG+++SZnYuIUCofQwEfZGJvNhlNPPRUHDx5EaWmp3+t1dnYiMzPTp4d+ICAnz/z8fNZAVafTISwsDDExMWyQE4lEQUsDelrztFqtGBwcREtLCzo6OtDR0cEOgzc0NKCpqQm1tbU+BWSGYWjDCuVkhQY+yuZ88skn+MlPfoJXXnnF74cl0bDctm1bSOpLrqS9rFYrbDYb8vLyIJVKIRaLQ17ram5uxhtvvIH777+ffZ0jIyPsQHh7ezt0Oh2Ki4udZuViYmJowKJQ/IMGPsrmMAyDq666CgcOHMC5557r93pjY2Pg8XjIzc31/8U54Eray263O53kiLRXT08PkpOTOdESJeapl112GXbs2IGxsTGoVCrk5+ezQa6xsRHx8fE0yFEogYcGPopnyOVynH/++fjggw8QERHh11qB8MxzJ+0lEonYObmNpL1CZZrLMAxmZ2fR2trKnuYUCgWysrKQl5eHI0eO4N1333XrK0ehUAIODXwUz3nggQfA4/Fwxx13+L2WSqWCUqlEVVXVpr/LMAyMRiM0Gg3UajU0Gg2sVitEIpFf0l5yuRwGgwHFxcW+vo11r3NxcZFtPGlra8P4+DhSUlLYmlxTUxOysrLY1OqPfvQjSCQSfPvb3w7Ia6BQKJtCAx/Fc4xGI3bs2IF//OMfARnCJmatjnN1pD3fscMyWNJeRMS6tLTUa/cEhmGg1WpZ89S2tjYMDw9DKpU6DYQXFBRsWD9cWVnB5ZdfjhdffJHKeVEooYEGPop3vPLKK3jllVfwxBNP+J2aMxgM6OzsRH5+Pjsvt7KygsjISDbASaXSoA57e+KeQE6cnZ2dbLqyv78fUVFRqKurY4NcaWkpNU+lULY+NPBRvMNut+Occ87B3Xffje3bt3v1b81mM5uqJNJexI0gMzOTVT0JNS+//DJmZmbw9a9/HcDqKaynp4dNV8pkMoSFhaGmpoZtPqmqqqInNArlPxMa+Cje09PTg69+9at499133Z5wLBbLOpFmV9JexLqorq7O76YZXyAyYjfccAP27NmD/v5+2Gw2VFRUsDW5mpoatzJkFArlPw4a+Ci+ceutt6KiogLXXHMNFhcXsbKywoo1eyvtNTc3h/n5+aAISDtis9kwPDzsZJ6q1+tRWlqKqKgoKBQKvPTSSxCLxTTIUSj/vdDAR/EOvV6P9vZ2fPzxx3jssccQGRmJqKgo/OhHP0JNTQ2reuJN4GAYBu3t7cjPz/dbE5RAZuUcOyyXl5dRWFjIdlg2NjYiNjYWPB4PDMPgoosuwre+9S3s3bs3IK+BQqFsSWjgo3jG2NgYLr30UoSHh6O+vh6NjY0YGRmBTqfDT3/6U7/X1+v1kMlkaGpq8kl+S6lUsrNyHR0dmJmZQXZ2NluTa2pqQlJS0oZrT0xM4Cc/+Qn+8Ic/+Pt2KBTK1oUGPopn2Gw22Gw2pw5Lq9WKU045BU888URAZuGGhoYQGRmJrKwst7/DMAxUKpXTSW5ychJpaWmseWpTUxMyMjJoupJCobiCBj6Kf3z44Yf4xS9+gRdffNHvQGOz2XD77bfjnnvuQVpaGhiGgVqtRnt7OxvkRkZGEB8f7zQQnpeXR33lKBSKp9DAR/EPhmFwxRVX4LLLLsM555zj1zp6vR6/+tWvcOzYMSQnJ2NwcBAikYhNrW7btg3FxcV0Vo5CofgDDXwU/5mcnMRFF12EI0eOeDySYDKZ0N3dzXZYymQyhIeHo6amBp988gnuvfdefOlLX6KzchQKJdDQwEcJDPfffz+EQiFuv/32df/NbDajr6+PTVd2dXWBYRhUVlY6zcqRoNnb24ubbroJH330EU1hUiiUQEMDHyUwEB3PV155BUtLS2yQ6+zshMlkQnl5ORobG9HY2Ij6+vpNzVPvuusuXHzxxdi1a1cI3wWFQjkJoIGPEjh+8Ytf4JFHHsHu3bvZDsv6+npIpVLqEE6hULYKNPBRAgfDMLDb7bT5hEKhbGVo4KNQKBTKSYXbwEc7CigUypZFq9XivvvuQ3l5Ob7yla8AWJWpo1D8gQY+CoWyZREKheDz+fjmN7+Jzs5OAKAdwBS/oalOCoUScsipzZMgplarER0djV27duHZZ59FUVERbYqieAJNdVIoFG7o7OxET0+P08/CwsKcgt709DTGx8ddpjGlUimEQiGys7PR3NwMYLXBikLxFRr4KBRKwCCB6+WXX8bPfvYzWK1WTExMICwsDDabDcCqQ8fnn3+O++67D11dXfj1r3+N3bt345ZbbsGhQ4cAgP1dRyorK/H55587XYdC8QUa+CgUSsAgpzgej4fZ2VmMjY1h//790Gq14PP5eOSRR7B371689tprGB4exi233AKVSoXR0VHs378fjz76qNM6jtTU1KCvrw8AIBAIQvemKP910MBHoVAChkwmw6OPPoqjR4/CYrHAaDTi+PHjeOCBBzA9PY2qqiosLi7iG9/4Bv7617+isbERVqsVAHDaaadhZmYGAFzW73bv3o3JyUm8//77OH78eEjfF+W/Cxr4KBRKQJicnMSdd94JpVKJxMREvP3221AoFKioqEBcXBzkcjlqamoAAKmpqTCZTKiqqoLZbAYAVFdXw2g0QqFQrFv7N7/5DXbv3o2ZmRncddddmJycZAMmheItNPBRKJSA0NvbC71ej5/97Ge4++67cdppp6G/vx/x8fGIiIjA6OgokpOTIRAI0N/fj8jISCQnJ8NgMLDBjsfj4dixY+yapJa3b98+vPnmm1heXkZbWxsuu+wymu6k+AwNfBQKJSDMzc3hzDPPhFqtBgBUVVWxqcusrCzI5XIAQH5+PpuqlEgk0Gq1GB0dBQDce++9KCgoYNcktb7Kykqnn1Mo/kC3TBQKJSAUFRXh008/hVwuh1QqxcTEBPr7+6FWq5GdnY0PP/wQALBt2zZMTk4CAOrq6vDwww8jNTUVdrudVWehUIIJHWCnUCgBwWaz4c4778T09DQqKyvR2tqKxMRE3HrrrYiNjcXg4CD27t1LU5SUUEFFqikUSvBZWlrC3//+dywvL+O8885DeXk5DXQUrqCBj0KhUCgnFVSyjEKhUCgUgAY+CoVCoZxk0MBHoVAolJMKGvgoFAqFclJBAx+FQqFQTipo4KNQKBTKSQUNfBQKhUI5qaCBj0KhUCgnFTTwUSgUCuWkggY+CoVCoZxU0MBHoVAolJMKGvgoFAqFclJBAx+FQqFQTipo4KNQKBTKSQUNfBQKhUI5qaCBj0KhUCgnFTTwUSgUCuWkggY+CoVCoZxUCDb5726t2ykUCoVC+U+EnvgoFAqFclJBAx+FQqFQTipo4KNQKBTKSQUNfBQKhUI5qaCBj0KhUCgnFTTwUSgUCuWk4v8Drq/DF+46DSoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_data = datasets.make_classification(n_samples=5000, class_sep = 1, random_state = 1,\n",
    "                                           n_features=3, n_informative = 3, n_redundant = 0, n_classes=3)\n",
    "random_data_x, random_data_y = random_data[0], random_data[1]\n",
    "\n",
    "# \n",
    "visable_num = 450\n",
    "fig2 = plt.figure(1, figsize=(8, 6))\n",
    "ax2 = Axes3D(fig2, elev=-150, azim=110)\n",
    "ax2.scatter(random_data_x[:visable_num][:, 0], random_data_x[:visable_num][:, 1], \n",
    "            random_data_x[:visable_num][:, 2], c=random_data_y[:visable_num],\n",
    "           cmap=plt.cm.Set1, edgecolor='k', s=40)\n",
    "ax2.set_title(\"random_data\")\n",
    "ax2.set_xlabel(\"dim 1\")\n",
    "ax2.w_xaxis.set_ticklabels([])\n",
    "ax2.set_ylabel(\"dim 2\")\n",
    "ax2.w_yaxis.set_ticklabels([])\n",
    "ax2.set_zlabel(\"dim 3\")\n",
    "ax2.w_zaxis.set_ticklabels([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(-0.8, 0, ''),\n",
       " Text(-0.6000000000000001, 0, ''),\n",
       " Text(-0.4, 0, ''),\n",
       " Text(-0.19999999999999996, 0, ''),\n",
       " Text(0.0, 0, ''),\n",
       " Text(0.19999999999999996, 0, ''),\n",
       " Text(0.40000000000000013, 0, ''),\n",
       " Text(0.6000000000000001, 0, ''),\n",
       " Text(0.8, 0, ''),\n",
       " Text(1.0, 0, '')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "fig = plt.figure(1, figsize=(8, 6))\n",
    "ax = Axes3D(fig, elev=-150, azim=110)\n",
    "X_reduced = PCA(n_components=3).fit_transform(iris.data)\n",
    "y = iris.target\n",
    "\n",
    "# \n",
    "ax.scatter(X_reduced[:, 0], X_reduced[:, 1], X_reduced[:, 2], c=y,\n",
    "           cmap=plt.cm.Set1, edgecolor='k', s=40)\n",
    "ax.set_title(\"Iris data first three PCA directions\")\n",
    "ax.set_xlabel(\"1st eigenvector\")\n",
    "ax.w_xaxis.set_ticklabels([])\n",
    "ax.set_ylabel(\"2nd eigenvector\")\n",
    "ax.w_yaxis.set_ticklabels([])\n",
    "ax.set_zlabel(\"3rd eigenvector\")\n",
    "ax.w_zaxis.set_ticklabels([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def irisData_loader(x, y, batch_size = 30):\n",
    "\n",
    "    random_data_idx = np.random.choice(50, 50, replace=False)\n",
    "    X_train = torch.Tensor(x.reshape(3,50,3)[:,random_data_idx[:30],:].reshape(-1,3))\n",
    "    X_val = torch.Tensor(x.reshape(3,50,3)[:,random_data_idx[30:40],:].reshape(-1,3))\n",
    "    X_test = torch.Tensor(x.reshape(3,50,3)[:,random_data_idx[40:],:].reshape(-1,3))\n",
    "\n",
    "    y = torch.LongTensor(y)\n",
    "    y_train = y.reshape(3,50)[:,:30].reshape(-1)\n",
    "    y_val = y.reshape(3,50)[:,30:40].reshape(-1)\n",
    "    y_test = y.reshape(3,50)[:,40:].reshape(-1)\n",
    "    \n",
    "    train_data = TensorDataset(X_train, y_train)\n",
    "    val_data = TensorDataset(X_val, y_val)\n",
    "    test_data = TensorDataset(X_test, y_test)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    loader = {'train':train_loader, 'val':val_loader, 'test':test_loader}\n",
    "    return loader\n",
    "\n",
    "def randomData_loader(x, y, batch_size = 5000):\n",
    "    random_data_num = len(y)\n",
    "    X_train = torch.Tensor(x[:int(random_data_num*0.9)])\n",
    "    X_val = torch.Tensor(x[int(random_data_num*0.9):-int(random_data_num*0.05)])\n",
    "    X_test = torch.Tensor(x[-int(random_data_num*0.05):])\n",
    "\n",
    "    y = torch.LongTensor(y)\n",
    "    y_train = y[:int(random_data_num*0.9)]\n",
    "    y_val = y[int(random_data_num*0.9):-int(random_data_num*0.05)]\n",
    "    y_test = y[-int(random_data_num*0.05):]\n",
    "    \n",
    "    train_data = TensorDataset(X_train, y_train)\n",
    "    val_data = TensorDataset(X_val, y_val)\n",
    "    test_data = TensorDataset(X_test, y_test)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    loader = {'train':train_loader, 'val':val_loader, 'test':test_loader}\n",
    "    return loader\n",
    "\n",
    "np.random.seed(123)\n",
    "loader = irisData_loader(X_reduced, y)\n",
    "loader_random = randomData_loader(random_data_x, random_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, test_size=0.33, random_state=1234)# 17 17 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_iris_3_10 = LinearNetwork().to(device)\n",
    "model_iris_1_10 = LinearNetwork(n_layer = 1).to(device)\n",
    "model_iris_5_10 = LinearNetwork(n_layer = 5).to(device)\n",
    "model_iris_3_05 = LinearNetwork(n_hidden = 5).to(device)\n",
    "model_iris_3_15 = LinearNetwork(n_hidden = 15).to(device)\n",
    "\n",
    "# model_random_3_10 = LinearNetwork().to(device)\n",
    "# model_random_1_10 = LinearNetwork(n_layer = 1).to(device)\n",
    "# model_random_5_10 = LinearNetwork(n_layer = 5).to(device)\n",
    "# model_random_3_05 = LinearNetwork(n_hidden = 5).to(device)\n",
    "# model_random_3_15 = LinearNetwork(n_hidden = 15).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "\n",
    "#     val_acc_history = []\n",
    "    acc_history = {'train':[], 'val':[], 'test':[]}\n",
    "    loss_history = {'train':[], 'val':[], 'test':[]}\n",
    "    f1_history = {'train':[], 'val':[], 'test':[]}\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        for phase in ['train', 'val', 'test']:\n",
    "            if phase == 'train':\n",
    "                model.train()  \n",
    "            else:\n",
    "                model.eval()   \n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    if is_inception and phase == 'train':\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            if phase == 'test' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "            preds = np.array(preds.cpu())\n",
    "            ytest = np.array(labels.data.cpu())\n",
    "            epoch_f1 = metrics.f1_score(ytest, preds, zero_division=False, average='macro')\n",
    "            acc_history[phase].append(np.array(epoch_acc.cpu()))\n",
    "            loss_history[phase].append(epoch_loss)\n",
    "            f1_history[phase].append(epoch_f1)\n",
    "\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best test Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, acc_history, loss_history, f1_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 1.0992 Acc: 0.3333\n",
      "val Loss: 1.0965 Acc: 0.3333\n",
      "test Loss: 1.0973 Acc: 0.3333\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 1.0964 Acc: 0.3333\n",
      "val Loss: 1.0940 Acc: 0.3333\n",
      "test Loss: 1.0955 Acc: 0.3333\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 1.0976 Acc: 0.3333\n",
      "val Loss: 1.0952 Acc: 0.3333\n",
      "test Loss: 1.0913 Acc: 0.3333\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 1.0958 Acc: 0.3333\n",
      "val Loss: 1.0934 Acc: 0.3333\n",
      "test Loss: 1.0933 Acc: 0.3333\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 1.0950 Acc: 0.3333\n",
      "val Loss: 1.0939 Acc: 0.3333\n",
      "test Loss: 1.0895 Acc: 0.3333\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 1.0937 Acc: 0.3333\n",
      "val Loss: 1.0923 Acc: 0.3333\n",
      "test Loss: 1.0928 Acc: 0.3333\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 1.0921 Acc: 0.3333\n",
      "val Loss: 1.0935 Acc: 0.3333\n",
      "test Loss: 1.0909 Acc: 0.3333\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 1.0914 Acc: 0.3333\n",
      "val Loss: 1.0889 Acc: 0.3667\n",
      "test Loss: 1.0910 Acc: 0.3333\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 1.0915 Acc: 0.3333\n",
      "val Loss: 1.0882 Acc: 0.4000\n",
      "test Loss: 1.0879 Acc: 0.4000\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 1.0892 Acc: 0.3667\n",
      "val Loss: 1.0872 Acc: 0.5000\n",
      "test Loss: 1.0875 Acc: 0.5000\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 1.0892 Acc: 0.5111\n",
      "val Loss: 1.0862 Acc: 0.5333\n",
      "test Loss: 1.0872 Acc: 0.5667\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 1.0857 Acc: 0.5556\n",
      "val Loss: 1.0828 Acc: 0.6333\n",
      "test Loss: 1.0863 Acc: 0.5333\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 1.0852 Acc: 0.5778\n",
      "val Loss: 1.0856 Acc: 0.5333\n",
      "test Loss: 1.0827 Acc: 0.6667\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 1.0848 Acc: 0.5889\n",
      "val Loss: 1.0810 Acc: 0.6000\n",
      "test Loss: 1.0822 Acc: 0.6667\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 1.0833 Acc: 0.5778\n",
      "val Loss: 1.0772 Acc: 0.6667\n",
      "test Loss: 1.0794 Acc: 0.6333\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 1.0802 Acc: 0.6111\n",
      "val Loss: 1.0781 Acc: 0.6667\n",
      "test Loss: 1.0770 Acc: 0.6333\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 1.0791 Acc: 0.6333\n",
      "val Loss: 1.0774 Acc: 0.6333\n",
      "test Loss: 1.0757 Acc: 0.6667\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 1.0783 Acc: 0.5889\n",
      "val Loss: 1.0773 Acc: 0.6000\n",
      "test Loss: 1.0761 Acc: 0.6333\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 1.0761 Acc: 0.6556\n",
      "val Loss: 1.0752 Acc: 0.6333\n",
      "test Loss: 1.0713 Acc: 0.6667\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 1.0753 Acc: 0.6556\n",
      "val Loss: 1.0711 Acc: 0.7000\n",
      "test Loss: 1.0722 Acc: 0.6333\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 1.0710 Acc: 0.6889\n",
      "val Loss: 1.0696 Acc: 0.6667\n",
      "test Loss: 1.0684 Acc: 0.6667\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 1.0718 Acc: 0.6667\n",
      "val Loss: 1.0656 Acc: 0.7000\n",
      "test Loss: 1.0734 Acc: 0.5333\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 1.0667 Acc: 0.7000\n",
      "val Loss: 1.0685 Acc: 0.6333\n",
      "test Loss: 1.0652 Acc: 0.6333\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 1.0681 Acc: 0.6667\n",
      "val Loss: 1.0577 Acc: 0.6667\n",
      "test Loss: 1.0679 Acc: 0.6000\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 1.0659 Acc: 0.6778\n",
      "val Loss: 1.0591 Acc: 0.7333\n",
      "test Loss: 1.0580 Acc: 0.7000\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 1.0609 Acc: 0.7111\n",
      "val Loss: 1.0584 Acc: 0.7000\n",
      "test Loss: 1.0568 Acc: 0.7000\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 1.0552 Acc: 0.7333\n",
      "val Loss: 1.0491 Acc: 0.7667\n",
      "test Loss: 1.0556 Acc: 0.7000\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 1.0545 Acc: 0.7222\n",
      "val Loss: 1.0527 Acc: 0.7667\n",
      "test Loss: 1.0472 Acc: 0.7000\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 1.0524 Acc: 0.7000\n",
      "val Loss: 1.0458 Acc: 0.7667\n",
      "test Loss: 1.0423 Acc: 0.7333\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 1.0485 Acc: 0.7000\n",
      "val Loss: 1.0421 Acc: 0.8000\n",
      "test Loss: 1.0405 Acc: 0.7000\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 1.0462 Acc: 0.6889\n",
      "val Loss: 1.0385 Acc: 0.7333\n",
      "test Loss: 1.0341 Acc: 0.8000\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 1.0422 Acc: 0.7333\n",
      "val Loss: 1.0354 Acc: 0.7333\n",
      "test Loss: 1.0352 Acc: 0.7667\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 1.0340 Acc: 0.7111\n",
      "val Loss: 1.0301 Acc: 0.7667\n",
      "test Loss: 1.0308 Acc: 0.8000\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 1.0321 Acc: 0.7111\n",
      "val Loss: 1.0264 Acc: 0.8000\n",
      "test Loss: 1.0382 Acc: 0.6667\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 1.0284 Acc: 0.7111\n",
      "val Loss: 1.0247 Acc: 0.7333\n",
      "test Loss: 1.0161 Acc: 0.7667\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 1.0244 Acc: 0.6889\n",
      "val Loss: 1.0236 Acc: 0.7000\n",
      "test Loss: 1.0160 Acc: 0.8000\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 1.0193 Acc: 0.7000\n",
      "val Loss: 1.0106 Acc: 0.8000\n",
      "test Loss: 1.0134 Acc: 0.7667\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 1.0148 Acc: 0.7111\n",
      "val Loss: 1.0184 Acc: 0.6667\n",
      "test Loss: 1.0149 Acc: 0.7667\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 1.0086 Acc: 0.7222\n",
      "val Loss: 1.0046 Acc: 0.7667\n",
      "test Loss: 1.0085 Acc: 0.8000\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 1.0032 Acc: 0.7222\n",
      "val Loss: 0.9937 Acc: 0.7333\n",
      "test Loss: 0.9934 Acc: 0.8000\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 1.0001 Acc: 0.7444\n",
      "val Loss: 0.9940 Acc: 0.8000\n",
      "test Loss: 0.9986 Acc: 0.7667\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.9976 Acc: 0.7222\n",
      "val Loss: 0.9848 Acc: 0.8000\n",
      "test Loss: 0.9883 Acc: 0.8000\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.9933 Acc: 0.7444\n",
      "val Loss: 0.9933 Acc: 0.7667\n",
      "test Loss: 0.9904 Acc: 0.8000\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.9841 Acc: 0.7444\n",
      "val Loss: 0.9752 Acc: 0.8000\n",
      "test Loss: 0.9797 Acc: 0.7667\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.9825 Acc: 0.6889\n",
      "val Loss: 0.9861 Acc: 0.7000\n",
      "test Loss: 0.9767 Acc: 0.7333\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.9750 Acc: 0.7444\n",
      "val Loss: 0.9811 Acc: 0.8000\n",
      "test Loss: 0.9751 Acc: 0.7667\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.9766 Acc: 0.7111\n",
      "val Loss: 0.9633 Acc: 0.8000\n",
      "test Loss: 0.9641 Acc: 0.8000\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.9723 Acc: 0.7222\n",
      "val Loss: 0.9666 Acc: 0.7667\n",
      "test Loss: 0.9659 Acc: 0.8000\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.9661 Acc: 0.7000\n",
      "val Loss: 0.9566 Acc: 0.7333\n",
      "test Loss: 0.9637 Acc: 0.7667\n",
      "Epoch 49/499\n",
      "----------\n",
      "train Loss: 0.9649 Acc: 0.7111\n",
      "val Loss: 0.9592 Acc: 0.7667\n",
      "test Loss: 0.9607 Acc: 0.8333\n",
      "Epoch 50/499\n",
      "----------\n",
      "train Loss: 0.9530 Acc: 0.7333\n",
      "val Loss: 0.9626 Acc: 0.8000\n",
      "test Loss: 0.9577 Acc: 0.7333\n",
      "Epoch 51/499\n",
      "----------\n",
      "train Loss: 0.9523 Acc: 0.7333\n",
      "val Loss: 0.9581 Acc: 0.7333\n",
      "test Loss: 0.9506 Acc: 0.8333\n",
      "Epoch 52/499\n",
      "----------\n",
      "train Loss: 0.9469 Acc: 0.7333\n",
      "val Loss: 0.9377 Acc: 0.8000\n",
      "test Loss: 0.9398 Acc: 0.8000\n",
      "Epoch 53/499\n",
      "----------\n",
      "train Loss: 0.9471 Acc: 0.7222\n",
      "val Loss: 0.9394 Acc: 0.7333\n",
      "test Loss: 0.9373 Acc: 0.7667\n",
      "Epoch 54/499\n",
      "----------\n",
      "train Loss: 0.9397 Acc: 0.7111\n",
      "val Loss: 0.9306 Acc: 0.8000\n",
      "test Loss: 0.9410 Acc: 0.8333\n",
      "Epoch 55/499\n",
      "----------\n",
      "train Loss: 0.9396 Acc: 0.7222\n",
      "val Loss: 0.9244 Acc: 0.8000\n",
      "test Loss: 0.9313 Acc: 0.7667\n",
      "Epoch 56/499\n",
      "----------\n",
      "train Loss: 0.9296 Acc: 0.7111\n",
      "val Loss: 0.9259 Acc: 0.7667\n",
      "test Loss: 0.9275 Acc: 0.8000\n",
      "Epoch 57/499\n",
      "----------\n",
      "train Loss: 0.9235 Acc: 0.7111\n",
      "val Loss: 0.9412 Acc: 0.7667\n",
      "test Loss: 0.9155 Acc: 0.8000\n",
      "Epoch 58/499\n",
      "----------\n",
      "train Loss: 0.9215 Acc: 0.7222\n",
      "val Loss: 0.9151 Acc: 0.8333\n",
      "test Loss: 0.9104 Acc: 0.7667\n",
      "Epoch 59/499\n",
      "----------\n",
      "train Loss: 0.9160 Acc: 0.7222\n",
      "val Loss: 0.9181 Acc: 0.8000\n",
      "test Loss: 0.9074 Acc: 0.7667\n",
      "Epoch 60/499\n",
      "----------\n",
      "train Loss: 0.9159 Acc: 0.7222\n",
      "val Loss: 0.9125 Acc: 0.8000\n",
      "test Loss: 0.9066 Acc: 0.7333\n",
      "Epoch 61/499\n",
      "----------\n",
      "train Loss: 0.9084 Acc: 0.7556\n",
      "val Loss: 0.9097 Acc: 0.7000\n",
      "test Loss: 0.9018 Acc: 0.8000\n",
      "Epoch 62/499\n",
      "----------\n",
      "train Loss: 0.9046 Acc: 0.7111\n",
      "val Loss: 0.9006 Acc: 0.7667\n",
      "test Loss: 0.9007 Acc: 0.7333\n",
      "Epoch 63/499\n",
      "----------\n",
      "train Loss: 0.8976 Acc: 0.7111\n",
      "val Loss: 0.8974 Acc: 0.8000\n",
      "test Loss: 0.8906 Acc: 0.7000\n",
      "Epoch 64/499\n",
      "----------\n",
      "train Loss: 0.8982 Acc: 0.7222\n",
      "val Loss: 0.8916 Acc: 0.7667\n",
      "test Loss: 0.8957 Acc: 0.7667\n",
      "Epoch 65/499\n",
      "----------\n",
      "train Loss: 0.8922 Acc: 0.7111\n",
      "val Loss: 0.8835 Acc: 0.7667\n",
      "test Loss: 0.8801 Acc: 0.7333\n",
      "Epoch 66/499\n",
      "----------\n",
      "train Loss: 0.8825 Acc: 0.7111\n",
      "val Loss: 0.8868 Acc: 0.7000\n",
      "test Loss: 0.8838 Acc: 0.7667\n",
      "Epoch 67/499\n",
      "----------\n",
      "train Loss: 0.8808 Acc: 0.6889\n",
      "val Loss: 0.8726 Acc: 0.7333\n",
      "test Loss: 0.8701 Acc: 0.7333\n",
      "Epoch 68/499\n",
      "----------\n",
      "train Loss: 0.8751 Acc: 0.7000\n",
      "val Loss: 0.8675 Acc: 0.8000\n",
      "test Loss: 0.8727 Acc: 0.7333\n",
      "Epoch 69/499\n",
      "----------\n",
      "train Loss: 0.8699 Acc: 0.6889\n",
      "val Loss: 0.8853 Acc: 0.7000\n",
      "test Loss: 0.8687 Acc: 0.7333\n",
      "Epoch 70/499\n",
      "----------\n",
      "train Loss: 0.8712 Acc: 0.7111\n",
      "val Loss: 0.8625 Acc: 0.7000\n",
      "test Loss: 0.8618 Acc: 0.6667\n",
      "Epoch 71/499\n",
      "----------\n",
      "train Loss: 0.8673 Acc: 0.7222\n",
      "val Loss: 0.8541 Acc: 0.6667\n",
      "test Loss: 0.8509 Acc: 0.7333\n",
      "Epoch 72/499\n",
      "----------\n",
      "train Loss: 0.8624 Acc: 0.7222\n",
      "val Loss: 0.8442 Acc: 0.7667\n",
      "test Loss: 0.8468 Acc: 0.7000\n",
      "Epoch 73/499\n",
      "----------\n",
      "train Loss: 0.8524 Acc: 0.7000\n",
      "val Loss: 0.8490 Acc: 0.7000\n",
      "test Loss: 0.8412 Acc: 0.7000\n",
      "Epoch 74/499\n",
      "----------\n",
      "train Loss: 0.8470 Acc: 0.7222\n",
      "val Loss: 0.8408 Acc: 0.7000\n",
      "test Loss: 0.8486 Acc: 0.7000\n",
      "Epoch 75/499\n",
      "----------\n",
      "train Loss: 0.8449 Acc: 0.7333\n",
      "val Loss: 0.8440 Acc: 0.7333\n",
      "test Loss: 0.8395 Acc: 0.7000\n",
      "Epoch 76/499\n",
      "----------\n",
      "train Loss: 0.8397 Acc: 0.7222\n",
      "val Loss: 0.8284 Acc: 0.7333\n",
      "test Loss: 0.8464 Acc: 0.6667\n",
      "Epoch 77/499\n",
      "----------\n",
      "train Loss: 0.8395 Acc: 0.7111\n",
      "val Loss: 0.8300 Acc: 0.7333\n",
      "test Loss: 0.8325 Acc: 0.7000\n",
      "Epoch 78/499\n",
      "----------\n",
      "train Loss: 0.8305 Acc: 0.7111\n",
      "val Loss: 0.8208 Acc: 0.7333\n",
      "test Loss: 0.8336 Acc: 0.7000\n",
      "Epoch 79/499\n",
      "----------\n",
      "train Loss: 0.8327 Acc: 0.7000\n",
      "val Loss: 0.8159 Acc: 0.7000\n",
      "test Loss: 0.8162 Acc: 0.7000\n",
      "Epoch 80/499\n",
      "----------\n",
      "train Loss: 0.8235 Acc: 0.7111\n",
      "val Loss: 0.8205 Acc: 0.7333\n",
      "test Loss: 0.8146 Acc: 0.7000\n",
      "Epoch 81/499\n",
      "----------\n",
      "train Loss: 0.8200 Acc: 0.6778\n",
      "val Loss: 0.8086 Acc: 0.7333\n",
      "test Loss: 0.8194 Acc: 0.7000\n",
      "Epoch 82/499\n",
      "----------\n",
      "train Loss: 0.8191 Acc: 0.7111\n",
      "val Loss: 0.8092 Acc: 0.7000\n",
      "test Loss: 0.8114 Acc: 0.6667\n",
      "Epoch 83/499\n",
      "----------\n",
      "train Loss: 0.8108 Acc: 0.7000\n",
      "val Loss: 0.8079 Acc: 0.7667\n",
      "test Loss: 0.8057 Acc: 0.7333\n",
      "Epoch 84/499\n",
      "----------\n",
      "train Loss: 0.8058 Acc: 0.7222\n",
      "val Loss: 0.7982 Acc: 0.7333\n",
      "test Loss: 0.8003 Acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/499\n",
      "----------\n",
      "train Loss: 0.8045 Acc: 0.7333\n",
      "val Loss: 0.8021 Acc: 0.7333\n",
      "test Loss: 0.8051 Acc: 0.6667\n",
      "Epoch 86/499\n",
      "----------\n",
      "train Loss: 0.8066 Acc: 0.6889\n",
      "val Loss: 0.7908 Acc: 0.8000\n",
      "test Loss: 0.7936 Acc: 0.7667\n",
      "Epoch 87/499\n",
      "----------\n",
      "train Loss: 0.7976 Acc: 0.7778\n",
      "val Loss: 0.7859 Acc: 0.7667\n",
      "test Loss: 0.8036 Acc: 0.6667\n",
      "Epoch 88/499\n",
      "----------\n",
      "train Loss: 0.7988 Acc: 0.7111\n",
      "val Loss: 0.7864 Acc: 0.7333\n",
      "test Loss: 0.7901 Acc: 0.7000\n",
      "Epoch 89/499\n",
      "----------\n",
      "train Loss: 0.7937 Acc: 0.7333\n",
      "val Loss: 0.7781 Acc: 0.7667\n",
      "test Loss: 0.7922 Acc: 0.7000\n",
      "Epoch 90/499\n",
      "----------\n",
      "train Loss: 0.7960 Acc: 0.7222\n",
      "val Loss: 0.7682 Acc: 0.7667\n",
      "test Loss: 0.7831 Acc: 0.7333\n",
      "Epoch 91/499\n",
      "----------\n",
      "train Loss: 0.7902 Acc: 0.7444\n",
      "val Loss: 0.7823 Acc: 0.7333\n",
      "test Loss: 0.7745 Acc: 0.7333\n",
      "Epoch 92/499\n",
      "----------\n",
      "train Loss: 0.7928 Acc: 0.7111\n",
      "val Loss: 0.7815 Acc: 0.7333\n",
      "test Loss: 0.7829 Acc: 0.7667\n",
      "Epoch 93/499\n",
      "----------\n",
      "train Loss: 0.7818 Acc: 0.7222\n",
      "val Loss: 0.7720 Acc: 0.8000\n",
      "test Loss: 0.7820 Acc: 0.8000\n",
      "Epoch 94/499\n",
      "----------\n",
      "train Loss: 0.7857 Acc: 0.7333\n",
      "val Loss: 0.7723 Acc: 0.7667\n",
      "test Loss: 0.7896 Acc: 0.7667\n",
      "Epoch 95/499\n",
      "----------\n",
      "train Loss: 0.7865 Acc: 0.7222\n",
      "val Loss: 0.7880 Acc: 0.7000\n",
      "test Loss: 0.7693 Acc: 0.7667\n",
      "Epoch 96/499\n",
      "----------\n",
      "train Loss: 0.7704 Acc: 0.7444\n",
      "val Loss: 0.7649 Acc: 0.7667\n",
      "test Loss: 0.7829 Acc: 0.7667\n",
      "Epoch 97/499\n",
      "----------\n",
      "train Loss: 0.7706 Acc: 0.7556\n",
      "val Loss: 0.7586 Acc: 0.7667\n",
      "test Loss: 0.7764 Acc: 0.7667\n",
      "Epoch 98/499\n",
      "----------\n",
      "train Loss: 0.7690 Acc: 0.7667\n",
      "val Loss: 0.7579 Acc: 0.8000\n",
      "test Loss: 0.7684 Acc: 0.8000\n",
      "Epoch 99/499\n",
      "----------\n",
      "train Loss: 0.7657 Acc: 0.7556\n",
      "val Loss: 0.7554 Acc: 0.8333\n",
      "test Loss: 0.7836 Acc: 0.7667\n",
      "Epoch 100/499\n",
      "----------\n",
      "train Loss: 0.7665 Acc: 0.7556\n",
      "val Loss: 0.7518 Acc: 0.8000\n",
      "test Loss: 0.7692 Acc: 0.8000\n",
      "Epoch 101/499\n",
      "----------\n",
      "train Loss: 0.7656 Acc: 0.7556\n",
      "val Loss: 0.7453 Acc: 0.8000\n",
      "test Loss: 0.7707 Acc: 0.7667\n",
      "Epoch 102/499\n",
      "----------\n",
      "train Loss: 0.7653 Acc: 0.7667\n",
      "val Loss: 0.7434 Acc: 0.9000\n",
      "test Loss: 0.7752 Acc: 0.8000\n",
      "Epoch 103/499\n",
      "----------\n",
      "train Loss: 0.7588 Acc: 0.7667\n",
      "val Loss: 0.7448 Acc: 0.8333\n",
      "test Loss: 0.7615 Acc: 0.7667\n",
      "Epoch 104/499\n",
      "----------\n",
      "train Loss: 0.7590 Acc: 0.7667\n",
      "val Loss: 0.7495 Acc: 0.8333\n",
      "test Loss: 0.7438 Acc: 0.8000\n",
      "Epoch 105/499\n",
      "----------\n",
      "train Loss: 0.7623 Acc: 0.7667\n",
      "val Loss: 0.7342 Acc: 0.8667\n",
      "test Loss: 0.7705 Acc: 0.8000\n",
      "Epoch 106/499\n",
      "----------\n",
      "train Loss: 0.7552 Acc: 0.7556\n",
      "val Loss: 0.7479 Acc: 0.8333\n",
      "test Loss: 0.7613 Acc: 0.8333\n",
      "Epoch 107/499\n",
      "----------\n",
      "train Loss: 0.7504 Acc: 0.7556\n",
      "val Loss: 0.7370 Acc: 0.8667\n",
      "test Loss: 0.7499 Acc: 0.8333\n",
      "Epoch 108/499\n",
      "----------\n",
      "train Loss: 0.7483 Acc: 0.7889\n",
      "val Loss: 0.7441 Acc: 0.8333\n",
      "test Loss: 0.7586 Acc: 0.8000\n",
      "Epoch 109/499\n",
      "----------\n",
      "train Loss: 0.7500 Acc: 0.7889\n",
      "val Loss: 0.7309 Acc: 0.8333\n",
      "test Loss: 0.7638 Acc: 0.7667\n",
      "Epoch 110/499\n",
      "----------\n",
      "train Loss: 0.7487 Acc: 0.7889\n",
      "val Loss: 0.7381 Acc: 0.8333\n",
      "test Loss: 0.7380 Acc: 0.8333\n",
      "Epoch 111/499\n",
      "----------\n",
      "train Loss: 0.7399 Acc: 0.8111\n",
      "val Loss: 0.7332 Acc: 0.8000\n",
      "test Loss: 0.7654 Acc: 0.8000\n",
      "Epoch 112/499\n",
      "----------\n",
      "train Loss: 0.7436 Acc: 0.8111\n",
      "val Loss: 0.7224 Acc: 0.8667\n",
      "test Loss: 0.7510 Acc: 0.7667\n",
      "Epoch 113/499\n",
      "----------\n",
      "train Loss: 0.7485 Acc: 0.8111\n",
      "val Loss: 0.7257 Acc: 0.8333\n",
      "test Loss: 0.7471 Acc: 0.8000\n",
      "Epoch 114/499\n",
      "----------\n",
      "train Loss: 0.7387 Acc: 0.8222\n",
      "val Loss: 0.7324 Acc: 0.8667\n",
      "test Loss: 0.7328 Acc: 0.8000\n",
      "Epoch 115/499\n",
      "----------\n",
      "train Loss: 0.7442 Acc: 0.8000\n",
      "val Loss: 0.7264 Acc: 0.8333\n",
      "test Loss: 0.7535 Acc: 0.7667\n",
      "Epoch 116/499\n",
      "----------\n",
      "train Loss: 0.7408 Acc: 0.8222\n",
      "val Loss: 0.7220 Acc: 0.9000\n",
      "test Loss: 0.7523 Acc: 0.7333\n",
      "Epoch 117/499\n",
      "----------\n",
      "train Loss: 0.7346 Acc: 0.8444\n",
      "val Loss: 0.7145 Acc: 0.8667\n",
      "test Loss: 0.7380 Acc: 0.8000\n",
      "Epoch 118/499\n",
      "----------\n",
      "train Loss: 0.7321 Acc: 0.8667\n",
      "val Loss: 0.7141 Acc: 0.9000\n",
      "test Loss: 0.7492 Acc: 0.8333\n",
      "Epoch 119/499\n",
      "----------\n",
      "train Loss: 0.7411 Acc: 0.8222\n",
      "val Loss: 0.7150 Acc: 0.9667\n",
      "test Loss: 0.7338 Acc: 0.8333\n",
      "Epoch 120/499\n",
      "----------\n",
      "train Loss: 0.7300 Acc: 0.8444\n",
      "val Loss: 0.7247 Acc: 0.8667\n",
      "test Loss: 0.7390 Acc: 0.8333\n",
      "Epoch 121/499\n",
      "----------\n",
      "train Loss: 0.7228 Acc: 0.8333\n",
      "val Loss: 0.7091 Acc: 0.8667\n",
      "test Loss: 0.7355 Acc: 0.8333\n",
      "Epoch 122/499\n",
      "----------\n",
      "train Loss: 0.7207 Acc: 0.8556\n",
      "val Loss: 0.7071 Acc: 0.9333\n",
      "test Loss: 0.7419 Acc: 0.8333\n",
      "Epoch 123/499\n",
      "----------\n",
      "train Loss: 0.7216 Acc: 0.8667\n",
      "val Loss: 0.7241 Acc: 0.8667\n",
      "test Loss: 0.7447 Acc: 0.8000\n",
      "Epoch 124/499\n",
      "----------\n",
      "train Loss: 0.7302 Acc: 0.8667\n",
      "val Loss: 0.6986 Acc: 0.9000\n",
      "test Loss: 0.7202 Acc: 0.8333\n",
      "Epoch 125/499\n",
      "----------\n",
      "train Loss: 0.7166 Acc: 0.8778\n",
      "val Loss: 0.7005 Acc: 0.9000\n",
      "test Loss: 0.7340 Acc: 0.8333\n",
      "Epoch 126/499\n",
      "----------\n",
      "train Loss: 0.7242 Acc: 0.8667\n",
      "val Loss: 0.7073 Acc: 0.9333\n",
      "test Loss: 0.7324 Acc: 0.8333\n",
      "Epoch 127/499\n",
      "----------\n",
      "train Loss: 0.7211 Acc: 0.9111\n",
      "val Loss: 0.6899 Acc: 0.9333\n",
      "test Loss: 0.7247 Acc: 0.8667\n",
      "Epoch 128/499\n",
      "----------\n",
      "train Loss: 0.7110 Acc: 0.8889\n",
      "val Loss: 0.6968 Acc: 0.9000\n",
      "test Loss: 0.7362 Acc: 0.8333\n",
      "Epoch 129/499\n",
      "----------\n",
      "train Loss: 0.7129 Acc: 0.8889\n",
      "val Loss: 0.7024 Acc: 0.9333\n",
      "test Loss: 0.7279 Acc: 0.8667\n",
      "Epoch 130/499\n",
      "----------\n",
      "train Loss: 0.7043 Acc: 0.8778\n",
      "val Loss: 0.7094 Acc: 0.9000\n",
      "test Loss: 0.7224 Acc: 0.8333\n",
      "Epoch 131/499\n",
      "----------\n",
      "train Loss: 0.7180 Acc: 0.9000\n",
      "val Loss: 0.6867 Acc: 0.9000\n",
      "test Loss: 0.7209 Acc: 0.8333\n",
      "Epoch 132/499\n",
      "----------\n",
      "train Loss: 0.7019 Acc: 0.9111\n",
      "val Loss: 0.6984 Acc: 0.9000\n",
      "test Loss: 0.7123 Acc: 0.8333\n",
      "Epoch 133/499\n",
      "----------\n",
      "train Loss: 0.6997 Acc: 0.9111\n",
      "val Loss: 0.6893 Acc: 0.9333\n",
      "test Loss: 0.7371 Acc: 0.8333\n",
      "Epoch 134/499\n",
      "----------\n",
      "train Loss: 0.7003 Acc: 0.9222\n",
      "val Loss: 0.6938 Acc: 0.9667\n",
      "test Loss: 0.7086 Acc: 0.8667\n",
      "Epoch 135/499\n",
      "----------\n",
      "train Loss: 0.6918 Acc: 0.9333\n",
      "val Loss: 0.6977 Acc: 1.0000\n",
      "test Loss: 0.7141 Acc: 0.8333\n",
      "Epoch 136/499\n",
      "----------\n",
      "train Loss: 0.7064 Acc: 0.9222\n",
      "val Loss: 0.6759 Acc: 1.0000\n",
      "test Loss: 0.7135 Acc: 0.8667\n",
      "Epoch 137/499\n",
      "----------\n",
      "train Loss: 0.7066 Acc: 0.9222\n",
      "val Loss: 0.6827 Acc: 0.9667\n",
      "test Loss: 0.6928 Acc: 0.9000\n",
      "Epoch 138/499\n",
      "----------\n",
      "train Loss: 0.6995 Acc: 0.9111\n",
      "val Loss: 0.6772 Acc: 0.9333\n",
      "test Loss: 0.7051 Acc: 0.8667\n",
      "Epoch 139/499\n",
      "----------\n",
      "train Loss: 0.6967 Acc: 0.9333\n",
      "val Loss: 0.6907 Acc: 0.9000\n",
      "test Loss: 0.7049 Acc: 0.8667\n",
      "Epoch 140/499\n",
      "----------\n",
      "train Loss: 0.6836 Acc: 0.9333\n",
      "val Loss: 0.6734 Acc: 0.9667\n",
      "test Loss: 0.7017 Acc: 0.9333\n",
      "Epoch 141/499\n",
      "----------\n",
      "train Loss: 0.6851 Acc: 0.9222\n",
      "val Loss: 0.6731 Acc: 0.9667\n",
      "test Loss: 0.7203 Acc: 0.8333\n",
      "Epoch 142/499\n",
      "----------\n",
      "train Loss: 0.6971 Acc: 0.9222\n",
      "val Loss: 0.6766 Acc: 0.9667\n",
      "test Loss: 0.7109 Acc: 0.8667\n",
      "Epoch 143/499\n",
      "----------\n",
      "train Loss: 0.6777 Acc: 0.9444\n",
      "val Loss: 0.6840 Acc: 0.9667\n",
      "test Loss: 0.7146 Acc: 0.9000\n",
      "Epoch 144/499\n",
      "----------\n",
      "train Loss: 0.6854 Acc: 0.9444\n",
      "val Loss: 0.6692 Acc: 0.9667\n",
      "test Loss: 0.7017 Acc: 0.9000\n",
      "Epoch 145/499\n",
      "----------\n",
      "train Loss: 0.6866 Acc: 0.9667\n",
      "val Loss: 0.6683 Acc: 0.9667\n",
      "test Loss: 0.7037 Acc: 0.9000\n",
      "Epoch 146/499\n",
      "----------\n",
      "train Loss: 0.6878 Acc: 0.9556\n",
      "val Loss: 0.6719 Acc: 0.9333\n",
      "test Loss: 0.7063 Acc: 0.8667\n",
      "Epoch 147/499\n",
      "----------\n",
      "train Loss: 0.6820 Acc: 0.9444\n",
      "val Loss: 0.6810 Acc: 0.9667\n",
      "test Loss: 0.7081 Acc: 0.8667\n",
      "Epoch 148/499\n",
      "----------\n",
      "train Loss: 0.6767 Acc: 0.9667\n",
      "val Loss: 0.6647 Acc: 0.9667\n",
      "test Loss: 0.7073 Acc: 0.9000\n",
      "Epoch 149/499\n",
      "----------\n",
      "train Loss: 0.6897 Acc: 0.9444\n",
      "val Loss: 0.6646 Acc: 0.9333\n",
      "test Loss: 0.7050 Acc: 0.8667\n",
      "Epoch 150/499\n",
      "----------\n",
      "train Loss: 0.6764 Acc: 0.9556\n",
      "val Loss: 0.6583 Acc: 0.9667\n",
      "test Loss: 0.7151 Acc: 0.8667\n",
      "Epoch 151/499\n",
      "----------\n",
      "train Loss: 0.6688 Acc: 0.9667\n",
      "val Loss: 0.6561 Acc: 1.0000\n",
      "test Loss: 0.6919 Acc: 0.9000\n",
      "Epoch 152/499\n",
      "----------\n",
      "train Loss: 0.6692 Acc: 0.9778\n",
      "val Loss: 0.6675 Acc: 0.9667\n",
      "test Loss: 0.6889 Acc: 0.9000\n",
      "Epoch 153/499\n",
      "----------\n",
      "train Loss: 0.6631 Acc: 0.9778\n",
      "val Loss: 0.6603 Acc: 0.9667\n",
      "test Loss: 0.6861 Acc: 0.9000\n",
      "Epoch 154/499\n",
      "----------\n",
      "train Loss: 0.6717 Acc: 0.9667\n",
      "val Loss: 0.6534 Acc: 0.9667\n",
      "test Loss: 0.6888 Acc: 0.9000\n",
      "Epoch 155/499\n",
      "----------\n",
      "train Loss: 0.6743 Acc: 0.9444\n",
      "val Loss: 0.6389 Acc: 1.0000\n",
      "test Loss: 0.6893 Acc: 0.8667\n",
      "Epoch 156/499\n",
      "----------\n",
      "train Loss: 0.6670 Acc: 0.9556\n",
      "val Loss: 0.6331 Acc: 1.0000\n",
      "test Loss: 0.6889 Acc: 0.8667\n",
      "Epoch 157/499\n",
      "----------\n",
      "train Loss: 0.6632 Acc: 0.9556\n",
      "val Loss: 0.6318 Acc: 1.0000\n",
      "test Loss: 0.6742 Acc: 0.9333\n",
      "Epoch 158/499\n",
      "----------\n",
      "train Loss: 0.6558 Acc: 0.9778\n",
      "val Loss: 0.6467 Acc: 1.0000\n",
      "test Loss: 0.6611 Acc: 0.9333\n",
      "Epoch 159/499\n",
      "----------\n",
      "train Loss: 0.6600 Acc: 0.9667\n",
      "val Loss: 0.6376 Acc: 1.0000\n",
      "test Loss: 0.6749 Acc: 0.8667\n",
      "Epoch 160/499\n",
      "----------\n",
      "train Loss: 0.6524 Acc: 0.9667\n",
      "val Loss: 0.6263 Acc: 1.0000\n",
      "test Loss: 0.6814 Acc: 0.9667\n",
      "Epoch 161/499\n",
      "----------\n",
      "train Loss: 0.6652 Acc: 0.9444\n",
      "val Loss: 0.6301 Acc: 1.0000\n",
      "test Loss: 0.6841 Acc: 0.9000\n",
      "Epoch 162/499\n",
      "----------\n",
      "train Loss: 0.6581 Acc: 0.9444\n",
      "val Loss: 0.6308 Acc: 1.0000\n",
      "test Loss: 0.6697 Acc: 0.9333\n",
      "Epoch 163/499\n",
      "----------\n",
      "train Loss: 0.6463 Acc: 0.9778\n",
      "val Loss: 0.6243 Acc: 1.0000\n",
      "test Loss: 0.6779 Acc: 0.9667\n",
      "Epoch 164/499\n",
      "----------\n",
      "train Loss: 0.6431 Acc: 0.9667\n",
      "val Loss: 0.6244 Acc: 1.0000\n",
      "test Loss: 0.6702 Acc: 0.9333\n",
      "Epoch 165/499\n",
      "----------\n",
      "train Loss: 0.6340 Acc: 0.9667\n",
      "val Loss: 0.6073 Acc: 1.0000\n",
      "test Loss: 0.6595 Acc: 0.9333\n",
      "Epoch 166/499\n",
      "----------\n",
      "train Loss: 0.6384 Acc: 0.9667\n",
      "val Loss: 0.6096 Acc: 1.0000\n",
      "test Loss: 0.6744 Acc: 0.9333\n",
      "Epoch 167/499\n",
      "----------\n",
      "train Loss: 0.6391 Acc: 0.9667\n",
      "val Loss: 0.6155 Acc: 1.0000\n",
      "test Loss: 0.6499 Acc: 0.9333\n",
      "Epoch 168/499\n",
      "----------\n",
      "train Loss: 0.6323 Acc: 0.9778\n",
      "val Loss: 0.6034 Acc: 1.0000\n",
      "test Loss: 0.6569 Acc: 0.9667\n",
      "Epoch 169/499\n",
      "----------\n",
      "train Loss: 0.6385 Acc: 0.9556\n",
      "val Loss: 0.6070 Acc: 1.0000\n",
      "test Loss: 0.6680 Acc: 0.9333\n",
      "Epoch 170/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6261 Acc: 0.9889\n",
      "val Loss: 0.6119 Acc: 1.0000\n",
      "test Loss: 0.6775 Acc: 0.9000\n",
      "Epoch 171/499\n",
      "----------\n",
      "train Loss: 0.6262 Acc: 0.9778\n",
      "val Loss: 0.6032 Acc: 1.0000\n",
      "test Loss: 0.6531 Acc: 0.9333\n",
      "Epoch 172/499\n",
      "----------\n",
      "train Loss: 0.6188 Acc: 0.9778\n",
      "val Loss: 0.5975 Acc: 1.0000\n",
      "test Loss: 0.6466 Acc: 0.9667\n",
      "Epoch 173/499\n",
      "----------\n",
      "train Loss: 0.6219 Acc: 0.9778\n",
      "val Loss: 0.6025 Acc: 1.0000\n",
      "test Loss: 0.6483 Acc: 0.9667\n",
      "Epoch 174/499\n",
      "----------\n",
      "train Loss: 0.6238 Acc: 0.9889\n",
      "val Loss: 0.5922 Acc: 1.0000\n",
      "test Loss: 0.6466 Acc: 0.9333\n",
      "Epoch 175/499\n",
      "----------\n",
      "train Loss: 0.6191 Acc: 0.9778\n",
      "val Loss: 0.5979 Acc: 1.0000\n",
      "test Loss: 0.6563 Acc: 0.9667\n",
      "Epoch 176/499\n",
      "----------\n",
      "train Loss: 0.6243 Acc: 0.9667\n",
      "val Loss: 0.6004 Acc: 0.9667\n",
      "test Loss: 0.6624 Acc: 0.9333\n",
      "Epoch 177/499\n",
      "----------\n",
      "train Loss: 0.6142 Acc: 0.9778\n",
      "val Loss: 0.5925 Acc: 1.0000\n",
      "test Loss: 0.6407 Acc: 0.9667\n",
      "Epoch 178/499\n",
      "----------\n",
      "train Loss: 0.6130 Acc: 0.9667\n",
      "val Loss: 0.5795 Acc: 1.0000\n",
      "test Loss: 0.6441 Acc: 0.9667\n",
      "Epoch 179/499\n",
      "----------\n",
      "train Loss: 0.6254 Acc: 0.9556\n",
      "val Loss: 0.5845 Acc: 1.0000\n",
      "test Loss: 0.6482 Acc: 0.9333\n",
      "Epoch 180/499\n",
      "----------\n",
      "train Loss: 0.6075 Acc: 0.9778\n",
      "val Loss: 0.5899 Acc: 1.0000\n",
      "test Loss: 0.6364 Acc: 0.9333\n",
      "Epoch 181/499\n",
      "----------\n",
      "train Loss: 0.6085 Acc: 0.9889\n",
      "val Loss: 0.5850 Acc: 1.0000\n",
      "test Loss: 0.6357 Acc: 0.9667\n",
      "Epoch 182/499\n",
      "----------\n",
      "train Loss: 0.6066 Acc: 0.9889\n",
      "val Loss: 0.5959 Acc: 0.9667\n",
      "test Loss: 0.6434 Acc: 0.9333\n",
      "Epoch 183/499\n",
      "----------\n",
      "train Loss: 0.6026 Acc: 0.9889\n",
      "val Loss: 0.5868 Acc: 1.0000\n",
      "test Loss: 0.6547 Acc: 0.9333\n",
      "Epoch 184/499\n",
      "----------\n",
      "train Loss: 0.6093 Acc: 0.9778\n",
      "val Loss: 0.5993 Acc: 0.9667\n",
      "test Loss: 0.6509 Acc: 0.9000\n",
      "Epoch 185/499\n",
      "----------\n",
      "train Loss: 0.5953 Acc: 0.9889\n",
      "val Loss: 0.5706 Acc: 1.0000\n",
      "test Loss: 0.6260 Acc: 0.9333\n",
      "Epoch 186/499\n",
      "----------\n",
      "train Loss: 0.5982 Acc: 0.9889\n",
      "val Loss: 0.5753 Acc: 1.0000\n",
      "test Loss: 0.6414 Acc: 0.9667\n",
      "Epoch 187/499\n",
      "----------\n",
      "train Loss: 0.6042 Acc: 0.9778\n",
      "val Loss: 0.5771 Acc: 1.0000\n",
      "test Loss: 0.6390 Acc: 0.9333\n",
      "Epoch 188/499\n",
      "----------\n",
      "train Loss: 0.6097 Acc: 0.9556\n",
      "val Loss: 0.5737 Acc: 1.0000\n",
      "test Loss: 0.6214 Acc: 0.9333\n",
      "Epoch 189/499\n",
      "----------\n",
      "train Loss: 0.5982 Acc: 0.9889\n",
      "val Loss: 0.5756 Acc: 1.0000\n",
      "test Loss: 0.6117 Acc: 0.9667\n",
      "Epoch 190/499\n",
      "----------\n",
      "train Loss: 0.6037 Acc: 0.9778\n",
      "val Loss: 0.5739 Acc: 1.0000\n",
      "test Loss: 0.6263 Acc: 0.9667\n",
      "Epoch 191/499\n",
      "----------\n",
      "train Loss: 0.6013 Acc: 0.9667\n",
      "val Loss: 0.5948 Acc: 0.9667\n",
      "test Loss: 0.6444 Acc: 0.9333\n",
      "Epoch 192/499\n",
      "----------\n",
      "train Loss: 0.5961 Acc: 0.9778\n",
      "val Loss: 0.5832 Acc: 1.0000\n",
      "test Loss: 0.6338 Acc: 0.9667\n",
      "Epoch 193/499\n",
      "----------\n",
      "train Loss: 0.5910 Acc: 0.9778\n",
      "val Loss: 0.5705 Acc: 1.0000\n",
      "test Loss: 0.6467 Acc: 0.9000\n",
      "Epoch 194/499\n",
      "----------\n",
      "train Loss: 0.5897 Acc: 0.9889\n",
      "val Loss: 0.5755 Acc: 1.0000\n",
      "test Loss: 0.6219 Acc: 0.9667\n",
      "Epoch 195/499\n",
      "----------\n",
      "train Loss: 0.5858 Acc: 0.9889\n",
      "val Loss: 0.5724 Acc: 1.0000\n",
      "test Loss: 0.6259 Acc: 0.9667\n",
      "Epoch 196/499\n",
      "----------\n",
      "train Loss: 0.5888 Acc: 1.0000\n",
      "val Loss: 0.5682 Acc: 1.0000\n",
      "test Loss: 0.6378 Acc: 0.9667\n",
      "Epoch 197/499\n",
      "----------\n",
      "train Loss: 0.6075 Acc: 0.9556\n",
      "val Loss: 0.5785 Acc: 0.9667\n",
      "test Loss: 0.6184 Acc: 0.9667\n",
      "Epoch 198/499\n",
      "----------\n",
      "train Loss: 0.5903 Acc: 0.9667\n",
      "val Loss: 0.5743 Acc: 1.0000\n",
      "test Loss: 0.6148 Acc: 0.9667\n",
      "Epoch 199/499\n",
      "----------\n",
      "train Loss: 0.5925 Acc: 0.9778\n",
      "val Loss: 0.5929 Acc: 0.9667\n",
      "test Loss: 0.6252 Acc: 0.9333\n",
      "Epoch 200/499\n",
      "----------\n",
      "train Loss: 0.5909 Acc: 0.9778\n",
      "val Loss: 0.5687 Acc: 1.0000\n",
      "test Loss: 0.6306 Acc: 0.9000\n",
      "Epoch 201/499\n",
      "----------\n",
      "train Loss: 0.5940 Acc: 0.9778\n",
      "val Loss: 0.5679 Acc: 1.0000\n",
      "test Loss: 0.6313 Acc: 0.9333\n",
      "Epoch 202/499\n",
      "----------\n",
      "train Loss: 0.5848 Acc: 0.9889\n",
      "val Loss: 0.5628 Acc: 1.0000\n",
      "test Loss: 0.6372 Acc: 0.9333\n",
      "Epoch 203/499\n",
      "----------\n",
      "train Loss: 0.5845 Acc: 0.9889\n",
      "val Loss: 0.5625 Acc: 1.0000\n",
      "test Loss: 0.6299 Acc: 0.9333\n",
      "Epoch 204/499\n",
      "----------\n",
      "train Loss: 0.5869 Acc: 1.0000\n",
      "val Loss: 0.5742 Acc: 1.0000\n",
      "test Loss: 0.6150 Acc: 0.9667\n",
      "Epoch 205/499\n",
      "----------\n",
      "train Loss: 0.5949 Acc: 0.9667\n",
      "val Loss: 0.5608 Acc: 1.0000\n",
      "test Loss: 0.6067 Acc: 0.9667\n",
      "Epoch 206/499\n",
      "----------\n",
      "train Loss: 0.5939 Acc: 0.9778\n",
      "val Loss: 0.5712 Acc: 1.0000\n",
      "test Loss: 0.6188 Acc: 0.9333\n",
      "Epoch 207/499\n",
      "----------\n",
      "train Loss: 0.5925 Acc: 0.9667\n",
      "val Loss: 0.5662 Acc: 1.0000\n",
      "test Loss: 0.6238 Acc: 0.9667\n",
      "Epoch 208/499\n",
      "----------\n",
      "train Loss: 0.5911 Acc: 0.9889\n",
      "val Loss: 0.5654 Acc: 1.0000\n",
      "test Loss: 0.6343 Acc: 0.9333\n",
      "Epoch 209/499\n",
      "----------\n",
      "train Loss: 0.5883 Acc: 0.9667\n",
      "val Loss: 0.5620 Acc: 1.0000\n",
      "test Loss: 0.6163 Acc: 0.9667\n",
      "Epoch 210/499\n",
      "----------\n",
      "train Loss: 0.5923 Acc: 0.9667\n",
      "val Loss: 0.5638 Acc: 1.0000\n",
      "test Loss: 0.6140 Acc: 0.9667\n",
      "Epoch 211/499\n",
      "----------\n",
      "train Loss: 0.5828 Acc: 0.9889\n",
      "val Loss: 0.5616 Acc: 1.0000\n",
      "test Loss: 0.6304 Acc: 0.9333\n",
      "Epoch 212/499\n",
      "----------\n",
      "train Loss: 0.5861 Acc: 0.9889\n",
      "val Loss: 0.5891 Acc: 0.9667\n",
      "test Loss: 0.6143 Acc: 0.9667\n",
      "Epoch 213/499\n",
      "----------\n",
      "train Loss: 0.5835 Acc: 0.9778\n",
      "val Loss: 0.5602 Acc: 1.0000\n",
      "test Loss: 0.6220 Acc: 0.9333\n",
      "Epoch 214/499\n",
      "----------\n",
      "train Loss: 0.5904 Acc: 0.9667\n",
      "val Loss: 0.5627 Acc: 1.0000\n",
      "test Loss: 0.6111 Acc: 0.9667\n",
      "Epoch 215/499\n",
      "----------\n",
      "train Loss: 0.5842 Acc: 0.9778\n",
      "val Loss: 0.5625 Acc: 1.0000\n",
      "test Loss: 0.6298 Acc: 0.9333\n",
      "Epoch 216/499\n",
      "----------\n",
      "train Loss: 0.5925 Acc: 0.9667\n",
      "val Loss: 0.5693 Acc: 1.0000\n",
      "test Loss: 0.6065 Acc: 0.9667\n",
      "Epoch 217/499\n",
      "----------\n",
      "train Loss: 0.5876 Acc: 0.9889\n",
      "val Loss: 0.5594 Acc: 1.0000\n",
      "test Loss: 0.6049 Acc: 0.9667\n",
      "Epoch 218/499\n",
      "----------\n",
      "train Loss: 0.5799 Acc: 0.9778\n",
      "val Loss: 0.5616 Acc: 1.0000\n",
      "test Loss: 0.6225 Acc: 0.9667\n",
      "Epoch 219/499\n",
      "----------\n",
      "train Loss: 0.5853 Acc: 0.9778\n",
      "val Loss: 0.5668 Acc: 1.0000\n",
      "test Loss: 0.6081 Acc: 0.9667\n",
      "Epoch 220/499\n",
      "----------\n",
      "train Loss: 0.5826 Acc: 0.9889\n",
      "val Loss: 0.5645 Acc: 1.0000\n",
      "test Loss: 0.6236 Acc: 0.9333\n",
      "Epoch 221/499\n",
      "----------\n",
      "train Loss: 0.5775 Acc: 0.9889\n",
      "val Loss: 0.5682 Acc: 1.0000\n",
      "test Loss: 0.6324 Acc: 0.9333\n",
      "Epoch 222/499\n",
      "----------\n",
      "train Loss: 0.5823 Acc: 0.9778\n",
      "val Loss: 0.5613 Acc: 1.0000\n",
      "test Loss: 0.6206 Acc: 0.9667\n",
      "Epoch 223/499\n",
      "----------\n",
      "train Loss: 0.5766 Acc: 0.9778\n",
      "val Loss: 0.5632 Acc: 1.0000\n",
      "test Loss: 0.6264 Acc: 0.9333\n",
      "Epoch 224/499\n",
      "----------\n",
      "train Loss: 0.5890 Acc: 0.9667\n",
      "val Loss: 0.5627 Acc: 1.0000\n",
      "test Loss: 0.6304 Acc: 0.9000\n",
      "Epoch 225/499\n",
      "----------\n",
      "train Loss: 0.5767 Acc: 0.9889\n",
      "val Loss: 0.5608 Acc: 1.0000\n",
      "test Loss: 0.6190 Acc: 0.9667\n",
      "Epoch 226/499\n",
      "----------\n",
      "train Loss: 0.5792 Acc: 0.9778\n",
      "val Loss: 0.5578 Acc: 1.0000\n",
      "test Loss: 0.6401 Acc: 0.9000\n",
      "Epoch 227/499\n",
      "----------\n",
      "train Loss: 0.5870 Acc: 0.9556\n",
      "val Loss: 0.5551 Acc: 1.0000\n",
      "test Loss: 0.6063 Acc: 0.9667\n",
      "Epoch 228/499\n",
      "----------\n",
      "train Loss: 0.5860 Acc: 0.9556\n",
      "val Loss: 0.5612 Acc: 1.0000\n",
      "test Loss: 0.6250 Acc: 0.9667\n",
      "Epoch 229/499\n",
      "----------\n",
      "train Loss: 0.5706 Acc: 1.0000\n",
      "val Loss: 0.5623 Acc: 1.0000\n",
      "test Loss: 0.6082 Acc: 0.9667\n",
      "Epoch 230/499\n",
      "----------\n",
      "train Loss: 0.5748 Acc: 0.9778\n",
      "val Loss: 0.5644 Acc: 1.0000\n",
      "test Loss: 0.6199 Acc: 0.9667\n",
      "Epoch 231/499\n",
      "----------\n",
      "train Loss: 0.5732 Acc: 1.0000\n",
      "val Loss: 0.5617 Acc: 1.0000\n",
      "test Loss: 0.6235 Acc: 0.9667\n",
      "Epoch 232/499\n",
      "----------\n",
      "train Loss: 0.5754 Acc: 0.9778\n",
      "val Loss: 0.5621 Acc: 1.0000\n",
      "test Loss: 0.6217 Acc: 0.9333\n",
      "Epoch 233/499\n",
      "----------\n",
      "train Loss: 0.5795 Acc: 0.9778\n",
      "val Loss: 0.5587 Acc: 1.0000\n",
      "test Loss: 0.6234 Acc: 0.9333\n",
      "Epoch 234/499\n",
      "----------\n",
      "train Loss: 0.5788 Acc: 0.9889\n",
      "val Loss: 0.5586 Acc: 1.0000\n",
      "test Loss: 0.6093 Acc: 0.9667\n",
      "Epoch 235/499\n",
      "----------\n",
      "train Loss: 0.5769 Acc: 0.9778\n",
      "val Loss: 0.5812 Acc: 0.9667\n",
      "test Loss: 0.5911 Acc: 1.0000\n",
      "Epoch 236/499\n",
      "----------\n",
      "train Loss: 0.5797 Acc: 0.9889\n",
      "val Loss: 0.5576 Acc: 1.0000\n",
      "test Loss: 0.6082 Acc: 0.9667\n",
      "Epoch 237/499\n",
      "----------\n",
      "train Loss: 0.5793 Acc: 0.9778\n",
      "val Loss: 0.5765 Acc: 0.9667\n",
      "test Loss: 0.6089 Acc: 0.9667\n",
      "Epoch 238/499\n",
      "----------\n",
      "train Loss: 0.5741 Acc: 0.9889\n",
      "val Loss: 0.5613 Acc: 1.0000\n",
      "test Loss: 0.6293 Acc: 0.9333\n",
      "Epoch 239/499\n",
      "----------\n",
      "train Loss: 0.5794 Acc: 0.9667\n",
      "val Loss: 0.5740 Acc: 0.9667\n",
      "test Loss: 0.6133 Acc: 0.9667\n",
      "Epoch 240/499\n",
      "----------\n",
      "train Loss: 0.5771 Acc: 0.9778\n",
      "val Loss: 0.5655 Acc: 1.0000\n",
      "test Loss: 0.6307 Acc: 0.9333\n",
      "Epoch 241/499\n",
      "----------\n",
      "train Loss: 0.5823 Acc: 0.9778\n",
      "val Loss: 0.5615 Acc: 1.0000\n",
      "test Loss: 0.6025 Acc: 0.9333\n",
      "Epoch 242/499\n",
      "----------\n",
      "train Loss: 0.5757 Acc: 0.9778\n",
      "val Loss: 0.5567 Acc: 1.0000\n",
      "test Loss: 0.6200 Acc: 0.9333\n",
      "Epoch 243/499\n",
      "----------\n",
      "train Loss: 0.5751 Acc: 0.9889\n",
      "val Loss: 0.5559 Acc: 1.0000\n",
      "test Loss: 0.6179 Acc: 0.9667\n",
      "Epoch 244/499\n",
      "----------\n",
      "train Loss: 0.5783 Acc: 0.9778\n",
      "val Loss: 0.5854 Acc: 0.9667\n",
      "test Loss: 0.6084 Acc: 0.9667\n",
      "Epoch 245/499\n",
      "----------\n",
      "train Loss: 0.5858 Acc: 0.9667\n",
      "val Loss: 0.5755 Acc: 0.9667\n",
      "test Loss: 0.6310 Acc: 0.9333\n",
      "Epoch 246/499\n",
      "----------\n",
      "train Loss: 0.5743 Acc: 0.9778\n",
      "val Loss: 0.5579 Acc: 1.0000\n",
      "test Loss: 0.6136 Acc: 0.9667\n",
      "Epoch 247/499\n",
      "----------\n",
      "train Loss: 0.5789 Acc: 0.9778\n",
      "val Loss: 0.5573 Acc: 1.0000\n",
      "test Loss: 0.6137 Acc: 0.9667\n",
      "Epoch 248/499\n",
      "----------\n",
      "train Loss: 0.5855 Acc: 0.9667\n",
      "val Loss: 0.5571 Acc: 1.0000\n",
      "test Loss: 0.6231 Acc: 0.9667\n",
      "Epoch 249/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5887 Acc: 0.9667\n",
      "val Loss: 0.5566 Acc: 1.0000\n",
      "test Loss: 0.6235 Acc: 0.9333\n",
      "Epoch 250/499\n",
      "----------\n",
      "train Loss: 0.5722 Acc: 0.9889\n",
      "val Loss: 0.5595 Acc: 1.0000\n",
      "test Loss: 0.6113 Acc: 0.9667\n",
      "Epoch 251/499\n",
      "----------\n",
      "train Loss: 0.5779 Acc: 0.9778\n",
      "val Loss: 0.5582 Acc: 1.0000\n",
      "test Loss: 0.6346 Acc: 0.9000\n",
      "Epoch 252/499\n",
      "----------\n",
      "train Loss: 0.5762 Acc: 0.9778\n",
      "val Loss: 0.5611 Acc: 1.0000\n",
      "test Loss: 0.6065 Acc: 0.9667\n",
      "Epoch 253/499\n",
      "----------\n",
      "train Loss: 0.5835 Acc: 0.9667\n",
      "val Loss: 0.5579 Acc: 1.0000\n",
      "test Loss: 0.6070 Acc: 0.9667\n",
      "Epoch 254/499\n",
      "----------\n",
      "train Loss: 0.5664 Acc: 1.0000\n",
      "val Loss: 0.5564 Acc: 1.0000\n",
      "test Loss: 0.6180 Acc: 0.9333\n",
      "Epoch 255/499\n",
      "----------\n",
      "train Loss: 0.5778 Acc: 0.9778\n",
      "val Loss: 0.5747 Acc: 0.9667\n",
      "test Loss: 0.6171 Acc: 0.9333\n",
      "Epoch 256/499\n",
      "----------\n",
      "train Loss: 0.5809 Acc: 0.9667\n",
      "val Loss: 0.5615 Acc: 1.0000\n",
      "test Loss: 0.6224 Acc: 0.9000\n",
      "Epoch 257/499\n",
      "----------\n",
      "train Loss: 0.5813 Acc: 0.9778\n",
      "val Loss: 0.5567 Acc: 1.0000\n",
      "test Loss: 0.6092 Acc: 0.9333\n",
      "Epoch 258/499\n",
      "----------\n",
      "train Loss: 0.5763 Acc: 0.9778\n",
      "val Loss: 0.5588 Acc: 1.0000\n",
      "test Loss: 0.6308 Acc: 0.9000\n",
      "Epoch 259/499\n",
      "----------\n",
      "train Loss: 0.5768 Acc: 0.9778\n",
      "val Loss: 0.5588 Acc: 1.0000\n",
      "test Loss: 0.6125 Acc: 0.9667\n",
      "Epoch 260/499\n",
      "----------\n",
      "train Loss: 0.5765 Acc: 0.9889\n",
      "val Loss: 0.5761 Acc: 0.9667\n",
      "test Loss: 0.6107 Acc: 0.9667\n",
      "Epoch 261/499\n",
      "----------\n",
      "train Loss: 0.5667 Acc: 0.9889\n",
      "val Loss: 0.5589 Acc: 1.0000\n",
      "test Loss: 0.6180 Acc: 0.9667\n",
      "Epoch 262/499\n",
      "----------\n",
      "train Loss: 0.5701 Acc: 0.9889\n",
      "val Loss: 0.5620 Acc: 1.0000\n",
      "test Loss: 0.6292 Acc: 0.9333\n",
      "Epoch 263/499\n",
      "----------\n",
      "train Loss: 0.5728 Acc: 0.9889\n",
      "val Loss: 0.5579 Acc: 1.0000\n",
      "test Loss: 0.6044 Acc: 0.9667\n",
      "Epoch 264/499\n",
      "----------\n",
      "train Loss: 0.5780 Acc: 0.9778\n",
      "val Loss: 0.5584 Acc: 1.0000\n",
      "test Loss: 0.6071 Acc: 0.9667\n",
      "Epoch 265/499\n",
      "----------\n",
      "train Loss: 0.5830 Acc: 0.9667\n",
      "val Loss: 0.5552 Acc: 1.0000\n",
      "test Loss: 0.6085 Acc: 0.9667\n",
      "Epoch 266/499\n",
      "----------\n",
      "train Loss: 0.5742 Acc: 0.9778\n",
      "val Loss: 0.5616 Acc: 1.0000\n",
      "test Loss: 0.5974 Acc: 0.9667\n",
      "Epoch 267/499\n",
      "----------\n",
      "train Loss: 0.5785 Acc: 0.9889\n",
      "val Loss: 0.5555 Acc: 1.0000\n",
      "test Loss: 0.6082 Acc: 0.9667\n",
      "Epoch 268/499\n",
      "----------\n",
      "train Loss: 0.5784 Acc: 0.9778\n",
      "val Loss: 0.5568 Acc: 1.0000\n",
      "test Loss: 0.5964 Acc: 0.9667\n",
      "Epoch 269/499\n",
      "----------\n",
      "train Loss: 0.5683 Acc: 0.9889\n",
      "val Loss: 0.5559 Acc: 1.0000\n",
      "test Loss: 0.6071 Acc: 0.9667\n",
      "Epoch 270/499\n",
      "----------\n",
      "train Loss: 0.5765 Acc: 0.9778\n",
      "val Loss: 0.5568 Acc: 1.0000\n",
      "test Loss: 0.6151 Acc: 0.9333\n",
      "Epoch 271/499\n",
      "----------\n",
      "train Loss: 0.5669 Acc: 0.9889\n",
      "val Loss: 0.5766 Acc: 0.9667\n",
      "test Loss: 0.5979 Acc: 0.9667\n",
      "Epoch 272/499\n",
      "----------\n",
      "train Loss: 0.5675 Acc: 0.9889\n",
      "val Loss: 0.5545 Acc: 1.0000\n",
      "test Loss: 0.6013 Acc: 0.9667\n",
      "Epoch 273/499\n",
      "----------\n",
      "train Loss: 0.5734 Acc: 0.9889\n",
      "val Loss: 0.5582 Acc: 1.0000\n",
      "test Loss: 0.6131 Acc: 0.9333\n",
      "Epoch 274/499\n",
      "----------\n",
      "train Loss: 0.5736 Acc: 0.9889\n",
      "val Loss: 0.5532 Acc: 1.0000\n",
      "test Loss: 0.6129 Acc: 0.9667\n",
      "Epoch 275/499\n",
      "----------\n",
      "train Loss: 0.5677 Acc: 0.9889\n",
      "val Loss: 0.5550 Acc: 1.0000\n",
      "test Loss: 0.6289 Acc: 0.9000\n",
      "Epoch 276/499\n",
      "----------\n",
      "train Loss: 0.5797 Acc: 0.9778\n",
      "val Loss: 0.5560 Acc: 1.0000\n",
      "test Loss: 0.6231 Acc: 0.9333\n",
      "Epoch 277/499\n",
      "----------\n",
      "train Loss: 0.5712 Acc: 0.9778\n",
      "val Loss: 0.5534 Acc: 1.0000\n",
      "test Loss: 0.6241 Acc: 0.9333\n",
      "Epoch 278/499\n",
      "----------\n",
      "train Loss: 0.5695 Acc: 0.9889\n",
      "val Loss: 0.5541 Acc: 1.0000\n",
      "test Loss: 0.6157 Acc: 0.9667\n",
      "Epoch 279/499\n",
      "----------\n",
      "train Loss: 0.5725 Acc: 0.9889\n",
      "val Loss: 0.5582 Acc: 1.0000\n",
      "test Loss: 0.6120 Acc: 0.9667\n",
      "Epoch 280/499\n",
      "----------\n",
      "train Loss: 0.5725 Acc: 0.9778\n",
      "val Loss: 0.5556 Acc: 1.0000\n",
      "test Loss: 0.6254 Acc: 0.9333\n",
      "Epoch 281/499\n",
      "----------\n",
      "train Loss: 0.5708 Acc: 0.9889\n",
      "val Loss: 0.5539 Acc: 1.0000\n",
      "test Loss: 0.6217 Acc: 0.9333\n",
      "Epoch 282/499\n",
      "----------\n",
      "train Loss: 0.5714 Acc: 0.9889\n",
      "val Loss: 0.5547 Acc: 1.0000\n",
      "test Loss: 0.6065 Acc: 0.9333\n",
      "Epoch 283/499\n",
      "----------\n",
      "train Loss: 0.5756 Acc: 0.9889\n",
      "val Loss: 0.5566 Acc: 1.0000\n",
      "test Loss: 0.6060 Acc: 0.9667\n",
      "Epoch 284/499\n",
      "----------\n",
      "train Loss: 0.5690 Acc: 1.0000\n",
      "val Loss: 0.5538 Acc: 1.0000\n",
      "test Loss: 0.6110 Acc: 0.9667\n",
      "Epoch 285/499\n",
      "----------\n",
      "train Loss: 0.5682 Acc: 0.9889\n",
      "val Loss: 0.5759 Acc: 0.9667\n",
      "test Loss: 0.6095 Acc: 0.9667\n",
      "Epoch 286/499\n",
      "----------\n",
      "train Loss: 0.5688 Acc: 1.0000\n",
      "val Loss: 0.5580 Acc: 1.0000\n",
      "test Loss: 0.6459 Acc: 0.8667\n",
      "Epoch 287/499\n",
      "----------\n",
      "train Loss: 0.5771 Acc: 0.9778\n",
      "val Loss: 0.5542 Acc: 1.0000\n",
      "test Loss: 0.6310 Acc: 0.9333\n",
      "Epoch 288/499\n",
      "----------\n",
      "train Loss: 0.5861 Acc: 0.9667\n",
      "val Loss: 0.5582 Acc: 1.0000\n",
      "test Loss: 0.6189 Acc: 0.9333\n",
      "Epoch 289/499\n",
      "----------\n",
      "train Loss: 0.5627 Acc: 1.0000\n",
      "val Loss: 0.5558 Acc: 1.0000\n",
      "test Loss: 0.6160 Acc: 0.9333\n",
      "Epoch 290/499\n",
      "----------\n",
      "train Loss: 0.5741 Acc: 0.9778\n",
      "val Loss: 0.5572 Acc: 1.0000\n",
      "test Loss: 0.6086 Acc: 0.9333\n",
      "Epoch 291/499\n",
      "----------\n",
      "train Loss: 0.5740 Acc: 0.9778\n",
      "val Loss: 0.5557 Acc: 1.0000\n",
      "test Loss: 0.6138 Acc: 0.9333\n",
      "Epoch 292/499\n",
      "----------\n",
      "train Loss: 0.5714 Acc: 0.9778\n",
      "val Loss: 0.5571 Acc: 1.0000\n",
      "test Loss: 0.6010 Acc: 0.9667\n",
      "Epoch 293/499\n",
      "----------\n",
      "train Loss: 0.5736 Acc: 0.9778\n",
      "val Loss: 0.5756 Acc: 0.9667\n",
      "test Loss: 0.6334 Acc: 0.9333\n",
      "Epoch 294/499\n",
      "----------\n",
      "train Loss: 0.5745 Acc: 0.9778\n",
      "val Loss: 0.5528 Acc: 1.0000\n",
      "test Loss: 0.6109 Acc: 0.9667\n",
      "Epoch 295/499\n",
      "----------\n",
      "train Loss: 0.5742 Acc: 0.9778\n",
      "val Loss: 0.5748 Acc: 0.9667\n",
      "test Loss: 0.6015 Acc: 0.9667\n",
      "Epoch 296/499\n",
      "----------\n",
      "train Loss: 0.5833 Acc: 0.9667\n",
      "val Loss: 0.5536 Acc: 1.0000\n",
      "test Loss: 0.6045 Acc: 0.9667\n",
      "Epoch 297/499\n",
      "----------\n",
      "train Loss: 0.5691 Acc: 0.9889\n",
      "val Loss: 0.5534 Acc: 1.0000\n",
      "test Loss: 0.6091 Acc: 0.9667\n",
      "Epoch 298/499\n",
      "----------\n",
      "train Loss: 0.5707 Acc: 0.9889\n",
      "val Loss: 0.5565 Acc: 1.0000\n",
      "test Loss: 0.6104 Acc: 0.9667\n",
      "Epoch 299/499\n",
      "----------\n",
      "train Loss: 0.5747 Acc: 0.9778\n",
      "val Loss: 0.5528 Acc: 1.0000\n",
      "test Loss: 0.6075 Acc: 0.9667\n",
      "Epoch 300/499\n",
      "----------\n",
      "train Loss: 0.5784 Acc: 0.9667\n",
      "val Loss: 0.5542 Acc: 1.0000\n",
      "test Loss: 0.6141 Acc: 0.9333\n",
      "Epoch 301/499\n",
      "----------\n",
      "train Loss: 0.5718 Acc: 0.9889\n",
      "val Loss: 0.5547 Acc: 1.0000\n",
      "test Loss: 0.6360 Acc: 0.9000\n",
      "Epoch 302/499\n",
      "----------\n",
      "train Loss: 0.5759 Acc: 0.9778\n",
      "val Loss: 0.5778 Acc: 0.9667\n",
      "test Loss: 0.5964 Acc: 0.9667\n",
      "Epoch 303/499\n",
      "----------\n",
      "train Loss: 0.5625 Acc: 1.0000\n",
      "val Loss: 0.5545 Acc: 1.0000\n",
      "test Loss: 0.6587 Acc: 0.8333\n",
      "Epoch 304/499\n",
      "----------\n",
      "train Loss: 0.5742 Acc: 0.9778\n",
      "val Loss: 0.5548 Acc: 1.0000\n",
      "test Loss: 0.5992 Acc: 0.9667\n",
      "Epoch 305/499\n",
      "----------\n",
      "train Loss: 0.5776 Acc: 0.9778\n",
      "val Loss: 0.5550 Acc: 1.0000\n",
      "test Loss: 0.6283 Acc: 0.9000\n",
      "Epoch 306/499\n",
      "----------\n",
      "train Loss: 0.5709 Acc: 0.9889\n",
      "val Loss: 0.5576 Acc: 1.0000\n",
      "test Loss: 0.6122 Acc: 0.9333\n",
      "Epoch 307/499\n",
      "----------\n",
      "train Loss: 0.5677 Acc: 0.9889\n",
      "val Loss: 0.5555 Acc: 1.0000\n",
      "test Loss: 0.6087 Acc: 0.9333\n",
      "Epoch 308/499\n",
      "----------\n",
      "train Loss: 0.5766 Acc: 0.9778\n",
      "val Loss: 0.5542 Acc: 1.0000\n",
      "test Loss: 0.6335 Acc: 0.9000\n",
      "Epoch 309/499\n",
      "----------\n",
      "train Loss: 0.5689 Acc: 0.9889\n",
      "val Loss: 0.5542 Acc: 1.0000\n",
      "test Loss: 0.6094 Acc: 0.9333\n",
      "Epoch 310/499\n",
      "----------\n",
      "train Loss: 0.5711 Acc: 0.9778\n",
      "val Loss: 0.5532 Acc: 1.0000\n",
      "test Loss: 0.6328 Acc: 0.9333\n",
      "Epoch 311/499\n",
      "----------\n",
      "train Loss: 0.5688 Acc: 0.9889\n",
      "val Loss: 0.5542 Acc: 1.0000\n",
      "test Loss: 0.6277 Acc: 0.9000\n",
      "Epoch 312/499\n",
      "----------\n",
      "train Loss: 0.5660 Acc: 0.9889\n",
      "val Loss: 0.5560 Acc: 1.0000\n",
      "test Loss: 0.6226 Acc: 0.9000\n",
      "Epoch 313/499\n",
      "----------\n",
      "train Loss: 0.5611 Acc: 1.0000\n",
      "val Loss: 0.5527 Acc: 1.0000\n",
      "test Loss: 0.6026 Acc: 0.9667\n",
      "Epoch 314/499\n",
      "----------\n",
      "train Loss: 0.5692 Acc: 0.9778\n",
      "val Loss: 0.5539 Acc: 1.0000\n",
      "test Loss: 0.6137 Acc: 0.9333\n",
      "Epoch 315/499\n",
      "----------\n",
      "train Loss: 0.5764 Acc: 0.9667\n",
      "val Loss: 0.5726 Acc: 0.9667\n",
      "test Loss: 0.6111 Acc: 0.9333\n",
      "Epoch 316/499\n",
      "----------\n",
      "train Loss: 0.5658 Acc: 1.0000\n",
      "val Loss: 0.5539 Acc: 1.0000\n",
      "test Loss: 0.6205 Acc: 0.9000\n",
      "Epoch 317/499\n",
      "----------\n",
      "train Loss: 0.5676 Acc: 0.9889\n",
      "val Loss: 0.5535 Acc: 1.0000\n",
      "test Loss: 0.6069 Acc: 0.9333\n",
      "Epoch 318/499\n",
      "----------\n",
      "train Loss: 0.5696 Acc: 0.9889\n",
      "val Loss: 0.5528 Acc: 1.0000\n",
      "test Loss: 0.6098 Acc: 0.9333\n",
      "Epoch 319/499\n",
      "----------\n",
      "train Loss: 0.5620 Acc: 1.0000\n",
      "val Loss: 0.5552 Acc: 1.0000\n",
      "test Loss: 0.6062 Acc: 0.9667\n",
      "Epoch 320/499\n",
      "----------\n",
      "train Loss: 0.5695 Acc: 0.9889\n",
      "val Loss: 0.5538 Acc: 1.0000\n",
      "test Loss: 0.6097 Acc: 0.9333\n",
      "Epoch 321/499\n",
      "----------\n",
      "train Loss: 0.5704 Acc: 0.9778\n",
      "val Loss: 0.5647 Acc: 1.0000\n",
      "test Loss: 0.5977 Acc: 0.9667\n",
      "Epoch 322/499\n",
      "----------\n",
      "train Loss: 0.5664 Acc: 1.0000\n",
      "val Loss: 0.5535 Acc: 1.0000\n",
      "test Loss: 0.6072 Acc: 0.9333\n",
      "Epoch 323/499\n",
      "----------\n",
      "train Loss: 0.5707 Acc: 0.9889\n",
      "val Loss: 0.5543 Acc: 1.0000\n",
      "test Loss: 0.6073 Acc: 0.9333\n",
      "Epoch 324/499\n",
      "----------\n",
      "train Loss: 0.5654 Acc: 0.9889\n",
      "val Loss: 0.5599 Acc: 1.0000\n",
      "test Loss: 0.6193 Acc: 0.9333\n",
      "Epoch 325/499\n",
      "----------\n",
      "train Loss: 0.5613 Acc: 1.0000\n",
      "val Loss: 0.5534 Acc: 1.0000\n",
      "test Loss: 0.6463 Acc: 0.8667\n",
      "Epoch 326/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5770 Acc: 0.9667\n",
      "val Loss: 0.5526 Acc: 1.0000\n",
      "test Loss: 0.6205 Acc: 0.9333\n",
      "Epoch 327/499\n",
      "----------\n",
      "train Loss: 0.5721 Acc: 0.9778\n",
      "val Loss: 0.5534 Acc: 1.0000\n",
      "test Loss: 0.6231 Acc: 0.9333\n",
      "Epoch 328/499\n",
      "----------\n",
      "train Loss: 0.5723 Acc: 0.9778\n",
      "val Loss: 0.5530 Acc: 1.0000\n",
      "test Loss: 0.6278 Acc: 0.9333\n",
      "Epoch 329/499\n",
      "----------\n",
      "train Loss: 0.5624 Acc: 1.0000\n",
      "val Loss: 0.5705 Acc: 0.9667\n",
      "test Loss: 0.6220 Acc: 0.9000\n",
      "Epoch 330/499\n",
      "----------\n",
      "train Loss: 0.5635 Acc: 0.9889\n",
      "val Loss: 0.5580 Acc: 1.0000\n",
      "test Loss: 0.6079 Acc: 0.9333\n",
      "Epoch 331/499\n",
      "----------\n",
      "train Loss: 0.5708 Acc: 0.9889\n",
      "val Loss: 0.5540 Acc: 1.0000\n",
      "test Loss: 0.6110 Acc: 0.9333\n",
      "Epoch 332/499\n",
      "----------\n",
      "train Loss: 0.5637 Acc: 0.9889\n",
      "val Loss: 0.5522 Acc: 1.0000\n",
      "test Loss: 0.6187 Acc: 0.9000\n",
      "Epoch 333/499\n",
      "----------\n",
      "train Loss: 0.5661 Acc: 0.9889\n",
      "val Loss: 0.5533 Acc: 1.0000\n",
      "test Loss: 0.6109 Acc: 0.9333\n",
      "Epoch 334/499\n",
      "----------\n",
      "train Loss: 0.5783 Acc: 0.9667\n",
      "val Loss: 0.5553 Acc: 1.0000\n",
      "test Loss: 0.6070 Acc: 0.9333\n",
      "Epoch 335/499\n",
      "----------\n",
      "train Loss: 0.5669 Acc: 0.9889\n",
      "val Loss: 0.5712 Acc: 0.9667\n",
      "test Loss: 0.6116 Acc: 0.9333\n",
      "Epoch 336/499\n",
      "----------\n",
      "train Loss: 0.5714 Acc: 0.9889\n",
      "val Loss: 0.5537 Acc: 1.0000\n",
      "test Loss: 0.6158 Acc: 0.9333\n",
      "Epoch 337/499\n",
      "----------\n",
      "train Loss: 0.5664 Acc: 0.9889\n",
      "val Loss: 0.5545 Acc: 1.0000\n",
      "test Loss: 0.6351 Acc: 0.9000\n",
      "Epoch 338/499\n",
      "----------\n",
      "train Loss: 0.5782 Acc: 0.9778\n",
      "val Loss: 0.5553 Acc: 1.0000\n",
      "test Loss: 0.6095 Acc: 0.9333\n",
      "Epoch 339/499\n",
      "----------\n",
      "train Loss: 0.5680 Acc: 0.9889\n",
      "val Loss: 0.5706 Acc: 0.9667\n",
      "test Loss: 0.6084 Acc: 0.9333\n",
      "Epoch 340/499\n",
      "----------\n",
      "train Loss: 0.5687 Acc: 0.9778\n",
      "val Loss: 0.5523 Acc: 1.0000\n",
      "test Loss: 0.5721 Acc: 1.0000\n",
      "Epoch 341/499\n",
      "----------\n",
      "train Loss: 0.5609 Acc: 1.0000\n",
      "val Loss: 0.5722 Acc: 0.9667\n",
      "test Loss: 0.6081 Acc: 0.9333\n",
      "Epoch 342/499\n",
      "----------\n",
      "train Loss: 0.5691 Acc: 0.9889\n",
      "val Loss: 0.5535 Acc: 1.0000\n",
      "test Loss: 0.6142 Acc: 0.9333\n",
      "Epoch 343/499\n",
      "----------\n",
      "train Loss: 0.5715 Acc: 0.9778\n",
      "val Loss: 0.5531 Acc: 1.0000\n",
      "test Loss: 0.6410 Acc: 0.9000\n",
      "Epoch 344/499\n",
      "----------\n",
      "train Loss: 0.5644 Acc: 0.9889\n",
      "val Loss: 0.5531 Acc: 1.0000\n",
      "test Loss: 0.6311 Acc: 0.9000\n",
      "Epoch 345/499\n",
      "----------\n",
      "train Loss: 0.5606 Acc: 1.0000\n",
      "val Loss: 0.5532 Acc: 1.0000\n",
      "test Loss: 0.6137 Acc: 0.9333\n",
      "Epoch 346/499\n",
      "----------\n",
      "train Loss: 0.5629 Acc: 1.0000\n",
      "val Loss: 0.5523 Acc: 1.0000\n",
      "test Loss: 0.6169 Acc: 0.9333\n",
      "Epoch 347/499\n",
      "----------\n",
      "train Loss: 0.5627 Acc: 0.9889\n",
      "val Loss: 0.5535 Acc: 1.0000\n",
      "test Loss: 0.6174 Acc: 0.9333\n",
      "Epoch 348/499\n",
      "----------\n",
      "train Loss: 0.5654 Acc: 0.9889\n",
      "val Loss: 0.5539 Acc: 1.0000\n",
      "test Loss: 0.6097 Acc: 0.9333\n",
      "Epoch 349/499\n",
      "----------\n",
      "train Loss: 0.5671 Acc: 0.9889\n",
      "val Loss: 0.5721 Acc: 0.9667\n",
      "test Loss: 0.6172 Acc: 0.9333\n",
      "Epoch 350/499\n",
      "----------\n",
      "train Loss: 0.5694 Acc: 0.9778\n",
      "val Loss: 0.5532 Acc: 1.0000\n",
      "test Loss: 0.6048 Acc: 0.9333\n",
      "Epoch 351/499\n",
      "----------\n",
      "train Loss: 0.5675 Acc: 0.9778\n",
      "val Loss: 0.5530 Acc: 1.0000\n",
      "test Loss: 0.6062 Acc: 0.9333\n",
      "Epoch 352/499\n",
      "----------\n",
      "train Loss: 0.5685 Acc: 0.9889\n",
      "val Loss: 0.5549 Acc: 1.0000\n",
      "test Loss: 0.6219 Acc: 0.9000\n",
      "Epoch 353/499\n",
      "----------\n",
      "train Loss: 0.5671 Acc: 0.9889\n",
      "val Loss: 0.5540 Acc: 1.0000\n",
      "test Loss: 0.6137 Acc: 0.9333\n",
      "Epoch 354/499\n",
      "----------\n",
      "train Loss: 0.5668 Acc: 0.9778\n",
      "val Loss: 0.5533 Acc: 1.0000\n",
      "test Loss: 0.6170 Acc: 0.9333\n",
      "Epoch 355/499\n",
      "----------\n",
      "train Loss: 0.5837 Acc: 0.9667\n",
      "val Loss: 0.5721 Acc: 0.9667\n",
      "test Loss: 0.6425 Acc: 0.8667\n",
      "Epoch 356/499\n",
      "----------\n",
      "train Loss: 0.5601 Acc: 1.0000\n",
      "val Loss: 0.5532 Acc: 1.0000\n",
      "test Loss: 0.6149 Acc: 0.9333\n",
      "Epoch 357/499\n",
      "----------\n",
      "train Loss: 0.5652 Acc: 1.0000\n",
      "val Loss: 0.5527 Acc: 1.0000\n",
      "test Loss: 0.6126 Acc: 0.9333\n",
      "Epoch 358/499\n",
      "----------\n",
      "train Loss: 0.5669 Acc: 0.9889\n",
      "val Loss: 0.5539 Acc: 1.0000\n",
      "test Loss: 0.6351 Acc: 0.9000\n",
      "Epoch 359/499\n",
      "----------\n",
      "train Loss: 0.5664 Acc: 0.9778\n",
      "val Loss: 0.5942 Acc: 0.9333\n",
      "test Loss: 0.6119 Acc: 0.9333\n",
      "Epoch 360/499\n",
      "----------\n",
      "train Loss: 0.5654 Acc: 0.9889\n",
      "val Loss: 0.5535 Acc: 1.0000\n",
      "test Loss: 0.6219 Acc: 0.9000\n",
      "Epoch 361/499\n",
      "----------\n",
      "train Loss: 0.5650 Acc: 0.9889\n",
      "val Loss: 0.5537 Acc: 1.0000\n",
      "test Loss: 0.5967 Acc: 0.9667\n",
      "Epoch 362/499\n",
      "----------\n",
      "train Loss: 0.5603 Acc: 1.0000\n",
      "val Loss: 0.5529 Acc: 1.0000\n",
      "test Loss: 0.6009 Acc: 0.9667\n",
      "Epoch 363/499\n",
      "----------\n",
      "train Loss: 0.5628 Acc: 1.0000\n",
      "val Loss: 0.5706 Acc: 0.9667\n",
      "test Loss: 0.6115 Acc: 0.9333\n",
      "Epoch 364/499\n",
      "----------\n",
      "train Loss: 0.5615 Acc: 1.0000\n",
      "val Loss: 0.5520 Acc: 1.0000\n",
      "test Loss: 0.6215 Acc: 0.9000\n",
      "Epoch 365/499\n",
      "----------\n",
      "train Loss: 0.5619 Acc: 0.9889\n",
      "val Loss: 0.5534 Acc: 1.0000\n",
      "test Loss: 0.6086 Acc: 0.9667\n",
      "Epoch 366/499\n",
      "----------\n",
      "train Loss: 0.5680 Acc: 0.9889\n",
      "val Loss: 0.5709 Acc: 0.9667\n",
      "test Loss: 0.6386 Acc: 0.8667\n",
      "Epoch 367/499\n",
      "----------\n",
      "train Loss: 0.5698 Acc: 0.9778\n",
      "val Loss: 0.5523 Acc: 1.0000\n",
      "test Loss: 0.6120 Acc: 0.9333\n",
      "Epoch 368/499\n",
      "----------\n",
      "train Loss: 0.5638 Acc: 0.9889\n",
      "val Loss: 0.5538 Acc: 1.0000\n",
      "test Loss: 0.6074 Acc: 0.9333\n",
      "Epoch 369/499\n",
      "----------\n",
      "train Loss: 0.5688 Acc: 0.9889\n",
      "val Loss: 0.5555 Acc: 1.0000\n",
      "test Loss: 0.5923 Acc: 0.9667\n",
      "Epoch 370/499\n",
      "----------\n",
      "train Loss: 0.5636 Acc: 0.9889\n",
      "val Loss: 0.5525 Acc: 1.0000\n",
      "test Loss: 0.5933 Acc: 0.9667\n",
      "Epoch 371/499\n",
      "----------\n",
      "train Loss: 0.5665 Acc: 0.9889\n",
      "val Loss: 0.5536 Acc: 1.0000\n",
      "test Loss: 0.6343 Acc: 0.9000\n",
      "Epoch 372/499\n",
      "----------\n",
      "train Loss: 0.5693 Acc: 0.9889\n",
      "val Loss: 0.5535 Acc: 1.0000\n",
      "test Loss: 0.6316 Acc: 0.9333\n",
      "Epoch 373/499\n",
      "----------\n",
      "train Loss: 0.5662 Acc: 0.9889\n",
      "val Loss: 0.5532 Acc: 1.0000\n",
      "test Loss: 0.6120 Acc: 0.9333\n",
      "Epoch 374/499\n",
      "----------\n",
      "train Loss: 0.5688 Acc: 0.9889\n",
      "val Loss: 0.5530 Acc: 1.0000\n",
      "test Loss: 0.5970 Acc: 0.9667\n",
      "Epoch 375/499\n",
      "----------\n",
      "train Loss: 0.5640 Acc: 0.9889\n",
      "val Loss: 0.5696 Acc: 0.9667\n",
      "test Loss: 0.6201 Acc: 0.9333\n",
      "Epoch 376/499\n",
      "----------\n",
      "train Loss: 0.5748 Acc: 0.9667\n",
      "val Loss: 0.5708 Acc: 0.9667\n",
      "test Loss: 0.6249 Acc: 0.9000\n",
      "Epoch 377/499\n",
      "----------\n",
      "train Loss: 0.5648 Acc: 0.9889\n",
      "val Loss: 0.5526 Acc: 1.0000\n",
      "test Loss: 0.6008 Acc: 0.9667\n",
      "Epoch 378/499\n",
      "----------\n",
      "train Loss: 0.5672 Acc: 0.9889\n",
      "val Loss: 0.5524 Acc: 1.0000\n",
      "test Loss: 0.6251 Acc: 0.9000\n",
      "Epoch 379/499\n",
      "----------\n",
      "train Loss: 0.5633 Acc: 1.0000\n",
      "val Loss: 0.5535 Acc: 1.0000\n",
      "test Loss: 0.6167 Acc: 0.9333\n",
      "Epoch 380/499\n",
      "----------\n",
      "train Loss: 0.5691 Acc: 1.0000\n",
      "val Loss: 0.5527 Acc: 1.0000\n",
      "test Loss: 0.6273 Acc: 0.9000\n",
      "Epoch 381/499\n",
      "----------\n",
      "train Loss: 0.5625 Acc: 0.9889\n",
      "val Loss: 0.5528 Acc: 1.0000\n",
      "test Loss: 0.6323 Acc: 0.9000\n",
      "Epoch 382/499\n",
      "----------\n",
      "train Loss: 0.5623 Acc: 0.9889\n",
      "val Loss: 0.5520 Acc: 1.0000\n",
      "test Loss: 0.6255 Acc: 0.9333\n",
      "Epoch 383/499\n",
      "----------\n",
      "train Loss: 0.5653 Acc: 0.9889\n",
      "val Loss: 0.5532 Acc: 1.0000\n",
      "test Loss: 0.6252 Acc: 0.9000\n",
      "Epoch 384/499\n",
      "----------\n",
      "train Loss: 0.5604 Acc: 1.0000\n",
      "val Loss: 0.5566 Acc: 1.0000\n",
      "test Loss: 0.6334 Acc: 0.9000\n",
      "Epoch 385/499\n",
      "----------\n",
      "train Loss: 0.5575 Acc: 1.0000\n",
      "val Loss: 0.5691 Acc: 0.9667\n",
      "test Loss: 0.6306 Acc: 0.9000\n",
      "Epoch 386/499\n",
      "----------\n",
      "train Loss: 0.5607 Acc: 0.9889\n",
      "val Loss: 0.5524 Acc: 1.0000\n",
      "test Loss: 0.6123 Acc: 0.9333\n",
      "Epoch 387/499\n",
      "----------\n",
      "train Loss: 0.5669 Acc: 0.9889\n",
      "val Loss: 0.5526 Acc: 1.0000\n",
      "test Loss: 0.6139 Acc: 0.9333\n",
      "Epoch 388/499\n",
      "----------\n",
      "train Loss: 0.5642 Acc: 1.0000\n",
      "val Loss: 0.5554 Acc: 1.0000\n",
      "test Loss: 0.6152 Acc: 0.9333\n",
      "Epoch 389/499\n",
      "----------\n",
      "train Loss: 0.5608 Acc: 1.0000\n",
      "val Loss: 0.5526 Acc: 1.0000\n",
      "test Loss: 0.6071 Acc: 0.9333\n",
      "Epoch 390/499\n",
      "----------\n",
      "train Loss: 0.5624 Acc: 1.0000\n",
      "val Loss: 0.5522 Acc: 1.0000\n",
      "test Loss: 0.6211 Acc: 0.9333\n",
      "Epoch 391/499\n",
      "----------\n",
      "train Loss: 0.5651 Acc: 0.9889\n",
      "val Loss: 0.5531 Acc: 1.0000\n",
      "test Loss: 0.6239 Acc: 0.9000\n",
      "Epoch 392/499\n",
      "----------\n",
      "train Loss: 0.5636 Acc: 0.9889\n",
      "val Loss: 0.5521 Acc: 1.0000\n",
      "test Loss: 0.6184 Acc: 0.9333\n",
      "Epoch 393/499\n",
      "----------\n",
      "train Loss: 0.5654 Acc: 1.0000\n",
      "val Loss: 0.5519 Acc: 1.0000\n",
      "test Loss: 0.5979 Acc: 0.9667\n",
      "Epoch 394/499\n",
      "----------\n",
      "train Loss: 0.5604 Acc: 1.0000\n",
      "val Loss: 0.5523 Acc: 1.0000\n",
      "test Loss: 0.6116 Acc: 0.9333\n",
      "Epoch 395/499\n",
      "----------\n",
      "train Loss: 0.5684 Acc: 0.9778\n",
      "val Loss: 0.5531 Acc: 1.0000\n",
      "test Loss: 0.6097 Acc: 0.9333\n",
      "Epoch 396/499\n",
      "----------\n",
      "train Loss: 0.5616 Acc: 1.0000\n",
      "val Loss: 0.5697 Acc: 0.9667\n",
      "test Loss: 0.6246 Acc: 0.9000\n",
      "Epoch 397/499\n",
      "----------\n",
      "train Loss: 0.5708 Acc: 0.9889\n",
      "val Loss: 0.5530 Acc: 1.0000\n",
      "test Loss: 0.6390 Acc: 0.9000\n",
      "Epoch 398/499\n",
      "----------\n",
      "train Loss: 0.5616 Acc: 0.9889\n",
      "val Loss: 0.5550 Acc: 1.0000\n",
      "test Loss: 0.6231 Acc: 0.9000\n",
      "Epoch 399/499\n",
      "----------\n",
      "train Loss: 0.5781 Acc: 0.9778\n",
      "val Loss: 0.5518 Acc: 1.0000\n",
      "test Loss: 0.6098 Acc: 0.9333\n",
      "Epoch 400/499\n",
      "----------\n",
      "train Loss: 0.5632 Acc: 1.0000\n",
      "val Loss: 0.5530 Acc: 1.0000\n",
      "test Loss: 0.6102 Acc: 0.9333\n",
      "Epoch 401/499\n",
      "----------\n",
      "train Loss: 0.5621 Acc: 1.0000\n",
      "val Loss: 0.5519 Acc: 1.0000\n",
      "test Loss: 0.6209 Acc: 0.9333\n",
      "Epoch 402/499\n",
      "----------\n",
      "train Loss: 0.5626 Acc: 1.0000\n",
      "val Loss: 0.5522 Acc: 1.0000\n",
      "test Loss: 0.6124 Acc: 0.9333\n",
      "Epoch 403/499\n",
      "----------\n",
      "train Loss: 0.5646 Acc: 0.9889\n",
      "val Loss: 0.5532 Acc: 1.0000\n",
      "test Loss: 0.6263 Acc: 0.9000\n",
      "Epoch 404/499\n",
      "----------\n",
      "train Loss: 0.5777 Acc: 0.9778\n",
      "val Loss: 0.5524 Acc: 1.0000\n",
      "test Loss: 0.6272 Acc: 0.9333\n",
      "Epoch 405/499\n",
      "----------\n",
      "train Loss: 0.5660 Acc: 0.9889\n",
      "val Loss: 0.5527 Acc: 1.0000\n",
      "test Loss: 0.6281 Acc: 0.9000\n",
      "Epoch 406/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5611 Acc: 1.0000\n",
      "val Loss: 0.5519 Acc: 1.0000\n",
      "test Loss: 0.6272 Acc: 0.9333\n",
      "Epoch 407/499\n",
      "----------\n",
      "train Loss: 0.5589 Acc: 1.0000\n",
      "val Loss: 0.5525 Acc: 1.0000\n",
      "test Loss: 0.6193 Acc: 0.9333\n",
      "Epoch 408/499\n",
      "----------\n",
      "train Loss: 0.5582 Acc: 1.0000\n",
      "val Loss: 0.5518 Acc: 1.0000\n",
      "test Loss: 0.6163 Acc: 0.9333\n",
      "Epoch 409/499\n",
      "----------\n",
      "train Loss: 0.5576 Acc: 1.0000\n",
      "val Loss: 0.5517 Acc: 1.0000\n",
      "test Loss: 0.6033 Acc: 0.9667\n",
      "Epoch 410/499\n",
      "----------\n",
      "train Loss: 0.5693 Acc: 0.9889\n",
      "val Loss: 0.5552 Acc: 1.0000\n",
      "test Loss: 0.6152 Acc: 0.9333\n",
      "Epoch 411/499\n",
      "----------\n",
      "train Loss: 0.5610 Acc: 1.0000\n",
      "val Loss: 0.5523 Acc: 1.0000\n",
      "test Loss: 0.6170 Acc: 0.9333\n",
      "Epoch 412/499\n",
      "----------\n",
      "train Loss: 0.5649 Acc: 0.9889\n",
      "val Loss: 0.5705 Acc: 0.9667\n",
      "test Loss: 0.6267 Acc: 0.9000\n",
      "Epoch 413/499\n",
      "----------\n",
      "train Loss: 0.5731 Acc: 0.9889\n",
      "val Loss: 0.5521 Acc: 1.0000\n",
      "test Loss: 0.6105 Acc: 0.9333\n",
      "Epoch 414/499\n",
      "----------\n",
      "train Loss: 0.5645 Acc: 0.9889\n",
      "val Loss: 0.5529 Acc: 1.0000\n",
      "test Loss: 0.6018 Acc: 0.9667\n",
      "Epoch 415/499\n",
      "----------\n",
      "train Loss: 0.5665 Acc: 0.9889\n",
      "val Loss: 0.5529 Acc: 1.0000\n",
      "test Loss: 0.6228 Acc: 0.9000\n",
      "Epoch 416/499\n",
      "----------\n",
      "train Loss: 0.5579 Acc: 1.0000\n",
      "val Loss: 0.5534 Acc: 1.0000\n",
      "test Loss: 0.6109 Acc: 0.9333\n",
      "Epoch 417/499\n",
      "----------\n",
      "train Loss: 0.5620 Acc: 1.0000\n",
      "val Loss: 0.5520 Acc: 1.0000\n",
      "test Loss: 0.6129 Acc: 0.9333\n",
      "Epoch 418/499\n",
      "----------\n",
      "train Loss: 0.5709 Acc: 0.9778\n",
      "val Loss: 0.5530 Acc: 1.0000\n",
      "test Loss: 0.6117 Acc: 0.9667\n",
      "Epoch 419/499\n",
      "----------\n",
      "train Loss: 0.5648 Acc: 0.9889\n",
      "val Loss: 0.5524 Acc: 1.0000\n",
      "test Loss: 0.6156 Acc: 0.9667\n",
      "Epoch 420/499\n",
      "----------\n",
      "train Loss: 0.5631 Acc: 0.9889\n",
      "val Loss: 0.5525 Acc: 1.0000\n",
      "test Loss: 0.6135 Acc: 0.9333\n",
      "Epoch 421/499\n",
      "----------\n",
      "train Loss: 0.5681 Acc: 0.9889\n",
      "val Loss: 0.5528 Acc: 1.0000\n",
      "test Loss: 0.6284 Acc: 0.9000\n",
      "Epoch 422/499\n",
      "----------\n",
      "train Loss: 0.5597 Acc: 1.0000\n",
      "val Loss: 0.5529 Acc: 1.0000\n",
      "test Loss: 0.6082 Acc: 0.9667\n",
      "Epoch 423/499\n",
      "----------\n",
      "train Loss: 0.5682 Acc: 0.9778\n",
      "val Loss: 0.5523 Acc: 1.0000\n",
      "test Loss: 0.6277 Acc: 0.9333\n",
      "Epoch 424/499\n",
      "----------\n",
      "train Loss: 0.5594 Acc: 1.0000\n",
      "val Loss: 0.5533 Acc: 1.0000\n",
      "test Loss: 0.6076 Acc: 0.9667\n",
      "Epoch 425/499\n",
      "----------\n",
      "train Loss: 0.5600 Acc: 1.0000\n",
      "val Loss: 0.5527 Acc: 1.0000\n",
      "test Loss: 0.6145 Acc: 0.9333\n",
      "Epoch 426/499\n",
      "----------\n",
      "train Loss: 0.5701 Acc: 0.9778\n",
      "val Loss: 0.5532 Acc: 1.0000\n",
      "test Loss: 0.6387 Acc: 0.9000\n",
      "Epoch 427/499\n",
      "----------\n",
      "train Loss: 0.5616 Acc: 0.9889\n",
      "val Loss: 0.5516 Acc: 1.0000\n",
      "test Loss: 0.6219 Acc: 0.9333\n",
      "Epoch 428/499\n",
      "----------\n",
      "train Loss: 0.5605 Acc: 1.0000\n",
      "val Loss: 0.5534 Acc: 1.0000\n",
      "test Loss: 0.6168 Acc: 0.9333\n",
      "Epoch 429/499\n",
      "----------\n",
      "train Loss: 0.5640 Acc: 0.9889\n",
      "val Loss: 0.5525 Acc: 1.0000\n",
      "test Loss: 0.6166 Acc: 0.9333\n",
      "Epoch 430/499\n",
      "----------\n",
      "train Loss: 0.5616 Acc: 0.9889\n",
      "val Loss: 0.5524 Acc: 1.0000\n",
      "test Loss: 0.6032 Acc: 0.9667\n",
      "Epoch 431/499\n",
      "----------\n",
      "train Loss: 0.5597 Acc: 1.0000\n",
      "val Loss: 0.5521 Acc: 1.0000\n",
      "test Loss: 0.6224 Acc: 0.9333\n",
      "Epoch 432/499\n",
      "----------\n",
      "train Loss: 0.5659 Acc: 0.9889\n",
      "val Loss: 0.5602 Acc: 1.0000\n",
      "test Loss: 0.6130 Acc: 0.9333\n",
      "Epoch 433/499\n",
      "----------\n",
      "train Loss: 0.5601 Acc: 1.0000\n",
      "val Loss: 0.5528 Acc: 1.0000\n",
      "test Loss: 0.6136 Acc: 0.9333\n",
      "Epoch 434/499\n",
      "----------\n",
      "train Loss: 0.5560 Acc: 1.0000\n",
      "val Loss: 0.5521 Acc: 1.0000\n",
      "test Loss: 0.6385 Acc: 0.9000\n",
      "Epoch 435/499\n",
      "----------\n",
      "train Loss: 0.5628 Acc: 0.9889\n",
      "val Loss: 0.5528 Acc: 1.0000\n",
      "test Loss: 0.6336 Acc: 0.9000\n",
      "Epoch 436/499\n",
      "----------\n",
      "train Loss: 0.5601 Acc: 0.9889\n",
      "val Loss: 0.5527 Acc: 1.0000\n",
      "test Loss: 0.6163 Acc: 0.9333\n",
      "Epoch 437/499\n",
      "----------\n",
      "train Loss: 0.5653 Acc: 0.9889\n",
      "val Loss: 0.5527 Acc: 1.0000\n",
      "test Loss: 0.6214 Acc: 0.9333\n",
      "Epoch 438/499\n",
      "----------\n",
      "train Loss: 0.5579 Acc: 1.0000\n",
      "val Loss: 0.5523 Acc: 1.0000\n",
      "test Loss: 0.6172 Acc: 0.9333\n",
      "Epoch 439/499\n",
      "----------\n",
      "train Loss: 0.5575 Acc: 1.0000\n",
      "val Loss: 0.5524 Acc: 1.0000\n",
      "test Loss: 0.6159 Acc: 0.9667\n",
      "Epoch 440/499\n",
      "----------\n",
      "train Loss: 0.5612 Acc: 1.0000\n",
      "val Loss: 0.5526 Acc: 1.0000\n",
      "test Loss: 0.6342 Acc: 0.9000\n",
      "Epoch 441/499\n",
      "----------\n",
      "train Loss: 0.5561 Acc: 1.0000\n",
      "val Loss: 0.5523 Acc: 1.0000\n",
      "test Loss: 0.6177 Acc: 0.9333\n",
      "Epoch 442/499\n",
      "----------\n",
      "train Loss: 0.5616 Acc: 1.0000\n",
      "val Loss: 0.5528 Acc: 1.0000\n",
      "test Loss: 0.6235 Acc: 0.9000\n",
      "Epoch 443/499\n",
      "----------\n",
      "train Loss: 0.5669 Acc: 1.0000\n",
      "val Loss: 0.5523 Acc: 1.0000\n",
      "test Loss: 0.6271 Acc: 0.9000\n",
      "Epoch 444/499\n",
      "----------\n",
      "train Loss: 0.5655 Acc: 0.9889\n",
      "val Loss: 0.5525 Acc: 1.0000\n",
      "test Loss: 0.6162 Acc: 0.9333\n",
      "Epoch 445/499\n",
      "----------\n",
      "train Loss: 0.5609 Acc: 1.0000\n",
      "val Loss: 0.5527 Acc: 1.0000\n",
      "test Loss: 0.6002 Acc: 0.9667\n",
      "Epoch 446/499\n",
      "----------\n",
      "train Loss: 0.5602 Acc: 0.9889\n",
      "val Loss: 0.5532 Acc: 1.0000\n",
      "test Loss: 0.6188 Acc: 0.9333\n",
      "Epoch 447/499\n",
      "----------\n",
      "train Loss: 0.5573 Acc: 1.0000\n",
      "val Loss: 0.5535 Acc: 1.0000\n",
      "test Loss: 0.6604 Acc: 0.8667\n",
      "Epoch 448/499\n",
      "----------\n",
      "train Loss: 0.5712 Acc: 0.9778\n",
      "val Loss: 0.5522 Acc: 1.0000\n",
      "test Loss: 0.6368 Acc: 0.9000\n",
      "Epoch 449/499\n",
      "----------\n",
      "train Loss: 0.5647 Acc: 0.9889\n",
      "val Loss: 0.5523 Acc: 1.0000\n",
      "test Loss: 0.6215 Acc: 0.9333\n",
      "Epoch 450/499\n",
      "----------\n",
      "train Loss: 0.5607 Acc: 0.9889\n",
      "val Loss: 0.5542 Acc: 1.0000\n",
      "test Loss: 0.6213 Acc: 0.9333\n",
      "Epoch 451/499\n",
      "----------\n",
      "train Loss: 0.5554 Acc: 1.0000\n",
      "val Loss: 0.5529 Acc: 1.0000\n",
      "test Loss: 0.6173 Acc: 0.9333\n",
      "Epoch 452/499\n",
      "----------\n",
      "train Loss: 0.5573 Acc: 1.0000\n",
      "val Loss: 0.5524 Acc: 1.0000\n",
      "test Loss: 0.6178 Acc: 0.9333\n",
      "Epoch 453/499\n",
      "----------\n",
      "train Loss: 0.5779 Acc: 0.9778\n",
      "val Loss: 0.5519 Acc: 1.0000\n",
      "test Loss: 0.6186 Acc: 0.9333\n",
      "Epoch 454/499\n",
      "----------\n",
      "train Loss: 0.5572 Acc: 1.0000\n",
      "val Loss: 0.5528 Acc: 1.0000\n",
      "test Loss: 0.6168 Acc: 0.9333\n",
      "Epoch 455/499\n",
      "----------\n",
      "train Loss: 0.5633 Acc: 0.9889\n",
      "val Loss: 0.5691 Acc: 0.9667\n",
      "test Loss: 0.6075 Acc: 0.9667\n",
      "Epoch 456/499\n",
      "----------\n",
      "train Loss: 0.5557 Acc: 1.0000\n",
      "val Loss: 0.5522 Acc: 1.0000\n",
      "test Loss: 0.6247 Acc: 0.9333\n",
      "Epoch 457/499\n",
      "----------\n",
      "train Loss: 0.5618 Acc: 1.0000\n",
      "val Loss: 0.5693 Acc: 0.9667\n",
      "test Loss: 0.6150 Acc: 0.9333\n",
      "Epoch 458/499\n",
      "----------\n",
      "train Loss: 0.5591 Acc: 1.0000\n",
      "val Loss: 0.5522 Acc: 1.0000\n",
      "test Loss: 0.6431 Acc: 0.9000\n",
      "Epoch 459/499\n",
      "----------\n",
      "train Loss: 0.5614 Acc: 0.9889\n",
      "val Loss: 0.5520 Acc: 1.0000\n",
      "test Loss: 0.6470 Acc: 0.8667\n",
      "Epoch 460/499\n",
      "----------\n",
      "train Loss: 0.5586 Acc: 1.0000\n",
      "val Loss: 0.5524 Acc: 1.0000\n",
      "test Loss: 0.6347 Acc: 0.9000\n",
      "Epoch 461/499\n",
      "----------\n",
      "train Loss: 0.5627 Acc: 0.9889\n",
      "val Loss: 0.5529 Acc: 1.0000\n",
      "test Loss: 0.6032 Acc: 0.9667\n",
      "Epoch 462/499\n",
      "----------\n",
      "train Loss: 0.5584 Acc: 1.0000\n",
      "val Loss: 0.5530 Acc: 1.0000\n",
      "test Loss: 0.6103 Acc: 0.9333\n",
      "Epoch 463/499\n",
      "----------\n",
      "train Loss: 0.5609 Acc: 1.0000\n",
      "val Loss: 0.5522 Acc: 1.0000\n",
      "test Loss: 0.6339 Acc: 0.9000\n",
      "Epoch 464/499\n",
      "----------\n",
      "train Loss: 0.5587 Acc: 1.0000\n",
      "val Loss: 0.5532 Acc: 1.0000\n",
      "test Loss: 0.6177 Acc: 0.9333\n",
      "Epoch 465/499\n",
      "----------\n",
      "train Loss: 0.5588 Acc: 1.0000\n",
      "val Loss: 0.5516 Acc: 1.0000\n",
      "test Loss: 0.6342 Acc: 0.9000\n",
      "Epoch 466/499\n",
      "----------\n",
      "train Loss: 0.5582 Acc: 1.0000\n",
      "val Loss: 0.5520 Acc: 1.0000\n",
      "test Loss: 0.5921 Acc: 0.9667\n",
      "Epoch 467/499\n",
      "----------\n",
      "train Loss: 0.5630 Acc: 0.9889\n",
      "val Loss: 0.5521 Acc: 1.0000\n",
      "test Loss: 0.6220 Acc: 0.9333\n",
      "Epoch 468/499\n",
      "----------\n",
      "train Loss: 0.5570 Acc: 1.0000\n",
      "val Loss: 0.5527 Acc: 1.0000\n",
      "test Loss: 0.6248 Acc: 0.9333\n",
      "Epoch 469/499\n",
      "----------\n",
      "train Loss: 0.5579 Acc: 1.0000\n",
      "val Loss: 0.5694 Acc: 0.9667\n",
      "test Loss: 0.6264 Acc: 0.9000\n",
      "Epoch 470/499\n",
      "----------\n",
      "train Loss: 0.5572 Acc: 1.0000\n",
      "val Loss: 0.5528 Acc: 1.0000\n",
      "test Loss: 0.6172 Acc: 0.9333\n",
      "Epoch 471/499\n",
      "----------\n",
      "train Loss: 0.5621 Acc: 1.0000\n",
      "val Loss: 0.5519 Acc: 1.0000\n",
      "test Loss: 0.6219 Acc: 0.9333\n",
      "Epoch 472/499\n",
      "----------\n",
      "train Loss: 0.5580 Acc: 1.0000\n",
      "val Loss: 0.5526 Acc: 1.0000\n",
      "test Loss: 0.6215 Acc: 0.9333\n",
      "Epoch 473/499\n",
      "----------\n",
      "train Loss: 0.5690 Acc: 0.9778\n",
      "val Loss: 0.5522 Acc: 1.0000\n",
      "test Loss: 0.6119 Acc: 0.9333\n",
      "Epoch 474/499\n",
      "----------\n",
      "train Loss: 0.5583 Acc: 1.0000\n",
      "val Loss: 0.5530 Acc: 1.0000\n",
      "test Loss: 0.6144 Acc: 0.9333\n",
      "Epoch 475/499\n",
      "----------\n",
      "train Loss: 0.5626 Acc: 1.0000\n",
      "val Loss: 0.5520 Acc: 1.0000\n",
      "test Loss: 0.6426 Acc: 0.9000\n",
      "Epoch 476/499\n",
      "----------\n",
      "train Loss: 0.5583 Acc: 1.0000\n",
      "val Loss: 0.5536 Acc: 1.0000\n",
      "test Loss: 0.6184 Acc: 0.9333\n",
      "Epoch 477/499\n",
      "----------\n",
      "train Loss: 0.5569 Acc: 1.0000\n",
      "val Loss: 0.5528 Acc: 1.0000\n",
      "test Loss: 0.6178 Acc: 0.9333\n",
      "Epoch 478/499\n",
      "----------\n",
      "train Loss: 0.5556 Acc: 1.0000\n",
      "val Loss: 0.5692 Acc: 0.9667\n",
      "test Loss: 0.6311 Acc: 0.9000\n",
      "Epoch 479/499\n",
      "----------\n",
      "train Loss: 0.5630 Acc: 0.9889\n",
      "val Loss: 0.5524 Acc: 1.0000\n",
      "test Loss: 0.6109 Acc: 0.9667\n",
      "Epoch 480/499\n",
      "----------\n",
      "train Loss: 0.5558 Acc: 1.0000\n",
      "val Loss: 0.5740 Acc: 0.9667\n",
      "test Loss: 0.6192 Acc: 0.9333\n",
      "Epoch 481/499\n",
      "----------\n",
      "train Loss: 0.5624 Acc: 0.9889\n",
      "val Loss: 0.5524 Acc: 1.0000\n",
      "test Loss: 0.6218 Acc: 0.9333\n",
      "Epoch 482/499\n",
      "----------\n",
      "train Loss: 0.5592 Acc: 1.0000\n",
      "val Loss: 0.5523 Acc: 1.0000\n",
      "test Loss: 0.6202 Acc: 0.9333\n",
      "Epoch 483/499\n",
      "----------\n",
      "train Loss: 0.5674 Acc: 0.9889\n",
      "val Loss: 0.5525 Acc: 1.0000\n",
      "test Loss: 0.6198 Acc: 0.9333\n",
      "Epoch 484/499\n",
      "----------\n",
      "train Loss: 0.5582 Acc: 1.0000\n",
      "val Loss: 0.5519 Acc: 1.0000\n",
      "test Loss: 0.6345 Acc: 0.9000\n",
      "Epoch 485/499\n",
      "----------\n",
      "train Loss: 0.5578 Acc: 1.0000\n",
      "val Loss: 0.5697 Acc: 0.9667\n",
      "test Loss: 0.6305 Acc: 0.9000\n",
      "Epoch 486/499\n",
      "----------\n",
      "train Loss: 0.5554 Acc: 1.0000\n",
      "val Loss: 0.5520 Acc: 1.0000\n",
      "test Loss: 0.6293 Acc: 0.9333\n",
      "Epoch 487/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5561 Acc: 1.0000\n",
      "val Loss: 0.5518 Acc: 1.0000\n",
      "test Loss: 0.6392 Acc: 0.9000\n",
      "Epoch 488/499\n",
      "----------\n",
      "train Loss: 0.5556 Acc: 1.0000\n",
      "val Loss: 0.5527 Acc: 1.0000\n",
      "test Loss: 0.6051 Acc: 0.9667\n",
      "Epoch 489/499\n",
      "----------\n",
      "train Loss: 0.5571 Acc: 1.0000\n",
      "val Loss: 0.5517 Acc: 1.0000\n",
      "test Loss: 0.6310 Acc: 0.9000\n",
      "Epoch 490/499\n",
      "----------\n",
      "train Loss: 0.5659 Acc: 0.9889\n",
      "val Loss: 0.5520 Acc: 1.0000\n",
      "test Loss: 0.6196 Acc: 0.9333\n",
      "Epoch 491/499\n",
      "----------\n",
      "train Loss: 0.5563 Acc: 1.0000\n",
      "val Loss: 0.5690 Acc: 0.9667\n",
      "test Loss: 0.6433 Acc: 0.9000\n",
      "Epoch 492/499\n",
      "----------\n",
      "train Loss: 0.5568 Acc: 1.0000\n",
      "val Loss: 0.5550 Acc: 1.0000\n",
      "test Loss: 0.6158 Acc: 0.9333\n",
      "Epoch 493/499\n",
      "----------\n",
      "train Loss: 0.5591 Acc: 0.9889\n",
      "val Loss: 0.5519 Acc: 1.0000\n",
      "test Loss: 0.6385 Acc: 0.9000\n",
      "Epoch 494/499\n",
      "----------\n",
      "train Loss: 0.5567 Acc: 1.0000\n",
      "val Loss: 0.5526 Acc: 1.0000\n",
      "test Loss: 0.6187 Acc: 0.9333\n",
      "Epoch 495/499\n",
      "----------\n",
      "train Loss: 0.5584 Acc: 1.0000\n",
      "val Loss: 0.5523 Acc: 1.0000\n",
      "test Loss: 0.6180 Acc: 0.9333\n",
      "Epoch 496/499\n",
      "----------\n",
      "train Loss: 0.5596 Acc: 1.0000\n",
      "val Loss: 0.5520 Acc: 1.0000\n",
      "test Loss: 0.6336 Acc: 0.9000\n",
      "Epoch 497/499\n",
      "----------\n",
      "train Loss: 0.5606 Acc: 1.0000\n",
      "val Loss: 0.5519 Acc: 1.0000\n",
      "test Loss: 0.6231 Acc: 0.9333\n",
      "Epoch 498/499\n",
      "----------\n",
      "train Loss: 0.5575 Acc: 1.0000\n",
      "val Loss: 0.5524 Acc: 1.0000\n",
      "test Loss: 0.6245 Acc: 0.9000\n",
      "Epoch 499/499\n",
      "----------\n",
      "train Loss: 0.5588 Acc: 1.0000\n",
      "val Loss: 0.5521 Acc: 1.0000\n",
      "test Loss: 0.6146 Acc: 0.9333\n",
      "Training complete in 0m 6s\n",
      "Best test Acc: 1.000000\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 1.1077 Acc: 0.3000\n",
      "val Loss: 1.1147 Acc: 0.3333\n",
      "test Loss: 1.1097 Acc: 0.3000\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 1.1041 Acc: 0.3222\n",
      "val Loss: 1.1190 Acc: 0.2333\n",
      "test Loss: 1.1056 Acc: 0.3000\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 1.1030 Acc: 0.3333\n",
      "val Loss: 1.1103 Acc: 0.2667\n",
      "test Loss: 1.0989 Acc: 0.3333\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 1.1043 Acc: 0.3222\n",
      "val Loss: 1.0968 Acc: 0.3333\n",
      "test Loss: 1.0951 Acc: 0.3333\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 1.0984 Acc: 0.3222\n",
      "val Loss: 1.0976 Acc: 0.3333\n",
      "test Loss: 1.1057 Acc: 0.3000\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 1.0972 Acc: 0.3333\n",
      "val Loss: 1.0913 Acc: 0.3333\n",
      "test Loss: 1.0891 Acc: 0.3333\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 1.0906 Acc: 0.3333\n",
      "val Loss: 1.0932 Acc: 0.3333\n",
      "test Loss: 1.0848 Acc: 0.3333\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 1.0928 Acc: 0.3333\n",
      "val Loss: 1.0930 Acc: 0.3000\n",
      "test Loss: 1.0819 Acc: 0.3333\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 1.0899 Acc: 0.3333\n",
      "val Loss: 1.0872 Acc: 0.3333\n",
      "test Loss: 1.0810 Acc: 0.3333\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 1.0836 Acc: 0.3333\n",
      "val Loss: 1.0821 Acc: 0.3333\n",
      "test Loss: 1.0732 Acc: 0.3333\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 1.0784 Acc: 0.3333\n",
      "val Loss: 1.0843 Acc: 0.3333\n",
      "test Loss: 1.0832 Acc: 0.3333\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 1.0810 Acc: 0.3333\n",
      "val Loss: 1.0779 Acc: 0.3333\n",
      "test Loss: 1.0761 Acc: 0.3333\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 1.0761 Acc: 0.3333\n",
      "val Loss: 1.0763 Acc: 0.3333\n",
      "test Loss: 1.0690 Acc: 0.3333\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 1.0837 Acc: 0.3333\n",
      "val Loss: 1.0784 Acc: 0.3333\n",
      "test Loss: 1.0609 Acc: 0.3333\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 1.0699 Acc: 0.3333\n",
      "val Loss: 1.0717 Acc: 0.3333\n",
      "test Loss: 1.0711 Acc: 0.3333\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 1.0646 Acc: 0.3333\n",
      "val Loss: 1.0677 Acc: 0.3333\n",
      "test Loss: 1.0570 Acc: 0.3333\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 1.0677 Acc: 0.3333\n",
      "val Loss: 1.0700 Acc: 0.3333\n",
      "test Loss: 1.0556 Acc: 0.3333\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 1.0647 Acc: 0.3333\n",
      "val Loss: 1.0645 Acc: 0.3333\n",
      "test Loss: 1.0530 Acc: 0.3333\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 1.0623 Acc: 0.3333\n",
      "val Loss: 1.0695 Acc: 0.3333\n",
      "test Loss: 1.0520 Acc: 0.3333\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 1.0577 Acc: 0.3333\n",
      "val Loss: 1.0547 Acc: 0.3333\n",
      "test Loss: 1.0521 Acc: 0.3333\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 1.0613 Acc: 0.3333\n",
      "val Loss: 1.0534 Acc: 0.3333\n",
      "test Loss: 1.0484 Acc: 0.3333\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 1.0456 Acc: 0.3333\n",
      "val Loss: 1.0501 Acc: 0.3333\n",
      "test Loss: 1.0424 Acc: 0.3333\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 1.0487 Acc: 0.3333\n",
      "val Loss: 1.0424 Acc: 0.3333\n",
      "test Loss: 1.0468 Acc: 0.3333\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 1.0471 Acc: 0.3333\n",
      "val Loss: 1.0540 Acc: 0.3333\n",
      "test Loss: 1.0376 Acc: 0.3333\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 1.0432 Acc: 0.3333\n",
      "val Loss: 1.0444 Acc: 0.3333\n",
      "test Loss: 1.0396 Acc: 0.3333\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 1.0422 Acc: 0.3333\n",
      "val Loss: 1.0457 Acc: 0.3333\n",
      "test Loss: 1.0416 Acc: 0.3333\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 1.0414 Acc: 0.3333\n",
      "val Loss: 1.0327 Acc: 0.3333\n",
      "test Loss: 1.0364 Acc: 0.3333\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 1.0368 Acc: 0.3333\n",
      "val Loss: 1.0347 Acc: 0.3333\n",
      "test Loss: 1.0288 Acc: 0.3333\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 1.0343 Acc: 0.3333\n",
      "val Loss: 1.0352 Acc: 0.3333\n",
      "test Loss: 1.0275 Acc: 0.3333\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 1.0324 Acc: 0.3333\n",
      "val Loss: 1.0245 Acc: 0.3333\n",
      "test Loss: 1.0290 Acc: 0.3333\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 1.0325 Acc: 0.3333\n",
      "val Loss: 1.0208 Acc: 0.3333\n",
      "test Loss: 1.0301 Acc: 0.3333\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 1.0269 Acc: 0.3333\n",
      "val Loss: 1.0252 Acc: 0.3333\n",
      "test Loss: 1.0204 Acc: 0.3333\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 1.0288 Acc: 0.3333\n",
      "val Loss: 1.0198 Acc: 0.3333\n",
      "test Loss: 1.0268 Acc: 0.3333\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 1.0308 Acc: 0.3333\n",
      "val Loss: 1.0153 Acc: 0.3333\n",
      "test Loss: 1.0131 Acc: 0.3333\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 1.0217 Acc: 0.3333\n",
      "val Loss: 1.0363 Acc: 0.3333\n",
      "test Loss: 1.0164 Acc: 0.3333\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 1.0249 Acc: 0.3333\n",
      "val Loss: 1.0129 Acc: 0.3333\n",
      "test Loss: 1.0214 Acc: 0.3333\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 1.0225 Acc: 0.3333\n",
      "val Loss: 1.0095 Acc: 0.3333\n",
      "test Loss: 1.0096 Acc: 0.3333\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 1.0152 Acc: 0.3333\n",
      "val Loss: 1.0198 Acc: 0.3333\n",
      "test Loss: 1.0070 Acc: 0.3333\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 1.0131 Acc: 0.3333\n",
      "val Loss: 1.0093 Acc: 0.3333\n",
      "test Loss: 1.0162 Acc: 0.3333\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 1.0108 Acc: 0.3333\n",
      "val Loss: 1.0089 Acc: 0.3333\n",
      "test Loss: 0.9969 Acc: 0.3333\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 1.0081 Acc: 0.3333\n",
      "val Loss: 1.0079 Acc: 0.3333\n",
      "test Loss: 1.0085 Acc: 0.3333\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 1.0102 Acc: 0.3333\n",
      "val Loss: 1.0020 Acc: 0.3333\n",
      "test Loss: 0.9953 Acc: 0.3333\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 1.0059 Acc: 0.3333\n",
      "val Loss: 1.0036 Acc: 0.3333\n",
      "test Loss: 0.9913 Acc: 0.3333\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 1.0064 Acc: 0.3333\n",
      "val Loss: 0.9950 Acc: 0.3333\n",
      "test Loss: 0.9968 Acc: 0.3333\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.9952 Acc: 0.3333\n",
      "val Loss: 0.9955 Acc: 0.3333\n",
      "test Loss: 0.9917 Acc: 0.3333\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.9975 Acc: 0.3333\n",
      "val Loss: 0.9949 Acc: 0.3333\n",
      "test Loss: 0.9945 Acc: 0.3333\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 1.0033 Acc: 0.3333\n",
      "val Loss: 0.9932 Acc: 0.3333\n",
      "test Loss: 0.9935 Acc: 0.3333\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.9940 Acc: 0.3333\n",
      "val Loss: 0.9986 Acc: 0.3333\n",
      "test Loss: 0.9925 Acc: 0.3333\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.9866 Acc: 0.3333\n",
      "val Loss: 0.9838 Acc: 0.3667\n",
      "test Loss: 0.9819 Acc: 0.3333\n",
      "Epoch 49/499\n",
      "----------\n",
      "train Loss: 0.9896 Acc: 0.3444\n",
      "val Loss: 1.0050 Acc: 0.3333\n",
      "test Loss: 0.9967 Acc: 0.4000\n",
      "Epoch 50/499\n",
      "----------\n",
      "train Loss: 0.9853 Acc: 0.4000\n",
      "val Loss: 0.9901 Acc: 0.4333\n",
      "test Loss: 0.9812 Acc: 0.4333\n",
      "Epoch 51/499\n",
      "----------\n",
      "train Loss: 0.9904 Acc: 0.4778\n",
      "val Loss: 0.9861 Acc: 0.5000\n",
      "test Loss: 0.9772 Acc: 0.5667\n",
      "Epoch 52/499\n",
      "----------\n",
      "train Loss: 0.9851 Acc: 0.4333\n",
      "val Loss: 0.9794 Acc: 0.5333\n",
      "test Loss: 0.9769 Acc: 0.5333\n",
      "Epoch 53/499\n",
      "----------\n",
      "train Loss: 0.9855 Acc: 0.5556\n",
      "val Loss: 0.9725 Acc: 0.5667\n",
      "test Loss: 0.9730 Acc: 0.6000\n",
      "Epoch 54/499\n",
      "----------\n",
      "train Loss: 0.9867 Acc: 0.6222\n",
      "val Loss: 0.9717 Acc: 0.5667\n",
      "test Loss: 0.9690 Acc: 0.5667\n",
      "Epoch 55/499\n",
      "----------\n",
      "train Loss: 0.9801 Acc: 0.6222\n",
      "val Loss: 0.9835 Acc: 0.6333\n",
      "test Loss: 0.9747 Acc: 0.6333\n",
      "Epoch 56/499\n",
      "----------\n",
      "train Loss: 0.9733 Acc: 0.6444\n",
      "val Loss: 0.9689 Acc: 0.6667\n",
      "test Loss: 0.9781 Acc: 0.6667\n",
      "Epoch 57/499\n",
      "----------\n",
      "train Loss: 0.9763 Acc: 0.6222\n",
      "val Loss: 0.9764 Acc: 0.6667\n",
      "test Loss: 0.9652 Acc: 0.6667\n",
      "Epoch 58/499\n",
      "----------\n",
      "train Loss: 0.9749 Acc: 0.6111\n",
      "val Loss: 0.9755 Acc: 0.6667\n",
      "test Loss: 0.9766 Acc: 0.6000\n",
      "Epoch 59/499\n",
      "----------\n",
      "train Loss: 0.9757 Acc: 0.6444\n",
      "val Loss: 0.9638 Acc: 0.6333\n",
      "test Loss: 0.9737 Acc: 0.6333\n",
      "Epoch 60/499\n",
      "----------\n",
      "train Loss: 0.9713 Acc: 0.6111\n",
      "val Loss: 0.9725 Acc: 0.6333\n",
      "test Loss: 0.9620 Acc: 0.5667\n",
      "Epoch 61/499\n",
      "----------\n",
      "train Loss: 0.9673 Acc: 0.6556\n",
      "val Loss: 0.9615 Acc: 0.6667\n",
      "test Loss: 0.9715 Acc: 0.6333\n",
      "Epoch 62/499\n",
      "----------\n",
      "train Loss: 0.9697 Acc: 0.6667\n",
      "val Loss: 0.9622 Acc: 0.6333\n",
      "test Loss: 0.9587 Acc: 0.6333\n",
      "Epoch 63/499\n",
      "----------\n",
      "train Loss: 0.9616 Acc: 0.6444\n",
      "val Loss: 0.9524 Acc: 0.6333\n",
      "test Loss: 0.9765 Acc: 0.6667\n",
      "Epoch 64/499\n",
      "----------\n",
      "train Loss: 0.9585 Acc: 0.6667\n",
      "val Loss: 0.9608 Acc: 0.6000\n",
      "test Loss: 0.9527 Acc: 0.6667\n",
      "Epoch 65/499\n",
      "----------\n",
      "train Loss: 0.9617 Acc: 0.6444\n",
      "val Loss: 0.9465 Acc: 0.7000\n",
      "test Loss: 0.9518 Acc: 0.6667\n",
      "Epoch 66/499\n",
      "----------\n",
      "train Loss: 0.9597 Acc: 0.6556\n",
      "val Loss: 0.9472 Acc: 0.6667\n",
      "test Loss: 0.9612 Acc: 0.6667\n",
      "Epoch 67/499\n",
      "----------\n",
      "train Loss: 0.9514 Acc: 0.6556\n",
      "val Loss: 0.9521 Acc: 0.6667\n",
      "test Loss: 0.9552 Acc: 0.6667\n",
      "Epoch 68/499\n",
      "----------\n",
      "train Loss: 0.9579 Acc: 0.6333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.9491 Acc: 0.6667\n",
      "test Loss: 0.9539 Acc: 0.6667\n",
      "Epoch 69/499\n",
      "----------\n",
      "train Loss: 0.9474 Acc: 0.6667\n",
      "val Loss: 0.9445 Acc: 0.6667\n",
      "test Loss: 0.9504 Acc: 0.6667\n",
      "Epoch 70/499\n",
      "----------\n",
      "train Loss: 0.9499 Acc: 0.6556\n",
      "val Loss: 0.9409 Acc: 0.6667\n",
      "test Loss: 0.9513 Acc: 0.6667\n",
      "Epoch 71/499\n",
      "----------\n",
      "train Loss: 0.9438 Acc: 0.6667\n",
      "val Loss: 0.9428 Acc: 0.6667\n",
      "test Loss: 0.9455 Acc: 0.6667\n",
      "Epoch 72/499\n",
      "----------\n",
      "train Loss: 0.9462 Acc: 0.6667\n",
      "val Loss: 0.9390 Acc: 0.6667\n",
      "test Loss: 0.9401 Acc: 0.6667\n",
      "Epoch 73/499\n",
      "----------\n",
      "train Loss: 0.9421 Acc: 0.6667\n",
      "val Loss: 0.9425 Acc: 0.6667\n",
      "test Loss: 0.9424 Acc: 0.6667\n",
      "Epoch 74/499\n",
      "----------\n",
      "train Loss: 0.9467 Acc: 0.6556\n",
      "val Loss: 0.9303 Acc: 0.6667\n",
      "test Loss: 0.9389 Acc: 0.6667\n",
      "Epoch 75/499\n",
      "----------\n",
      "train Loss: 0.9374 Acc: 0.6667\n",
      "val Loss: 0.9403 Acc: 0.6667\n",
      "test Loss: 0.9522 Acc: 0.6667\n",
      "Epoch 76/499\n",
      "----------\n",
      "train Loss: 0.9433 Acc: 0.6667\n",
      "val Loss: 0.9306 Acc: 0.6667\n",
      "test Loss: 0.9388 Acc: 0.6667\n",
      "Epoch 77/499\n",
      "----------\n",
      "train Loss: 0.9431 Acc: 0.6667\n",
      "val Loss: 0.9318 Acc: 0.6667\n",
      "test Loss: 0.9314 Acc: 0.6667\n",
      "Epoch 78/499\n",
      "----------\n",
      "train Loss: 0.9359 Acc: 0.6667\n",
      "val Loss: 0.9430 Acc: 0.7000\n",
      "test Loss: 0.9329 Acc: 0.6667\n",
      "Epoch 79/499\n",
      "----------\n",
      "train Loss: 0.9395 Acc: 0.6667\n",
      "val Loss: 0.9302 Acc: 0.6667\n",
      "test Loss: 0.9280 Acc: 0.6667\n",
      "Epoch 80/499\n",
      "----------\n",
      "train Loss: 0.9315 Acc: 0.6667\n",
      "val Loss: 0.9352 Acc: 0.7000\n",
      "test Loss: 0.9275 Acc: 0.6667\n",
      "Epoch 81/499\n",
      "----------\n",
      "train Loss: 0.9293 Acc: 0.6667\n",
      "val Loss: 0.9324 Acc: 0.6667\n",
      "test Loss: 0.9252 Acc: 0.6667\n",
      "Epoch 82/499\n",
      "----------\n",
      "train Loss: 0.9294 Acc: 0.6667\n",
      "val Loss: 0.9232 Acc: 0.6667\n",
      "test Loss: 0.9283 Acc: 0.6667\n",
      "Epoch 83/499\n",
      "----------\n",
      "train Loss: 0.9348 Acc: 0.6667\n",
      "val Loss: 0.9120 Acc: 0.6667\n",
      "test Loss: 0.9274 Acc: 0.6667\n",
      "Epoch 84/499\n",
      "----------\n",
      "train Loss: 0.9223 Acc: 0.6667\n",
      "val Loss: 0.9148 Acc: 0.6667\n",
      "test Loss: 0.9232 Acc: 0.6667\n",
      "Epoch 85/499\n",
      "----------\n",
      "train Loss: 0.9171 Acc: 0.6667\n",
      "val Loss: 0.9270 Acc: 0.6667\n",
      "test Loss: 0.9208 Acc: 0.6667\n",
      "Epoch 86/499\n",
      "----------\n",
      "train Loss: 0.9168 Acc: 0.6667\n",
      "val Loss: 0.9186 Acc: 0.6667\n",
      "test Loss: 0.9154 Acc: 0.6667\n",
      "Epoch 87/499\n",
      "----------\n",
      "train Loss: 0.9194 Acc: 0.6778\n",
      "val Loss: 0.9115 Acc: 0.6667\n",
      "test Loss: 0.9108 Acc: 0.6667\n",
      "Epoch 88/499\n",
      "----------\n",
      "train Loss: 0.9234 Acc: 0.6778\n",
      "val Loss: 0.9115 Acc: 0.6667\n",
      "test Loss: 0.9194 Acc: 0.6667\n",
      "Epoch 89/499\n",
      "----------\n",
      "train Loss: 0.9137 Acc: 0.6667\n",
      "val Loss: 0.9136 Acc: 0.7000\n",
      "test Loss: 0.9191 Acc: 0.6667\n",
      "Epoch 90/499\n",
      "----------\n",
      "train Loss: 0.9164 Acc: 0.6667\n",
      "val Loss: 0.8981 Acc: 0.6667\n",
      "test Loss: 0.9096 Acc: 0.6667\n",
      "Epoch 91/499\n",
      "----------\n",
      "train Loss: 0.9109 Acc: 0.6667\n",
      "val Loss: 0.9126 Acc: 0.6667\n",
      "test Loss: 0.9005 Acc: 0.6667\n",
      "Epoch 92/499\n",
      "----------\n",
      "train Loss: 0.9162 Acc: 0.6778\n",
      "val Loss: 0.9033 Acc: 0.6667\n",
      "test Loss: 0.9039 Acc: 0.6667\n",
      "Epoch 93/499\n",
      "----------\n",
      "train Loss: 0.9083 Acc: 0.6667\n",
      "val Loss: 0.9091 Acc: 0.6667\n",
      "test Loss: 0.9029 Acc: 0.6667\n",
      "Epoch 94/499\n",
      "----------\n",
      "train Loss: 0.9157 Acc: 0.6778\n",
      "val Loss: 0.9127 Acc: 0.6667\n",
      "test Loss: 0.8959 Acc: 0.6667\n",
      "Epoch 95/499\n",
      "----------\n",
      "train Loss: 0.9080 Acc: 0.6778\n",
      "val Loss: 0.8980 Acc: 0.6667\n",
      "test Loss: 0.8989 Acc: 0.6667\n",
      "Epoch 96/499\n",
      "----------\n",
      "train Loss: 0.9013 Acc: 0.6667\n",
      "val Loss: 0.9021 Acc: 0.6667\n",
      "test Loss: 0.8988 Acc: 0.6667\n",
      "Epoch 97/499\n",
      "----------\n",
      "train Loss: 0.8999 Acc: 0.6778\n",
      "val Loss: 0.8932 Acc: 0.6667\n",
      "test Loss: 0.8970 Acc: 0.6667\n",
      "Epoch 98/499\n",
      "----------\n",
      "train Loss: 0.9041 Acc: 0.6667\n",
      "val Loss: 0.8948 Acc: 0.7000\n",
      "test Loss: 0.8896 Acc: 0.6667\n",
      "Epoch 99/499\n",
      "----------\n",
      "train Loss: 0.8960 Acc: 0.6778\n",
      "val Loss: 0.8968 Acc: 0.6667\n",
      "test Loss: 0.8953 Acc: 0.6667\n",
      "Epoch 100/499\n",
      "----------\n",
      "train Loss: 0.8922 Acc: 0.6778\n",
      "val Loss: 0.8886 Acc: 0.6667\n",
      "test Loss: 0.8985 Acc: 0.6667\n",
      "Epoch 101/499\n",
      "----------\n",
      "train Loss: 0.8931 Acc: 0.6667\n",
      "val Loss: 0.8930 Acc: 0.6667\n",
      "test Loss: 0.8943 Acc: 0.6667\n",
      "Epoch 102/499\n",
      "----------\n",
      "train Loss: 0.8914 Acc: 0.6889\n",
      "val Loss: 0.8904 Acc: 0.6667\n",
      "test Loss: 0.8925 Acc: 0.6667\n",
      "Epoch 103/499\n",
      "----------\n",
      "train Loss: 0.8917 Acc: 0.6889\n",
      "val Loss: 0.8750 Acc: 0.6667\n",
      "test Loss: 0.8876 Acc: 0.6667\n",
      "Epoch 104/499\n",
      "----------\n",
      "train Loss: 0.8958 Acc: 0.6667\n",
      "val Loss: 0.8820 Acc: 0.6667\n",
      "test Loss: 0.8941 Acc: 0.6667\n",
      "Epoch 105/499\n",
      "----------\n",
      "train Loss: 0.8949 Acc: 0.6778\n",
      "val Loss: 0.8866 Acc: 0.6667\n",
      "test Loss: 0.8778 Acc: 0.6667\n",
      "Epoch 106/499\n",
      "----------\n",
      "train Loss: 0.8874 Acc: 0.6889\n",
      "val Loss: 0.8773 Acc: 0.6667\n",
      "test Loss: 0.8815 Acc: 0.6667\n",
      "Epoch 107/499\n",
      "----------\n",
      "train Loss: 0.8833 Acc: 0.7000\n",
      "val Loss: 0.8717 Acc: 0.6667\n",
      "test Loss: 0.8771 Acc: 0.6667\n",
      "Epoch 108/499\n",
      "----------\n",
      "train Loss: 0.8779 Acc: 0.6778\n",
      "val Loss: 0.8838 Acc: 0.6667\n",
      "test Loss: 0.8855 Acc: 0.6667\n",
      "Epoch 109/499\n",
      "----------\n",
      "train Loss: 0.8768 Acc: 0.6778\n",
      "val Loss: 0.8719 Acc: 0.6667\n",
      "test Loss: 0.8789 Acc: 0.7000\n",
      "Epoch 110/499\n",
      "----------\n",
      "train Loss: 0.8798 Acc: 0.6778\n",
      "val Loss: 0.8747 Acc: 0.6667\n",
      "test Loss: 0.8889 Acc: 0.7000\n",
      "Epoch 111/499\n",
      "----------\n",
      "train Loss: 0.8775 Acc: 0.6889\n",
      "val Loss: 0.8673 Acc: 0.6667\n",
      "test Loss: 0.8877 Acc: 0.7000\n",
      "Epoch 112/499\n",
      "----------\n",
      "train Loss: 0.8728 Acc: 0.6889\n",
      "val Loss: 0.8696 Acc: 0.6667\n",
      "test Loss: 0.8863 Acc: 0.7000\n",
      "Epoch 113/499\n",
      "----------\n",
      "train Loss: 0.8787 Acc: 0.6889\n",
      "val Loss: 0.8581 Acc: 0.6667\n",
      "test Loss: 0.8768 Acc: 0.7000\n",
      "Epoch 114/499\n",
      "----------\n",
      "train Loss: 0.8659 Acc: 0.6778\n",
      "val Loss: 0.8714 Acc: 0.7000\n",
      "test Loss: 0.8801 Acc: 0.6667\n",
      "Epoch 115/499\n",
      "----------\n",
      "train Loss: 0.8688 Acc: 0.7000\n",
      "val Loss: 0.8635 Acc: 0.7000\n",
      "test Loss: 0.8758 Acc: 0.7333\n",
      "Epoch 116/499\n",
      "----------\n",
      "train Loss: 0.8638 Acc: 0.7000\n",
      "val Loss: 0.8641 Acc: 0.6667\n",
      "test Loss: 0.8653 Acc: 0.7333\n",
      "Epoch 117/499\n",
      "----------\n",
      "train Loss: 0.8719 Acc: 0.6778\n",
      "val Loss: 0.8608 Acc: 0.7000\n",
      "test Loss: 0.8716 Acc: 0.6667\n",
      "Epoch 118/499\n",
      "----------\n",
      "train Loss: 0.8619 Acc: 0.7111\n",
      "val Loss: 0.8563 Acc: 0.6667\n",
      "test Loss: 0.8646 Acc: 0.7000\n",
      "Epoch 119/499\n",
      "----------\n",
      "train Loss: 0.8714 Acc: 0.7000\n",
      "val Loss: 0.8599 Acc: 0.6667\n",
      "test Loss: 0.8624 Acc: 0.7000\n",
      "Epoch 120/499\n",
      "----------\n",
      "train Loss: 0.8692 Acc: 0.7000\n",
      "val Loss: 0.8562 Acc: 0.7000\n",
      "test Loss: 0.8711 Acc: 0.7333\n",
      "Epoch 121/499\n",
      "----------\n",
      "train Loss: 0.8632 Acc: 0.6778\n",
      "val Loss: 0.8608 Acc: 0.7000\n",
      "test Loss: 0.8656 Acc: 0.7333\n",
      "Epoch 122/499\n",
      "----------\n",
      "train Loss: 0.8631 Acc: 0.6889\n",
      "val Loss: 0.8479 Acc: 0.6667\n",
      "test Loss: 0.8673 Acc: 0.7667\n",
      "Epoch 123/499\n",
      "----------\n",
      "train Loss: 0.8564 Acc: 0.6778\n",
      "val Loss: 0.8666 Acc: 0.7000\n",
      "test Loss: 0.8577 Acc: 0.7000\n",
      "Epoch 124/499\n",
      "----------\n",
      "train Loss: 0.8660 Acc: 0.6778\n",
      "val Loss: 0.8531 Acc: 0.7000\n",
      "test Loss: 0.8514 Acc: 0.7333\n",
      "Epoch 125/499\n",
      "----------\n",
      "train Loss: 0.8562 Acc: 0.7222\n",
      "val Loss: 0.8471 Acc: 0.7333\n",
      "test Loss: 0.8434 Acc: 0.7333\n",
      "Epoch 126/499\n",
      "----------\n",
      "train Loss: 0.8580 Acc: 0.7000\n",
      "val Loss: 0.8478 Acc: 0.7000\n",
      "test Loss: 0.8558 Acc: 0.7333\n",
      "Epoch 127/499\n",
      "----------\n",
      "train Loss: 0.8540 Acc: 0.7000\n",
      "val Loss: 0.8584 Acc: 0.6667\n",
      "test Loss: 0.8552 Acc: 0.7333\n",
      "Epoch 128/499\n",
      "----------\n",
      "train Loss: 0.8553 Acc: 0.6778\n",
      "val Loss: 0.8418 Acc: 0.7000\n",
      "test Loss: 0.8462 Acc: 0.7333\n",
      "Epoch 129/499\n",
      "----------\n",
      "train Loss: 0.8495 Acc: 0.7333\n",
      "val Loss: 0.8468 Acc: 0.7000\n",
      "test Loss: 0.8542 Acc: 0.7333\n",
      "Epoch 130/499\n",
      "----------\n",
      "train Loss: 0.8483 Acc: 0.7000\n",
      "val Loss: 0.8404 Acc: 0.7000\n",
      "test Loss: 0.8492 Acc: 0.7333\n",
      "Epoch 131/499\n",
      "----------\n",
      "train Loss: 0.8517 Acc: 0.7111\n",
      "val Loss: 0.8407 Acc: 0.7000\n",
      "test Loss: 0.8521 Acc: 0.7000\n",
      "Epoch 132/499\n",
      "----------\n",
      "train Loss: 0.8473 Acc: 0.7222\n",
      "val Loss: 0.8471 Acc: 0.7333\n",
      "test Loss: 0.8457 Acc: 0.7333\n",
      "Epoch 133/499\n",
      "----------\n",
      "train Loss: 0.8481 Acc: 0.7444\n",
      "val Loss: 0.8342 Acc: 0.7000\n",
      "test Loss: 0.8477 Acc: 0.7667\n",
      "Epoch 134/499\n",
      "----------\n",
      "train Loss: 0.8441 Acc: 0.6889\n",
      "val Loss: 0.8198 Acc: 0.7333\n",
      "test Loss: 0.8518 Acc: 0.7667\n",
      "Epoch 135/499\n",
      "----------\n",
      "train Loss: 0.8476 Acc: 0.7444\n",
      "val Loss: 0.8339 Acc: 0.7000\n",
      "test Loss: 0.8413 Acc: 0.7667\n",
      "Epoch 136/499\n",
      "----------\n",
      "train Loss: 0.8466 Acc: 0.7222\n",
      "val Loss: 0.8244 Acc: 0.7667\n",
      "test Loss: 0.8447 Acc: 0.7333\n",
      "Epoch 137/499\n",
      "----------\n",
      "train Loss: 0.8446 Acc: 0.7222\n",
      "val Loss: 0.8379 Acc: 0.7000\n",
      "test Loss: 0.8362 Acc: 0.7667\n",
      "Epoch 138/499\n",
      "----------\n",
      "train Loss: 0.8362 Acc: 0.7333\n",
      "val Loss: 0.8199 Acc: 0.7000\n",
      "test Loss: 0.8334 Acc: 0.8000\n",
      "Epoch 139/499\n",
      "----------\n",
      "train Loss: 0.8393 Acc: 0.7444\n",
      "val Loss: 0.8337 Acc: 0.7000\n",
      "test Loss: 0.8425 Acc: 0.7333\n",
      "Epoch 140/499\n",
      "----------\n",
      "train Loss: 0.8393 Acc: 0.7444\n",
      "val Loss: 0.8212 Acc: 0.7333\n",
      "test Loss: 0.8458 Acc: 0.7667\n",
      "Epoch 141/499\n",
      "----------\n",
      "train Loss: 0.8291 Acc: 0.7667\n",
      "val Loss: 0.8269 Acc: 0.7333\n",
      "test Loss: 0.8434 Acc: 0.7667\n",
      "Epoch 142/499\n",
      "----------\n",
      "train Loss: 0.8369 Acc: 0.7111\n",
      "val Loss: 0.8230 Acc: 0.7333\n",
      "test Loss: 0.8335 Acc: 0.7333\n",
      "Epoch 143/499\n",
      "----------\n",
      "train Loss: 0.8269 Acc: 0.7556\n",
      "val Loss: 0.8250 Acc: 0.7667\n",
      "test Loss: 0.8436 Acc: 0.8000\n",
      "Epoch 144/499\n",
      "----------\n",
      "train Loss: 0.8278 Acc: 0.7222\n",
      "val Loss: 0.8233 Acc: 0.7667\n",
      "test Loss: 0.8298 Acc: 0.7667\n",
      "Epoch 145/499\n",
      "----------\n",
      "train Loss: 0.8232 Acc: 0.7333\n",
      "val Loss: 0.8158 Acc: 0.7333\n",
      "test Loss: 0.8499 Acc: 0.7000\n",
      "Epoch 146/499\n",
      "----------\n",
      "train Loss: 0.8243 Acc: 0.7667\n",
      "val Loss: 0.8168 Acc: 0.7667\n",
      "test Loss: 0.8404 Acc: 0.7333\n",
      "Epoch 147/499\n",
      "----------\n",
      "train Loss: 0.8348 Acc: 0.7222\n",
      "val Loss: 0.8223 Acc: 0.7667\n",
      "test Loss: 0.8292 Acc: 0.7667\n",
      "Epoch 148/499\n",
      "----------\n",
      "train Loss: 0.8195 Acc: 0.7444\n",
      "val Loss: 0.8034 Acc: 0.7333\n",
      "test Loss: 0.8290 Acc: 0.8000\n",
      "Epoch 149/499\n",
      "----------\n",
      "train Loss: 0.8192 Acc: 0.7333\n",
      "val Loss: 0.8031 Acc: 0.7667\n",
      "test Loss: 0.8271 Acc: 0.7667\n",
      "Epoch 150/499\n",
      "----------\n",
      "train Loss: 0.8187 Acc: 0.7444\n",
      "val Loss: 0.8024 Acc: 0.7333\n",
      "test Loss: 0.8258 Acc: 0.7667\n",
      "Epoch 151/499\n",
      "----------\n",
      "train Loss: 0.8144 Acc: 0.7556\n",
      "val Loss: 0.8023 Acc: 0.7667\n",
      "test Loss: 0.8285 Acc: 0.7333\n",
      "Epoch 152/499\n",
      "----------\n",
      "train Loss: 0.8142 Acc: 0.7778\n",
      "val Loss: 0.8233 Acc: 0.7333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.8322 Acc: 0.7333\n",
      "Epoch 153/499\n",
      "----------\n",
      "train Loss: 0.8197 Acc: 0.7333\n",
      "val Loss: 0.7990 Acc: 0.8333\n",
      "test Loss: 0.8442 Acc: 0.7667\n",
      "Epoch 154/499\n",
      "----------\n",
      "train Loss: 0.8139 Acc: 0.7444\n",
      "val Loss: 0.8046 Acc: 0.8333\n",
      "test Loss: 0.8140 Acc: 0.7667\n",
      "Epoch 155/499\n",
      "----------\n",
      "train Loss: 0.8090 Acc: 0.7444\n",
      "val Loss: 0.7931 Acc: 0.8333\n",
      "test Loss: 0.8252 Acc: 0.7667\n",
      "Epoch 156/499\n",
      "----------\n",
      "train Loss: 0.8147 Acc: 0.7222\n",
      "val Loss: 0.8185 Acc: 0.7667\n",
      "test Loss: 0.8114 Acc: 0.7667\n",
      "Epoch 157/499\n",
      "----------\n",
      "train Loss: 0.8104 Acc: 0.7333\n",
      "val Loss: 0.7949 Acc: 0.8667\n",
      "test Loss: 0.8181 Acc: 0.7667\n",
      "Epoch 158/499\n",
      "----------\n",
      "train Loss: 0.8046 Acc: 0.7667\n",
      "val Loss: 0.7901 Acc: 0.8000\n",
      "test Loss: 0.8180 Acc: 0.7667\n",
      "Epoch 159/499\n",
      "----------\n",
      "train Loss: 0.8005 Acc: 0.7778\n",
      "val Loss: 0.7925 Acc: 0.8000\n",
      "test Loss: 0.8235 Acc: 0.7667\n",
      "Epoch 160/499\n",
      "----------\n",
      "train Loss: 0.8131 Acc: 0.7444\n",
      "val Loss: 0.7921 Acc: 0.8333\n",
      "test Loss: 0.8273 Acc: 0.8000\n",
      "Epoch 161/499\n",
      "----------\n",
      "train Loss: 0.8044 Acc: 0.7778\n",
      "val Loss: 0.7816 Acc: 0.8667\n",
      "test Loss: 0.8157 Acc: 0.7667\n",
      "Epoch 162/499\n",
      "----------\n",
      "train Loss: 0.8050 Acc: 0.7667\n",
      "val Loss: 0.8010 Acc: 0.8000\n",
      "test Loss: 0.8158 Acc: 0.7333\n",
      "Epoch 163/499\n",
      "----------\n",
      "train Loss: 0.8059 Acc: 0.7556\n",
      "val Loss: 0.7976 Acc: 0.7667\n",
      "test Loss: 0.8131 Acc: 0.7333\n",
      "Epoch 164/499\n",
      "----------\n",
      "train Loss: 0.8006 Acc: 0.7667\n",
      "val Loss: 0.7911 Acc: 0.8667\n",
      "test Loss: 0.8044 Acc: 0.7667\n",
      "Epoch 165/499\n",
      "----------\n",
      "train Loss: 0.7928 Acc: 0.7889\n",
      "val Loss: 0.7742 Acc: 0.8333\n",
      "test Loss: 0.8174 Acc: 0.7333\n",
      "Epoch 166/499\n",
      "----------\n",
      "train Loss: 0.8016 Acc: 0.8000\n",
      "val Loss: 0.7846 Acc: 0.8333\n",
      "test Loss: 0.8095 Acc: 0.7667\n",
      "Epoch 167/499\n",
      "----------\n",
      "train Loss: 0.7987 Acc: 0.8333\n",
      "val Loss: 0.7833 Acc: 0.9000\n",
      "test Loss: 0.8076 Acc: 0.7667\n",
      "Epoch 168/499\n",
      "----------\n",
      "train Loss: 0.8003 Acc: 0.7778\n",
      "val Loss: 0.7789 Acc: 0.8333\n",
      "test Loss: 0.8028 Acc: 0.7667\n",
      "Epoch 169/499\n",
      "----------\n",
      "train Loss: 0.7898 Acc: 0.8111\n",
      "val Loss: 0.7818 Acc: 0.8333\n",
      "test Loss: 0.8180 Acc: 0.7667\n",
      "Epoch 170/499\n",
      "----------\n",
      "train Loss: 0.7923 Acc: 0.7889\n",
      "val Loss: 0.8192 Acc: 0.7667\n",
      "test Loss: 0.7943 Acc: 0.7667\n",
      "Epoch 171/499\n",
      "----------\n",
      "train Loss: 0.7958 Acc: 0.8000\n",
      "val Loss: 0.7744 Acc: 0.8667\n",
      "test Loss: 0.8042 Acc: 0.8667\n",
      "Epoch 172/499\n",
      "----------\n",
      "train Loss: 0.7958 Acc: 0.8000\n",
      "val Loss: 0.7859 Acc: 0.8333\n",
      "test Loss: 0.8211 Acc: 0.8000\n",
      "Epoch 173/499\n",
      "----------\n",
      "train Loss: 0.7956 Acc: 0.7889\n",
      "val Loss: 0.7675 Acc: 0.8333\n",
      "test Loss: 0.7915 Acc: 0.7667\n",
      "Epoch 174/499\n",
      "----------\n",
      "train Loss: 0.7899 Acc: 0.7889\n",
      "val Loss: 0.7750 Acc: 0.8333\n",
      "test Loss: 0.7952 Acc: 0.8333\n",
      "Epoch 175/499\n",
      "----------\n",
      "train Loss: 0.7866 Acc: 0.8222\n",
      "val Loss: 0.7747 Acc: 0.8000\n",
      "test Loss: 0.8162 Acc: 0.7667\n",
      "Epoch 176/499\n",
      "----------\n",
      "train Loss: 0.7858 Acc: 0.8222\n",
      "val Loss: 0.7850 Acc: 0.8667\n",
      "test Loss: 0.8042 Acc: 0.8333\n",
      "Epoch 177/499\n",
      "----------\n",
      "train Loss: 0.7811 Acc: 0.8667\n",
      "val Loss: 0.7752 Acc: 0.8667\n",
      "test Loss: 0.7892 Acc: 0.8333\n",
      "Epoch 178/499\n",
      "----------\n",
      "train Loss: 0.7834 Acc: 0.8111\n",
      "val Loss: 0.7692 Acc: 0.8000\n",
      "test Loss: 0.7993 Acc: 0.8333\n",
      "Epoch 179/499\n",
      "----------\n",
      "train Loss: 0.7841 Acc: 0.8333\n",
      "val Loss: 0.7658 Acc: 0.8333\n",
      "test Loss: 0.7882 Acc: 0.8333\n",
      "Epoch 180/499\n",
      "----------\n",
      "train Loss: 0.7887 Acc: 0.8111\n",
      "val Loss: 0.7595 Acc: 0.8667\n",
      "test Loss: 0.7941 Acc: 0.8333\n",
      "Epoch 181/499\n",
      "----------\n",
      "train Loss: 0.7821 Acc: 0.8222\n",
      "val Loss: 0.7575 Acc: 0.8667\n",
      "test Loss: 0.7894 Acc: 0.8333\n",
      "Epoch 182/499\n",
      "----------\n",
      "train Loss: 0.7934 Acc: 0.8333\n",
      "val Loss: 0.7523 Acc: 0.8667\n",
      "test Loss: 0.7876 Acc: 0.8333\n",
      "Epoch 183/499\n",
      "----------\n",
      "train Loss: 0.7755 Acc: 0.8111\n",
      "val Loss: 0.7552 Acc: 0.8667\n",
      "test Loss: 0.8028 Acc: 0.7667\n",
      "Epoch 184/499\n",
      "----------\n",
      "train Loss: 0.7798 Acc: 0.8333\n",
      "val Loss: 0.7653 Acc: 0.8333\n",
      "test Loss: 0.7903 Acc: 0.8333\n",
      "Epoch 185/499\n",
      "----------\n",
      "train Loss: 0.7770 Acc: 0.8556\n",
      "val Loss: 0.7557 Acc: 0.8667\n",
      "test Loss: 0.7856 Acc: 0.8333\n",
      "Epoch 186/499\n",
      "----------\n",
      "train Loss: 0.7790 Acc: 0.8333\n",
      "val Loss: 0.7449 Acc: 0.8667\n",
      "test Loss: 0.7948 Acc: 0.7667\n",
      "Epoch 187/499\n",
      "----------\n",
      "train Loss: 0.7714 Acc: 0.8556\n",
      "val Loss: 0.7495 Acc: 0.8667\n",
      "test Loss: 0.7899 Acc: 0.8333\n",
      "Epoch 188/499\n",
      "----------\n",
      "train Loss: 0.7752 Acc: 0.8222\n",
      "val Loss: 0.7835 Acc: 0.8000\n",
      "test Loss: 0.7710 Acc: 0.9000\n",
      "Epoch 189/499\n",
      "----------\n",
      "train Loss: 0.7806 Acc: 0.8111\n",
      "val Loss: 0.7520 Acc: 0.8333\n",
      "test Loss: 0.7760 Acc: 0.8000\n",
      "Epoch 190/499\n",
      "----------\n",
      "train Loss: 0.7691 Acc: 0.8778\n",
      "val Loss: 0.7486 Acc: 0.8667\n",
      "test Loss: 0.7766 Acc: 0.8000\n",
      "Epoch 191/499\n",
      "----------\n",
      "train Loss: 0.7666 Acc: 0.8556\n",
      "val Loss: 0.7555 Acc: 0.8667\n",
      "test Loss: 0.7858 Acc: 0.8000\n",
      "Epoch 192/499\n",
      "----------\n",
      "train Loss: 0.7678 Acc: 0.8111\n",
      "val Loss: 0.7476 Acc: 0.8667\n",
      "test Loss: 0.7876 Acc: 0.8667\n",
      "Epoch 193/499\n",
      "----------\n",
      "train Loss: 0.7709 Acc: 0.8556\n",
      "val Loss: 0.7414 Acc: 0.9000\n",
      "test Loss: 0.7931 Acc: 0.7667\n",
      "Epoch 194/499\n",
      "----------\n",
      "train Loss: 0.7581 Acc: 0.8667\n",
      "val Loss: 0.7589 Acc: 0.7667\n",
      "test Loss: 0.7745 Acc: 0.8000\n",
      "Epoch 195/499\n",
      "----------\n",
      "train Loss: 0.7706 Acc: 0.8556\n",
      "val Loss: 0.7465 Acc: 0.9333\n",
      "test Loss: 0.7725 Acc: 0.8000\n",
      "Epoch 196/499\n",
      "----------\n",
      "train Loss: 0.7615 Acc: 0.8333\n",
      "val Loss: 0.7443 Acc: 0.8333\n",
      "test Loss: 0.7740 Acc: 0.8333\n",
      "Epoch 197/499\n",
      "----------\n",
      "train Loss: 0.7651 Acc: 0.8333\n",
      "val Loss: 0.7427 Acc: 0.8667\n",
      "test Loss: 0.7781 Acc: 0.8000\n",
      "Epoch 198/499\n",
      "----------\n",
      "train Loss: 0.7672 Acc: 0.8444\n",
      "val Loss: 0.7503 Acc: 0.9000\n",
      "test Loss: 0.7680 Acc: 0.8333\n",
      "Epoch 199/499\n",
      "----------\n",
      "train Loss: 0.7586 Acc: 0.8667\n",
      "val Loss: 0.7360 Acc: 0.8333\n",
      "test Loss: 0.7777 Acc: 0.7667\n",
      "Epoch 200/499\n",
      "----------\n",
      "train Loss: 0.7584 Acc: 0.8667\n",
      "val Loss: 0.7341 Acc: 0.9333\n",
      "test Loss: 0.7791 Acc: 0.8000\n",
      "Epoch 201/499\n",
      "----------\n",
      "train Loss: 0.7517 Acc: 0.8778\n",
      "val Loss: 0.7257 Acc: 0.8667\n",
      "test Loss: 0.7750 Acc: 0.8000\n",
      "Epoch 202/499\n",
      "----------\n",
      "train Loss: 0.7624 Acc: 0.8667\n",
      "val Loss: 0.7397 Acc: 0.8333\n",
      "test Loss: 0.7791 Acc: 0.8000\n",
      "Epoch 203/499\n",
      "----------\n",
      "train Loss: 0.7917 Acc: 0.8111\n",
      "val Loss: 0.7465 Acc: 0.9000\n",
      "test Loss: 0.7735 Acc: 0.7667\n",
      "Epoch 204/499\n",
      "----------\n",
      "train Loss: 0.7525 Acc: 0.8778\n",
      "val Loss: 0.7313 Acc: 0.9000\n",
      "test Loss: 0.7803 Acc: 0.7667\n",
      "Epoch 205/499\n",
      "----------\n",
      "train Loss: 0.7458 Acc: 0.8889\n",
      "val Loss: 0.7288 Acc: 0.9000\n",
      "test Loss: 0.7696 Acc: 0.8333\n",
      "Epoch 206/499\n",
      "----------\n",
      "train Loss: 0.7571 Acc: 0.8778\n",
      "val Loss: 0.7186 Acc: 0.8333\n",
      "test Loss: 0.7695 Acc: 0.8000\n",
      "Epoch 207/499\n",
      "----------\n",
      "train Loss: 0.7463 Acc: 0.9111\n",
      "val Loss: 0.7287 Acc: 0.9000\n",
      "test Loss: 0.7496 Acc: 0.9000\n",
      "Epoch 208/499\n",
      "----------\n",
      "train Loss: 0.7556 Acc: 0.9000\n",
      "val Loss: 0.7129 Acc: 0.9000\n",
      "test Loss: 0.7848 Acc: 0.7667\n",
      "Epoch 209/499\n",
      "----------\n",
      "train Loss: 0.7508 Acc: 0.8667\n",
      "val Loss: 0.7218 Acc: 0.9000\n",
      "test Loss: 0.7634 Acc: 0.8333\n",
      "Epoch 210/499\n",
      "----------\n",
      "train Loss: 0.7465 Acc: 0.8778\n",
      "val Loss: 0.7354 Acc: 0.9000\n",
      "test Loss: 0.7709 Acc: 0.8000\n",
      "Epoch 211/499\n",
      "----------\n",
      "train Loss: 0.7499 Acc: 0.8889\n",
      "val Loss: 0.7311 Acc: 0.8667\n",
      "test Loss: 0.7769 Acc: 0.9000\n",
      "Epoch 212/499\n",
      "----------\n",
      "train Loss: 0.7535 Acc: 0.8778\n",
      "val Loss: 0.7293 Acc: 0.9667\n",
      "test Loss: 0.7576 Acc: 0.8667\n",
      "Epoch 213/499\n",
      "----------\n",
      "train Loss: 0.7505 Acc: 0.9000\n",
      "val Loss: 0.7256 Acc: 0.9333\n",
      "test Loss: 0.7974 Acc: 0.7667\n",
      "Epoch 214/499\n",
      "----------\n",
      "train Loss: 0.7464 Acc: 0.8778\n",
      "val Loss: 0.7202 Acc: 0.9333\n",
      "test Loss: 0.7674 Acc: 0.8000\n",
      "Epoch 215/499\n",
      "----------\n",
      "train Loss: 0.7468 Acc: 0.8778\n",
      "val Loss: 0.7357 Acc: 0.8667\n",
      "test Loss: 0.7502 Acc: 0.8333\n",
      "Epoch 216/499\n",
      "----------\n",
      "train Loss: 0.7420 Acc: 0.8889\n",
      "val Loss: 0.7092 Acc: 0.9333\n",
      "test Loss: 0.7643 Acc: 0.8333\n",
      "Epoch 217/499\n",
      "----------\n",
      "train Loss: 0.7445 Acc: 0.9222\n",
      "val Loss: 0.7295 Acc: 0.9333\n",
      "test Loss: 0.7635 Acc: 0.8333\n",
      "Epoch 218/499\n",
      "----------\n",
      "train Loss: 0.7482 Acc: 0.8889\n",
      "val Loss: 0.7147 Acc: 0.9667\n",
      "test Loss: 0.7516 Acc: 0.8000\n",
      "Epoch 219/499\n",
      "----------\n",
      "train Loss: 0.7435 Acc: 0.8667\n",
      "val Loss: 0.7054 Acc: 0.9667\n",
      "test Loss: 0.7787 Acc: 0.8000\n",
      "Epoch 220/499\n",
      "----------\n",
      "train Loss: 0.7361 Acc: 0.9222\n",
      "val Loss: 0.7078 Acc: 0.9667\n",
      "test Loss: 0.7605 Acc: 0.8000\n",
      "Epoch 221/499\n",
      "----------\n",
      "train Loss: 0.7507 Acc: 0.9000\n",
      "val Loss: 0.7135 Acc: 0.9000\n",
      "test Loss: 0.7651 Acc: 0.8000\n",
      "Epoch 222/499\n",
      "----------\n",
      "train Loss: 0.7393 Acc: 0.8889\n",
      "val Loss: 0.7072 Acc: 0.9333\n",
      "test Loss: 0.7617 Acc: 0.8667\n",
      "Epoch 223/499\n",
      "----------\n",
      "train Loss: 0.7349 Acc: 0.8778\n",
      "val Loss: 0.7150 Acc: 0.9000\n",
      "test Loss: 0.7717 Acc: 0.7667\n",
      "Epoch 224/499\n",
      "----------\n",
      "train Loss: 0.7389 Acc: 0.9000\n",
      "val Loss: 0.7092 Acc: 0.9333\n",
      "test Loss: 0.7718 Acc: 0.7667\n",
      "Epoch 225/499\n",
      "----------\n",
      "train Loss: 0.7310 Acc: 0.9111\n",
      "val Loss: 0.7175 Acc: 0.9333\n",
      "test Loss: 0.7710 Acc: 0.7333\n",
      "Epoch 226/499\n",
      "----------\n",
      "train Loss: 0.7286 Acc: 0.9111\n",
      "val Loss: 0.7036 Acc: 0.9000\n",
      "test Loss: 0.7492 Acc: 0.8333\n",
      "Epoch 227/499\n",
      "----------\n",
      "train Loss: 0.7334 Acc: 0.9111\n",
      "val Loss: 0.7104 Acc: 0.8667\n",
      "test Loss: 0.7352 Acc: 0.8667\n",
      "Epoch 228/499\n",
      "----------\n",
      "train Loss: 0.7292 Acc: 0.8667\n",
      "val Loss: 0.7272 Acc: 0.9000\n",
      "test Loss: 0.7427 Acc: 0.8333\n",
      "Epoch 229/499\n",
      "----------\n",
      "train Loss: 0.7261 Acc: 0.9000\n",
      "val Loss: 0.7359 Acc: 0.9333\n",
      "test Loss: 0.7576 Acc: 0.8000\n",
      "Epoch 230/499\n",
      "----------\n",
      "train Loss: 0.7346 Acc: 0.9111\n",
      "val Loss: 0.7203 Acc: 0.9667\n",
      "test Loss: 0.7644 Acc: 0.8000\n",
      "Epoch 231/499\n",
      "----------\n",
      "train Loss: 0.7286 Acc: 0.8778\n",
      "val Loss: 0.7206 Acc: 0.9000\n",
      "test Loss: 0.7508 Acc: 0.8333\n",
      "Epoch 232/499\n",
      "----------\n",
      "train Loss: 0.7359 Acc: 0.9222\n",
      "val Loss: 0.7019 Acc: 0.9333\n",
      "test Loss: 0.7450 Acc: 0.8667\n",
      "Epoch 233/499\n",
      "----------\n",
      "train Loss: 0.7405 Acc: 0.8889\n",
      "val Loss: 0.7056 Acc: 0.9333\n",
      "test Loss: 0.7499 Acc: 0.8000\n",
      "Epoch 234/499\n",
      "----------\n",
      "train Loss: 0.7327 Acc: 0.9000\n",
      "val Loss: 0.6871 Acc: 0.9333\n",
      "test Loss: 0.7507 Acc: 0.8000\n",
      "Epoch 235/499\n",
      "----------\n",
      "train Loss: 0.7296 Acc: 0.8444\n",
      "val Loss: 0.6892 Acc: 0.9333\n",
      "test Loss: 0.7385 Acc: 0.9000\n",
      "Epoch 236/499\n",
      "----------\n",
      "train Loss: 0.7323 Acc: 0.9000\n",
      "val Loss: 0.6956 Acc: 0.9333\n",
      "test Loss: 0.7396 Acc: 0.8333\n",
      "Epoch 237/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.7352 Acc: 0.8778\n",
      "val Loss: 0.7031 Acc: 0.9000\n",
      "test Loss: 0.7400 Acc: 0.9000\n",
      "Epoch 238/499\n",
      "----------\n",
      "train Loss: 0.7303 Acc: 0.9000\n",
      "val Loss: 0.6973 Acc: 0.9000\n",
      "test Loss: 0.7497 Acc: 0.8667\n",
      "Epoch 239/499\n",
      "----------\n",
      "train Loss: 0.7212 Acc: 0.9111\n",
      "val Loss: 0.7057 Acc: 0.9000\n",
      "test Loss: 0.7590 Acc: 0.8667\n",
      "Epoch 240/499\n",
      "----------\n",
      "train Loss: 0.7270 Acc: 0.9000\n",
      "val Loss: 0.7083 Acc: 0.9333\n",
      "test Loss: 0.7457 Acc: 0.8333\n",
      "Epoch 241/499\n",
      "----------\n",
      "train Loss: 0.7281 Acc: 0.8556\n",
      "val Loss: 0.6963 Acc: 0.9000\n",
      "test Loss: 0.7625 Acc: 0.8000\n",
      "Epoch 242/499\n",
      "----------\n",
      "train Loss: 0.7184 Acc: 0.9000\n",
      "val Loss: 0.6947 Acc: 0.9333\n",
      "test Loss: 0.7301 Acc: 0.8667\n",
      "Epoch 243/499\n",
      "----------\n",
      "train Loss: 0.7189 Acc: 0.9111\n",
      "val Loss: 0.6974 Acc: 0.9333\n",
      "test Loss: 0.7290 Acc: 0.8667\n",
      "Epoch 244/499\n",
      "----------\n",
      "train Loss: 0.7159 Acc: 0.9111\n",
      "val Loss: 0.7112 Acc: 0.8667\n",
      "test Loss: 0.7373 Acc: 0.8333\n",
      "Epoch 245/499\n",
      "----------\n",
      "train Loss: 0.7278 Acc: 0.8889\n",
      "val Loss: 0.6863 Acc: 0.9000\n",
      "test Loss: 0.7602 Acc: 0.7667\n",
      "Epoch 246/499\n",
      "----------\n",
      "train Loss: 0.7233 Acc: 0.9333\n",
      "val Loss: 0.7056 Acc: 0.9333\n",
      "test Loss: 0.7283 Acc: 0.8667\n",
      "Epoch 247/499\n",
      "----------\n",
      "train Loss: 0.7196 Acc: 0.9222\n",
      "val Loss: 0.6886 Acc: 0.9333\n",
      "test Loss: 0.7492 Acc: 0.8333\n",
      "Epoch 248/499\n",
      "----------\n",
      "train Loss: 0.7175 Acc: 0.9111\n",
      "val Loss: 0.6909 Acc: 0.9333\n",
      "test Loss: 0.7358 Acc: 0.7667\n",
      "Epoch 249/499\n",
      "----------\n",
      "train Loss: 0.7090 Acc: 0.9333\n",
      "val Loss: 0.6886 Acc: 0.9000\n",
      "test Loss: 0.7348 Acc: 0.9667\n",
      "Epoch 250/499\n",
      "----------\n",
      "train Loss: 0.7123 Acc: 0.9444\n",
      "val Loss: 0.6986 Acc: 0.9000\n",
      "test Loss: 0.7411 Acc: 0.8000\n",
      "Epoch 251/499\n",
      "----------\n",
      "train Loss: 0.7105 Acc: 0.9222\n",
      "val Loss: 0.7012 Acc: 0.9333\n",
      "test Loss: 0.7360 Acc: 0.9000\n",
      "Epoch 252/499\n",
      "----------\n",
      "train Loss: 0.7211 Acc: 0.9222\n",
      "val Loss: 0.6870 Acc: 0.9333\n",
      "test Loss: 0.7515 Acc: 0.8667\n",
      "Epoch 253/499\n",
      "----------\n",
      "train Loss: 0.7212 Acc: 0.8889\n",
      "val Loss: 0.6836 Acc: 0.9333\n",
      "test Loss: 0.7666 Acc: 0.8000\n",
      "Epoch 254/499\n",
      "----------\n",
      "train Loss: 0.7117 Acc: 0.9222\n",
      "val Loss: 0.7077 Acc: 0.9333\n",
      "test Loss: 0.7443 Acc: 0.8333\n",
      "Epoch 255/499\n",
      "----------\n",
      "train Loss: 0.7155 Acc: 0.9111\n",
      "val Loss: 0.6769 Acc: 0.9333\n",
      "test Loss: 0.7413 Acc: 0.8333\n",
      "Epoch 256/499\n",
      "----------\n",
      "train Loss: 0.7146 Acc: 0.9111\n",
      "val Loss: 0.6982 Acc: 0.9000\n",
      "test Loss: 0.7409 Acc: 0.8333\n",
      "Epoch 257/499\n",
      "----------\n",
      "train Loss: 0.7261 Acc: 0.8889\n",
      "val Loss: 0.7101 Acc: 0.8667\n",
      "test Loss: 0.7356 Acc: 0.9000\n",
      "Epoch 258/499\n",
      "----------\n",
      "train Loss: 0.7026 Acc: 0.9111\n",
      "val Loss: 0.6895 Acc: 0.9333\n",
      "test Loss: 0.7259 Acc: 0.9000\n",
      "Epoch 259/499\n",
      "----------\n",
      "train Loss: 0.7091 Acc: 0.9444\n",
      "val Loss: 0.6873 Acc: 0.9333\n",
      "test Loss: 0.7405 Acc: 0.8000\n",
      "Epoch 260/499\n",
      "----------\n",
      "train Loss: 0.7140 Acc: 0.9111\n",
      "val Loss: 0.6802 Acc: 0.9333\n",
      "test Loss: 0.7346 Acc: 0.8333\n",
      "Epoch 261/499\n",
      "----------\n",
      "train Loss: 0.7100 Acc: 0.9444\n",
      "val Loss: 0.6759 Acc: 0.9333\n",
      "test Loss: 0.7195 Acc: 0.8667\n",
      "Epoch 262/499\n",
      "----------\n",
      "train Loss: 0.7175 Acc: 0.9111\n",
      "val Loss: 0.6773 Acc: 0.9333\n",
      "test Loss: 0.7255 Acc: 0.9667\n",
      "Epoch 263/499\n",
      "----------\n",
      "train Loss: 0.7139 Acc: 0.9222\n",
      "val Loss: 0.6818 Acc: 0.9333\n",
      "test Loss: 0.7166 Acc: 0.9000\n",
      "Epoch 264/499\n",
      "----------\n",
      "train Loss: 0.7091 Acc: 0.9222\n",
      "val Loss: 0.6851 Acc: 0.9333\n",
      "test Loss: 0.7388 Acc: 0.8667\n",
      "Epoch 265/499\n",
      "----------\n",
      "train Loss: 0.7079 Acc: 0.9111\n",
      "val Loss: 0.6894 Acc: 0.9667\n",
      "test Loss: 0.7196 Acc: 0.9000\n",
      "Epoch 266/499\n",
      "----------\n",
      "train Loss: 0.7092 Acc: 0.9333\n",
      "val Loss: 0.6831 Acc: 0.9667\n",
      "test Loss: 0.7405 Acc: 0.8333\n",
      "Epoch 267/499\n",
      "----------\n",
      "train Loss: 0.7176 Acc: 0.9000\n",
      "val Loss: 0.6631 Acc: 0.9667\n",
      "test Loss: 0.7270 Acc: 0.9000\n",
      "Epoch 268/499\n",
      "----------\n",
      "train Loss: 0.7007 Acc: 0.9333\n",
      "val Loss: 0.6906 Acc: 0.9000\n",
      "test Loss: 0.7661 Acc: 0.7667\n",
      "Epoch 269/499\n",
      "----------\n",
      "train Loss: 0.7078 Acc: 0.9333\n",
      "val Loss: 0.6809 Acc: 0.9667\n",
      "test Loss: 0.7127 Acc: 0.8667\n",
      "Epoch 270/499\n",
      "----------\n",
      "train Loss: 0.7029 Acc: 0.9222\n",
      "val Loss: 0.6693 Acc: 1.0000\n",
      "test Loss: 0.7387 Acc: 0.8667\n",
      "Epoch 271/499\n",
      "----------\n",
      "train Loss: 0.7183 Acc: 0.8778\n",
      "val Loss: 0.6793 Acc: 1.0000\n",
      "test Loss: 0.7429 Acc: 0.8333\n",
      "Epoch 272/499\n",
      "----------\n",
      "train Loss: 0.6966 Acc: 0.9222\n",
      "val Loss: 0.6625 Acc: 0.9667\n",
      "test Loss: 0.7409 Acc: 0.8333\n",
      "Epoch 273/499\n",
      "----------\n",
      "train Loss: 0.7049 Acc: 0.9000\n",
      "val Loss: 0.6743 Acc: 0.9000\n",
      "test Loss: 0.7244 Acc: 0.8667\n",
      "Epoch 274/499\n",
      "----------\n",
      "train Loss: 0.7114 Acc: 0.8889\n",
      "val Loss: 0.6809 Acc: 0.9667\n",
      "test Loss: 0.7488 Acc: 0.8333\n",
      "Epoch 275/499\n",
      "----------\n",
      "train Loss: 0.6977 Acc: 0.9444\n",
      "val Loss: 0.6669 Acc: 0.9667\n",
      "test Loss: 0.7384 Acc: 0.8333\n",
      "Epoch 276/499\n",
      "----------\n",
      "train Loss: 0.6973 Acc: 0.9222\n",
      "val Loss: 0.6858 Acc: 0.9333\n",
      "test Loss: 0.7262 Acc: 0.8333\n",
      "Epoch 277/499\n",
      "----------\n",
      "train Loss: 0.6999 Acc: 0.9444\n",
      "val Loss: 0.6702 Acc: 0.9667\n",
      "test Loss: 0.7246 Acc: 0.9667\n",
      "Epoch 278/499\n",
      "----------\n",
      "train Loss: 0.7095 Acc: 0.9333\n",
      "val Loss: 0.6548 Acc: 0.9333\n",
      "test Loss: 0.7365 Acc: 0.8333\n",
      "Epoch 279/499\n",
      "----------\n",
      "train Loss: 0.7108 Acc: 0.9333\n",
      "val Loss: 0.6726 Acc: 0.9667\n",
      "test Loss: 0.7167 Acc: 0.9000\n",
      "Epoch 280/499\n",
      "----------\n",
      "train Loss: 0.7085 Acc: 0.9222\n",
      "val Loss: 0.6552 Acc: 0.9667\n",
      "test Loss: 0.7171 Acc: 0.8333\n",
      "Epoch 281/499\n",
      "----------\n",
      "train Loss: 0.7020 Acc: 0.9111\n",
      "val Loss: 0.6841 Acc: 0.9667\n",
      "test Loss: 0.7117 Acc: 0.8667\n",
      "Epoch 282/499\n",
      "----------\n",
      "train Loss: 0.7097 Acc: 0.9222\n",
      "val Loss: 0.6558 Acc: 1.0000\n",
      "test Loss: 0.7209 Acc: 0.8333\n",
      "Epoch 283/499\n",
      "----------\n",
      "train Loss: 0.7054 Acc: 0.9222\n",
      "val Loss: 0.6549 Acc: 0.9667\n",
      "test Loss: 0.7081 Acc: 0.9000\n",
      "Epoch 284/499\n",
      "----------\n",
      "train Loss: 0.7046 Acc: 0.9444\n",
      "val Loss: 0.6759 Acc: 0.9333\n",
      "test Loss: 0.7272 Acc: 0.8667\n",
      "Epoch 285/499\n",
      "----------\n",
      "train Loss: 0.6999 Acc: 0.9222\n",
      "val Loss: 0.6799 Acc: 0.9667\n",
      "test Loss: 0.7123 Acc: 0.8667\n",
      "Epoch 286/499\n",
      "----------\n",
      "train Loss: 0.6976 Acc: 0.9444\n",
      "val Loss: 0.6640 Acc: 0.9333\n",
      "test Loss: 0.7062 Acc: 0.8333\n",
      "Epoch 287/499\n",
      "----------\n",
      "train Loss: 0.6970 Acc: 0.9333\n",
      "val Loss: 0.6485 Acc: 0.9667\n",
      "test Loss: 0.7323 Acc: 0.8333\n",
      "Epoch 288/499\n",
      "----------\n",
      "train Loss: 0.6985 Acc: 0.9000\n",
      "val Loss: 0.6665 Acc: 0.9667\n",
      "test Loss: 0.7299 Acc: 0.8667\n",
      "Epoch 289/499\n",
      "----------\n",
      "train Loss: 0.6970 Acc: 0.9333\n",
      "val Loss: 0.6596 Acc: 0.9667\n",
      "test Loss: 0.7122 Acc: 0.8667\n",
      "Epoch 290/499\n",
      "----------\n",
      "train Loss: 0.7080 Acc: 0.9111\n",
      "val Loss: 0.6871 Acc: 0.9000\n",
      "test Loss: 0.7180 Acc: 0.8667\n",
      "Epoch 291/499\n",
      "----------\n",
      "train Loss: 0.7078 Acc: 0.9333\n",
      "val Loss: 0.6664 Acc: 0.9667\n",
      "test Loss: 0.7229 Acc: 0.8000\n",
      "Epoch 292/499\n",
      "----------\n",
      "train Loss: 0.6977 Acc: 0.9556\n",
      "val Loss: 0.6499 Acc: 0.9667\n",
      "test Loss: 0.7169 Acc: 0.9333\n",
      "Epoch 293/499\n",
      "----------\n",
      "train Loss: 0.6903 Acc: 0.9444\n",
      "val Loss: 0.6664 Acc: 0.9667\n",
      "test Loss: 0.7011 Acc: 0.9333\n",
      "Epoch 294/499\n",
      "----------\n",
      "train Loss: 0.6876 Acc: 0.9333\n",
      "val Loss: 0.6573 Acc: 0.9667\n",
      "test Loss: 0.7182 Acc: 0.9000\n",
      "Epoch 295/499\n",
      "----------\n",
      "train Loss: 0.6852 Acc: 0.9444\n",
      "val Loss: 0.6643 Acc: 0.9667\n",
      "test Loss: 0.7496 Acc: 0.8667\n",
      "Epoch 296/499\n",
      "----------\n",
      "train Loss: 0.6871 Acc: 0.9333\n",
      "val Loss: 0.6927 Acc: 0.9000\n",
      "test Loss: 0.7286 Acc: 0.8333\n",
      "Epoch 297/499\n",
      "----------\n",
      "train Loss: 0.6904 Acc: 0.9000\n",
      "val Loss: 0.6630 Acc: 0.9667\n",
      "test Loss: 0.7230 Acc: 0.9000\n",
      "Epoch 298/499\n",
      "----------\n",
      "train Loss: 0.6896 Acc: 0.9222\n",
      "val Loss: 0.6483 Acc: 0.9667\n",
      "test Loss: 0.7395 Acc: 0.8667\n",
      "Epoch 299/499\n",
      "----------\n",
      "train Loss: 0.6966 Acc: 0.9333\n",
      "val Loss: 0.6487 Acc: 1.0000\n",
      "test Loss: 0.7129 Acc: 0.8667\n",
      "Epoch 300/499\n",
      "----------\n",
      "train Loss: 0.6912 Acc: 0.9333\n",
      "val Loss: 0.6445 Acc: 0.9667\n",
      "test Loss: 0.7051 Acc: 0.9333\n",
      "Epoch 301/499\n",
      "----------\n",
      "train Loss: 0.7012 Acc: 0.9444\n",
      "val Loss: 0.6582 Acc: 0.9667\n",
      "test Loss: 0.7080 Acc: 0.8667\n",
      "Epoch 302/499\n",
      "----------\n",
      "train Loss: 0.6968 Acc: 0.9111\n",
      "val Loss: 0.6622 Acc: 0.9333\n",
      "test Loss: 0.7197 Acc: 0.9000\n",
      "Epoch 303/499\n",
      "----------\n",
      "train Loss: 0.6903 Acc: 0.9333\n",
      "val Loss: 0.6388 Acc: 0.9667\n",
      "test Loss: 0.7065 Acc: 0.9000\n",
      "Epoch 304/499\n",
      "----------\n",
      "train Loss: 0.7039 Acc: 0.8778\n",
      "val Loss: 0.6606 Acc: 0.9667\n",
      "test Loss: 0.7285 Acc: 0.8333\n",
      "Epoch 305/499\n",
      "----------\n",
      "train Loss: 0.6866 Acc: 0.9222\n",
      "val Loss: 0.6498 Acc: 0.9667\n",
      "test Loss: 0.7105 Acc: 0.9000\n",
      "Epoch 306/499\n",
      "----------\n",
      "train Loss: 0.6876 Acc: 0.9111\n",
      "val Loss: 0.6422 Acc: 0.9667\n",
      "test Loss: 0.6982 Acc: 0.9000\n",
      "Epoch 307/499\n",
      "----------\n",
      "train Loss: 0.6836 Acc: 0.9444\n",
      "val Loss: 0.6536 Acc: 0.9667\n",
      "test Loss: 0.7346 Acc: 0.8000\n",
      "Epoch 308/499\n",
      "----------\n",
      "train Loss: 0.6913 Acc: 0.9111\n",
      "val Loss: 0.6615 Acc: 0.9667\n",
      "test Loss: 0.7048 Acc: 0.9000\n",
      "Epoch 309/499\n",
      "----------\n",
      "train Loss: 0.6884 Acc: 0.9556\n",
      "val Loss: 0.6524 Acc: 0.9333\n",
      "test Loss: 0.7046 Acc: 0.9000\n",
      "Epoch 310/499\n",
      "----------\n",
      "train Loss: 0.6954 Acc: 0.9222\n",
      "val Loss: 0.6435 Acc: 0.9333\n",
      "test Loss: 0.7135 Acc: 0.9000\n",
      "Epoch 311/499\n",
      "----------\n",
      "train Loss: 0.6904 Acc: 0.9222\n",
      "val Loss: 0.6631 Acc: 0.9667\n",
      "test Loss: 0.7075 Acc: 0.8667\n",
      "Epoch 312/499\n",
      "----------\n",
      "train Loss: 0.6884 Acc: 0.9444\n",
      "val Loss: 0.6445 Acc: 0.9667\n",
      "test Loss: 0.7130 Acc: 0.8333\n",
      "Epoch 313/499\n",
      "----------\n",
      "train Loss: 0.6771 Acc: 0.9556\n",
      "val Loss: 0.6571 Acc: 0.9667\n",
      "test Loss: 0.7248 Acc: 0.8333\n",
      "Epoch 314/499\n",
      "----------\n",
      "train Loss: 0.6893 Acc: 0.9111\n",
      "val Loss: 0.6673 Acc: 0.9333\n",
      "test Loss: 0.7129 Acc: 0.9000\n",
      "Epoch 315/499\n",
      "----------\n",
      "train Loss: 0.6716 Acc: 0.9444\n",
      "val Loss: 0.6462 Acc: 1.0000\n",
      "test Loss: 0.7042 Acc: 0.9000\n",
      "Epoch 316/499\n",
      "----------\n",
      "train Loss: 0.6879 Acc: 0.9333\n",
      "val Loss: 0.6518 Acc: 0.9000\n",
      "test Loss: 0.6988 Acc: 0.9000\n",
      "Epoch 317/499\n",
      "----------\n",
      "train Loss: 0.6788 Acc: 0.9556\n",
      "val Loss: 0.6266 Acc: 1.0000\n",
      "test Loss: 0.7066 Acc: 0.8333\n",
      "Epoch 318/499\n",
      "----------\n",
      "train Loss: 0.6656 Acc: 0.9667\n",
      "val Loss: 0.6378 Acc: 1.0000\n",
      "test Loss: 0.7127 Acc: 0.8667\n",
      "Epoch 319/499\n",
      "----------\n",
      "train Loss: 0.6853 Acc: 0.9222\n",
      "val Loss: 0.6329 Acc: 0.9667\n",
      "test Loss: 0.6959 Acc: 0.9000\n",
      "Epoch 320/499\n",
      "----------\n",
      "train Loss: 0.6870 Acc: 0.9333\n",
      "val Loss: 0.6376 Acc: 0.9667\n",
      "test Loss: 0.7100 Acc: 0.9333\n",
      "Epoch 321/499\n",
      "----------\n",
      "train Loss: 0.6790 Acc: 0.9222\n",
      "val Loss: 0.6656 Acc: 0.9000\n",
      "test Loss: 0.6971 Acc: 0.9000\n",
      "Epoch 322/499\n",
      "----------\n",
      "train Loss: 0.6856 Acc: 0.9222\n",
      "val Loss: 0.6422 Acc: 0.9667\n",
      "test Loss: 0.7119 Acc: 0.8333\n",
      "Epoch 323/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6815 Acc: 0.9222\n",
      "val Loss: 0.6515 Acc: 0.9333\n",
      "test Loss: 0.7153 Acc: 0.8333\n",
      "Epoch 324/499\n",
      "----------\n",
      "train Loss: 0.6852 Acc: 0.9333\n",
      "val Loss: 0.6534 Acc: 0.9667\n",
      "test Loss: 0.7003 Acc: 0.9000\n",
      "Epoch 325/499\n",
      "----------\n",
      "train Loss: 0.6840 Acc: 0.9111\n",
      "val Loss: 0.6388 Acc: 0.9667\n",
      "test Loss: 0.7034 Acc: 0.8667\n",
      "Epoch 326/499\n",
      "----------\n",
      "train Loss: 0.6797 Acc: 0.9444\n",
      "val Loss: 0.6463 Acc: 0.9333\n",
      "test Loss: 0.6977 Acc: 0.8667\n",
      "Epoch 327/499\n",
      "----------\n",
      "train Loss: 0.6722 Acc: 0.9556\n",
      "val Loss: 0.6522 Acc: 0.9667\n",
      "test Loss: 0.7397 Acc: 0.8667\n",
      "Epoch 328/499\n",
      "----------\n",
      "train Loss: 0.6837 Acc: 0.9333\n",
      "val Loss: 0.6658 Acc: 0.9333\n",
      "test Loss: 0.7325 Acc: 0.8667\n",
      "Epoch 329/499\n",
      "----------\n",
      "train Loss: 0.6845 Acc: 0.9333\n",
      "val Loss: 0.6372 Acc: 0.9667\n",
      "test Loss: 0.7139 Acc: 0.8333\n",
      "Epoch 330/499\n",
      "----------\n",
      "train Loss: 0.6736 Acc: 0.9556\n",
      "val Loss: 0.6424 Acc: 0.9667\n",
      "test Loss: 0.6860 Acc: 0.9333\n",
      "Epoch 331/499\n",
      "----------\n",
      "train Loss: 0.6777 Acc: 0.9444\n",
      "val Loss: 0.6463 Acc: 0.9667\n",
      "test Loss: 0.6969 Acc: 0.9000\n",
      "Epoch 332/499\n",
      "----------\n",
      "train Loss: 0.6730 Acc: 0.9222\n",
      "val Loss: 0.6638 Acc: 0.9667\n",
      "test Loss: 0.7027 Acc: 0.9000\n",
      "Epoch 333/499\n",
      "----------\n",
      "train Loss: 0.6870 Acc: 0.9222\n",
      "val Loss: 0.6413 Acc: 1.0000\n",
      "test Loss: 0.7075 Acc: 0.8667\n",
      "Epoch 334/499\n",
      "----------\n",
      "train Loss: 0.6758 Acc: 0.9667\n",
      "val Loss: 0.6366 Acc: 0.9333\n",
      "test Loss: 0.7141 Acc: 0.9000\n",
      "Epoch 335/499\n",
      "----------\n",
      "train Loss: 0.6774 Acc: 0.9000\n",
      "val Loss: 0.6679 Acc: 0.9000\n",
      "test Loss: 0.6726 Acc: 0.9333\n",
      "Epoch 336/499\n",
      "----------\n",
      "train Loss: 0.6693 Acc: 0.9333\n",
      "val Loss: 0.6456 Acc: 0.9667\n",
      "test Loss: 0.7030 Acc: 0.9000\n",
      "Epoch 337/499\n",
      "----------\n",
      "train Loss: 0.6810 Acc: 0.9000\n",
      "val Loss: 0.6445 Acc: 0.9333\n",
      "test Loss: 0.7036 Acc: 0.8667\n",
      "Epoch 338/499\n",
      "----------\n",
      "train Loss: 0.6895 Acc: 0.9111\n",
      "val Loss: 0.6489 Acc: 0.9667\n",
      "test Loss: 0.6856 Acc: 0.9333\n",
      "Epoch 339/499\n",
      "----------\n",
      "train Loss: 0.6742 Acc: 0.9333\n",
      "val Loss: 0.6458 Acc: 0.9667\n",
      "test Loss: 0.6714 Acc: 0.9333\n",
      "Epoch 340/499\n",
      "----------\n",
      "train Loss: 0.6701 Acc: 0.9333\n",
      "val Loss: 0.6326 Acc: 0.9667\n",
      "test Loss: 0.6926 Acc: 0.9000\n",
      "Epoch 341/499\n",
      "----------\n",
      "train Loss: 0.6786 Acc: 0.9333\n",
      "val Loss: 0.6438 Acc: 0.9667\n",
      "test Loss: 0.7077 Acc: 0.8333\n",
      "Epoch 342/499\n",
      "----------\n",
      "train Loss: 0.6672 Acc: 0.9222\n",
      "val Loss: 0.6547 Acc: 1.0000\n",
      "test Loss: 0.6889 Acc: 0.9000\n",
      "Epoch 343/499\n",
      "----------\n",
      "train Loss: 0.6844 Acc: 0.9222\n",
      "val Loss: 0.6301 Acc: 1.0000\n",
      "test Loss: 0.7038 Acc: 0.8667\n",
      "Epoch 344/499\n",
      "----------\n",
      "train Loss: 0.6725 Acc: 0.9444\n",
      "val Loss: 0.6375 Acc: 0.9667\n",
      "test Loss: 0.6984 Acc: 0.8667\n",
      "Epoch 345/499\n",
      "----------\n",
      "train Loss: 0.6731 Acc: 0.9444\n",
      "val Loss: 0.6493 Acc: 0.9333\n",
      "test Loss: 0.6938 Acc: 0.8667\n",
      "Epoch 346/499\n",
      "----------\n",
      "train Loss: 0.6710 Acc: 0.9444\n",
      "val Loss: 0.6462 Acc: 0.9667\n",
      "test Loss: 0.6855 Acc: 0.9000\n",
      "Epoch 347/499\n",
      "----------\n",
      "train Loss: 0.6609 Acc: 0.9556\n",
      "val Loss: 0.6406 Acc: 0.9667\n",
      "test Loss: 0.7174 Acc: 0.7667\n",
      "Epoch 348/499\n",
      "----------\n",
      "train Loss: 0.6842 Acc: 0.9333\n",
      "val Loss: 0.6354 Acc: 0.9667\n",
      "test Loss: 0.6919 Acc: 0.8667\n",
      "Epoch 349/499\n",
      "----------\n",
      "train Loss: 0.6667 Acc: 0.9444\n",
      "val Loss: 0.6305 Acc: 0.9667\n",
      "test Loss: 0.6879 Acc: 0.9000\n",
      "Epoch 350/499\n",
      "----------\n",
      "train Loss: 0.6685 Acc: 0.9333\n",
      "val Loss: 0.6215 Acc: 0.9667\n",
      "test Loss: 0.7243 Acc: 0.8667\n",
      "Epoch 351/499\n",
      "----------\n",
      "train Loss: 0.6752 Acc: 0.9333\n",
      "val Loss: 0.6709 Acc: 0.9000\n",
      "test Loss: 0.6827 Acc: 0.9333\n",
      "Epoch 352/499\n",
      "----------\n",
      "train Loss: 0.6752 Acc: 0.9333\n",
      "val Loss: 0.6651 Acc: 0.9000\n",
      "test Loss: 0.6889 Acc: 0.8667\n",
      "Epoch 353/499\n",
      "----------\n",
      "train Loss: 0.6718 Acc: 0.9222\n",
      "val Loss: 0.6514 Acc: 0.9333\n",
      "test Loss: 0.6923 Acc: 0.9000\n",
      "Epoch 354/499\n",
      "----------\n",
      "train Loss: 0.6712 Acc: 0.9333\n",
      "val Loss: 0.6370 Acc: 0.9667\n",
      "test Loss: 0.6909 Acc: 0.9333\n",
      "Epoch 355/499\n",
      "----------\n",
      "train Loss: 0.6725 Acc: 0.9111\n",
      "val Loss: 0.6325 Acc: 1.0000\n",
      "test Loss: 0.6817 Acc: 0.9000\n",
      "Epoch 356/499\n",
      "----------\n",
      "train Loss: 0.6758 Acc: 0.9333\n",
      "val Loss: 0.6367 Acc: 0.9667\n",
      "test Loss: 0.7156 Acc: 0.9333\n",
      "Epoch 357/499\n",
      "----------\n",
      "train Loss: 0.6641 Acc: 0.9222\n",
      "val Loss: 0.6514 Acc: 0.9333\n",
      "test Loss: 0.6989 Acc: 0.8667\n",
      "Epoch 358/499\n",
      "----------\n",
      "train Loss: 0.6725 Acc: 0.9333\n",
      "val Loss: 0.6347 Acc: 0.9667\n",
      "test Loss: 0.7202 Acc: 0.8667\n",
      "Epoch 359/499\n",
      "----------\n",
      "train Loss: 0.6781 Acc: 0.9111\n",
      "val Loss: 0.6179 Acc: 0.9667\n",
      "test Loss: 0.6882 Acc: 0.9333\n",
      "Epoch 360/499\n",
      "----------\n",
      "train Loss: 0.6626 Acc: 0.9444\n",
      "val Loss: 0.6357 Acc: 0.9667\n",
      "test Loss: 0.6980 Acc: 0.8667\n",
      "Epoch 361/499\n",
      "----------\n",
      "train Loss: 0.6648 Acc: 0.9111\n",
      "val Loss: 0.6337 Acc: 0.9667\n",
      "test Loss: 0.7061 Acc: 0.8667\n",
      "Epoch 362/499\n",
      "----------\n",
      "train Loss: 0.6745 Acc: 0.9000\n",
      "val Loss: 0.6305 Acc: 1.0000\n",
      "test Loss: 0.6986 Acc: 0.8667\n",
      "Epoch 363/499\n",
      "----------\n",
      "train Loss: 0.6724 Acc: 0.9444\n",
      "val Loss: 0.6400 Acc: 1.0000\n",
      "test Loss: 0.7187 Acc: 0.8333\n",
      "Epoch 364/499\n",
      "----------\n",
      "train Loss: 0.6660 Acc: 0.9444\n",
      "val Loss: 0.6416 Acc: 1.0000\n",
      "test Loss: 0.6958 Acc: 0.9000\n",
      "Epoch 365/499\n",
      "----------\n",
      "train Loss: 0.6764 Acc: 0.9222\n",
      "val Loss: 0.6459 Acc: 0.9667\n",
      "test Loss: 0.7279 Acc: 0.8000\n",
      "Epoch 366/499\n",
      "----------\n",
      "train Loss: 0.6732 Acc: 0.9000\n",
      "val Loss: 0.6387 Acc: 0.9667\n",
      "test Loss: 0.6972 Acc: 0.9000\n",
      "Epoch 367/499\n",
      "----------\n",
      "train Loss: 0.6552 Acc: 0.9444\n",
      "val Loss: 0.6452 Acc: 0.9667\n",
      "test Loss: 0.6890 Acc: 0.9000\n",
      "Epoch 368/499\n",
      "----------\n",
      "train Loss: 0.6653 Acc: 0.9556\n",
      "val Loss: 0.6125 Acc: 1.0000\n",
      "test Loss: 0.7102 Acc: 0.8667\n",
      "Epoch 369/499\n",
      "----------\n",
      "train Loss: 0.6608 Acc: 0.9556\n",
      "val Loss: 0.6262 Acc: 0.9667\n",
      "test Loss: 0.6971 Acc: 0.9000\n",
      "Epoch 370/499\n",
      "----------\n",
      "train Loss: 0.6616 Acc: 0.9444\n",
      "val Loss: 0.6248 Acc: 0.9667\n",
      "test Loss: 0.7079 Acc: 0.8667\n",
      "Epoch 371/499\n",
      "----------\n",
      "train Loss: 0.6662 Acc: 0.9222\n",
      "val Loss: 0.6268 Acc: 0.9667\n",
      "test Loss: 0.7047 Acc: 0.8667\n",
      "Epoch 372/499\n",
      "----------\n",
      "train Loss: 0.6622 Acc: 0.9333\n",
      "val Loss: 0.6181 Acc: 0.9667\n",
      "test Loss: 0.7044 Acc: 0.8000\n",
      "Epoch 373/499\n",
      "----------\n",
      "train Loss: 0.6726 Acc: 0.9222\n",
      "val Loss: 0.6348 Acc: 0.9667\n",
      "test Loss: 0.6890 Acc: 0.8667\n",
      "Epoch 374/499\n",
      "----------\n",
      "train Loss: 0.6612 Acc: 0.9556\n",
      "val Loss: 0.6358 Acc: 0.9333\n",
      "test Loss: 0.6694 Acc: 0.9000\n",
      "Epoch 375/499\n",
      "----------\n",
      "train Loss: 0.6718 Acc: 0.9222\n",
      "val Loss: 0.6299 Acc: 1.0000\n",
      "test Loss: 0.6823 Acc: 0.8667\n",
      "Epoch 376/499\n",
      "----------\n",
      "train Loss: 0.6615 Acc: 0.9444\n",
      "val Loss: 0.6147 Acc: 0.9667\n",
      "test Loss: 0.6857 Acc: 0.9333\n",
      "Epoch 377/499\n",
      "----------\n",
      "train Loss: 0.6483 Acc: 0.9444\n",
      "val Loss: 0.6200 Acc: 0.9667\n",
      "test Loss: 0.6656 Acc: 0.9667\n",
      "Epoch 378/499\n",
      "----------\n",
      "train Loss: 0.6605 Acc: 0.9333\n",
      "val Loss: 0.6241 Acc: 0.9667\n",
      "test Loss: 0.6888 Acc: 0.9000\n",
      "Epoch 379/499\n",
      "----------\n",
      "train Loss: 0.6629 Acc: 0.9556\n",
      "val Loss: 0.6254 Acc: 0.9667\n",
      "test Loss: 0.6745 Acc: 0.9333\n",
      "Epoch 380/499\n",
      "----------\n",
      "train Loss: 0.6547 Acc: 0.9444\n",
      "val Loss: 0.6220 Acc: 0.9667\n",
      "test Loss: 0.6770 Acc: 0.9333\n",
      "Epoch 381/499\n",
      "----------\n",
      "train Loss: 0.6657 Acc: 0.9000\n",
      "val Loss: 0.6291 Acc: 0.9667\n",
      "test Loss: 0.6926 Acc: 0.8667\n",
      "Epoch 382/499\n",
      "----------\n",
      "train Loss: 0.6671 Acc: 0.9333\n",
      "val Loss: 0.6220 Acc: 1.0000\n",
      "test Loss: 0.7022 Acc: 0.8333\n",
      "Epoch 383/499\n",
      "----------\n",
      "train Loss: 0.6750 Acc: 0.9111\n",
      "val Loss: 0.6466 Acc: 0.9333\n",
      "test Loss: 0.7031 Acc: 0.8667\n",
      "Epoch 384/499\n",
      "----------\n",
      "train Loss: 0.6726 Acc: 0.9111\n",
      "val Loss: 0.6268 Acc: 0.9667\n",
      "test Loss: 0.6876 Acc: 0.9000\n",
      "Epoch 385/499\n",
      "----------\n",
      "train Loss: 0.6702 Acc: 0.9333\n",
      "val Loss: 0.6186 Acc: 1.0000\n",
      "test Loss: 0.6869 Acc: 0.9000\n",
      "Epoch 386/499\n",
      "----------\n",
      "train Loss: 0.6587 Acc: 0.9222\n",
      "val Loss: 0.6217 Acc: 0.9667\n",
      "test Loss: 0.6789 Acc: 0.9000\n",
      "Epoch 387/499\n",
      "----------\n",
      "train Loss: 0.6700 Acc: 0.9222\n",
      "val Loss: 0.6283 Acc: 0.9667\n",
      "test Loss: 0.6970 Acc: 0.9000\n",
      "Epoch 388/499\n",
      "----------\n",
      "train Loss: 0.6744 Acc: 0.9111\n",
      "val Loss: 0.6311 Acc: 0.9667\n",
      "test Loss: 0.6781 Acc: 0.9000\n",
      "Epoch 389/499\n",
      "----------\n",
      "train Loss: 0.6641 Acc: 0.9222\n",
      "val Loss: 0.6201 Acc: 0.9667\n",
      "test Loss: 0.6768 Acc: 0.9333\n",
      "Epoch 390/499\n",
      "----------\n",
      "train Loss: 0.6581 Acc: 0.9444\n",
      "val Loss: 0.6234 Acc: 0.9667\n",
      "test Loss: 0.7030 Acc: 0.8667\n",
      "Epoch 391/499\n",
      "----------\n",
      "train Loss: 0.6615 Acc: 0.9111\n",
      "val Loss: 0.6237 Acc: 0.9667\n",
      "test Loss: 0.6900 Acc: 0.8667\n",
      "Epoch 392/499\n",
      "----------\n",
      "train Loss: 0.6667 Acc: 0.9222\n",
      "val Loss: 0.6122 Acc: 0.9667\n",
      "test Loss: 0.7020 Acc: 0.8333\n",
      "Epoch 393/499\n",
      "----------\n",
      "train Loss: 0.6548 Acc: 0.9333\n",
      "val Loss: 0.6505 Acc: 0.9333\n",
      "test Loss: 0.6946 Acc: 0.8333\n",
      "Epoch 394/499\n",
      "----------\n",
      "train Loss: 0.6556 Acc: 0.9333\n",
      "val Loss: 0.6256 Acc: 0.9667\n",
      "test Loss: 0.7025 Acc: 0.8333\n",
      "Epoch 395/499\n",
      "----------\n",
      "train Loss: 0.6582 Acc: 0.9556\n",
      "val Loss: 0.6340 Acc: 0.9667\n",
      "test Loss: 0.7017 Acc: 0.8333\n",
      "Epoch 396/499\n",
      "----------\n",
      "train Loss: 0.6525 Acc: 0.9667\n",
      "val Loss: 0.6099 Acc: 0.9667\n",
      "test Loss: 0.6603 Acc: 0.9333\n",
      "Epoch 397/499\n",
      "----------\n",
      "train Loss: 0.6659 Acc: 0.9333\n",
      "val Loss: 0.6418 Acc: 0.9333\n",
      "test Loss: 0.6837 Acc: 0.8667\n",
      "Epoch 398/499\n",
      "----------\n",
      "train Loss: 0.6569 Acc: 0.9444\n",
      "val Loss: 0.6259 Acc: 0.9667\n",
      "test Loss: 0.6921 Acc: 0.9000\n",
      "Epoch 399/499\n",
      "----------\n",
      "train Loss: 0.6574 Acc: 0.9333\n",
      "val Loss: 0.6271 Acc: 0.9667\n",
      "test Loss: 0.6867 Acc: 0.8667\n",
      "Epoch 400/499\n",
      "----------\n",
      "train Loss: 0.6603 Acc: 0.9667\n",
      "val Loss: 0.6181 Acc: 0.9333\n",
      "test Loss: 0.6816 Acc: 0.8667\n",
      "Epoch 401/499\n",
      "----------\n",
      "train Loss: 0.6702 Acc: 0.9333\n",
      "val Loss: 0.6109 Acc: 0.9667\n",
      "test Loss: 0.7077 Acc: 0.9000\n",
      "Epoch 402/499\n",
      "----------\n",
      "train Loss: 0.6549 Acc: 0.9111\n",
      "val Loss: 0.6392 Acc: 0.9333\n",
      "test Loss: 0.6815 Acc: 0.8333\n",
      "Epoch 403/499\n",
      "----------\n",
      "train Loss: 0.6549 Acc: 0.9333\n",
      "val Loss: 0.6168 Acc: 0.9667\n",
      "test Loss: 0.6722 Acc: 0.9000\n",
      "Epoch 404/499\n",
      "----------\n",
      "train Loss: 0.6460 Acc: 0.9556\n",
      "val Loss: 0.6122 Acc: 0.9667\n",
      "test Loss: 0.6921 Acc: 0.8667\n",
      "Epoch 405/499\n",
      "----------\n",
      "train Loss: 0.6555 Acc: 0.9444\n",
      "val Loss: 0.6097 Acc: 0.9667\n",
      "test Loss: 0.6587 Acc: 0.9333\n",
      "Epoch 406/499\n",
      "----------\n",
      "train Loss: 0.6555 Acc: 0.9556\n",
      "val Loss: 0.6297 Acc: 0.9667\n",
      "test Loss: 0.6731 Acc: 0.9000\n",
      "Epoch 407/499\n",
      "----------\n",
      "train Loss: 0.6582 Acc: 0.9444\n",
      "val Loss: 0.6198 Acc: 0.9667\n",
      "test Loss: 0.6629 Acc: 0.9333\n",
      "Epoch 408/499\n",
      "----------\n",
      "train Loss: 0.6588 Acc: 0.9556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.6170 Acc: 0.9667\n",
      "test Loss: 0.7132 Acc: 0.8667\n",
      "Epoch 409/499\n",
      "----------\n",
      "train Loss: 0.6587 Acc: 0.9333\n",
      "val Loss: 0.6248 Acc: 0.9333\n",
      "test Loss: 0.6848 Acc: 0.9333\n",
      "Epoch 410/499\n",
      "----------\n",
      "train Loss: 0.6597 Acc: 0.9444\n",
      "val Loss: 0.6338 Acc: 0.9667\n",
      "test Loss: 0.6778 Acc: 0.9000\n",
      "Epoch 411/499\n",
      "----------\n",
      "train Loss: 0.6530 Acc: 0.9222\n",
      "val Loss: 0.6232 Acc: 0.9667\n",
      "test Loss: 0.6694 Acc: 0.9333\n",
      "Epoch 412/499\n",
      "----------\n",
      "train Loss: 0.6507 Acc: 0.9444\n",
      "val Loss: 0.6125 Acc: 1.0000\n",
      "test Loss: 0.6967 Acc: 0.9000\n",
      "Epoch 413/499\n",
      "----------\n",
      "train Loss: 0.6477 Acc: 0.9667\n",
      "val Loss: 0.6319 Acc: 0.9667\n",
      "test Loss: 0.6797 Acc: 0.9000\n",
      "Epoch 414/499\n",
      "----------\n",
      "train Loss: 0.6495 Acc: 0.9222\n",
      "val Loss: 0.5940 Acc: 1.0000\n",
      "test Loss: 0.6816 Acc: 0.9000\n",
      "Epoch 415/499\n",
      "----------\n",
      "train Loss: 0.6488 Acc: 0.9444\n",
      "val Loss: 0.6181 Acc: 0.9333\n",
      "test Loss: 0.6850 Acc: 0.9000\n",
      "Epoch 416/499\n",
      "----------\n",
      "train Loss: 0.6663 Acc: 0.9333\n",
      "val Loss: 0.6309 Acc: 0.9667\n",
      "test Loss: 0.7229 Acc: 0.8333\n",
      "Epoch 417/499\n",
      "----------\n",
      "train Loss: 0.6558 Acc: 0.9222\n",
      "val Loss: 0.6147 Acc: 0.9667\n",
      "test Loss: 0.6829 Acc: 0.9000\n",
      "Epoch 418/499\n",
      "----------\n",
      "train Loss: 0.6368 Acc: 0.9556\n",
      "val Loss: 0.6210 Acc: 0.9667\n",
      "test Loss: 0.6694 Acc: 0.9000\n",
      "Epoch 419/499\n",
      "----------\n",
      "train Loss: 0.6578 Acc: 0.9222\n",
      "val Loss: 0.6373 Acc: 0.9333\n",
      "test Loss: 0.6706 Acc: 0.9000\n",
      "Epoch 420/499\n",
      "----------\n",
      "train Loss: 0.6538 Acc: 0.9444\n",
      "val Loss: 0.6177 Acc: 0.9667\n",
      "test Loss: 0.6596 Acc: 0.9667\n",
      "Epoch 421/499\n",
      "----------\n",
      "train Loss: 0.6652 Acc: 0.9333\n",
      "val Loss: 0.6091 Acc: 0.9667\n",
      "test Loss: 0.6828 Acc: 0.8667\n",
      "Epoch 422/499\n",
      "----------\n",
      "train Loss: 0.6433 Acc: 0.9556\n",
      "val Loss: 0.6044 Acc: 1.0000\n",
      "test Loss: 0.6954 Acc: 0.8333\n",
      "Epoch 423/499\n",
      "----------\n",
      "train Loss: 0.6539 Acc: 0.9444\n",
      "val Loss: 0.6266 Acc: 1.0000\n",
      "test Loss: 0.6718 Acc: 0.9333\n",
      "Epoch 424/499\n",
      "----------\n",
      "train Loss: 0.6435 Acc: 0.9333\n",
      "val Loss: 0.6134 Acc: 0.9667\n",
      "test Loss: 0.6801 Acc: 0.9000\n",
      "Epoch 425/499\n",
      "----------\n",
      "train Loss: 0.6325 Acc: 0.9556\n",
      "val Loss: 0.6211 Acc: 0.9667\n",
      "test Loss: 0.6748 Acc: 0.9000\n",
      "Epoch 426/499\n",
      "----------\n",
      "train Loss: 0.6534 Acc: 0.9333\n",
      "val Loss: 0.6131 Acc: 0.9667\n",
      "test Loss: 0.6859 Acc: 0.9000\n",
      "Epoch 427/499\n",
      "----------\n",
      "train Loss: 0.6301 Acc: 0.9556\n",
      "val Loss: 0.6471 Acc: 0.9333\n",
      "test Loss: 0.6757 Acc: 0.9333\n",
      "Epoch 428/499\n",
      "----------\n",
      "train Loss: 0.6415 Acc: 0.9667\n",
      "val Loss: 0.6044 Acc: 0.9667\n",
      "test Loss: 0.6695 Acc: 0.9000\n",
      "Epoch 429/499\n",
      "----------\n",
      "train Loss: 0.6484 Acc: 0.9444\n",
      "val Loss: 0.6047 Acc: 1.0000\n",
      "test Loss: 0.6578 Acc: 0.9333\n",
      "Epoch 430/499\n",
      "----------\n",
      "train Loss: 0.6660 Acc: 0.9000\n",
      "val Loss: 0.6017 Acc: 0.9667\n",
      "test Loss: 0.6932 Acc: 0.9000\n",
      "Epoch 431/499\n",
      "----------\n",
      "train Loss: 0.6558 Acc: 0.9222\n",
      "val Loss: 0.6139 Acc: 1.0000\n",
      "test Loss: 0.6786 Acc: 0.9000\n",
      "Epoch 432/499\n",
      "----------\n",
      "train Loss: 0.6497 Acc: 0.9556\n",
      "val Loss: 0.6215 Acc: 0.9667\n",
      "test Loss: 0.6741 Acc: 0.9000\n",
      "Epoch 433/499\n",
      "----------\n",
      "train Loss: 0.6464 Acc: 0.9556\n",
      "val Loss: 0.6121 Acc: 0.9667\n",
      "test Loss: 0.6733 Acc: 0.9000\n",
      "Epoch 434/499\n",
      "----------\n",
      "train Loss: 0.6532 Acc: 0.9556\n",
      "val Loss: 0.6122 Acc: 0.9667\n",
      "test Loss: 0.6775 Acc: 0.9000\n",
      "Epoch 435/499\n",
      "----------\n",
      "train Loss: 0.6409 Acc: 0.9444\n",
      "val Loss: 0.6272 Acc: 0.9333\n",
      "test Loss: 0.6559 Acc: 0.9000\n",
      "Epoch 436/499\n",
      "----------\n",
      "train Loss: 0.6469 Acc: 0.9444\n",
      "val Loss: 0.6256 Acc: 0.9667\n",
      "test Loss: 0.6912 Acc: 0.8667\n",
      "Epoch 437/499\n",
      "----------\n",
      "train Loss: 0.6330 Acc: 0.9667\n",
      "val Loss: 0.6313 Acc: 0.9667\n",
      "test Loss: 0.6893 Acc: 0.8667\n",
      "Epoch 438/499\n",
      "----------\n",
      "train Loss: 0.6529 Acc: 0.9444\n",
      "val Loss: 0.6136 Acc: 0.9667\n",
      "test Loss: 0.6923 Acc: 0.9000\n",
      "Epoch 439/499\n",
      "----------\n",
      "train Loss: 0.6599 Acc: 0.9000\n",
      "val Loss: 0.6129 Acc: 1.0000\n",
      "test Loss: 0.6673 Acc: 0.9333\n",
      "Epoch 440/499\n",
      "----------\n",
      "train Loss: 0.6491 Acc: 0.9222\n",
      "val Loss: 0.6128 Acc: 0.9667\n",
      "test Loss: 0.6927 Acc: 0.8333\n",
      "Epoch 441/499\n",
      "----------\n",
      "train Loss: 0.6387 Acc: 0.9333\n",
      "val Loss: 0.6079 Acc: 0.9667\n",
      "test Loss: 0.6688 Acc: 0.9000\n",
      "Epoch 442/499\n",
      "----------\n",
      "train Loss: 0.6260 Acc: 0.9778\n",
      "val Loss: 0.6122 Acc: 0.9667\n",
      "test Loss: 0.6508 Acc: 0.9667\n",
      "Epoch 443/499\n",
      "----------\n",
      "train Loss: 0.6453 Acc: 0.9333\n",
      "val Loss: 0.6015 Acc: 1.0000\n",
      "test Loss: 0.6843 Acc: 0.9000\n",
      "Epoch 444/499\n",
      "----------\n",
      "train Loss: 0.6370 Acc: 0.9444\n",
      "val Loss: 0.6194 Acc: 1.0000\n",
      "test Loss: 0.6799 Acc: 0.8667\n",
      "Epoch 445/499\n",
      "----------\n",
      "train Loss: 0.6438 Acc: 0.9444\n",
      "val Loss: 0.6303 Acc: 0.9667\n",
      "test Loss: 0.6631 Acc: 0.9000\n",
      "Epoch 446/499\n",
      "----------\n",
      "train Loss: 0.6559 Acc: 0.9222\n",
      "val Loss: 0.6190 Acc: 0.9667\n",
      "test Loss: 0.6731 Acc: 0.9000\n",
      "Epoch 447/499\n",
      "----------\n",
      "train Loss: 0.6412 Acc: 0.9333\n",
      "val Loss: 0.6026 Acc: 0.9667\n",
      "test Loss: 0.6614 Acc: 0.9000\n",
      "Epoch 448/499\n",
      "----------\n",
      "train Loss: 0.6399 Acc: 0.9556\n",
      "val Loss: 0.6105 Acc: 0.9667\n",
      "test Loss: 0.6899 Acc: 0.9000\n",
      "Epoch 449/499\n",
      "----------\n",
      "train Loss: 0.6422 Acc: 0.9333\n",
      "val Loss: 0.5995 Acc: 0.9667\n",
      "test Loss: 0.6878 Acc: 0.8667\n",
      "Epoch 450/499\n",
      "----------\n",
      "train Loss: 0.6472 Acc: 0.9333\n",
      "val Loss: 0.6194 Acc: 0.9667\n",
      "test Loss: 0.6771 Acc: 0.9000\n",
      "Epoch 451/499\n",
      "----------\n",
      "train Loss: 0.6442 Acc: 0.9222\n",
      "val Loss: 0.6100 Acc: 0.9667\n",
      "test Loss: 0.7267 Acc: 0.8333\n",
      "Epoch 452/499\n",
      "----------\n",
      "train Loss: 0.6410 Acc: 0.9667\n",
      "val Loss: 0.6222 Acc: 0.9333\n",
      "test Loss: 0.6789 Acc: 0.8333\n",
      "Epoch 453/499\n",
      "----------\n",
      "train Loss: 0.6420 Acc: 0.9444\n",
      "val Loss: 0.6090 Acc: 0.9667\n",
      "test Loss: 0.6524 Acc: 0.9000\n",
      "Epoch 454/499\n",
      "----------\n",
      "train Loss: 0.6556 Acc: 0.9000\n",
      "val Loss: 0.6167 Acc: 0.9667\n",
      "test Loss: 0.6754 Acc: 0.9000\n",
      "Epoch 455/499\n",
      "----------\n",
      "train Loss: 0.6378 Acc: 0.9667\n",
      "val Loss: 0.6213 Acc: 0.9667\n",
      "test Loss: 0.6982 Acc: 0.8333\n",
      "Epoch 456/499\n",
      "----------\n",
      "train Loss: 0.6401 Acc: 0.9444\n",
      "val Loss: 0.6104 Acc: 0.9667\n",
      "test Loss: 0.6405 Acc: 0.9667\n",
      "Epoch 457/499\n",
      "----------\n",
      "train Loss: 0.6408 Acc: 0.9667\n",
      "val Loss: 0.6058 Acc: 0.9667\n",
      "test Loss: 0.6717 Acc: 0.9000\n",
      "Epoch 458/499\n",
      "----------\n",
      "train Loss: 0.6450 Acc: 0.9333\n",
      "val Loss: 0.6303 Acc: 0.9667\n",
      "test Loss: 0.6544 Acc: 0.9667\n",
      "Epoch 459/499\n",
      "----------\n",
      "train Loss: 0.6429 Acc: 0.9556\n",
      "val Loss: 0.6022 Acc: 0.9667\n",
      "test Loss: 0.6795 Acc: 0.8667\n",
      "Epoch 460/499\n",
      "----------\n",
      "train Loss: 0.6406 Acc: 0.9444\n",
      "val Loss: 0.6340 Acc: 0.9333\n",
      "test Loss: 0.6520 Acc: 0.9333\n",
      "Epoch 461/499\n",
      "----------\n",
      "train Loss: 0.6409 Acc: 0.9333\n",
      "val Loss: 0.6085 Acc: 0.9667\n",
      "test Loss: 0.6947 Acc: 0.8667\n",
      "Epoch 462/499\n",
      "----------\n",
      "train Loss: 0.6436 Acc: 0.9556\n",
      "val Loss: 0.6096 Acc: 0.9667\n",
      "test Loss: 0.6742 Acc: 0.9000\n",
      "Epoch 463/499\n",
      "----------\n",
      "train Loss: 0.6617 Acc: 0.9000\n",
      "val Loss: 0.6114 Acc: 0.9667\n",
      "test Loss: 0.6947 Acc: 0.8667\n",
      "Epoch 464/499\n",
      "----------\n",
      "train Loss: 0.6474 Acc: 0.9222\n",
      "val Loss: 0.6379 Acc: 0.9667\n",
      "test Loss: 0.6647 Acc: 0.8667\n",
      "Epoch 465/499\n",
      "----------\n",
      "train Loss: 0.6438 Acc: 0.9333\n",
      "val Loss: 0.6200 Acc: 0.9667\n",
      "test Loss: 0.6889 Acc: 0.9000\n",
      "Epoch 466/499\n",
      "----------\n",
      "train Loss: 0.6418 Acc: 0.9333\n",
      "val Loss: 0.6393 Acc: 0.9333\n",
      "test Loss: 0.6386 Acc: 0.9667\n",
      "Epoch 467/499\n",
      "----------\n",
      "train Loss: 0.6473 Acc: 0.9444\n",
      "val Loss: 0.6145 Acc: 1.0000\n",
      "test Loss: 0.6776 Acc: 0.9000\n",
      "Epoch 468/499\n",
      "----------\n",
      "train Loss: 0.6330 Acc: 0.9667\n",
      "val Loss: 0.6334 Acc: 0.9333\n",
      "test Loss: 0.6525 Acc: 0.9000\n",
      "Epoch 469/499\n",
      "----------\n",
      "train Loss: 0.6371 Acc: 0.9556\n",
      "val Loss: 0.6110 Acc: 0.9667\n",
      "test Loss: 0.6642 Acc: 0.8667\n",
      "Epoch 470/499\n",
      "----------\n",
      "train Loss: 0.6452 Acc: 0.9222\n",
      "val Loss: 0.6338 Acc: 0.9333\n",
      "test Loss: 0.6561 Acc: 0.9333\n",
      "Epoch 471/499\n",
      "----------\n",
      "train Loss: 0.6498 Acc: 0.9444\n",
      "val Loss: 0.6139 Acc: 0.9667\n",
      "test Loss: 0.6735 Acc: 0.9000\n",
      "Epoch 472/499\n",
      "----------\n",
      "train Loss: 0.6317 Acc: 0.9667\n",
      "val Loss: 0.5991 Acc: 0.9667\n",
      "test Loss: 0.6827 Acc: 0.9000\n",
      "Epoch 473/499\n",
      "----------\n",
      "train Loss: 0.6489 Acc: 0.9333\n",
      "val Loss: 0.6262 Acc: 0.9667\n",
      "test Loss: 0.6915 Acc: 0.8667\n",
      "Epoch 474/499\n",
      "----------\n",
      "train Loss: 0.6561 Acc: 0.9111\n",
      "val Loss: 0.6231 Acc: 0.9667\n",
      "test Loss: 0.6638 Acc: 0.9333\n",
      "Epoch 475/499\n",
      "----------\n",
      "train Loss: 0.6397 Acc: 0.9333\n",
      "val Loss: 0.6171 Acc: 0.9667\n",
      "test Loss: 0.6897 Acc: 0.8333\n",
      "Epoch 476/499\n",
      "----------\n",
      "train Loss: 0.6337 Acc: 0.9333\n",
      "val Loss: 0.5953 Acc: 0.9667\n",
      "test Loss: 0.6700 Acc: 0.8667\n",
      "Epoch 477/499\n",
      "----------\n",
      "train Loss: 0.6316 Acc: 0.9556\n",
      "val Loss: 0.6109 Acc: 0.9667\n",
      "test Loss: 0.6814 Acc: 0.8667\n",
      "Epoch 478/499\n",
      "----------\n",
      "train Loss: 0.6384 Acc: 0.9222\n",
      "val Loss: 0.6075 Acc: 0.9667\n",
      "test Loss: 0.6573 Acc: 0.9000\n",
      "Epoch 479/499\n",
      "----------\n",
      "train Loss: 0.6339 Acc: 0.9222\n",
      "val Loss: 0.5939 Acc: 0.9667\n",
      "test Loss: 0.6624 Acc: 0.8667\n",
      "Epoch 480/499\n",
      "----------\n",
      "train Loss: 0.6366 Acc: 0.9444\n",
      "val Loss: 0.5868 Acc: 0.9667\n",
      "test Loss: 0.6618 Acc: 0.9000\n",
      "Epoch 481/499\n",
      "----------\n",
      "train Loss: 0.6479 Acc: 0.9111\n",
      "val Loss: 0.6045 Acc: 0.9667\n",
      "test Loss: 0.6524 Acc: 0.9000\n",
      "Epoch 482/499\n",
      "----------\n",
      "train Loss: 0.6281 Acc: 0.9667\n",
      "val Loss: 0.6089 Acc: 0.9333\n",
      "test Loss: 0.6722 Acc: 0.9000\n",
      "Epoch 483/499\n",
      "----------\n",
      "train Loss: 0.6369 Acc: 0.9333\n",
      "val Loss: 0.6047 Acc: 0.9667\n",
      "test Loss: 0.6630 Acc: 0.9000\n",
      "Epoch 484/499\n",
      "----------\n",
      "train Loss: 0.6267 Acc: 0.9556\n",
      "val Loss: 0.6052 Acc: 0.9667\n",
      "test Loss: 0.6752 Acc: 0.8667\n",
      "Epoch 485/499\n",
      "----------\n",
      "train Loss: 0.6324 Acc: 0.9444\n",
      "val Loss: 0.6069 Acc: 0.9667\n",
      "test Loss: 0.6830 Acc: 0.9000\n",
      "Epoch 486/499\n",
      "----------\n",
      "train Loss: 0.6415 Acc: 0.9444\n",
      "val Loss: 0.6040 Acc: 0.9667\n",
      "test Loss: 0.6841 Acc: 0.8667\n",
      "Epoch 487/499\n",
      "----------\n",
      "train Loss: 0.6222 Acc: 0.9889\n",
      "val Loss: 0.6010 Acc: 1.0000\n",
      "test Loss: 0.6550 Acc: 0.9333\n",
      "Epoch 488/499\n",
      "----------\n",
      "train Loss: 0.6349 Acc: 0.9333\n",
      "val Loss: 0.6177 Acc: 0.9667\n",
      "test Loss: 0.6611 Acc: 0.9333\n",
      "Epoch 489/499\n",
      "----------\n",
      "train Loss: 0.6260 Acc: 0.9556\n",
      "val Loss: 0.6049 Acc: 0.9667\n",
      "test Loss: 0.6513 Acc: 0.9333\n",
      "Epoch 490/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6370 Acc: 0.9556\n",
      "val Loss: 0.6029 Acc: 0.9667\n",
      "test Loss: 0.6881 Acc: 0.8333\n",
      "Epoch 491/499\n",
      "----------\n",
      "train Loss: 0.6336 Acc: 0.9667\n",
      "val Loss: 0.6265 Acc: 0.9333\n",
      "test Loss: 0.6826 Acc: 0.8667\n",
      "Epoch 492/499\n",
      "----------\n",
      "train Loss: 0.6385 Acc: 0.9333\n",
      "val Loss: 0.6001 Acc: 0.9667\n",
      "test Loss: 0.6538 Acc: 0.9333\n",
      "Epoch 493/499\n",
      "----------\n",
      "train Loss: 0.6413 Acc: 0.9444\n",
      "val Loss: 0.6125 Acc: 0.9333\n",
      "test Loss: 0.6889 Acc: 0.8667\n",
      "Epoch 494/499\n",
      "----------\n",
      "train Loss: 0.6342 Acc: 0.9444\n",
      "val Loss: 0.5990 Acc: 0.9667\n",
      "test Loss: 0.6776 Acc: 0.9333\n",
      "Epoch 495/499\n",
      "----------\n",
      "train Loss: 0.6364 Acc: 0.9444\n",
      "val Loss: 0.6110 Acc: 0.9667\n",
      "test Loss: 0.6617 Acc: 0.9000\n",
      "Epoch 496/499\n",
      "----------\n",
      "train Loss: 0.6345 Acc: 0.9556\n",
      "val Loss: 0.6121 Acc: 1.0000\n",
      "test Loss: 0.6664 Acc: 0.9000\n",
      "Epoch 497/499\n",
      "----------\n",
      "train Loss: 0.6323 Acc: 0.9444\n",
      "val Loss: 0.6003 Acc: 1.0000\n",
      "test Loss: 0.6602 Acc: 0.9000\n",
      "Epoch 498/499\n",
      "----------\n",
      "train Loss: 0.6367 Acc: 0.9667\n",
      "val Loss: 0.5912 Acc: 1.0000\n",
      "test Loss: 0.6683 Acc: 0.9000\n",
      "Epoch 499/499\n",
      "----------\n",
      "train Loss: 0.6323 Acc: 0.9444\n",
      "val Loss: 0.6054 Acc: 0.9667\n",
      "test Loss: 0.6594 Acc: 0.9000\n",
      "Training complete in 0m 4s\n",
      "Best test Acc: 0.966667\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 1.0995 Acc: 0.3333\n",
      "val Loss: 1.0999 Acc: 0.3333\n",
      "test Loss: 1.0995 Acc: 0.3333\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 1.0995 Acc: 0.3333\n",
      "val Loss: 1.0996 Acc: 0.3333\n",
      "test Loss: 1.0991 Acc: 0.3333\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 1.0993 Acc: 0.3333\n",
      "val Loss: 1.0987 Acc: 0.3333\n",
      "test Loss: 1.0984 Acc: 0.3333\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 1.0988 Acc: 0.3333\n",
      "val Loss: 1.0981 Acc: 0.3333\n",
      "test Loss: 1.0988 Acc: 0.3333\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 1.0981 Acc: 0.3333\n",
      "val Loss: 1.0974 Acc: 0.3333\n",
      "test Loss: 1.0978 Acc: 0.3333\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 1.0977 Acc: 0.3333\n",
      "val Loss: 1.0970 Acc: 0.3333\n",
      "test Loss: 1.0975 Acc: 0.3333\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 1.0979 Acc: 0.3333\n",
      "val Loss: 1.0959 Acc: 0.3333\n",
      "test Loss: 1.0970 Acc: 0.3333\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 1.0968 Acc: 0.3333\n",
      "val Loss: 1.0970 Acc: 0.3333\n",
      "test Loss: 1.0956 Acc: 0.3333\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 1.0969 Acc: 0.3333\n",
      "val Loss: 1.0951 Acc: 0.3333\n",
      "test Loss: 1.0957 Acc: 0.3333\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 1.0951 Acc: 0.3333\n",
      "val Loss: 1.0936 Acc: 0.3333\n",
      "test Loss: 1.0942 Acc: 0.3333\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 1.0943 Acc: 0.3333\n",
      "val Loss: 1.0936 Acc: 0.3333\n",
      "test Loss: 1.0934 Acc: 0.3333\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 1.0934 Acc: 0.3333\n",
      "val Loss: 1.0918 Acc: 0.3333\n",
      "test Loss: 1.0919 Acc: 0.3333\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 1.0923 Acc: 0.3333\n",
      "val Loss: 1.0905 Acc: 0.3333\n",
      "test Loss: 1.0917 Acc: 0.3333\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 1.0908 Acc: 0.3333\n",
      "val Loss: 1.0897 Acc: 0.3333\n",
      "test Loss: 1.0932 Acc: 0.3333\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 1.0899 Acc: 0.3333\n",
      "val Loss: 1.0900 Acc: 0.3333\n",
      "test Loss: 1.0894 Acc: 0.3333\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 1.0884 Acc: 0.3333\n",
      "val Loss: 1.0858 Acc: 0.3333\n",
      "test Loss: 1.0870 Acc: 0.3333\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 1.0875 Acc: 0.3333\n",
      "val Loss: 1.0867 Acc: 0.3333\n",
      "test Loss: 1.0856 Acc: 0.3333\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 1.0843 Acc: 0.3333\n",
      "val Loss: 1.0832 Acc: 0.3333\n",
      "test Loss: 1.0834 Acc: 0.3333\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 1.0829 Acc: 0.3333\n",
      "val Loss: 1.0804 Acc: 0.3333\n",
      "test Loss: 1.0814 Acc: 0.3333\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 1.0807 Acc: 0.3333\n",
      "val Loss: 1.0811 Acc: 0.3333\n",
      "test Loss: 1.0779 Acc: 0.3333\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 1.0786 Acc: 0.3333\n",
      "val Loss: 1.0746 Acc: 0.3333\n",
      "test Loss: 1.0753 Acc: 0.3333\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 1.0754 Acc: 0.3333\n",
      "val Loss: 1.0746 Acc: 0.3333\n",
      "test Loss: 1.0745 Acc: 0.3333\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 1.0728 Acc: 0.3333\n",
      "val Loss: 1.0690 Acc: 0.3333\n",
      "test Loss: 1.0689 Acc: 0.3333\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 1.0698 Acc: 0.3333\n",
      "val Loss: 1.0699 Acc: 0.3333\n",
      "test Loss: 1.0633 Acc: 0.3333\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 1.0609 Acc: 0.3333\n",
      "val Loss: 1.0548 Acc: 0.3333\n",
      "test Loss: 1.0587 Acc: 0.3333\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 1.0574 Acc: 0.3333\n",
      "val Loss: 1.0524 Acc: 0.3333\n",
      "test Loss: 1.0546 Acc: 0.3333\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 1.0492 Acc: 0.3333\n",
      "val Loss: 1.0512 Acc: 0.3333\n",
      "test Loss: 1.0414 Acc: 0.3333\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 1.0462 Acc: 0.3333\n",
      "val Loss: 1.0466 Acc: 0.3333\n",
      "test Loss: 1.0337 Acc: 0.3333\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 1.0389 Acc: 0.3333\n",
      "val Loss: 1.0292 Acc: 0.3333\n",
      "test Loss: 1.0278 Acc: 0.3333\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 1.0312 Acc: 0.3333\n",
      "val Loss: 1.0283 Acc: 0.3333\n",
      "test Loss: 1.0271 Acc: 0.3333\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 1.0211 Acc: 0.3333\n",
      "val Loss: 1.0142 Acc: 0.3333\n",
      "test Loss: 1.0183 Acc: 0.3333\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 1.0089 Acc: 0.3333\n",
      "val Loss: 1.0064 Acc: 0.3333\n",
      "test Loss: 0.9982 Acc: 0.3333\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 1.0047 Acc: 0.3333\n",
      "val Loss: 0.9980 Acc: 0.3333\n",
      "test Loss: 0.9934 Acc: 0.3333\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.9990 Acc: 0.3333\n",
      "val Loss: 0.9853 Acc: 0.3333\n",
      "test Loss: 0.9942 Acc: 0.3333\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.9890 Acc: 0.3333\n",
      "val Loss: 0.9776 Acc: 0.3333\n",
      "test Loss: 0.9804 Acc: 0.3333\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.9895 Acc: 0.3333\n",
      "val Loss: 0.9804 Acc: 0.3333\n",
      "test Loss: 0.9686 Acc: 0.3333\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.9736 Acc: 0.3333\n",
      "val Loss: 0.9635 Acc: 0.3333\n",
      "test Loss: 0.9675 Acc: 0.3333\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.9623 Acc: 0.3333\n",
      "val Loss: 0.9598 Acc: 0.3333\n",
      "test Loss: 0.9580 Acc: 0.3333\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.9683 Acc: 0.3333\n",
      "val Loss: 0.9639 Acc: 0.3333\n",
      "test Loss: 0.9566 Acc: 0.3333\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.9591 Acc: 0.3333\n",
      "val Loss: 0.9486 Acc: 0.3333\n",
      "test Loss: 0.9460 Acc: 0.3333\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.9541 Acc: 0.3333\n",
      "val Loss: 0.9604 Acc: 0.3333\n",
      "test Loss: 0.9534 Acc: 0.3333\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.9538 Acc: 0.3333\n",
      "val Loss: 0.9456 Acc: 0.3333\n",
      "test Loss: 0.9382 Acc: 0.3333\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.9501 Acc: 0.3333\n",
      "val Loss: 0.9434 Acc: 0.3333\n",
      "test Loss: 0.9460 Acc: 0.3333\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.9422 Acc: 0.3444\n",
      "val Loss: 0.9362 Acc: 0.3667\n",
      "test Loss: 0.9373 Acc: 0.3333\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.9411 Acc: 0.3444\n",
      "val Loss: 0.9509 Acc: 0.3333\n",
      "test Loss: 0.9341 Acc: 0.3333\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.9440 Acc: 0.3667\n",
      "val Loss: 0.9404 Acc: 0.3333\n",
      "test Loss: 0.9344 Acc: 0.4000\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.9377 Acc: 0.3889\n",
      "val Loss: 0.9336 Acc: 0.3333\n",
      "test Loss: 0.9368 Acc: 0.3667\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.9374 Acc: 0.3444\n",
      "val Loss: 0.9318 Acc: 0.3333\n",
      "test Loss: 0.9322 Acc: 0.3333\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.9371 Acc: 0.3778\n",
      "val Loss: 0.9358 Acc: 0.4000\n",
      "test Loss: 0.9302 Acc: 0.4333\n",
      "Epoch 49/499\n",
      "----------\n",
      "train Loss: 0.9354 Acc: 0.5111\n",
      "val Loss: 0.9317 Acc: 0.6000\n",
      "test Loss: 0.9283 Acc: 0.6667\n",
      "Epoch 50/499\n",
      "----------\n",
      "train Loss: 0.9315 Acc: 0.6333\n",
      "val Loss: 0.9268 Acc: 0.6000\n",
      "test Loss: 0.9280 Acc: 0.6667\n",
      "Epoch 51/499\n",
      "----------\n",
      "train Loss: 0.9321 Acc: 0.6333\n",
      "val Loss: 0.9324 Acc: 0.6000\n",
      "test Loss: 0.9268 Acc: 0.6667\n",
      "Epoch 52/499\n",
      "----------\n",
      "train Loss: 0.9330 Acc: 0.6333\n",
      "val Loss: 0.9274 Acc: 0.6333\n",
      "test Loss: 0.9277 Acc: 0.6667\n",
      "Epoch 53/499\n",
      "----------\n",
      "train Loss: 0.9341 Acc: 0.6333\n",
      "val Loss: 0.9260 Acc: 0.6000\n",
      "test Loss: 0.9235 Acc: 0.6667\n",
      "Epoch 54/499\n",
      "----------\n",
      "train Loss: 0.9293 Acc: 0.6333\n",
      "val Loss: 0.9234 Acc: 0.6333\n",
      "test Loss: 0.9223 Acc: 0.6667\n",
      "Epoch 55/499\n",
      "----------\n",
      "train Loss: 0.9259 Acc: 0.6333\n",
      "val Loss: 0.9301 Acc: 0.6333\n",
      "test Loss: 0.9232 Acc: 0.6667\n",
      "Epoch 56/499\n",
      "----------\n",
      "train Loss: 0.9276 Acc: 0.6444\n",
      "val Loss: 0.9210 Acc: 0.6333\n",
      "test Loss: 0.9258 Acc: 0.6667\n",
      "Epoch 57/499\n",
      "----------\n",
      "train Loss: 0.9248 Acc: 0.6444\n",
      "val Loss: 0.9309 Acc: 0.6333\n",
      "test Loss: 0.9205 Acc: 0.6667\n",
      "Epoch 58/499\n",
      "----------\n",
      "train Loss: 0.9245 Acc: 0.6556\n",
      "val Loss: 0.9227 Acc: 0.6667\n",
      "test Loss: 0.9197 Acc: 0.6667\n",
      "Epoch 59/499\n",
      "----------\n",
      "train Loss: 0.9260 Acc: 0.6556\n",
      "val Loss: 0.9197 Acc: 0.6667\n",
      "test Loss: 0.9206 Acc: 0.6667\n",
      "Epoch 60/499\n",
      "----------\n",
      "train Loss: 0.9235 Acc: 0.6556\n",
      "val Loss: 0.9198 Acc: 0.6667\n",
      "test Loss: 0.9218 Acc: 0.6667\n",
      "Epoch 61/499\n",
      "----------\n",
      "train Loss: 0.9206 Acc: 0.6556\n",
      "val Loss: 0.9213 Acc: 0.6667\n",
      "test Loss: 0.9240 Acc: 0.6667\n",
      "Epoch 62/499\n",
      "----------\n",
      "train Loss: 0.9216 Acc: 0.6556\n",
      "val Loss: 0.9273 Acc: 0.6667\n",
      "test Loss: 0.9203 Acc: 0.6667\n",
      "Epoch 63/499\n",
      "----------\n",
      "train Loss: 0.9183 Acc: 0.6556\n",
      "val Loss: 0.9174 Acc: 0.6667\n",
      "test Loss: 0.9184 Acc: 0.6667\n",
      "Epoch 64/499\n",
      "----------\n",
      "train Loss: 0.9193 Acc: 0.6556\n",
      "val Loss: 0.9170 Acc: 0.6667\n",
      "test Loss: 0.9190 Acc: 0.6667\n",
      "Epoch 65/499\n",
      "----------\n",
      "train Loss: 0.9207 Acc: 0.6556\n",
      "val Loss: 0.9182 Acc: 0.6667\n",
      "test Loss: 0.9192 Acc: 0.6667\n",
      "Epoch 66/499\n",
      "----------\n",
      "train Loss: 0.9179 Acc: 0.6556\n",
      "val Loss: 0.9173 Acc: 0.6667\n",
      "test Loss: 0.9187 Acc: 0.6667\n",
      "Epoch 67/499\n",
      "----------\n",
      "train Loss: 0.9172 Acc: 0.6556\n",
      "val Loss: 0.9174 Acc: 0.6667\n",
      "test Loss: 0.9181 Acc: 0.6667\n",
      "Epoch 68/499\n",
      "----------\n",
      "train Loss: 0.9180 Acc: 0.6556\n",
      "val Loss: 0.9159 Acc: 0.6667\n",
      "test Loss: 0.9177 Acc: 0.6667\n",
      "Epoch 69/499\n",
      "----------\n",
      "train Loss: 0.9164 Acc: 0.6556\n",
      "val Loss: 0.9165 Acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.9351 Acc: 0.6333\n",
      "Epoch 70/499\n",
      "----------\n",
      "train Loss: 0.9153 Acc: 0.6556\n",
      "val Loss: 0.9224 Acc: 0.6667\n",
      "test Loss: 0.9144 Acc: 0.6667\n",
      "Epoch 71/499\n",
      "----------\n",
      "train Loss: 0.9178 Acc: 0.6667\n",
      "val Loss: 0.9147 Acc: 0.6667\n",
      "test Loss: 0.9140 Acc: 0.6667\n",
      "Epoch 72/499\n",
      "----------\n",
      "train Loss: 0.9148 Acc: 0.6667\n",
      "val Loss: 0.9157 Acc: 0.6667\n",
      "test Loss: 0.9135 Acc: 0.6667\n",
      "Epoch 73/499\n",
      "----------\n",
      "train Loss: 0.9148 Acc: 0.6667\n",
      "val Loss: 0.9131 Acc: 0.6667\n",
      "test Loss: 0.9131 Acc: 0.6667\n",
      "Epoch 74/499\n",
      "----------\n",
      "train Loss: 0.9147 Acc: 0.6667\n",
      "val Loss: 0.9136 Acc: 0.6667\n",
      "test Loss: 0.9126 Acc: 0.6667\n",
      "Epoch 75/499\n",
      "----------\n",
      "train Loss: 0.9128 Acc: 0.6667\n",
      "val Loss: 0.9129 Acc: 0.6667\n",
      "test Loss: 0.9129 Acc: 0.6667\n",
      "Epoch 76/499\n",
      "----------\n",
      "train Loss: 0.9141 Acc: 0.6667\n",
      "val Loss: 0.9120 Acc: 0.6667\n",
      "test Loss: 0.9118 Acc: 0.6667\n",
      "Epoch 77/499\n",
      "----------\n",
      "train Loss: 0.9128 Acc: 0.6667\n",
      "val Loss: 0.9120 Acc: 0.6667\n",
      "test Loss: 0.9121 Acc: 0.6667\n",
      "Epoch 78/499\n",
      "----------\n",
      "train Loss: 0.9116 Acc: 0.6667\n",
      "val Loss: 0.9111 Acc: 0.6667\n",
      "test Loss: 0.9133 Acc: 0.6667\n",
      "Epoch 79/499\n",
      "----------\n",
      "train Loss: 0.9126 Acc: 0.6667\n",
      "val Loss: 0.9143 Acc: 0.6667\n",
      "test Loss: 0.9109 Acc: 0.6667\n",
      "Epoch 80/499\n",
      "----------\n",
      "train Loss: 0.9128 Acc: 0.6667\n",
      "val Loss: 0.9110 Acc: 0.6667\n",
      "test Loss: 0.9104 Acc: 0.6667\n",
      "Epoch 81/499\n",
      "----------\n",
      "train Loss: 0.9116 Acc: 0.6667\n",
      "val Loss: 0.9103 Acc: 0.6667\n",
      "test Loss: 0.9148 Acc: 0.6667\n",
      "Epoch 82/499\n",
      "----------\n",
      "train Loss: 0.9103 Acc: 0.6667\n",
      "val Loss: 0.9112 Acc: 0.6667\n",
      "test Loss: 0.9097 Acc: 0.6667\n",
      "Epoch 83/499\n",
      "----------\n",
      "train Loss: 0.9105 Acc: 0.6667\n",
      "val Loss: 0.9095 Acc: 0.6667\n",
      "test Loss: 0.9099 Acc: 0.6667\n",
      "Epoch 84/499\n",
      "----------\n",
      "train Loss: 0.9094 Acc: 0.6667\n",
      "val Loss: 0.9088 Acc: 0.6667\n",
      "test Loss: 0.9089 Acc: 0.6667\n",
      "Epoch 85/499\n",
      "----------\n",
      "train Loss: 0.9101 Acc: 0.6667\n",
      "val Loss: 0.9103 Acc: 0.6667\n",
      "test Loss: 0.9088 Acc: 0.6667\n",
      "Epoch 86/499\n",
      "----------\n",
      "train Loss: 0.9095 Acc: 0.6667\n",
      "val Loss: 0.9084 Acc: 0.6667\n",
      "test Loss: 0.9085 Acc: 0.6667\n",
      "Epoch 87/499\n",
      "----------\n",
      "train Loss: 0.9121 Acc: 0.6667\n",
      "val Loss: 0.9103 Acc: 0.6667\n",
      "test Loss: 0.9093 Acc: 0.6667\n",
      "Epoch 88/499\n",
      "----------\n",
      "train Loss: 0.9082 Acc: 0.6667\n",
      "val Loss: 0.9076 Acc: 0.6667\n",
      "test Loss: 0.9075 Acc: 0.6667\n",
      "Epoch 89/499\n",
      "----------\n",
      "train Loss: 0.9081 Acc: 0.6667\n",
      "val Loss: 0.9071 Acc: 0.6667\n",
      "test Loss: 0.9074 Acc: 0.6667\n",
      "Epoch 90/499\n",
      "----------\n",
      "train Loss: 0.9074 Acc: 0.6667\n",
      "val Loss: 0.9074 Acc: 0.6667\n",
      "test Loss: 0.9081 Acc: 0.6667\n",
      "Epoch 91/499\n",
      "----------\n",
      "train Loss: 0.9120 Acc: 0.6667\n",
      "val Loss: 0.9068 Acc: 0.6667\n",
      "test Loss: 0.9071 Acc: 0.6667\n",
      "Epoch 92/499\n",
      "----------\n",
      "train Loss: 0.9066 Acc: 0.6667\n",
      "val Loss: 0.9073 Acc: 0.6667\n",
      "test Loss: 0.9077 Acc: 0.6667\n",
      "Epoch 93/499\n",
      "----------\n",
      "train Loss: 0.9071 Acc: 0.6667\n",
      "val Loss: 0.9074 Acc: 0.6667\n",
      "test Loss: 0.9063 Acc: 0.6667\n",
      "Epoch 94/499\n",
      "----------\n",
      "train Loss: 0.9062 Acc: 0.6667\n",
      "val Loss: 0.9079 Acc: 0.6667\n",
      "test Loss: 0.9097 Acc: 0.6667\n",
      "Epoch 95/499\n",
      "----------\n",
      "train Loss: 0.9060 Acc: 0.6667\n",
      "val Loss: 0.9050 Acc: 0.6667\n",
      "test Loss: 0.9050 Acc: 0.6667\n",
      "Epoch 96/499\n",
      "----------\n",
      "train Loss: 0.9051 Acc: 0.6667\n",
      "val Loss: 0.9050 Acc: 0.6667\n",
      "test Loss: 0.9046 Acc: 0.6667\n",
      "Epoch 97/499\n",
      "----------\n",
      "train Loss: 0.9082 Acc: 0.6667\n",
      "val Loss: 0.9043 Acc: 0.6667\n",
      "test Loss: 0.9059 Acc: 0.6667\n",
      "Epoch 98/499\n",
      "----------\n",
      "train Loss: 0.9045 Acc: 0.6667\n",
      "val Loss: 0.9040 Acc: 0.6667\n",
      "test Loss: 0.9043 Acc: 0.6667\n",
      "Epoch 99/499\n",
      "----------\n",
      "train Loss: 0.9043 Acc: 0.6667\n",
      "val Loss: 0.9040 Acc: 0.6667\n",
      "test Loss: 0.9037 Acc: 0.6667\n",
      "Epoch 100/499\n",
      "----------\n",
      "train Loss: 0.9050 Acc: 0.6667\n",
      "val Loss: 0.9044 Acc: 0.6667\n",
      "test Loss: 0.9033 Acc: 0.6667\n",
      "Epoch 101/499\n",
      "----------\n",
      "train Loss: 0.9035 Acc: 0.6667\n",
      "val Loss: 0.9034 Acc: 0.6667\n",
      "test Loss: 0.9033 Acc: 0.6667\n",
      "Epoch 102/499\n",
      "----------\n",
      "train Loss: 0.9042 Acc: 0.6667\n",
      "val Loss: 0.9026 Acc: 0.6667\n",
      "test Loss: 0.9039 Acc: 0.6667\n",
      "Epoch 103/499\n",
      "----------\n",
      "train Loss: 0.9026 Acc: 0.6667\n",
      "val Loss: 0.9023 Acc: 0.6667\n",
      "test Loss: 0.9025 Acc: 0.6667\n",
      "Epoch 104/499\n",
      "----------\n",
      "train Loss: 0.9033 Acc: 0.6667\n",
      "val Loss: 0.9021 Acc: 0.6667\n",
      "test Loss: 0.9032 Acc: 0.6667\n",
      "Epoch 105/499\n",
      "----------\n",
      "train Loss: 0.9021 Acc: 0.6667\n",
      "val Loss: 0.9018 Acc: 0.6667\n",
      "test Loss: 0.9016 Acc: 0.6667\n",
      "Epoch 106/499\n",
      "----------\n",
      "train Loss: 0.9044 Acc: 0.6667\n",
      "val Loss: 0.9021 Acc: 0.6667\n",
      "test Loss: 0.9016 Acc: 0.6667\n",
      "Epoch 107/499\n",
      "----------\n",
      "train Loss: 0.9015 Acc: 0.6667\n",
      "val Loss: 0.9022 Acc: 0.6667\n",
      "test Loss: 0.9010 Acc: 0.6667\n",
      "Epoch 108/499\n",
      "----------\n",
      "train Loss: 0.9015 Acc: 0.6667\n",
      "val Loss: 0.9006 Acc: 0.6667\n",
      "test Loss: 0.9006 Acc: 0.6667\n",
      "Epoch 109/499\n",
      "----------\n",
      "train Loss: 0.9011 Acc: 0.6667\n",
      "val Loss: 0.9006 Acc: 0.6667\n",
      "test Loss: 0.9008 Acc: 0.6667\n",
      "Epoch 110/499\n",
      "----------\n",
      "train Loss: 0.9004 Acc: 0.6667\n",
      "val Loss: 0.9030 Acc: 0.6667\n",
      "test Loss: 0.9002 Acc: 0.6667\n",
      "Epoch 111/499\n",
      "----------\n",
      "train Loss: 0.9000 Acc: 0.6667\n",
      "val Loss: 0.8999 Acc: 0.6667\n",
      "test Loss: 0.8997 Acc: 0.6667\n",
      "Epoch 112/499\n",
      "----------\n",
      "train Loss: 0.9001 Acc: 0.6667\n",
      "val Loss: 0.8994 Acc: 0.6667\n",
      "test Loss: 0.8993 Acc: 0.6667\n",
      "Epoch 113/499\n",
      "----------\n",
      "train Loss: 0.8997 Acc: 0.6667\n",
      "val Loss: 0.8991 Acc: 0.6667\n",
      "test Loss: 0.8990 Acc: 0.6667\n",
      "Epoch 114/499\n",
      "----------\n",
      "train Loss: 0.8991 Acc: 0.6667\n",
      "val Loss: 0.8991 Acc: 0.6667\n",
      "test Loss: 0.8988 Acc: 0.6667\n",
      "Epoch 115/499\n",
      "----------\n",
      "train Loss: 0.8986 Acc: 0.6667\n",
      "val Loss: 0.8985 Acc: 0.6667\n",
      "test Loss: 0.8989 Acc: 0.6667\n",
      "Epoch 116/499\n",
      "----------\n",
      "train Loss: 0.8984 Acc: 0.6667\n",
      "val Loss: 0.8980 Acc: 0.6667\n",
      "test Loss: 0.8985 Acc: 0.6667\n",
      "Epoch 117/499\n",
      "----------\n",
      "train Loss: 0.8981 Acc: 0.6667\n",
      "val Loss: 0.9027 Acc: 0.6667\n",
      "test Loss: 0.8984 Acc: 0.6667\n",
      "Epoch 118/499\n",
      "----------\n",
      "train Loss: 0.8985 Acc: 0.6667\n",
      "val Loss: 0.8974 Acc: 0.6667\n",
      "test Loss: 0.9005 Acc: 0.6667\n",
      "Epoch 119/499\n",
      "----------\n",
      "train Loss: 0.8977 Acc: 0.6667\n",
      "val Loss: 0.8976 Acc: 0.6667\n",
      "test Loss: 0.8975 Acc: 0.6667\n",
      "Epoch 120/499\n",
      "----------\n",
      "train Loss: 0.8970 Acc: 0.6667\n",
      "val Loss: 0.8970 Acc: 0.6667\n",
      "test Loss: 0.8969 Acc: 0.6667\n",
      "Epoch 121/499\n",
      "----------\n",
      "train Loss: 0.8969 Acc: 0.6667\n",
      "val Loss: 0.8968 Acc: 0.6667\n",
      "test Loss: 0.8970 Acc: 0.6667\n",
      "Epoch 122/499\n",
      "----------\n",
      "train Loss: 0.8968 Acc: 0.6667\n",
      "val Loss: 0.8962 Acc: 0.6667\n",
      "test Loss: 0.8989 Acc: 0.6667\n",
      "Epoch 123/499\n",
      "----------\n",
      "train Loss: 0.8964 Acc: 0.6667\n",
      "val Loss: 0.8961 Acc: 0.6667\n",
      "test Loss: 0.8960 Acc: 0.6667\n",
      "Epoch 124/499\n",
      "----------\n",
      "train Loss: 0.8963 Acc: 0.6667\n",
      "val Loss: 0.8957 Acc: 0.6667\n",
      "test Loss: 0.9050 Acc: 0.6667\n",
      "Epoch 125/499\n",
      "----------\n",
      "train Loss: 0.8958 Acc: 0.6667\n",
      "val Loss: 0.8955 Acc: 0.6667\n",
      "test Loss: 0.8955 Acc: 0.6667\n",
      "Epoch 126/499\n",
      "----------\n",
      "train Loss: 0.8953 Acc: 0.6667\n",
      "val Loss: 0.8949 Acc: 0.6667\n",
      "test Loss: 0.8951 Acc: 0.6667\n",
      "Epoch 127/499\n",
      "----------\n",
      "train Loss: 0.8949 Acc: 0.6667\n",
      "val Loss: 0.8946 Acc: 0.6667\n",
      "test Loss: 0.8949 Acc: 0.6667\n",
      "Epoch 128/499\n",
      "----------\n",
      "train Loss: 0.8946 Acc: 0.6667\n",
      "val Loss: 0.8945 Acc: 0.6667\n",
      "test Loss: 0.8954 Acc: 0.6667\n",
      "Epoch 129/499\n",
      "----------\n",
      "train Loss: 0.8948 Acc: 0.6667\n",
      "val Loss: 0.8941 Acc: 0.6667\n",
      "test Loss: 0.8944 Acc: 0.6667\n",
      "Epoch 130/499\n",
      "----------\n",
      "train Loss: 0.8943 Acc: 0.6667\n",
      "val Loss: 0.8938 Acc: 0.6667\n",
      "test Loss: 0.8940 Acc: 0.6667\n",
      "Epoch 131/499\n",
      "----------\n",
      "train Loss: 0.8942 Acc: 0.6667\n",
      "val Loss: 0.8937 Acc: 0.6667\n",
      "test Loss: 0.8935 Acc: 0.6667\n",
      "Epoch 132/499\n",
      "----------\n",
      "train Loss: 0.8941 Acc: 0.6667\n",
      "val Loss: 0.8931 Acc: 0.6667\n",
      "test Loss: 0.8932 Acc: 0.6667\n",
      "Epoch 133/499\n",
      "----------\n",
      "train Loss: 0.8932 Acc: 0.6667\n",
      "val Loss: 0.8929 Acc: 0.6667\n",
      "test Loss: 0.8931 Acc: 0.6667\n",
      "Epoch 134/499\n",
      "----------\n",
      "train Loss: 0.8931 Acc: 0.6667\n",
      "val Loss: 0.8925 Acc: 0.6667\n",
      "test Loss: 0.8940 Acc: 0.6667\n",
      "Epoch 135/499\n",
      "----------\n",
      "train Loss: 0.8936 Acc: 0.6667\n",
      "val Loss: 0.8926 Acc: 0.6667\n",
      "test Loss: 0.8922 Acc: 0.6667\n",
      "Epoch 136/499\n",
      "----------\n",
      "train Loss: 0.8928 Acc: 0.6667\n",
      "val Loss: 0.8919 Acc: 0.6667\n",
      "test Loss: 0.8919 Acc: 0.6667\n",
      "Epoch 137/499\n",
      "----------\n",
      "train Loss: 0.8921 Acc: 0.6667\n",
      "val Loss: 0.8921 Acc: 0.6667\n",
      "test Loss: 0.8917 Acc: 0.6667\n",
      "Epoch 138/499\n",
      "----------\n",
      "train Loss: 0.8917 Acc: 0.6667\n",
      "val Loss: 0.8920 Acc: 0.6667\n",
      "test Loss: 0.8913 Acc: 0.6667\n",
      "Epoch 139/499\n",
      "----------\n",
      "train Loss: 0.8917 Acc: 0.6667\n",
      "val Loss: 0.8911 Acc: 0.6667\n",
      "test Loss: 0.8911 Acc: 0.6667\n",
      "Epoch 140/499\n",
      "----------\n",
      "train Loss: 0.8910 Acc: 0.6667\n",
      "val Loss: 0.8913 Acc: 0.6667\n",
      "test Loss: 0.8909 Acc: 0.6667\n",
      "Epoch 141/499\n",
      "----------\n",
      "train Loss: 0.8909 Acc: 0.6667\n",
      "val Loss: 0.8904 Acc: 0.6667\n",
      "test Loss: 0.8906 Acc: 0.6667\n",
      "Epoch 142/499\n",
      "----------\n",
      "train Loss: 0.8906 Acc: 0.6667\n",
      "val Loss: 0.8902 Acc: 0.6667\n",
      "test Loss: 0.8901 Acc: 0.6667\n",
      "Epoch 143/499\n",
      "----------\n",
      "train Loss: 0.8901 Acc: 0.6667\n",
      "val Loss: 0.8900 Acc: 0.6667\n",
      "test Loss: 0.8899 Acc: 0.6667\n",
      "Epoch 144/499\n",
      "----------\n",
      "train Loss: 0.8898 Acc: 0.6667\n",
      "val Loss: 0.8896 Acc: 0.6667\n",
      "test Loss: 0.8896 Acc: 0.6667\n",
      "Epoch 145/499\n",
      "----------\n",
      "train Loss: 0.8897 Acc: 0.6667\n",
      "val Loss: 0.8893 Acc: 0.6667\n",
      "test Loss: 0.8894 Acc: 0.6667\n",
      "Epoch 146/499\n",
      "----------\n",
      "train Loss: 0.8895 Acc: 0.6667\n",
      "val Loss: 0.8890 Acc: 0.6667\n",
      "test Loss: 0.8895 Acc: 0.6667\n",
      "Epoch 147/499\n",
      "----------\n",
      "train Loss: 0.8892 Acc: 0.6667\n",
      "val Loss: 0.8887 Acc: 0.6667\n",
      "test Loss: 0.8888 Acc: 0.6667\n",
      "Epoch 148/499\n",
      "----------\n",
      "train Loss: 0.8886 Acc: 0.6667\n",
      "val Loss: 0.8884 Acc: 0.6667\n",
      "test Loss: 0.8884 Acc: 0.6667\n",
      "Epoch 149/499\n",
      "----------\n",
      "train Loss: 0.8886 Acc: 0.6667\n",
      "val Loss: 0.8881 Acc: 0.6667\n",
      "test Loss: 0.8882 Acc: 0.6667\n",
      "Epoch 150/499\n",
      "----------\n",
      "train Loss: 0.8882 Acc: 0.6667\n",
      "val Loss: 0.8879 Acc: 0.6667\n",
      "test Loss: 0.8880 Acc: 0.6667\n",
      "Epoch 151/499\n",
      "----------\n",
      "train Loss: 0.8879 Acc: 0.6667\n",
      "val Loss: 0.8876 Acc: 0.6667\n",
      "test Loss: 0.8877 Acc: 0.6667\n",
      "Epoch 152/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.8880 Acc: 0.6667\n",
      "val Loss: 0.8873 Acc: 0.6667\n",
      "test Loss: 0.8873 Acc: 0.6667\n",
      "Epoch 153/499\n",
      "----------\n",
      "train Loss: 0.8876 Acc: 0.6667\n",
      "val Loss: 0.8870 Acc: 0.6667\n",
      "test Loss: 0.8877 Acc: 0.6667\n",
      "Epoch 154/499\n",
      "----------\n",
      "train Loss: 0.8870 Acc: 0.6667\n",
      "val Loss: 0.8868 Acc: 0.6667\n",
      "test Loss: 0.8869 Acc: 0.6667\n",
      "Epoch 155/499\n",
      "----------\n",
      "train Loss: 0.8869 Acc: 0.6667\n",
      "val Loss: 0.8866 Acc: 0.6667\n",
      "test Loss: 0.8865 Acc: 0.6667\n",
      "Epoch 156/499\n",
      "----------\n",
      "train Loss: 0.8865 Acc: 0.6667\n",
      "val Loss: 0.8866 Acc: 0.6667\n",
      "test Loss: 0.8862 Acc: 0.6667\n",
      "Epoch 157/499\n",
      "----------\n",
      "train Loss: 0.8870 Acc: 0.6667\n",
      "val Loss: 0.8859 Acc: 0.6667\n",
      "test Loss: 0.8859 Acc: 0.6667\n",
      "Epoch 158/499\n",
      "----------\n",
      "train Loss: 0.8860 Acc: 0.6667\n",
      "val Loss: 0.8861 Acc: 0.6667\n",
      "test Loss: 0.8865 Acc: 0.6667\n",
      "Epoch 159/499\n",
      "----------\n",
      "train Loss: 0.8856 Acc: 0.6667\n",
      "val Loss: 0.8855 Acc: 0.6667\n",
      "test Loss: 0.8860 Acc: 0.6667\n",
      "Epoch 160/499\n",
      "----------\n",
      "train Loss: 0.8855 Acc: 0.6667\n",
      "val Loss: 0.8851 Acc: 0.6667\n",
      "test Loss: 0.8851 Acc: 0.6667\n",
      "Epoch 161/499\n",
      "----------\n",
      "train Loss: 0.8855 Acc: 0.6667\n",
      "val Loss: 0.8848 Acc: 0.6667\n",
      "test Loss: 0.8848 Acc: 0.6667\n",
      "Epoch 162/499\n",
      "----------\n",
      "train Loss: 0.8868 Acc: 0.6667\n",
      "val Loss: 0.8845 Acc: 0.6667\n",
      "test Loss: 0.8846 Acc: 0.6667\n",
      "Epoch 163/499\n",
      "----------\n",
      "train Loss: 0.8851 Acc: 0.6667\n",
      "val Loss: 0.8843 Acc: 0.6667\n",
      "test Loss: 0.8844 Acc: 0.6667\n",
      "Epoch 164/499\n",
      "----------\n",
      "train Loss: 0.8843 Acc: 0.6667\n",
      "val Loss: 0.8840 Acc: 0.6667\n",
      "test Loss: 0.8842 Acc: 0.6667\n",
      "Epoch 165/499\n",
      "----------\n",
      "train Loss: 0.8839 Acc: 0.6667\n",
      "val Loss: 0.8837 Acc: 0.6667\n",
      "test Loss: 0.8837 Acc: 0.6667\n",
      "Epoch 166/499\n",
      "----------\n",
      "train Loss: 0.8838 Acc: 0.6667\n",
      "val Loss: 0.8835 Acc: 0.6667\n",
      "test Loss: 0.8836 Acc: 0.6667\n",
      "Epoch 167/499\n",
      "----------\n",
      "train Loss: 0.8834 Acc: 0.6667\n",
      "val Loss: 0.8832 Acc: 0.6667\n",
      "test Loss: 0.8832 Acc: 0.6667\n",
      "Epoch 168/499\n",
      "----------\n",
      "train Loss: 0.8832 Acc: 0.6667\n",
      "val Loss: 0.8831 Acc: 0.6667\n",
      "test Loss: 0.8829 Acc: 0.6667\n",
      "Epoch 169/499\n",
      "----------\n",
      "train Loss: 0.8829 Acc: 0.6667\n",
      "val Loss: 0.8827 Acc: 0.6667\n",
      "test Loss: 0.8830 Acc: 0.6667\n",
      "Epoch 170/499\n",
      "----------\n",
      "train Loss: 0.8825 Acc: 0.6667\n",
      "val Loss: 0.8829 Acc: 0.6667\n",
      "test Loss: 0.8823 Acc: 0.6667\n",
      "Epoch 171/499\n",
      "----------\n",
      "train Loss: 0.8827 Acc: 0.6667\n",
      "val Loss: 0.8826 Acc: 0.6667\n",
      "test Loss: 0.8826 Acc: 0.6667\n",
      "Epoch 172/499\n",
      "----------\n",
      "train Loss: 0.8820 Acc: 0.6667\n",
      "val Loss: 0.8818 Acc: 0.6667\n",
      "test Loss: 0.8818 Acc: 0.6667\n",
      "Epoch 173/499\n",
      "----------\n",
      "train Loss: 0.8821 Acc: 0.6667\n",
      "val Loss: 0.8816 Acc: 0.6667\n",
      "test Loss: 0.8816 Acc: 0.6667\n",
      "Epoch 174/499\n",
      "----------\n",
      "train Loss: 0.8816 Acc: 0.6667\n",
      "val Loss: 0.8815 Acc: 0.6667\n",
      "test Loss: 0.8815 Acc: 0.6667\n",
      "Epoch 175/499\n",
      "----------\n",
      "train Loss: 0.8812 Acc: 0.6667\n",
      "val Loss: 0.8810 Acc: 0.6667\n",
      "test Loss: 0.8810 Acc: 0.6667\n",
      "Epoch 176/499\n",
      "----------\n",
      "train Loss: 0.8810 Acc: 0.6667\n",
      "val Loss: 0.8808 Acc: 0.6667\n",
      "test Loss: 0.8808 Acc: 0.6667\n",
      "Epoch 177/499\n",
      "----------\n",
      "train Loss: 0.8808 Acc: 0.6667\n",
      "val Loss: 0.8806 Acc: 0.6667\n",
      "test Loss: 0.8805 Acc: 0.6667\n",
      "Epoch 178/499\n",
      "----------\n",
      "train Loss: 0.8804 Acc: 0.6667\n",
      "val Loss: 0.8803 Acc: 0.6667\n",
      "test Loss: 0.8806 Acc: 0.6667\n",
      "Epoch 179/499\n",
      "----------\n",
      "train Loss: 0.8802 Acc: 0.6667\n",
      "val Loss: 0.8800 Acc: 0.6667\n",
      "test Loss: 0.8800 Acc: 0.6667\n",
      "Epoch 180/499\n",
      "----------\n",
      "train Loss: 0.8800 Acc: 0.6667\n",
      "val Loss: 0.8798 Acc: 0.6667\n",
      "test Loss: 0.8799 Acc: 0.6667\n",
      "Epoch 181/499\n",
      "----------\n",
      "train Loss: 0.8797 Acc: 0.6667\n",
      "val Loss: 0.8802 Acc: 0.6667\n",
      "test Loss: 0.8794 Acc: 0.6667\n",
      "Epoch 182/499\n",
      "----------\n",
      "train Loss: 0.8796 Acc: 0.6667\n",
      "val Loss: 0.8795 Acc: 0.6667\n",
      "test Loss: 0.8796 Acc: 0.6667\n",
      "Epoch 183/499\n",
      "----------\n",
      "train Loss: 0.8792 Acc: 0.6667\n",
      "val Loss: 0.8789 Acc: 0.6667\n",
      "test Loss: 0.8789 Acc: 0.6667\n",
      "Epoch 184/499\n",
      "----------\n",
      "train Loss: 0.8792 Acc: 0.6667\n",
      "val Loss: 0.8788 Acc: 0.6667\n",
      "test Loss: 0.8787 Acc: 0.6667\n",
      "Epoch 185/499\n",
      "----------\n",
      "train Loss: 0.8786 Acc: 0.6667\n",
      "val Loss: 0.8784 Acc: 0.6667\n",
      "test Loss: 0.8785 Acc: 0.6667\n",
      "Epoch 186/499\n",
      "----------\n",
      "train Loss: 0.8783 Acc: 0.6667\n",
      "val Loss: 0.8782 Acc: 0.6667\n",
      "test Loss: 0.8782 Acc: 0.6667\n",
      "Epoch 187/499\n",
      "----------\n",
      "train Loss: 0.8781 Acc: 0.6667\n",
      "val Loss: 0.8779 Acc: 0.6667\n",
      "test Loss: 0.8779 Acc: 0.6667\n",
      "Epoch 188/499\n",
      "----------\n",
      "train Loss: 0.8779 Acc: 0.6667\n",
      "val Loss: 0.8778 Acc: 0.6667\n",
      "test Loss: 0.8779 Acc: 0.6667\n",
      "Epoch 189/499\n",
      "----------\n",
      "train Loss: 0.8776 Acc: 0.6667\n",
      "val Loss: 0.8774 Acc: 0.6667\n",
      "test Loss: 0.8775 Acc: 0.6667\n",
      "Epoch 190/499\n",
      "----------\n",
      "train Loss: 0.8774 Acc: 0.6667\n",
      "val Loss: 0.8771 Acc: 0.6667\n",
      "test Loss: 0.8772 Acc: 0.6667\n",
      "Epoch 191/499\n",
      "----------\n",
      "train Loss: 0.8771 Acc: 0.6667\n",
      "val Loss: 0.8769 Acc: 0.6667\n",
      "test Loss: 0.8769 Acc: 0.6667\n",
      "Epoch 192/499\n",
      "----------\n",
      "train Loss: 0.8769 Acc: 0.6667\n",
      "val Loss: 0.8766 Acc: 0.6667\n",
      "test Loss: 0.8783 Acc: 0.6667\n",
      "Epoch 193/499\n",
      "----------\n",
      "train Loss: 0.8767 Acc: 0.6667\n",
      "val Loss: 0.8764 Acc: 0.6667\n",
      "test Loss: 0.8764 Acc: 0.6667\n",
      "Epoch 194/499\n",
      "----------\n",
      "train Loss: 0.8765 Acc: 0.6667\n",
      "val Loss: 0.8761 Acc: 0.6667\n",
      "test Loss: 0.8763 Acc: 0.6667\n",
      "Epoch 195/499\n",
      "----------\n",
      "train Loss: 0.8761 Acc: 0.6667\n",
      "val Loss: 0.8761 Acc: 0.6667\n",
      "test Loss: 0.8759 Acc: 0.6667\n",
      "Epoch 196/499\n",
      "----------\n",
      "train Loss: 0.8758 Acc: 0.6667\n",
      "val Loss: 0.8756 Acc: 0.6667\n",
      "test Loss: 0.8756 Acc: 0.6667\n",
      "Epoch 197/499\n",
      "----------\n",
      "train Loss: 0.8757 Acc: 0.6667\n",
      "val Loss: 0.8754 Acc: 0.6667\n",
      "test Loss: 0.8754 Acc: 0.6667\n",
      "Epoch 198/499\n",
      "----------\n",
      "train Loss: 0.8754 Acc: 0.6667\n",
      "val Loss: 0.8751 Acc: 0.6667\n",
      "test Loss: 0.8751 Acc: 0.6667\n",
      "Epoch 199/499\n",
      "----------\n",
      "train Loss: 0.8752 Acc: 0.6667\n",
      "val Loss: 0.8749 Acc: 0.6667\n",
      "test Loss: 0.8753 Acc: 0.6667\n",
      "Epoch 200/499\n",
      "----------\n",
      "train Loss: 0.8748 Acc: 0.6667\n",
      "val Loss: 0.8746 Acc: 0.6667\n",
      "test Loss: 0.8746 Acc: 0.6667\n",
      "Epoch 201/499\n",
      "----------\n",
      "train Loss: 0.8748 Acc: 0.6667\n",
      "val Loss: 0.8745 Acc: 0.6667\n",
      "test Loss: 0.8744 Acc: 0.6667\n",
      "Epoch 202/499\n",
      "----------\n",
      "train Loss: 0.8743 Acc: 0.6667\n",
      "val Loss: 0.8744 Acc: 0.6667\n",
      "test Loss: 0.8744 Acc: 0.6667\n",
      "Epoch 203/499\n",
      "----------\n",
      "train Loss: 0.8741 Acc: 0.6667\n",
      "val Loss: 0.8739 Acc: 0.6667\n",
      "test Loss: 0.8743 Acc: 0.6667\n",
      "Epoch 204/499\n",
      "----------\n",
      "train Loss: 0.8742 Acc: 0.6667\n",
      "val Loss: 0.8736 Acc: 0.6667\n",
      "test Loss: 0.8736 Acc: 0.6667\n",
      "Epoch 205/499\n",
      "----------\n",
      "train Loss: 0.8738 Acc: 0.6667\n",
      "val Loss: 0.8734 Acc: 0.6667\n",
      "test Loss: 0.8734 Acc: 0.6667\n",
      "Epoch 206/499\n",
      "----------\n",
      "train Loss: 0.8733 Acc: 0.6667\n",
      "val Loss: 0.8731 Acc: 0.6667\n",
      "test Loss: 0.8732 Acc: 0.6667\n",
      "Epoch 207/499\n",
      "----------\n",
      "train Loss: 0.8731 Acc: 0.6667\n",
      "val Loss: 0.8732 Acc: 0.6667\n",
      "test Loss: 0.8733 Acc: 0.6667\n",
      "Epoch 208/499\n",
      "----------\n",
      "train Loss: 0.8729 Acc: 0.6667\n",
      "val Loss: 0.8728 Acc: 0.6667\n",
      "test Loss: 0.8727 Acc: 0.6667\n",
      "Epoch 209/499\n",
      "----------\n",
      "train Loss: 0.8727 Acc: 0.6667\n",
      "val Loss: 0.8728 Acc: 0.6667\n",
      "test Loss: 0.8724 Acc: 0.6667\n",
      "Epoch 210/499\n",
      "----------\n",
      "train Loss: 0.8724 Acc: 0.6667\n",
      "val Loss: 0.8734 Acc: 0.6667\n",
      "test Loss: 0.8722 Acc: 0.6667\n",
      "Epoch 211/499\n",
      "----------\n",
      "train Loss: 0.8722 Acc: 0.6667\n",
      "val Loss: 0.8721 Acc: 0.6667\n",
      "test Loss: 0.8742 Acc: 0.6667\n",
      "Epoch 212/499\n",
      "----------\n",
      "train Loss: 0.8719 Acc: 0.6667\n",
      "val Loss: 0.8793 Acc: 0.6667\n",
      "test Loss: 0.8717 Acc: 0.6667\n",
      "Epoch 213/499\n",
      "----------\n",
      "train Loss: 0.8717 Acc: 0.6667\n",
      "val Loss: 0.8717 Acc: 0.6667\n",
      "test Loss: 0.8716 Acc: 0.6667\n",
      "Epoch 214/499\n",
      "----------\n",
      "train Loss: 0.8715 Acc: 0.6667\n",
      "val Loss: 0.8712 Acc: 0.6667\n",
      "test Loss: 0.8712 Acc: 0.6667\n",
      "Epoch 215/499\n",
      "----------\n",
      "train Loss: 0.8713 Acc: 0.6667\n",
      "val Loss: 0.8710 Acc: 0.6667\n",
      "test Loss: 0.8710 Acc: 0.6667\n",
      "Epoch 216/499\n",
      "----------\n",
      "train Loss: 0.8709 Acc: 0.6667\n",
      "val Loss: 0.8707 Acc: 0.6667\n",
      "test Loss: 0.8708 Acc: 0.6667\n",
      "Epoch 217/499\n",
      "----------\n",
      "train Loss: 0.8706 Acc: 0.6667\n",
      "val Loss: 0.8705 Acc: 0.6667\n",
      "test Loss: 0.8705 Acc: 0.6667\n",
      "Epoch 218/499\n",
      "----------\n",
      "train Loss: 0.8705 Acc: 0.6667\n",
      "val Loss: 0.8703 Acc: 0.6667\n",
      "test Loss: 0.8703 Acc: 0.6667\n",
      "Epoch 219/499\n",
      "----------\n",
      "train Loss: 0.8703 Acc: 0.6667\n",
      "val Loss: 0.8702 Acc: 0.6667\n",
      "test Loss: 0.8700 Acc: 0.6667\n",
      "Epoch 220/499\n",
      "----------\n",
      "train Loss: 0.8701 Acc: 0.6667\n",
      "val Loss: 0.8698 Acc: 0.6667\n",
      "test Loss: 0.8698 Acc: 0.6667\n",
      "Epoch 221/499\n",
      "----------\n",
      "train Loss: 0.8697 Acc: 0.6667\n",
      "val Loss: 0.8698 Acc: 0.6667\n",
      "test Loss: 0.8696 Acc: 0.6667\n",
      "Epoch 222/499\n",
      "----------\n",
      "train Loss: 0.8694 Acc: 0.6667\n",
      "val Loss: 0.8693 Acc: 0.6667\n",
      "test Loss: 0.8693 Acc: 0.6667\n",
      "Epoch 223/499\n",
      "----------\n",
      "train Loss: 0.8693 Acc: 0.6667\n",
      "val Loss: 0.8693 Acc: 0.6667\n",
      "test Loss: 0.8692 Acc: 0.6667\n",
      "Epoch 224/499\n",
      "----------\n",
      "train Loss: 0.8690 Acc: 0.6667\n",
      "val Loss: 0.8690 Acc: 0.6667\n",
      "test Loss: 0.8690 Acc: 0.6667\n",
      "Epoch 225/499\n",
      "----------\n",
      "train Loss: 0.8687 Acc: 0.6667\n",
      "val Loss: 0.8686 Acc: 0.6667\n",
      "test Loss: 0.8689 Acc: 0.6667\n",
      "Epoch 226/499\n",
      "----------\n",
      "train Loss: 0.8686 Acc: 0.6667\n",
      "val Loss: 0.8685 Acc: 0.6667\n",
      "test Loss: 0.8684 Acc: 0.6667\n",
      "Epoch 227/499\n",
      "----------\n",
      "train Loss: 0.8685 Acc: 0.6667\n",
      "val Loss: 0.8683 Acc: 0.6667\n",
      "test Loss: 0.8683 Acc: 0.6667\n",
      "Epoch 228/499\n",
      "----------\n",
      "train Loss: 0.8681 Acc: 0.6667\n",
      "val Loss: 0.8681 Acc: 0.6667\n",
      "test Loss: 0.8679 Acc: 0.6667\n",
      "Epoch 229/499\n",
      "----------\n",
      "train Loss: 0.8689 Acc: 0.6667\n",
      "val Loss: 0.8677 Acc: 0.6667\n",
      "test Loss: 0.8697 Acc: 0.6667\n",
      "Epoch 230/499\n",
      "----------\n",
      "train Loss: 0.8676 Acc: 0.6667\n",
      "val Loss: 0.8675 Acc: 0.6667\n",
      "test Loss: 0.8675 Acc: 0.6667\n",
      "Epoch 231/499\n",
      "----------\n",
      "train Loss: 0.8674 Acc: 0.6667\n",
      "val Loss: 0.8673 Acc: 0.6667\n",
      "test Loss: 0.8676 Acc: 0.6667\n",
      "Epoch 232/499\n",
      "----------\n",
      "train Loss: 0.8671 Acc: 0.6667\n",
      "val Loss: 0.8672 Acc: 0.6667\n",
      "test Loss: 0.8670 Acc: 0.6667\n",
      "Epoch 233/499\n",
      "----------\n",
      "train Loss: 0.8669 Acc: 0.6667\n",
      "val Loss: 0.8668 Acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.8668 Acc: 0.6667\n",
      "Epoch 234/499\n",
      "----------\n",
      "train Loss: 0.8667 Acc: 0.6667\n",
      "val Loss: 0.8668 Acc: 0.6667\n",
      "test Loss: 0.8666 Acc: 0.6667\n",
      "Epoch 235/499\n",
      "----------\n",
      "train Loss: 0.8665 Acc: 0.6667\n",
      "val Loss: 0.8663 Acc: 0.6667\n",
      "test Loss: 0.8665 Acc: 0.6667\n",
      "Epoch 236/499\n",
      "----------\n",
      "train Loss: 0.8664 Acc: 0.6667\n",
      "val Loss: 0.8661 Acc: 0.6667\n",
      "test Loss: 0.8661 Acc: 0.6667\n",
      "Epoch 237/499\n",
      "----------\n",
      "train Loss: 0.8661 Acc: 0.6667\n",
      "val Loss: 0.8659 Acc: 0.6667\n",
      "test Loss: 0.8660 Acc: 0.6667\n",
      "Epoch 238/499\n",
      "----------\n",
      "train Loss: 0.8659 Acc: 0.6667\n",
      "val Loss: 0.8658 Acc: 0.6667\n",
      "test Loss: 0.8657 Acc: 0.6667\n",
      "Epoch 239/499\n",
      "----------\n",
      "train Loss: 0.8655 Acc: 0.6667\n",
      "val Loss: 0.8654 Acc: 0.6667\n",
      "test Loss: 0.8655 Acc: 0.6667\n",
      "Epoch 240/499\n",
      "----------\n",
      "train Loss: 0.8679 Acc: 0.6667\n",
      "val Loss: 0.8653 Acc: 0.6667\n",
      "test Loss: 0.8652 Acc: 0.6667\n",
      "Epoch 241/499\n",
      "----------\n",
      "train Loss: 0.8651 Acc: 0.6667\n",
      "val Loss: 0.8650 Acc: 0.6667\n",
      "test Loss: 0.8650 Acc: 0.6667\n",
      "Epoch 242/499\n",
      "----------\n",
      "train Loss: 0.8649 Acc: 0.6667\n",
      "val Loss: 0.8648 Acc: 0.6667\n",
      "test Loss: 0.8648 Acc: 0.6667\n",
      "Epoch 243/499\n",
      "----------\n",
      "train Loss: 0.8647 Acc: 0.6667\n",
      "val Loss: 0.8645 Acc: 0.6667\n",
      "test Loss: 0.8645 Acc: 0.6667\n",
      "Epoch 244/499\n",
      "----------\n",
      "train Loss: 0.8645 Acc: 0.6667\n",
      "val Loss: 0.8643 Acc: 0.6667\n",
      "test Loss: 0.8644 Acc: 0.6667\n",
      "Epoch 245/499\n",
      "----------\n",
      "train Loss: 0.8642 Acc: 0.6667\n",
      "val Loss: 0.8641 Acc: 0.6667\n",
      "test Loss: 0.8641 Acc: 0.6667\n",
      "Epoch 246/499\n",
      "----------\n",
      "train Loss: 0.8640 Acc: 0.6667\n",
      "val Loss: 0.8639 Acc: 0.6667\n",
      "test Loss: 0.8640 Acc: 0.6667\n",
      "Epoch 247/499\n",
      "----------\n",
      "train Loss: 0.8639 Acc: 0.6667\n",
      "val Loss: 0.8657 Acc: 0.6667\n",
      "test Loss: 0.8638 Acc: 0.6667\n",
      "Epoch 248/499\n",
      "----------\n",
      "train Loss: 0.8635 Acc: 0.6667\n",
      "val Loss: 0.8637 Acc: 0.6667\n",
      "test Loss: 0.8634 Acc: 0.6667\n",
      "Epoch 249/499\n",
      "----------\n",
      "train Loss: 0.8633 Acc: 0.6667\n",
      "val Loss: 0.8632 Acc: 0.6667\n",
      "test Loss: 0.8632 Acc: 0.6667\n",
      "Epoch 250/499\n",
      "----------\n",
      "train Loss: 0.8632 Acc: 0.6667\n",
      "val Loss: 0.8631 Acc: 0.6667\n",
      "test Loss: 0.8630 Acc: 0.6667\n",
      "Epoch 251/499\n",
      "----------\n",
      "train Loss: 0.8629 Acc: 0.6667\n",
      "val Loss: 0.8628 Acc: 0.6667\n",
      "test Loss: 0.8628 Acc: 0.6667\n",
      "Epoch 252/499\n",
      "----------\n",
      "train Loss: 0.8628 Acc: 0.6667\n",
      "val Loss: 0.8626 Acc: 0.6667\n",
      "test Loss: 0.8626 Acc: 0.6667\n",
      "Epoch 253/499\n",
      "----------\n",
      "train Loss: 0.8625 Acc: 0.6667\n",
      "val Loss: 0.8623 Acc: 0.6667\n",
      "test Loss: 0.8624 Acc: 0.6667\n",
      "Epoch 254/499\n",
      "----------\n",
      "train Loss: 0.8622 Acc: 0.6667\n",
      "val Loss: 0.8621 Acc: 0.6667\n",
      "test Loss: 0.8621 Acc: 0.6667\n",
      "Epoch 255/499\n",
      "----------\n",
      "train Loss: 0.8620 Acc: 0.6667\n",
      "val Loss: 0.8619 Acc: 0.6667\n",
      "test Loss: 0.8619 Acc: 0.6667\n",
      "Epoch 256/499\n",
      "----------\n",
      "train Loss: 0.8627 Acc: 0.6667\n",
      "val Loss: 0.8617 Acc: 0.6667\n",
      "test Loss: 0.8617 Acc: 0.6667\n",
      "Epoch 257/499\n",
      "----------\n",
      "train Loss: 0.8622 Acc: 0.6667\n",
      "val Loss: 0.8615 Acc: 0.6667\n",
      "test Loss: 0.8615 Acc: 0.6667\n",
      "Epoch 258/499\n",
      "----------\n",
      "train Loss: 0.8614 Acc: 0.6667\n",
      "val Loss: 0.8613 Acc: 0.6667\n",
      "test Loss: 0.8613 Acc: 0.6667\n",
      "Epoch 259/499\n",
      "----------\n",
      "train Loss: 0.8612 Acc: 0.6667\n",
      "val Loss: 0.8611 Acc: 0.6667\n",
      "test Loss: 0.8612 Acc: 0.6667\n",
      "Epoch 260/499\n",
      "----------\n",
      "train Loss: 0.8610 Acc: 0.6667\n",
      "val Loss: 0.8608 Acc: 0.6667\n",
      "test Loss: 0.8608 Acc: 0.6667\n",
      "Epoch 261/499\n",
      "----------\n",
      "train Loss: 0.8607 Acc: 0.6667\n",
      "val Loss: 0.8607 Acc: 0.6667\n",
      "test Loss: 0.8673 Acc: 0.6667\n",
      "Epoch 262/499\n",
      "----------\n",
      "train Loss: 0.8607 Acc: 0.6667\n",
      "val Loss: 0.8604 Acc: 0.6667\n",
      "test Loss: 0.8604 Acc: 0.6667\n",
      "Epoch 263/499\n",
      "----------\n",
      "train Loss: 0.8603 Acc: 0.6667\n",
      "val Loss: 0.8603 Acc: 0.6667\n",
      "test Loss: 0.8602 Acc: 0.6667\n",
      "Epoch 264/499\n",
      "----------\n",
      "train Loss: 0.8601 Acc: 0.6667\n",
      "val Loss: 0.8600 Acc: 0.6667\n",
      "test Loss: 0.8600 Acc: 0.6667\n",
      "Epoch 265/499\n",
      "----------\n",
      "train Loss: 0.8599 Acc: 0.6667\n",
      "val Loss: 0.8598 Acc: 0.6667\n",
      "test Loss: 0.8599 Acc: 0.6667\n",
      "Epoch 266/499\n",
      "----------\n",
      "train Loss: 0.8598 Acc: 0.6667\n",
      "val Loss: 0.8596 Acc: 0.6667\n",
      "test Loss: 0.8597 Acc: 0.6667\n",
      "Epoch 267/499\n",
      "----------\n",
      "train Loss: 0.8595 Acc: 0.6667\n",
      "val Loss: 0.8594 Acc: 0.6667\n",
      "test Loss: 0.8595 Acc: 0.6667\n",
      "Epoch 268/499\n",
      "----------\n",
      "train Loss: 0.8593 Acc: 0.6667\n",
      "val Loss: 0.8592 Acc: 0.6667\n",
      "test Loss: 0.8592 Acc: 0.6667\n",
      "Epoch 269/499\n",
      "----------\n",
      "train Loss: 0.8591 Acc: 0.6667\n",
      "val Loss: 0.8590 Acc: 0.6667\n",
      "test Loss: 0.8590 Acc: 0.6667\n",
      "Epoch 270/499\n",
      "----------\n",
      "train Loss: 0.8589 Acc: 0.6667\n",
      "val Loss: 0.8590 Acc: 0.6667\n",
      "test Loss: 0.8588 Acc: 0.6667\n",
      "Epoch 271/499\n",
      "----------\n",
      "train Loss: 0.8587 Acc: 0.6667\n",
      "val Loss: 0.8587 Acc: 0.6667\n",
      "test Loss: 0.8646 Acc: 0.6667\n",
      "Epoch 272/499\n",
      "----------\n",
      "train Loss: 0.8585 Acc: 0.6667\n",
      "val Loss: 0.8583 Acc: 0.6667\n",
      "test Loss: 0.8586 Acc: 0.6667\n",
      "Epoch 273/499\n",
      "----------\n",
      "train Loss: 0.8582 Acc: 0.6667\n",
      "val Loss: 0.8583 Acc: 0.6667\n",
      "test Loss: 0.8581 Acc: 0.6667\n",
      "Epoch 274/499\n",
      "----------\n",
      "train Loss: 0.8580 Acc: 0.6667\n",
      "val Loss: 0.8582 Acc: 0.6667\n",
      "test Loss: 0.8579 Acc: 0.6667\n",
      "Epoch 275/499\n",
      "----------\n",
      "train Loss: 0.8578 Acc: 0.6667\n",
      "val Loss: 0.8577 Acc: 0.6667\n",
      "test Loss: 0.8578 Acc: 0.6667\n",
      "Epoch 276/499\n",
      "----------\n",
      "train Loss: 0.8576 Acc: 0.6667\n",
      "val Loss: 0.8576 Acc: 0.6667\n",
      "test Loss: 0.8575 Acc: 0.6667\n",
      "Epoch 277/499\n",
      "----------\n",
      "train Loss: 0.8574 Acc: 0.6667\n",
      "val Loss: 0.8573 Acc: 0.6667\n",
      "test Loss: 0.8574 Acc: 0.6667\n",
      "Epoch 278/499\n",
      "----------\n",
      "train Loss: 0.8572 Acc: 0.6667\n",
      "val Loss: 0.8571 Acc: 0.6667\n",
      "test Loss: 0.8571 Acc: 0.6667\n",
      "Epoch 279/499\n",
      "----------\n",
      "train Loss: 0.8569 Acc: 0.6667\n",
      "val Loss: 0.8570 Acc: 0.6667\n",
      "test Loss: 0.8569 Acc: 0.6667\n",
      "Epoch 280/499\n",
      "----------\n",
      "train Loss: 0.8575 Acc: 0.6667\n",
      "val Loss: 0.8569 Acc: 0.6667\n",
      "test Loss: 0.8567 Acc: 0.6667\n",
      "Epoch 281/499\n",
      "----------\n",
      "train Loss: 0.8566 Acc: 0.6667\n",
      "val Loss: 0.8565 Acc: 0.6667\n",
      "test Loss: 0.8565 Acc: 0.6667\n",
      "Epoch 282/499\n",
      "----------\n",
      "train Loss: 0.8564 Acc: 0.6667\n",
      "val Loss: 0.8564 Acc: 0.6667\n",
      "test Loss: 0.8563 Acc: 0.6667\n",
      "Epoch 283/499\n",
      "----------\n",
      "train Loss: 0.8584 Acc: 0.6667\n",
      "val Loss: 0.8561 Acc: 0.6667\n",
      "test Loss: 0.8561 Acc: 0.6667\n",
      "Epoch 284/499\n",
      "----------\n",
      "train Loss: 0.8559 Acc: 0.6667\n",
      "val Loss: 0.8559 Acc: 0.6667\n",
      "test Loss: 0.8559 Acc: 0.6667\n",
      "Epoch 285/499\n",
      "----------\n",
      "train Loss: 0.8560 Acc: 0.6667\n",
      "val Loss: 0.8558 Acc: 0.6667\n",
      "test Loss: 0.8557 Acc: 0.6667\n",
      "Epoch 286/499\n",
      "----------\n",
      "train Loss: 0.8556 Acc: 0.6667\n",
      "val Loss: 0.8556 Acc: 0.6667\n",
      "test Loss: 0.8555 Acc: 0.6667\n",
      "Epoch 287/499\n",
      "----------\n",
      "train Loss: 0.8554 Acc: 0.6667\n",
      "val Loss: 0.8553 Acc: 0.6667\n",
      "test Loss: 0.8553 Acc: 0.6667\n",
      "Epoch 288/499\n",
      "----------\n",
      "train Loss: 0.8555 Acc: 0.6667\n",
      "val Loss: 0.8552 Acc: 0.6667\n",
      "test Loss: 0.8552 Acc: 0.6667\n",
      "Epoch 289/499\n",
      "----------\n",
      "train Loss: 0.8550 Acc: 0.6667\n",
      "val Loss: 0.8549 Acc: 0.6667\n",
      "test Loss: 0.8549 Acc: 0.6667\n",
      "Epoch 290/499\n",
      "----------\n",
      "train Loss: 0.8549 Acc: 0.6667\n",
      "val Loss: 0.8547 Acc: 0.6667\n",
      "test Loss: 0.8547 Acc: 0.6667\n",
      "Epoch 291/499\n",
      "----------\n",
      "train Loss: 0.8546 Acc: 0.6667\n",
      "val Loss: 0.8546 Acc: 0.6667\n",
      "test Loss: 0.8545 Acc: 0.6667\n",
      "Epoch 292/499\n",
      "----------\n",
      "train Loss: 0.8544 Acc: 0.6667\n",
      "val Loss: 0.8544 Acc: 0.6667\n",
      "test Loss: 0.8544 Acc: 0.6667\n",
      "Epoch 293/499\n",
      "----------\n",
      "train Loss: 0.8542 Acc: 0.6667\n",
      "val Loss: 0.8541 Acc: 0.6667\n",
      "test Loss: 0.8541 Acc: 0.6667\n",
      "Epoch 294/499\n",
      "----------\n",
      "train Loss: 0.8540 Acc: 0.6667\n",
      "val Loss: 0.8539 Acc: 0.6667\n",
      "test Loss: 0.8540 Acc: 0.6667\n",
      "Epoch 295/499\n",
      "----------\n",
      "train Loss: 0.8538 Acc: 0.6667\n",
      "val Loss: 0.8608 Acc: 0.6667\n",
      "test Loss: 0.8537 Acc: 0.6667\n",
      "Epoch 296/499\n",
      "----------\n",
      "train Loss: 0.8536 Acc: 0.6667\n",
      "val Loss: 0.8535 Acc: 0.6667\n",
      "test Loss: 0.8537 Acc: 0.6667\n",
      "Epoch 297/499\n",
      "----------\n",
      "train Loss: 0.8535 Acc: 0.6667\n",
      "val Loss: 0.8534 Acc: 0.6667\n",
      "test Loss: 0.8533 Acc: 0.6667\n",
      "Epoch 298/499\n",
      "----------\n",
      "train Loss: 0.8533 Acc: 0.6667\n",
      "val Loss: 0.8532 Acc: 0.6667\n",
      "test Loss: 0.8532 Acc: 0.6667\n",
      "Epoch 299/499\n",
      "----------\n",
      "train Loss: 0.8531 Acc: 0.6667\n",
      "val Loss: 0.8530 Acc: 0.6667\n",
      "test Loss: 0.8531 Acc: 0.6667\n",
      "Epoch 300/499\n",
      "----------\n",
      "train Loss: 0.8529 Acc: 0.6667\n",
      "val Loss: 0.8529 Acc: 0.6667\n",
      "test Loss: 0.8528 Acc: 0.6667\n",
      "Epoch 301/499\n",
      "----------\n",
      "train Loss: 0.8569 Acc: 0.6667\n",
      "val Loss: 0.8526 Acc: 0.6667\n",
      "test Loss: 0.8526 Acc: 0.6667\n",
      "Epoch 302/499\n",
      "----------\n",
      "train Loss: 0.8524 Acc: 0.6667\n",
      "val Loss: 0.8524 Acc: 0.6667\n",
      "test Loss: 0.8524 Acc: 0.6667\n",
      "Epoch 303/499\n",
      "----------\n",
      "train Loss: 0.8523 Acc: 0.6667\n",
      "val Loss: 0.8522 Acc: 0.6667\n",
      "test Loss: 0.8522 Acc: 0.6667\n",
      "Epoch 304/499\n",
      "----------\n",
      "train Loss: 0.8521 Acc: 0.6667\n",
      "val Loss: 0.8521 Acc: 0.6667\n",
      "test Loss: 0.8520 Acc: 0.6667\n",
      "Epoch 305/499\n",
      "----------\n",
      "train Loss: 0.8519 Acc: 0.6667\n",
      "val Loss: 0.8518 Acc: 0.6667\n",
      "test Loss: 0.8518 Acc: 0.6667\n",
      "Epoch 306/499\n",
      "----------\n",
      "train Loss: 0.8516 Acc: 0.6667\n",
      "val Loss: 0.8516 Acc: 0.6667\n",
      "test Loss: 0.8516 Acc: 0.6667\n",
      "Epoch 307/499\n",
      "----------\n",
      "train Loss: 0.8514 Acc: 0.6667\n",
      "val Loss: 0.8514 Acc: 0.6667\n",
      "test Loss: 0.8514 Acc: 0.6667\n",
      "Epoch 308/499\n",
      "----------\n",
      "train Loss: 0.8513 Acc: 0.6667\n",
      "val Loss: 0.8512 Acc: 0.6667\n",
      "test Loss: 0.8514 Acc: 0.6667\n",
      "Epoch 309/499\n",
      "----------\n",
      "train Loss: 0.8527 Acc: 0.6667\n",
      "val Loss: 0.8510 Acc: 0.6667\n",
      "test Loss: 0.8512 Acc: 0.6667\n",
      "Epoch 310/499\n",
      "----------\n",
      "train Loss: 0.8509 Acc: 0.6667\n",
      "val Loss: 0.8508 Acc: 0.6667\n",
      "test Loss: 0.8510 Acc: 0.6667\n",
      "Epoch 311/499\n",
      "----------\n",
      "train Loss: 0.8507 Acc: 0.6667\n",
      "val Loss: 0.8506 Acc: 0.6667\n",
      "test Loss: 0.8507 Acc: 0.6667\n",
      "Epoch 312/499\n",
      "----------\n",
      "train Loss: 0.8505 Acc: 0.6667\n",
      "val Loss: 0.8505 Acc: 0.6667\n",
      "test Loss: 0.8505 Acc: 0.6667\n",
      "Epoch 313/499\n",
      "----------\n",
      "train Loss: 0.8504 Acc: 0.6667\n",
      "val Loss: 0.8503 Acc: 0.6667\n",
      "test Loss: 0.8504 Acc: 0.6667\n",
      "Epoch 314/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.8501 Acc: 0.6667\n",
      "val Loss: 0.8501 Acc: 0.6667\n",
      "test Loss: 0.8762 Acc: 0.6333\n",
      "Epoch 315/499\n",
      "----------\n",
      "train Loss: 0.8501 Acc: 0.6667\n",
      "val Loss: 0.8499 Acc: 0.6667\n",
      "test Loss: 0.8499 Acc: 0.6667\n",
      "Epoch 316/499\n",
      "----------\n",
      "train Loss: 0.8497 Acc: 0.6667\n",
      "val Loss: 0.8496 Acc: 0.6667\n",
      "test Loss: 0.8498 Acc: 0.6667\n",
      "Epoch 317/499\n",
      "----------\n",
      "train Loss: 0.8495 Acc: 0.6667\n",
      "val Loss: 0.8494 Acc: 0.6667\n",
      "test Loss: 0.8496 Acc: 0.6667\n",
      "Epoch 318/499\n",
      "----------\n",
      "train Loss: 0.8493 Acc: 0.6667\n",
      "val Loss: 0.8491 Acc: 0.6667\n",
      "test Loss: 0.8492 Acc: 0.6667\n",
      "Epoch 319/499\n",
      "----------\n",
      "train Loss: 0.8491 Acc: 0.6667\n",
      "val Loss: 0.8488 Acc: 0.6667\n",
      "test Loss: 0.8491 Acc: 0.6667\n",
      "Epoch 320/499\n",
      "----------\n",
      "train Loss: 0.8487 Acc: 0.6667\n",
      "val Loss: 0.8488 Acc: 0.6667\n",
      "test Loss: 0.8488 Acc: 0.6667\n",
      "Epoch 321/499\n",
      "----------\n",
      "train Loss: 0.8485 Acc: 0.6667\n",
      "val Loss: 0.8486 Acc: 0.6667\n",
      "test Loss: 0.8486 Acc: 0.6667\n",
      "Epoch 322/499\n",
      "----------\n",
      "train Loss: 0.8483 Acc: 0.6667\n",
      "val Loss: 0.8483 Acc: 0.6667\n",
      "test Loss: 0.8484 Acc: 0.6667\n",
      "Epoch 323/499\n",
      "----------\n",
      "train Loss: 0.8481 Acc: 0.6667\n",
      "val Loss: 0.8479 Acc: 0.6667\n",
      "test Loss: 0.8482 Acc: 0.6667\n",
      "Epoch 324/499\n",
      "----------\n",
      "train Loss: 0.8479 Acc: 0.6667\n",
      "val Loss: 0.8476 Acc: 0.6667\n",
      "test Loss: 0.8480 Acc: 0.6667\n",
      "Epoch 325/499\n",
      "----------\n",
      "train Loss: 0.8477 Acc: 0.6667\n",
      "val Loss: 0.8474 Acc: 0.6667\n",
      "test Loss: 0.8477 Acc: 0.6667\n",
      "Epoch 326/499\n",
      "----------\n",
      "train Loss: 0.8475 Acc: 0.6667\n",
      "val Loss: 0.8473 Acc: 0.6667\n",
      "test Loss: 0.8478 Acc: 0.6667\n",
      "Epoch 327/499\n",
      "----------\n",
      "train Loss: 0.8477 Acc: 0.6667\n",
      "val Loss: 0.8471 Acc: 0.6667\n",
      "test Loss: 0.8474 Acc: 0.6667\n",
      "Epoch 328/499\n",
      "----------\n",
      "train Loss: 0.8469 Acc: 0.6667\n",
      "val Loss: 0.8468 Acc: 0.6667\n",
      "test Loss: 0.8472 Acc: 0.6667\n",
      "Epoch 329/499\n",
      "----------\n",
      "train Loss: 0.8470 Acc: 0.6667\n",
      "val Loss: 0.8467 Acc: 0.6667\n",
      "test Loss: 0.8469 Acc: 0.6667\n",
      "Epoch 330/499\n",
      "----------\n",
      "train Loss: 0.8466 Acc: 0.6667\n",
      "val Loss: 0.8467 Acc: 0.6667\n",
      "test Loss: 0.8469 Acc: 0.6667\n",
      "Epoch 331/499\n",
      "----------\n",
      "train Loss: 0.8465 Acc: 0.6667\n",
      "val Loss: 0.8464 Acc: 0.6667\n",
      "test Loss: 0.8468 Acc: 0.6667\n",
      "Epoch 332/499\n",
      "----------\n",
      "train Loss: 0.8462 Acc: 0.6667\n",
      "val Loss: 0.8459 Acc: 0.6667\n",
      "test Loss: 0.8465 Acc: 0.6667\n",
      "Epoch 333/499\n",
      "----------\n",
      "train Loss: 0.8461 Acc: 0.6667\n",
      "val Loss: 0.8455 Acc: 0.6667\n",
      "test Loss: 0.8504 Acc: 0.6667\n",
      "Epoch 334/499\n",
      "----------\n",
      "train Loss: 0.8490 Acc: 0.6667\n",
      "val Loss: 0.8453 Acc: 0.6667\n",
      "test Loss: 0.8459 Acc: 0.6667\n",
      "Epoch 335/499\n",
      "----------\n",
      "train Loss: 0.8454 Acc: 0.6667\n",
      "val Loss: 0.8452 Acc: 0.6667\n",
      "test Loss: 0.8457 Acc: 0.6667\n",
      "Epoch 336/499\n",
      "----------\n",
      "train Loss: 0.8452 Acc: 0.6667\n",
      "val Loss: 0.8450 Acc: 0.6667\n",
      "test Loss: 0.8455 Acc: 0.6667\n",
      "Epoch 337/499\n",
      "----------\n",
      "train Loss: 0.8463 Acc: 0.6667\n",
      "val Loss: 0.8446 Acc: 0.6667\n",
      "test Loss: 0.8453 Acc: 0.6667\n",
      "Epoch 338/499\n",
      "----------\n",
      "train Loss: 0.8449 Acc: 0.6667\n",
      "val Loss: 0.8449 Acc: 0.6667\n",
      "test Loss: 0.8450 Acc: 0.6667\n",
      "Epoch 339/499\n",
      "----------\n",
      "train Loss: 0.8445 Acc: 0.6667\n",
      "val Loss: 0.8443 Acc: 0.6667\n",
      "test Loss: 0.8451 Acc: 0.6667\n",
      "Epoch 340/499\n",
      "----------\n",
      "train Loss: 0.8442 Acc: 0.6667\n",
      "val Loss: 0.8440 Acc: 0.6667\n",
      "test Loss: 0.8448 Acc: 0.6667\n",
      "Epoch 341/499\n",
      "----------\n",
      "train Loss: 0.8440 Acc: 0.6667\n",
      "val Loss: 0.8436 Acc: 0.6667\n",
      "test Loss: 0.8443 Acc: 0.6667\n",
      "Epoch 342/499\n",
      "----------\n",
      "train Loss: 0.8438 Acc: 0.6667\n",
      "val Loss: 0.8439 Acc: 0.6667\n",
      "test Loss: 0.8442 Acc: 0.6667\n",
      "Epoch 343/499\n",
      "----------\n",
      "train Loss: 0.8438 Acc: 0.6667\n",
      "val Loss: 0.8431 Acc: 0.6667\n",
      "test Loss: 0.8439 Acc: 0.6667\n",
      "Epoch 344/499\n",
      "----------\n",
      "train Loss: 0.8432 Acc: 0.6667\n",
      "val Loss: 0.8425 Acc: 0.6667\n",
      "test Loss: 0.8440 Acc: 0.6667\n",
      "Epoch 345/499\n",
      "----------\n",
      "train Loss: 0.8429 Acc: 0.6667\n",
      "val Loss: 0.8423 Acc: 0.6667\n",
      "test Loss: 0.8434 Acc: 0.6667\n",
      "Epoch 346/499\n",
      "----------\n",
      "train Loss: 0.8425 Acc: 0.6667\n",
      "val Loss: 0.8421 Acc: 0.6667\n",
      "test Loss: 0.8431 Acc: 0.6667\n",
      "Epoch 347/499\n",
      "----------\n",
      "train Loss: 0.8423 Acc: 0.6667\n",
      "val Loss: 0.8417 Acc: 0.6667\n",
      "test Loss: 0.8431 Acc: 0.6667\n",
      "Epoch 348/499\n",
      "----------\n",
      "train Loss: 0.8420 Acc: 0.6667\n",
      "val Loss: 0.8414 Acc: 0.6667\n",
      "test Loss: 0.8429 Acc: 0.6667\n",
      "Epoch 349/499\n",
      "----------\n",
      "train Loss: 0.8420 Acc: 0.6667\n",
      "val Loss: 0.8416 Acc: 0.6667\n",
      "test Loss: 0.8426 Acc: 0.6667\n",
      "Epoch 350/499\n",
      "----------\n",
      "train Loss: 0.8412 Acc: 0.6667\n",
      "val Loss: 0.8406 Acc: 0.6667\n",
      "test Loss: 0.8421 Acc: 0.6667\n",
      "Epoch 351/499\n",
      "----------\n",
      "train Loss: 0.8408 Acc: 0.6667\n",
      "val Loss: 0.8400 Acc: 0.6667\n",
      "test Loss: 0.8421 Acc: 0.6667\n",
      "Epoch 352/499\n",
      "----------\n",
      "train Loss: 0.8403 Acc: 0.6667\n",
      "val Loss: 0.8406 Acc: 0.6667\n",
      "test Loss: 0.8418 Acc: 0.6667\n",
      "Epoch 353/499\n",
      "----------\n",
      "train Loss: 0.8399 Acc: 0.6667\n",
      "val Loss: 0.8385 Acc: 0.6667\n",
      "test Loss: 0.8417 Acc: 0.6667\n",
      "Epoch 354/499\n",
      "----------\n",
      "train Loss: 0.8407 Acc: 0.6667\n",
      "val Loss: 0.8383 Acc: 0.6667\n",
      "test Loss: 0.8405 Acc: 0.6667\n",
      "Epoch 355/499\n",
      "----------\n",
      "train Loss: 0.8394 Acc: 0.6667\n",
      "val Loss: 0.8393 Acc: 0.6667\n",
      "test Loss: 0.8400 Acc: 0.6667\n",
      "Epoch 356/499\n",
      "----------\n",
      "train Loss: 0.8383 Acc: 0.6667\n",
      "val Loss: 0.8373 Acc: 0.6667\n",
      "test Loss: 0.8406 Acc: 0.6667\n",
      "Epoch 357/499\n",
      "----------\n",
      "train Loss: 0.8389 Acc: 0.6667\n",
      "val Loss: 0.8379 Acc: 0.6667\n",
      "test Loss: 0.8389 Acc: 0.6667\n",
      "Epoch 358/499\n",
      "----------\n",
      "train Loss: 0.8377 Acc: 0.6667\n",
      "val Loss: 0.8349 Acc: 0.6667\n",
      "test Loss: 0.8386 Acc: 0.6667\n",
      "Epoch 359/499\n",
      "----------\n",
      "train Loss: 0.8363 Acc: 0.6667\n",
      "val Loss: 0.8339 Acc: 0.6667\n",
      "test Loss: 0.8386 Acc: 0.6667\n",
      "Epoch 360/499\n",
      "----------\n",
      "train Loss: 0.8359 Acc: 0.6667\n",
      "val Loss: 0.8339 Acc: 0.6667\n",
      "test Loss: 0.8368 Acc: 0.6667\n",
      "Epoch 361/499\n",
      "----------\n",
      "train Loss: 0.8344 Acc: 0.6667\n",
      "val Loss: 0.8330 Acc: 0.6667\n",
      "test Loss: 0.8359 Acc: 0.6667\n",
      "Epoch 362/499\n",
      "----------\n",
      "train Loss: 0.8351 Acc: 0.6667\n",
      "val Loss: 0.8330 Acc: 0.6667\n",
      "test Loss: 0.8377 Acc: 0.6667\n",
      "Epoch 363/499\n",
      "----------\n",
      "train Loss: 0.8308 Acc: 0.6667\n",
      "val Loss: 0.8304 Acc: 0.6667\n",
      "test Loss: 0.8354 Acc: 0.6667\n",
      "Epoch 364/499\n",
      "----------\n",
      "train Loss: 0.8295 Acc: 0.6667\n",
      "val Loss: 0.8284 Acc: 0.6667\n",
      "test Loss: 0.8346 Acc: 0.6667\n",
      "Epoch 365/499\n",
      "----------\n",
      "train Loss: 0.8285 Acc: 0.6667\n",
      "val Loss: 0.8238 Acc: 0.6667\n",
      "test Loss: 0.8323 Acc: 0.6667\n",
      "Epoch 366/499\n",
      "----------\n",
      "train Loss: 0.8322 Acc: 0.6667\n",
      "val Loss: 0.8210 Acc: 0.6667\n",
      "test Loss: 0.8294 Acc: 0.6667\n",
      "Epoch 367/499\n",
      "----------\n",
      "train Loss: 0.8248 Acc: 0.6667\n",
      "val Loss: 0.8186 Acc: 0.6667\n",
      "test Loss: 0.8276 Acc: 0.6667\n",
      "Epoch 368/499\n",
      "----------\n",
      "train Loss: 0.8231 Acc: 0.6667\n",
      "val Loss: 0.8245 Acc: 0.6667\n",
      "test Loss: 0.8311 Acc: 0.6667\n",
      "Epoch 369/499\n",
      "----------\n",
      "train Loss: 0.8189 Acc: 0.6667\n",
      "val Loss: 0.8146 Acc: 0.6667\n",
      "test Loss: 0.8224 Acc: 0.6667\n",
      "Epoch 370/499\n",
      "----------\n",
      "train Loss: 0.8182 Acc: 0.6667\n",
      "val Loss: 0.8044 Acc: 0.6667\n",
      "test Loss: 0.8199 Acc: 0.6667\n",
      "Epoch 371/499\n",
      "----------\n",
      "train Loss: 0.8141 Acc: 0.6667\n",
      "val Loss: 0.8012 Acc: 0.6667\n",
      "test Loss: 0.8195 Acc: 0.6667\n",
      "Epoch 372/499\n",
      "----------\n",
      "train Loss: 0.8058 Acc: 0.6667\n",
      "val Loss: 0.8010 Acc: 0.6667\n",
      "test Loss: 0.8146 Acc: 0.6667\n",
      "Epoch 373/499\n",
      "----------\n",
      "train Loss: 0.8058 Acc: 0.6667\n",
      "val Loss: 0.7936 Acc: 0.6667\n",
      "test Loss: 0.8035 Acc: 0.6667\n",
      "Epoch 374/499\n",
      "----------\n",
      "train Loss: 0.7971 Acc: 0.6667\n",
      "val Loss: 0.7896 Acc: 0.6667\n",
      "test Loss: 0.8127 Acc: 0.6667\n",
      "Epoch 375/499\n",
      "----------\n",
      "train Loss: 0.7928 Acc: 0.6667\n",
      "val Loss: 0.7810 Acc: 0.6667\n",
      "test Loss: 0.8085 Acc: 0.6667\n",
      "Epoch 376/499\n",
      "----------\n",
      "train Loss: 0.7899 Acc: 0.6667\n",
      "val Loss: 0.7729 Acc: 0.6667\n",
      "test Loss: 0.7945 Acc: 0.6667\n",
      "Epoch 377/499\n",
      "----------\n",
      "train Loss: 0.7913 Acc: 0.6667\n",
      "val Loss: 0.7695 Acc: 0.6667\n",
      "test Loss: 0.7919 Acc: 0.6667\n",
      "Epoch 378/499\n",
      "----------\n",
      "train Loss: 0.7747 Acc: 0.6667\n",
      "val Loss: 0.7655 Acc: 0.6667\n",
      "test Loss: 0.7909 Acc: 0.6667\n",
      "Epoch 379/499\n",
      "----------\n",
      "train Loss: 0.7799 Acc: 0.6667\n",
      "val Loss: 0.7638 Acc: 0.6667\n",
      "test Loss: 0.7946 Acc: 0.6667\n",
      "Epoch 380/499\n",
      "----------\n",
      "train Loss: 0.7709 Acc: 0.6667\n",
      "val Loss: 0.7708 Acc: 0.6333\n",
      "test Loss: 0.7931 Acc: 0.6667\n",
      "Epoch 381/499\n",
      "----------\n",
      "train Loss: 0.7630 Acc: 0.6667\n",
      "val Loss: 0.7556 Acc: 0.6667\n",
      "test Loss: 0.7793 Acc: 0.6667\n",
      "Epoch 382/499\n",
      "----------\n",
      "train Loss: 0.7672 Acc: 0.6667\n",
      "val Loss: 0.7494 Acc: 0.6667\n",
      "test Loss: 0.7808 Acc: 0.6667\n",
      "Epoch 383/499\n",
      "----------\n",
      "train Loss: 0.7555 Acc: 0.6667\n",
      "val Loss: 0.7524 Acc: 0.6667\n",
      "test Loss: 0.7791 Acc: 0.6667\n",
      "Epoch 384/499\n",
      "----------\n",
      "train Loss: 0.7652 Acc: 0.6667\n",
      "val Loss: 0.7569 Acc: 0.6667\n",
      "test Loss: 0.7840 Acc: 0.6667\n",
      "Epoch 385/499\n",
      "----------\n",
      "train Loss: 0.7552 Acc: 0.6667\n",
      "val Loss: 0.7389 Acc: 0.6667\n",
      "test Loss: 0.7678 Acc: 0.6667\n",
      "Epoch 386/499\n",
      "----------\n",
      "train Loss: 0.7501 Acc: 0.6667\n",
      "val Loss: 0.7326 Acc: 0.6667\n",
      "test Loss: 0.7631 Acc: 0.6667\n",
      "Epoch 387/499\n",
      "----------\n",
      "train Loss: 0.7424 Acc: 0.6667\n",
      "val Loss: 0.7295 Acc: 0.6667\n",
      "test Loss: 0.7618 Acc: 0.6667\n",
      "Epoch 388/499\n",
      "----------\n",
      "train Loss: 0.7462 Acc: 0.6556\n",
      "val Loss: 0.7360 Acc: 0.6667\n",
      "test Loss: 0.7696 Acc: 0.6667\n",
      "Epoch 389/499\n",
      "----------\n",
      "train Loss: 0.7409 Acc: 0.6667\n",
      "val Loss: 0.7284 Acc: 0.6667\n",
      "test Loss: 0.7548 Acc: 0.6667\n",
      "Epoch 390/499\n",
      "----------\n",
      "train Loss: 0.7375 Acc: 0.6667\n",
      "val Loss: 0.7218 Acc: 0.6667\n",
      "test Loss: 0.7519 Acc: 0.6667\n",
      "Epoch 391/499\n",
      "----------\n",
      "train Loss: 0.7318 Acc: 0.6667\n",
      "val Loss: 0.7221 Acc: 0.6667\n",
      "test Loss: 0.7483 Acc: 0.6667\n",
      "Epoch 392/499\n",
      "----------\n",
      "train Loss: 0.7246 Acc: 0.6667\n",
      "val Loss: 0.7254 Acc: 0.6667\n",
      "test Loss: 0.7451 Acc: 0.6667\n",
      "Epoch 393/499\n",
      "----------\n",
      "train Loss: 0.7267 Acc: 0.6667\n",
      "val Loss: 0.7166 Acc: 0.6667\n",
      "test Loss: 0.7473 Acc: 0.6667\n",
      "Epoch 394/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.7298 Acc: 0.6667\n",
      "val Loss: 0.7195 Acc: 0.6667\n",
      "test Loss: 0.7608 Acc: 0.6667\n",
      "Epoch 395/499\n",
      "----------\n",
      "train Loss: 0.7285 Acc: 0.6556\n",
      "val Loss: 0.7167 Acc: 0.6667\n",
      "test Loss: 0.7487 Acc: 0.6667\n",
      "Epoch 396/499\n",
      "----------\n",
      "train Loss: 0.7268 Acc: 0.6556\n",
      "val Loss: 0.7096 Acc: 0.6667\n",
      "test Loss: 0.7348 Acc: 0.6667\n",
      "Epoch 397/499\n",
      "----------\n",
      "train Loss: 0.7233 Acc: 0.6667\n",
      "val Loss: 0.7077 Acc: 0.6667\n",
      "test Loss: 0.7384 Acc: 0.6667\n",
      "Epoch 398/499\n",
      "----------\n",
      "train Loss: 0.7223 Acc: 0.6667\n",
      "val Loss: 0.7083 Acc: 0.6667\n",
      "test Loss: 0.7402 Acc: 0.6667\n",
      "Epoch 399/499\n",
      "----------\n",
      "train Loss: 0.7202 Acc: 0.6667\n",
      "val Loss: 0.7135 Acc: 0.6667\n",
      "test Loss: 0.7428 Acc: 0.6667\n",
      "Epoch 400/499\n",
      "----------\n",
      "train Loss: 0.7221 Acc: 0.6667\n",
      "val Loss: 0.7131 Acc: 0.6667\n",
      "test Loss: 0.7326 Acc: 0.6667\n",
      "Epoch 401/499\n",
      "----------\n",
      "train Loss: 0.7183 Acc: 0.6667\n",
      "val Loss: 0.7194 Acc: 0.6667\n",
      "test Loss: 0.7339 Acc: 0.6667\n",
      "Epoch 402/499\n",
      "----------\n",
      "train Loss: 0.7274 Acc: 0.6556\n",
      "val Loss: 0.7137 Acc: 0.6667\n",
      "test Loss: 0.7592 Acc: 0.6667\n",
      "Epoch 403/499\n",
      "----------\n",
      "train Loss: 0.7154 Acc: 0.6667\n",
      "val Loss: 0.7153 Acc: 0.6667\n",
      "test Loss: 0.7325 Acc: 0.6667\n",
      "Epoch 404/499\n",
      "----------\n",
      "train Loss: 0.7200 Acc: 0.6667\n",
      "val Loss: 0.7093 Acc: 0.6667\n",
      "test Loss: 0.7349 Acc: 0.6667\n",
      "Epoch 405/499\n",
      "----------\n",
      "train Loss: 0.7204 Acc: 0.6667\n",
      "val Loss: 0.7037 Acc: 0.6667\n",
      "test Loss: 0.7318 Acc: 0.6667\n",
      "Epoch 406/499\n",
      "----------\n",
      "train Loss: 0.7141 Acc: 0.6667\n",
      "val Loss: 0.7100 Acc: 0.6667\n",
      "test Loss: 0.7357 Acc: 0.6667\n",
      "Epoch 407/499\n",
      "----------\n",
      "train Loss: 0.7101 Acc: 0.6667\n",
      "val Loss: 0.7042 Acc: 0.6667\n",
      "test Loss: 0.7343 Acc: 0.6667\n",
      "Epoch 408/499\n",
      "----------\n",
      "train Loss: 0.7080 Acc: 0.6667\n",
      "val Loss: 0.7009 Acc: 0.6667\n",
      "test Loss: 0.7295 Acc: 0.6667\n",
      "Epoch 409/499\n",
      "----------\n",
      "train Loss: 0.7106 Acc: 0.6667\n",
      "val Loss: 0.7033 Acc: 0.6667\n",
      "test Loss: 0.7253 Acc: 0.6667\n",
      "Epoch 410/499\n",
      "----------\n",
      "train Loss: 0.7183 Acc: 0.6667\n",
      "val Loss: 0.7007 Acc: 0.6667\n",
      "test Loss: 0.7291 Acc: 0.6667\n",
      "Epoch 411/499\n",
      "----------\n",
      "train Loss: 0.7121 Acc: 0.6667\n",
      "val Loss: 0.7022 Acc: 0.6667\n",
      "test Loss: 0.7427 Acc: 0.6667\n",
      "Epoch 412/499\n",
      "----------\n",
      "train Loss: 0.7102 Acc: 0.6667\n",
      "val Loss: 0.6998 Acc: 0.6667\n",
      "test Loss: 0.7289 Acc: 0.6667\n",
      "Epoch 413/499\n",
      "----------\n",
      "train Loss: 0.7187 Acc: 0.6667\n",
      "val Loss: 0.7005 Acc: 0.6667\n",
      "test Loss: 0.7319 Acc: 0.6667\n",
      "Epoch 414/499\n",
      "----------\n",
      "train Loss: 0.7077 Acc: 0.6667\n",
      "val Loss: 0.6985 Acc: 0.6667\n",
      "test Loss: 0.7234 Acc: 0.6667\n",
      "Epoch 415/499\n",
      "----------\n",
      "train Loss: 0.7074 Acc: 0.6667\n",
      "val Loss: 0.7114 Acc: 0.6667\n",
      "test Loss: 0.7228 Acc: 0.6667\n",
      "Epoch 416/499\n",
      "----------\n",
      "train Loss: 0.7101 Acc: 0.6667\n",
      "val Loss: 0.7054 Acc: 0.6667\n",
      "test Loss: 0.7254 Acc: 0.6667\n",
      "Epoch 417/499\n",
      "----------\n",
      "train Loss: 0.7023 Acc: 0.6667\n",
      "val Loss: 0.7132 Acc: 0.6667\n",
      "test Loss: 0.7195 Acc: 0.6667\n",
      "Epoch 418/499\n",
      "----------\n",
      "train Loss: 0.7104 Acc: 0.6667\n",
      "val Loss: 0.7128 Acc: 0.6667\n",
      "test Loss: 0.7247 Acc: 0.6667\n",
      "Epoch 419/499\n",
      "----------\n",
      "train Loss: 0.7073 Acc: 0.6667\n",
      "val Loss: 0.7004 Acc: 0.6667\n",
      "test Loss: 0.7327 Acc: 0.6667\n",
      "Epoch 420/499\n",
      "----------\n",
      "train Loss: 0.7024 Acc: 0.6667\n",
      "val Loss: 0.6974 Acc: 1.0000\n",
      "test Loss: 0.7246 Acc: 0.9000\n",
      "Epoch 421/499\n",
      "----------\n",
      "train Loss: 0.7027 Acc: 0.9667\n",
      "val Loss: 0.6980 Acc: 1.0000\n",
      "test Loss: 0.7241 Acc: 0.9000\n",
      "Epoch 422/499\n",
      "----------\n",
      "train Loss: 0.7036 Acc: 0.9667\n",
      "val Loss: 0.6949 Acc: 1.0000\n",
      "test Loss: 0.7592 Acc: 0.8667\n",
      "Epoch 423/499\n",
      "----------\n",
      "train Loss: 0.7045 Acc: 0.9667\n",
      "val Loss: 0.6951 Acc: 1.0000\n",
      "test Loss: 0.7210 Acc: 0.9000\n",
      "Epoch 424/499\n",
      "----------\n",
      "train Loss: 0.7038 Acc: 0.9778\n",
      "val Loss: 0.6961 Acc: 1.0000\n",
      "test Loss: 0.7247 Acc: 0.9000\n",
      "Epoch 425/499\n",
      "----------\n",
      "train Loss: 0.7059 Acc: 0.9889\n",
      "val Loss: 0.6935 Acc: 1.0000\n",
      "test Loss: 0.7162 Acc: 0.9000\n",
      "Epoch 426/499\n",
      "----------\n",
      "train Loss: 0.6989 Acc: 0.9889\n",
      "val Loss: 0.6962 Acc: 1.0000\n",
      "test Loss: 0.7164 Acc: 0.9000\n",
      "Epoch 427/499\n",
      "----------\n",
      "train Loss: 0.6998 Acc: 0.9889\n",
      "val Loss: 0.6926 Acc: 1.0000\n",
      "test Loss: 0.7206 Acc: 0.9000\n",
      "Epoch 428/499\n",
      "----------\n",
      "train Loss: 0.7005 Acc: 0.9889\n",
      "val Loss: 0.6967 Acc: 1.0000\n",
      "test Loss: 0.7215 Acc: 0.9000\n",
      "Epoch 429/499\n",
      "----------\n",
      "train Loss: 0.6972 Acc: 0.9889\n",
      "val Loss: 0.6941 Acc: 1.0000\n",
      "test Loss: 0.7140 Acc: 0.9000\n",
      "Epoch 430/499\n",
      "----------\n",
      "train Loss: 0.6979 Acc: 0.9889\n",
      "val Loss: 0.6940 Acc: 1.0000\n",
      "test Loss: 0.7530 Acc: 0.8333\n",
      "Epoch 431/499\n",
      "----------\n",
      "train Loss: 0.7003 Acc: 0.9778\n",
      "val Loss: 0.7005 Acc: 1.0000\n",
      "test Loss: 0.7166 Acc: 0.9000\n",
      "Epoch 432/499\n",
      "----------\n",
      "train Loss: 0.6987 Acc: 0.9889\n",
      "val Loss: 0.7056 Acc: 0.9667\n",
      "test Loss: 0.7152 Acc: 0.9000\n",
      "Epoch 433/499\n",
      "----------\n",
      "train Loss: 0.6969 Acc: 0.9889\n",
      "val Loss: 0.6905 Acc: 1.0000\n",
      "test Loss: 0.7242 Acc: 0.9000\n",
      "Epoch 434/499\n",
      "----------\n",
      "train Loss: 0.6993 Acc: 0.9778\n",
      "val Loss: 0.6933 Acc: 1.0000\n",
      "test Loss: 0.7226 Acc: 0.9000\n",
      "Epoch 435/499\n",
      "----------\n",
      "train Loss: 0.7015 Acc: 0.9667\n",
      "val Loss: 0.7108 Acc: 0.9667\n",
      "test Loss: 0.7145 Acc: 0.9000\n",
      "Epoch 436/499\n",
      "----------\n",
      "train Loss: 0.6956 Acc: 0.9889\n",
      "val Loss: 0.6947 Acc: 1.0000\n",
      "test Loss: 0.7175 Acc: 0.9000\n",
      "Epoch 437/499\n",
      "----------\n",
      "train Loss: 0.6950 Acc: 0.9889\n",
      "val Loss: 0.6916 Acc: 1.0000\n",
      "test Loss: 0.7167 Acc: 0.9000\n",
      "Epoch 438/499\n",
      "----------\n",
      "train Loss: 0.6993 Acc: 0.9667\n",
      "val Loss: 0.6904 Acc: 1.0000\n",
      "test Loss: 0.7198 Acc: 0.9000\n",
      "Epoch 439/499\n",
      "----------\n",
      "train Loss: 0.6973 Acc: 0.9889\n",
      "val Loss: 0.6921 Acc: 1.0000\n",
      "test Loss: 0.7112 Acc: 0.9000\n",
      "Epoch 440/499\n",
      "----------\n",
      "train Loss: 0.6932 Acc: 0.9889\n",
      "val Loss: 0.6885 Acc: 1.0000\n",
      "test Loss: 0.7330 Acc: 0.8667\n",
      "Epoch 441/499\n",
      "----------\n",
      "train Loss: 0.6971 Acc: 0.9778\n",
      "val Loss: 0.6882 Acc: 1.0000\n",
      "test Loss: 0.7126 Acc: 0.9333\n",
      "Epoch 442/499\n",
      "----------\n",
      "train Loss: 0.6925 Acc: 1.0000\n",
      "val Loss: 0.6898 Acc: 1.0000\n",
      "test Loss: 0.7158 Acc: 0.9333\n",
      "Epoch 443/499\n",
      "----------\n",
      "train Loss: 0.6914 Acc: 1.0000\n",
      "val Loss: 0.6886 Acc: 1.0000\n",
      "test Loss: 0.7152 Acc: 0.9333\n",
      "Epoch 444/499\n",
      "----------\n",
      "train Loss: 0.6905 Acc: 1.0000\n",
      "val Loss: 0.6874 Acc: 1.0000\n",
      "test Loss: 0.7162 Acc: 0.9333\n",
      "Epoch 445/499\n",
      "----------\n",
      "train Loss: 0.6909 Acc: 0.9889\n",
      "val Loss: 0.6908 Acc: 1.0000\n",
      "test Loss: 0.7522 Acc: 0.9000\n",
      "Epoch 446/499\n",
      "----------\n",
      "train Loss: 0.6899 Acc: 0.9889\n",
      "val Loss: 0.6874 Acc: 1.0000\n",
      "test Loss: 0.7133 Acc: 0.9333\n",
      "Epoch 447/499\n",
      "----------\n",
      "train Loss: 0.6961 Acc: 0.9889\n",
      "val Loss: 0.6884 Acc: 1.0000\n",
      "test Loss: 0.7101 Acc: 0.9333\n",
      "Epoch 448/499\n",
      "----------\n",
      "train Loss: 0.6917 Acc: 1.0000\n",
      "val Loss: 0.6862 Acc: 1.0000\n",
      "test Loss: 0.7168 Acc: 0.9333\n",
      "Epoch 449/499\n",
      "----------\n",
      "train Loss: 0.6893 Acc: 1.0000\n",
      "val Loss: 0.6906 Acc: 1.0000\n",
      "test Loss: 0.7167 Acc: 0.9000\n",
      "Epoch 450/499\n",
      "----------\n",
      "train Loss: 0.6952 Acc: 0.9778\n",
      "val Loss: 0.6873 Acc: 1.0000\n",
      "test Loss: 0.7198 Acc: 0.9000\n",
      "Epoch 451/499\n",
      "----------\n",
      "train Loss: 0.6921 Acc: 0.9889\n",
      "val Loss: 0.6855 Acc: 1.0000\n",
      "test Loss: 0.7124 Acc: 0.9333\n",
      "Epoch 452/499\n",
      "----------\n",
      "train Loss: 0.6887 Acc: 1.0000\n",
      "val Loss: 0.6853 Acc: 1.0000\n",
      "test Loss: 0.7127 Acc: 0.9333\n",
      "Epoch 453/499\n",
      "----------\n",
      "train Loss: 0.6987 Acc: 0.9778\n",
      "val Loss: 0.6879 Acc: 1.0000\n",
      "test Loss: 0.7142 Acc: 0.9333\n",
      "Epoch 454/499\n",
      "----------\n",
      "train Loss: 0.6870 Acc: 1.0000\n",
      "val Loss: 0.6857 Acc: 1.0000\n",
      "test Loss: 0.7105 Acc: 0.9333\n",
      "Epoch 455/499\n",
      "----------\n",
      "train Loss: 0.6866 Acc: 1.0000\n",
      "val Loss: 0.7001 Acc: 0.9667\n",
      "test Loss: 0.7140 Acc: 0.9333\n",
      "Epoch 456/499\n",
      "----------\n",
      "train Loss: 0.6880 Acc: 1.0000\n",
      "val Loss: 0.6876 Acc: 1.0000\n",
      "test Loss: 0.7166 Acc: 0.9333\n",
      "Epoch 457/499\n",
      "----------\n",
      "train Loss: 0.6928 Acc: 0.9889\n",
      "val Loss: 0.6851 Acc: 1.0000\n",
      "test Loss: 0.7141 Acc: 0.9333\n",
      "Epoch 458/499\n",
      "----------\n",
      "train Loss: 0.6938 Acc: 0.9889\n",
      "val Loss: 0.6884 Acc: 1.0000\n",
      "test Loss: 0.7160 Acc: 0.9333\n",
      "Epoch 459/499\n",
      "----------\n",
      "train Loss: 0.6880 Acc: 1.0000\n",
      "val Loss: 0.6833 Acc: 1.0000\n",
      "test Loss: 0.7263 Acc: 0.9000\n",
      "Epoch 460/499\n",
      "----------\n",
      "train Loss: 0.6885 Acc: 1.0000\n",
      "val Loss: 0.6859 Acc: 1.0000\n",
      "test Loss: 0.7104 Acc: 0.9333\n",
      "Epoch 461/499\n",
      "----------\n",
      "train Loss: 0.6875 Acc: 1.0000\n",
      "val Loss: 0.6829 Acc: 1.0000\n",
      "test Loss: 0.7145 Acc: 0.9333\n",
      "Epoch 462/499\n",
      "----------\n",
      "train Loss: 0.6853 Acc: 1.0000\n",
      "val Loss: 0.6824 Acc: 1.0000\n",
      "test Loss: 0.7199 Acc: 0.9333\n",
      "Epoch 463/499\n",
      "----------\n",
      "train Loss: 0.6893 Acc: 0.9778\n",
      "val Loss: 0.6877 Acc: 1.0000\n",
      "test Loss: 0.7148 Acc: 0.9333\n",
      "Epoch 464/499\n",
      "----------\n",
      "train Loss: 0.6836 Acc: 1.0000\n",
      "val Loss: 0.6832 Acc: 1.0000\n",
      "test Loss: 0.7140 Acc: 0.9333\n",
      "Epoch 465/499\n",
      "----------\n",
      "train Loss: 0.6925 Acc: 0.9889\n",
      "val Loss: 0.6818 Acc: 1.0000\n",
      "test Loss: 0.7070 Acc: 0.9333\n",
      "Epoch 466/499\n",
      "----------\n",
      "train Loss: 0.6950 Acc: 0.9889\n",
      "val Loss: 0.6832 Acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.7079 Acc: 0.9333\n",
      "Epoch 467/499\n",
      "----------\n",
      "train Loss: 0.6850 Acc: 1.0000\n",
      "val Loss: 0.6836 Acc: 1.0000\n",
      "test Loss: 0.7076 Acc: 0.9333\n",
      "Epoch 468/499\n",
      "----------\n",
      "train Loss: 0.6890 Acc: 0.9889\n",
      "val Loss: 0.6825 Acc: 1.0000\n",
      "test Loss: 0.7135 Acc: 0.9333\n",
      "Epoch 469/499\n",
      "----------\n",
      "train Loss: 0.6829 Acc: 0.9889\n",
      "val Loss: 0.6821 Acc: 1.0000\n",
      "test Loss: 0.7131 Acc: 0.9333\n",
      "Epoch 470/499\n",
      "----------\n",
      "train Loss: 0.6891 Acc: 0.9889\n",
      "val Loss: 0.6805 Acc: 1.0000\n",
      "test Loss: 0.7083 Acc: 0.9333\n",
      "Epoch 471/499\n",
      "----------\n",
      "train Loss: 0.6843 Acc: 1.0000\n",
      "val Loss: 0.6808 Acc: 1.0000\n",
      "test Loss: 0.7104 Acc: 0.9333\n",
      "Epoch 472/499\n",
      "----------\n",
      "train Loss: 0.6835 Acc: 1.0000\n",
      "val Loss: 0.6802 Acc: 1.0000\n",
      "test Loss: 0.7084 Acc: 0.9333\n",
      "Epoch 473/499\n",
      "----------\n",
      "train Loss: 0.6817 Acc: 1.0000\n",
      "val Loss: 0.6961 Acc: 0.9667\n",
      "test Loss: 0.7179 Acc: 0.9000\n",
      "Epoch 474/499\n",
      "----------\n",
      "train Loss: 0.6871 Acc: 0.9889\n",
      "val Loss: 0.6796 Acc: 1.0000\n",
      "test Loss: 0.7095 Acc: 0.9333\n",
      "Epoch 475/499\n",
      "----------\n",
      "train Loss: 0.6807 Acc: 1.0000\n",
      "val Loss: 0.6816 Acc: 1.0000\n",
      "test Loss: 0.7057 Acc: 0.9333\n",
      "Epoch 476/499\n",
      "----------\n",
      "train Loss: 0.6886 Acc: 0.9889\n",
      "val Loss: 0.6966 Acc: 0.9667\n",
      "test Loss: 0.7086 Acc: 0.9333\n",
      "Epoch 477/499\n",
      "----------\n",
      "train Loss: 0.6819 Acc: 1.0000\n",
      "val Loss: 0.6787 Acc: 1.0000\n",
      "test Loss: 0.7097 Acc: 0.9333\n",
      "Epoch 478/499\n",
      "----------\n",
      "train Loss: 0.6817 Acc: 1.0000\n",
      "val Loss: 0.6785 Acc: 1.0000\n",
      "test Loss: 0.7064 Acc: 0.9333\n",
      "Epoch 479/499\n",
      "----------\n",
      "train Loss: 0.6860 Acc: 0.9889\n",
      "val Loss: 0.6788 Acc: 1.0000\n",
      "test Loss: 0.7049 Acc: 0.9333\n",
      "Epoch 480/499\n",
      "----------\n",
      "train Loss: 0.6851 Acc: 0.9889\n",
      "val Loss: 0.6781 Acc: 1.0000\n",
      "test Loss: 0.7139 Acc: 0.9333\n",
      "Epoch 481/499\n",
      "----------\n",
      "train Loss: 0.6799 Acc: 1.0000\n",
      "val Loss: 0.6777 Acc: 1.0000\n",
      "test Loss: 0.7068 Acc: 0.9333\n",
      "Epoch 482/499\n",
      "----------\n",
      "train Loss: 0.6792 Acc: 1.0000\n",
      "val Loss: 0.6806 Acc: 1.0000\n",
      "test Loss: 0.7218 Acc: 0.9000\n",
      "Epoch 483/499\n",
      "----------\n",
      "train Loss: 0.6849 Acc: 0.9889\n",
      "val Loss: 0.6775 Acc: 1.0000\n",
      "test Loss: 0.7036 Acc: 0.9333\n",
      "Epoch 484/499\n",
      "----------\n",
      "train Loss: 0.6796 Acc: 1.0000\n",
      "val Loss: 0.6771 Acc: 1.0000\n",
      "test Loss: 0.7069 Acc: 0.9333\n",
      "Epoch 485/499\n",
      "----------\n",
      "train Loss: 0.6790 Acc: 1.0000\n",
      "val Loss: 0.6767 Acc: 1.0000\n",
      "test Loss: 0.7082 Acc: 0.9333\n",
      "Epoch 486/499\n",
      "----------\n",
      "train Loss: 0.6780 Acc: 1.0000\n",
      "val Loss: 0.6765 Acc: 1.0000\n",
      "test Loss: 0.7005 Acc: 0.9333\n",
      "Epoch 487/499\n",
      "----------\n",
      "train Loss: 0.6845 Acc: 0.9889\n",
      "val Loss: 0.6767 Acc: 1.0000\n",
      "test Loss: 0.7004 Acc: 0.9333\n",
      "Epoch 488/499\n",
      "----------\n",
      "train Loss: 0.6956 Acc: 0.9778\n",
      "val Loss: 0.6767 Acc: 1.0000\n",
      "test Loss: 0.7073 Acc: 0.9333\n",
      "Epoch 489/499\n",
      "----------\n",
      "train Loss: 0.6771 Acc: 1.0000\n",
      "val Loss: 0.6782 Acc: 1.0000\n",
      "test Loss: 0.7036 Acc: 0.9333\n",
      "Epoch 490/499\n",
      "----------\n",
      "train Loss: 0.6829 Acc: 0.9889\n",
      "val Loss: 0.6788 Acc: 1.0000\n",
      "test Loss: 0.7043 Acc: 0.9333\n",
      "Epoch 491/499\n",
      "----------\n",
      "train Loss: 0.6843 Acc: 0.9889\n",
      "val Loss: 0.6753 Acc: 1.0000\n",
      "test Loss: 0.7112 Acc: 0.9333\n",
      "Epoch 492/499\n",
      "----------\n",
      "train Loss: 0.6771 Acc: 1.0000\n",
      "val Loss: 0.6921 Acc: 0.9667\n",
      "test Loss: 0.7433 Acc: 0.9000\n",
      "Epoch 493/499\n",
      "----------\n",
      "train Loss: 0.6775 Acc: 1.0000\n",
      "val Loss: 0.6768 Acc: 1.0000\n",
      "test Loss: 0.7030 Acc: 0.9333\n",
      "Epoch 494/499\n",
      "----------\n",
      "train Loss: 0.6767 Acc: 1.0000\n",
      "val Loss: 0.6751 Acc: 1.0000\n",
      "test Loss: 0.7024 Acc: 0.9333\n",
      "Epoch 495/499\n",
      "----------\n",
      "train Loss: 0.6765 Acc: 1.0000\n",
      "val Loss: 0.6744 Acc: 1.0000\n",
      "test Loss: 0.7028 Acc: 0.9333\n",
      "Epoch 496/499\n",
      "----------\n",
      "train Loss: 0.6858 Acc: 0.9778\n",
      "val Loss: 0.6756 Acc: 1.0000\n",
      "test Loss: 0.7043 Acc: 0.9333\n",
      "Epoch 497/499\n",
      "----------\n",
      "train Loss: 0.6801 Acc: 0.9889\n",
      "val Loss: 0.6753 Acc: 1.0000\n",
      "test Loss: 0.7043 Acc: 0.9333\n",
      "Epoch 498/499\n",
      "----------\n",
      "train Loss: 0.6752 Acc: 1.0000\n",
      "val Loss: 0.6746 Acc: 1.0000\n",
      "test Loss: 0.7070 Acc: 0.9333\n",
      "Epoch 499/499\n",
      "----------\n",
      "train Loss: 0.6758 Acc: 1.0000\n",
      "val Loss: 0.6911 Acc: 0.9667\n",
      "test Loss: 0.7044 Acc: 0.9333\n",
      "Training complete in 0m 7s\n",
      "Best test Acc: 0.933333\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 1.0933 Acc: 0.3333\n",
      "val Loss: 1.0987 Acc: 0.3333\n",
      "test Loss: 1.0917 Acc: 0.3333\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 1.0951 Acc: 0.3333\n",
      "val Loss: 1.0925 Acc: 0.3333\n",
      "test Loss: 1.0894 Acc: 0.3333\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 1.0930 Acc: 0.3333\n",
      "val Loss: 1.0931 Acc: 0.3333\n",
      "test Loss: 1.0903 Acc: 0.3333\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 1.0929 Acc: 0.3333\n",
      "val Loss: 1.0927 Acc: 0.3333\n",
      "test Loss: 1.0897 Acc: 0.3333\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 1.0908 Acc: 0.3333\n",
      "val Loss: 1.0898 Acc: 0.3333\n",
      "test Loss: 1.0879 Acc: 0.3333\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 1.0912 Acc: 0.3333\n",
      "val Loss: 1.0876 Acc: 0.3333\n",
      "test Loss: 1.0878 Acc: 0.3333\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 1.0914 Acc: 0.3333\n",
      "val Loss: 1.0876 Acc: 0.3333\n",
      "test Loss: 1.0849 Acc: 0.3333\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 1.0885 Acc: 0.3333\n",
      "val Loss: 1.0879 Acc: 0.3333\n",
      "test Loss: 1.0849 Acc: 0.3333\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 1.0883 Acc: 0.3444\n",
      "val Loss: 1.0848 Acc: 0.3333\n",
      "test Loss: 1.0870 Acc: 0.3333\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 1.0846 Acc: 0.3333\n",
      "val Loss: 1.0891 Acc: 0.3333\n",
      "test Loss: 1.0831 Acc: 0.3333\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 1.0815 Acc: 0.3333\n",
      "val Loss: 1.0874 Acc: 0.3333\n",
      "test Loss: 1.0813 Acc: 0.3333\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 1.0841 Acc: 0.3333\n",
      "val Loss: 1.0801 Acc: 0.3333\n",
      "test Loss: 1.0859 Acc: 0.3333\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 1.0866 Acc: 0.3444\n",
      "val Loss: 1.0874 Acc: 0.3333\n",
      "test Loss: 1.0801 Acc: 0.3333\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 1.0827 Acc: 0.3333\n",
      "val Loss: 1.0815 Acc: 0.3333\n",
      "test Loss: 1.0809 Acc: 0.3333\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 1.0785 Acc: 0.3333\n",
      "val Loss: 1.0803 Acc: 0.3333\n",
      "test Loss: 1.0820 Acc: 0.3333\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 1.0775 Acc: 0.3444\n",
      "val Loss: 1.0788 Acc: 0.3333\n",
      "test Loss: 1.0799 Acc: 0.3333\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 1.0785 Acc: 0.3333\n",
      "val Loss: 1.0752 Acc: 0.3333\n",
      "test Loss: 1.0773 Acc: 0.3333\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 1.0766 Acc: 0.3333\n",
      "val Loss: 1.0734 Acc: 0.3667\n",
      "test Loss: 1.0730 Acc: 0.3333\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 1.0755 Acc: 0.3444\n",
      "val Loss: 1.0762 Acc: 0.3333\n",
      "test Loss: 1.0737 Acc: 0.3333\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 1.0755 Acc: 0.3333\n",
      "val Loss: 1.0745 Acc: 0.3333\n",
      "test Loss: 1.0693 Acc: 0.3333\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 1.0721 Acc: 0.3333\n",
      "val Loss: 1.0682 Acc: 0.3333\n",
      "test Loss: 1.0672 Acc: 0.3333\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 1.0707 Acc: 0.3444\n",
      "val Loss: 1.0726 Acc: 0.3333\n",
      "test Loss: 1.0709 Acc: 0.3333\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 1.0657 Acc: 0.3556\n",
      "val Loss: 1.0621 Acc: 0.4333\n",
      "test Loss: 1.0620 Acc: 0.3667\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 1.0666 Acc: 0.3556\n",
      "val Loss: 1.0668 Acc: 0.3333\n",
      "test Loss: 1.0592 Acc: 0.3667\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 1.0647 Acc: 0.3556\n",
      "val Loss: 1.0605 Acc: 0.3333\n",
      "test Loss: 1.0567 Acc: 0.3333\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 1.0601 Acc: 0.3778\n",
      "val Loss: 1.0580 Acc: 0.4000\n",
      "test Loss: 1.0589 Acc: 0.4000\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 1.0585 Acc: 0.3556\n",
      "val Loss: 1.0612 Acc: 0.3667\n",
      "test Loss: 1.0638 Acc: 0.4000\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 1.0552 Acc: 0.3667\n",
      "val Loss: 1.0571 Acc: 0.3333\n",
      "test Loss: 1.0580 Acc: 0.4333\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 1.0528 Acc: 0.3889\n",
      "val Loss: 1.0489 Acc: 0.3667\n",
      "test Loss: 1.0497 Acc: 0.4000\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 1.0556 Acc: 0.4000\n",
      "val Loss: 1.0540 Acc: 0.3333\n",
      "test Loss: 1.0432 Acc: 0.4000\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 1.0504 Acc: 0.4333\n",
      "val Loss: 1.0470 Acc: 0.3667\n",
      "test Loss: 1.0413 Acc: 0.4667\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 1.0498 Acc: 0.4333\n",
      "val Loss: 1.0410 Acc: 0.4667\n",
      "test Loss: 1.0420 Acc: 0.4667\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 1.0446 Acc: 0.4556\n",
      "val Loss: 1.0451 Acc: 0.4333\n",
      "test Loss: 1.0346 Acc: 0.4333\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 1.0401 Acc: 0.4778\n",
      "val Loss: 1.0323 Acc: 0.6333\n",
      "test Loss: 1.0339 Acc: 0.5333\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 1.0421 Acc: 0.5111\n",
      "val Loss: 1.0369 Acc: 0.5667\n",
      "test Loss: 1.0318 Acc: 0.6000\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 1.0386 Acc: 0.4667\n",
      "val Loss: 1.0279 Acc: 0.6333\n",
      "test Loss: 1.0289 Acc: 0.5333\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 1.0320 Acc: 0.5667\n",
      "val Loss: 1.0316 Acc: 0.6333\n",
      "test Loss: 1.0346 Acc: 0.6000\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 1.0323 Acc: 0.6000\n",
      "val Loss: 1.0339 Acc: 0.6000\n",
      "test Loss: 1.0192 Acc: 0.6000\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 1.0293 Acc: 0.5778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0234 Acc: 0.6333\n",
      "test Loss: 1.0174 Acc: 0.6333\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 1.0228 Acc: 0.6000\n",
      "val Loss: 1.0236 Acc: 0.6667\n",
      "test Loss: 1.0141 Acc: 0.6333\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 1.0161 Acc: 0.6111\n",
      "val Loss: 1.0148 Acc: 0.6333\n",
      "test Loss: 1.0103 Acc: 0.6333\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 1.0120 Acc: 0.6111\n",
      "val Loss: 1.0105 Acc: 0.6333\n",
      "test Loss: 1.0113 Acc: 0.6667\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 1.0085 Acc: 0.6222\n",
      "val Loss: 1.0093 Acc: 0.6333\n",
      "test Loss: 1.0048 Acc: 0.6333\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 1.0038 Acc: 0.6333\n",
      "val Loss: 1.0035 Acc: 0.6667\n",
      "test Loss: 0.9930 Acc: 0.6333\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 1.0005 Acc: 0.6222\n",
      "val Loss: 0.9989 Acc: 0.6333\n",
      "test Loss: 0.9970 Acc: 0.6000\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.9956 Acc: 0.6667\n",
      "val Loss: 0.9860 Acc: 0.6667\n",
      "test Loss: 0.9853 Acc: 0.6667\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.9947 Acc: 0.6000\n",
      "val Loss: 0.9880 Acc: 0.6667\n",
      "test Loss: 0.9966 Acc: 0.6333\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.9906 Acc: 0.6222\n",
      "val Loss: 0.9929 Acc: 0.6000\n",
      "test Loss: 0.9752 Acc: 0.6667\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.9796 Acc: 0.6333\n",
      "val Loss: 0.9747 Acc: 0.6000\n",
      "test Loss: 0.9883 Acc: 0.5667\n",
      "Epoch 49/499\n",
      "----------\n",
      "train Loss: 0.9756 Acc: 0.6333\n",
      "val Loss: 0.9753 Acc: 0.6667\n",
      "test Loss: 0.9814 Acc: 0.6333\n",
      "Epoch 50/499\n",
      "----------\n",
      "train Loss: 0.9745 Acc: 0.6333\n",
      "val Loss: 0.9709 Acc: 0.5667\n",
      "test Loss: 0.9831 Acc: 0.6000\n",
      "Epoch 51/499\n",
      "----------\n",
      "train Loss: 0.9698 Acc: 0.6333\n",
      "val Loss: 0.9692 Acc: 0.6000\n",
      "test Loss: 0.9654 Acc: 0.6333\n",
      "Epoch 52/499\n",
      "----------\n",
      "train Loss: 0.9676 Acc: 0.6333\n",
      "val Loss: 0.9717 Acc: 0.6000\n",
      "test Loss: 0.9578 Acc: 0.6333\n",
      "Epoch 53/499\n",
      "----------\n",
      "train Loss: 0.9622 Acc: 0.6556\n",
      "val Loss: 0.9520 Acc: 0.6667\n",
      "test Loss: 0.9661 Acc: 0.5667\n",
      "Epoch 54/499\n",
      "----------\n",
      "train Loss: 0.9593 Acc: 0.6333\n",
      "val Loss: 0.9460 Acc: 0.6000\n",
      "test Loss: 0.9402 Acc: 0.6667\n",
      "Epoch 55/499\n",
      "----------\n",
      "train Loss: 0.9557 Acc: 0.6111\n",
      "val Loss: 0.9466 Acc: 0.6333\n",
      "test Loss: 0.9360 Acc: 0.6333\n",
      "Epoch 56/499\n",
      "----------\n",
      "train Loss: 0.9459 Acc: 0.6333\n",
      "val Loss: 0.9472 Acc: 0.6000\n",
      "test Loss: 0.9420 Acc: 0.6333\n",
      "Epoch 57/499\n",
      "----------\n",
      "train Loss: 0.9441 Acc: 0.6333\n",
      "val Loss: 0.9642 Acc: 0.5667\n",
      "test Loss: 0.9221 Acc: 0.6667\n",
      "Epoch 58/499\n",
      "----------\n",
      "train Loss: 0.9341 Acc: 0.6444\n",
      "val Loss: 0.9285 Acc: 0.6667\n",
      "test Loss: 0.9290 Acc: 0.6667\n",
      "Epoch 59/499\n",
      "----------\n",
      "train Loss: 0.9329 Acc: 0.6333\n",
      "val Loss: 0.9284 Acc: 0.6333\n",
      "test Loss: 0.9243 Acc: 0.6333\n",
      "Epoch 60/499\n",
      "----------\n",
      "train Loss: 0.9346 Acc: 0.6444\n",
      "val Loss: 0.9382 Acc: 0.6000\n",
      "test Loss: 0.9073 Acc: 0.6667\n",
      "Epoch 61/499\n",
      "----------\n",
      "train Loss: 0.9204 Acc: 0.6556\n",
      "val Loss: 0.9154 Acc: 0.6667\n",
      "test Loss: 0.9043 Acc: 0.6667\n",
      "Epoch 62/499\n",
      "----------\n",
      "train Loss: 0.9163 Acc: 0.6444\n",
      "val Loss: 0.9255 Acc: 0.5667\n",
      "test Loss: 0.9013 Acc: 0.6667\n",
      "Epoch 63/499\n",
      "----------\n",
      "train Loss: 0.9150 Acc: 0.6222\n",
      "val Loss: 0.9113 Acc: 0.6333\n",
      "test Loss: 0.8987 Acc: 0.6333\n",
      "Epoch 64/499\n",
      "----------\n",
      "train Loss: 0.9080 Acc: 0.6444\n",
      "val Loss: 0.9240 Acc: 0.6000\n",
      "test Loss: 0.9111 Acc: 0.6333\n",
      "Epoch 65/499\n",
      "----------\n",
      "train Loss: 0.9069 Acc: 0.6444\n",
      "val Loss: 0.9053 Acc: 0.6333\n",
      "test Loss: 0.9054 Acc: 0.6667\n",
      "Epoch 66/499\n",
      "----------\n",
      "train Loss: 0.9014 Acc: 0.6556\n",
      "val Loss: 0.9138 Acc: 0.6333\n",
      "test Loss: 0.8963 Acc: 0.6667\n",
      "Epoch 67/499\n",
      "----------\n",
      "train Loss: 0.9002 Acc: 0.6556\n",
      "val Loss: 0.9024 Acc: 0.6667\n",
      "test Loss: 0.9097 Acc: 0.6667\n",
      "Epoch 68/499\n",
      "----------\n",
      "train Loss: 0.8951 Acc: 0.6667\n",
      "val Loss: 0.8913 Acc: 0.6667\n",
      "test Loss: 0.9051 Acc: 0.6333\n",
      "Epoch 69/499\n",
      "----------\n",
      "train Loss: 0.8915 Acc: 0.6667\n",
      "val Loss: 0.8872 Acc: 0.6667\n",
      "test Loss: 0.8879 Acc: 0.6667\n",
      "Epoch 70/499\n",
      "----------\n",
      "train Loss: 0.8883 Acc: 0.6556\n",
      "val Loss: 0.9196 Acc: 0.6333\n",
      "test Loss: 0.8902 Acc: 0.6667\n",
      "Epoch 71/499\n",
      "----------\n",
      "train Loss: 0.8781 Acc: 0.6667\n",
      "val Loss: 0.8809 Acc: 0.6667\n",
      "test Loss: 0.8579 Acc: 0.6667\n",
      "Epoch 72/499\n",
      "----------\n",
      "train Loss: 0.8787 Acc: 0.6667\n",
      "val Loss: 0.8760 Acc: 0.7000\n",
      "test Loss: 0.8829 Acc: 0.6667\n",
      "Epoch 73/499\n",
      "----------\n",
      "train Loss: 0.8780 Acc: 0.6667\n",
      "val Loss: 0.8796 Acc: 0.6667\n",
      "test Loss: 0.8674 Acc: 0.6333\n",
      "Epoch 74/499\n",
      "----------\n",
      "train Loss: 0.8717 Acc: 0.6556\n",
      "val Loss: 0.8808 Acc: 0.6667\n",
      "test Loss: 0.8652 Acc: 0.6667\n",
      "Epoch 75/499\n",
      "----------\n",
      "train Loss: 0.8709 Acc: 0.6667\n",
      "val Loss: 0.8800 Acc: 0.6667\n",
      "test Loss: 0.8717 Acc: 0.6667\n",
      "Epoch 76/499\n",
      "----------\n",
      "train Loss: 0.8685 Acc: 0.6667\n",
      "val Loss: 0.8710 Acc: 0.6333\n",
      "test Loss: 0.8509 Acc: 0.6667\n",
      "Epoch 77/499\n",
      "----------\n",
      "train Loss: 0.8726 Acc: 0.6667\n",
      "val Loss: 0.8741 Acc: 0.6667\n",
      "test Loss: 0.8427 Acc: 0.6667\n",
      "Epoch 78/499\n",
      "----------\n",
      "train Loss: 0.8738 Acc: 0.6667\n",
      "val Loss: 0.8528 Acc: 0.6667\n",
      "test Loss: 0.8648 Acc: 0.6667\n",
      "Epoch 79/499\n",
      "----------\n",
      "train Loss: 0.8552 Acc: 0.6778\n",
      "val Loss: 0.8437 Acc: 0.7000\n",
      "test Loss: 0.8469 Acc: 0.6667\n",
      "Epoch 80/499\n",
      "----------\n",
      "train Loss: 0.8619 Acc: 0.6667\n",
      "val Loss: 0.8631 Acc: 0.6333\n",
      "test Loss: 0.8535 Acc: 0.6667\n",
      "Epoch 81/499\n",
      "----------\n",
      "train Loss: 0.8638 Acc: 0.6444\n",
      "val Loss: 0.8430 Acc: 0.7000\n",
      "test Loss: 0.8442 Acc: 0.6667\n",
      "Epoch 82/499\n",
      "----------\n",
      "train Loss: 0.8562 Acc: 0.6667\n",
      "val Loss: 0.8684 Acc: 0.6667\n",
      "test Loss: 0.8496 Acc: 0.6667\n",
      "Epoch 83/499\n",
      "----------\n",
      "train Loss: 0.8495 Acc: 0.6556\n",
      "val Loss: 0.8365 Acc: 0.6667\n",
      "test Loss: 0.8401 Acc: 0.6667\n",
      "Epoch 84/499\n",
      "----------\n",
      "train Loss: 0.8435 Acc: 0.6889\n",
      "val Loss: 0.8528 Acc: 0.7000\n",
      "test Loss: 0.8302 Acc: 0.6667\n",
      "Epoch 85/499\n",
      "----------\n",
      "train Loss: 0.8658 Acc: 0.6556\n",
      "val Loss: 0.8469 Acc: 0.6333\n",
      "test Loss: 0.8373 Acc: 0.6667\n",
      "Epoch 86/499\n",
      "----------\n",
      "train Loss: 0.8448 Acc: 0.6556\n",
      "val Loss: 0.8544 Acc: 0.6667\n",
      "test Loss: 0.8364 Acc: 0.6667\n",
      "Epoch 87/499\n",
      "----------\n",
      "train Loss: 0.8442 Acc: 0.6778\n",
      "val Loss: 0.8435 Acc: 0.6667\n",
      "test Loss: 0.8378 Acc: 0.7000\n",
      "Epoch 88/499\n",
      "----------\n",
      "train Loss: 0.8395 Acc: 0.7000\n",
      "val Loss: 0.8338 Acc: 0.7000\n",
      "test Loss: 0.8375 Acc: 0.6667\n",
      "Epoch 89/499\n",
      "----------\n",
      "train Loss: 0.8405 Acc: 0.6778\n",
      "val Loss: 0.8220 Acc: 0.6667\n",
      "test Loss: 0.8413 Acc: 0.6333\n",
      "Epoch 90/499\n",
      "----------\n",
      "train Loss: 0.8467 Acc: 0.7000\n",
      "val Loss: 0.8421 Acc: 0.7000\n",
      "test Loss: 0.8127 Acc: 0.6667\n",
      "Epoch 91/499\n",
      "----------\n",
      "train Loss: 0.8405 Acc: 0.6778\n",
      "val Loss: 0.8232 Acc: 0.7000\n",
      "test Loss: 0.8529 Acc: 0.6333\n",
      "Epoch 92/499\n",
      "----------\n",
      "train Loss: 0.8404 Acc: 0.6778\n",
      "val Loss: 0.8181 Acc: 0.7333\n",
      "test Loss: 0.8199 Acc: 0.6333\n",
      "Epoch 93/499\n",
      "----------\n",
      "train Loss: 0.8348 Acc: 0.6444\n",
      "val Loss: 0.8468 Acc: 0.7333\n",
      "test Loss: 0.8305 Acc: 0.6667\n",
      "Epoch 94/499\n",
      "----------\n",
      "train Loss: 0.8292 Acc: 0.6889\n",
      "val Loss: 0.8339 Acc: 0.6333\n",
      "test Loss: 0.8281 Acc: 0.6333\n",
      "Epoch 95/499\n",
      "----------\n",
      "train Loss: 0.8233 Acc: 0.7111\n",
      "val Loss: 0.8401 Acc: 0.7667\n",
      "test Loss: 0.8189 Acc: 0.7000\n",
      "Epoch 96/499\n",
      "----------\n",
      "train Loss: 0.8254 Acc: 0.6444\n",
      "val Loss: 0.8249 Acc: 0.6667\n",
      "test Loss: 0.8410 Acc: 0.6333\n",
      "Epoch 97/499\n",
      "----------\n",
      "train Loss: 0.8216 Acc: 0.6778\n",
      "val Loss: 0.8369 Acc: 0.6667\n",
      "test Loss: 0.8329 Acc: 0.7000\n",
      "Epoch 98/499\n",
      "----------\n",
      "train Loss: 0.8263 Acc: 0.7000\n",
      "val Loss: 0.8208 Acc: 0.7333\n",
      "test Loss: 0.8225 Acc: 0.7000\n",
      "Epoch 99/499\n",
      "----------\n",
      "train Loss: 0.8141 Acc: 0.6889\n",
      "val Loss: 0.8230 Acc: 0.6667\n",
      "test Loss: 0.8317 Acc: 0.6000\n",
      "Epoch 100/499\n",
      "----------\n",
      "train Loss: 0.8141 Acc: 0.6778\n",
      "val Loss: 0.8315 Acc: 0.6667\n",
      "test Loss: 0.8057 Acc: 0.7000\n",
      "Epoch 101/499\n",
      "----------\n",
      "train Loss: 0.8351 Acc: 0.6556\n",
      "val Loss: 0.8229 Acc: 0.7000\n",
      "test Loss: 0.8215 Acc: 0.6667\n",
      "Epoch 102/499\n",
      "----------\n",
      "train Loss: 0.8206 Acc: 0.6778\n",
      "val Loss: 0.8140 Acc: 0.6667\n",
      "test Loss: 0.8032 Acc: 0.7000\n",
      "Epoch 103/499\n",
      "----------\n",
      "train Loss: 0.8093 Acc: 0.6667\n",
      "val Loss: 0.7985 Acc: 0.7667\n",
      "test Loss: 0.8019 Acc: 0.7333\n",
      "Epoch 104/499\n",
      "----------\n",
      "train Loss: 0.8180 Acc: 0.6889\n",
      "val Loss: 0.8064 Acc: 0.7667\n",
      "test Loss: 0.8352 Acc: 0.6667\n",
      "Epoch 105/499\n",
      "----------\n",
      "train Loss: 0.8181 Acc: 0.6444\n",
      "val Loss: 0.8040 Acc: 0.7667\n",
      "test Loss: 0.8067 Acc: 0.6667\n",
      "Epoch 106/499\n",
      "----------\n",
      "train Loss: 0.8310 Acc: 0.6222\n",
      "val Loss: 0.8142 Acc: 0.6333\n",
      "test Loss: 0.8189 Acc: 0.6333\n",
      "Epoch 107/499\n",
      "----------\n",
      "train Loss: 0.8193 Acc: 0.6667\n",
      "val Loss: 0.8077 Acc: 0.8333\n",
      "test Loss: 0.8118 Acc: 0.6667\n",
      "Epoch 108/499\n",
      "----------\n",
      "train Loss: 0.8116 Acc: 0.6444\n",
      "val Loss: 0.8067 Acc: 0.6333\n",
      "test Loss: 0.7994 Acc: 0.6667\n",
      "Epoch 109/499\n",
      "----------\n",
      "train Loss: 0.8176 Acc: 0.6889\n",
      "val Loss: 0.8278 Acc: 0.7333\n",
      "test Loss: 0.8063 Acc: 0.7000\n",
      "Epoch 110/499\n",
      "----------\n",
      "train Loss: 0.8156 Acc: 0.6556\n",
      "val Loss: 0.8148 Acc: 0.7333\n",
      "test Loss: 0.7993 Acc: 0.6667\n",
      "Epoch 111/499\n",
      "----------\n",
      "train Loss: 0.8207 Acc: 0.6444\n",
      "val Loss: 0.8060 Acc: 0.7667\n",
      "test Loss: 0.8007 Acc: 0.6667\n",
      "Epoch 112/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.8059 Acc: 0.7000\n",
      "val Loss: 0.8099 Acc: 0.7333\n",
      "test Loss: 0.8296 Acc: 0.5667\n",
      "Epoch 113/499\n",
      "----------\n",
      "train Loss: 0.8047 Acc: 0.7222\n",
      "val Loss: 0.8124 Acc: 0.6333\n",
      "test Loss: 0.8086 Acc: 0.6667\n",
      "Epoch 114/499\n",
      "----------\n",
      "train Loss: 0.8025 Acc: 0.6889\n",
      "val Loss: 0.7987 Acc: 0.7667\n",
      "test Loss: 0.8106 Acc: 0.6333\n",
      "Epoch 115/499\n",
      "----------\n",
      "train Loss: 0.8187 Acc: 0.6667\n",
      "val Loss: 0.8094 Acc: 0.7000\n",
      "test Loss: 0.7995 Acc: 0.7000\n",
      "Epoch 116/499\n",
      "----------\n",
      "train Loss: 0.8103 Acc: 0.6444\n",
      "val Loss: 0.8039 Acc: 0.7333\n",
      "test Loss: 0.8126 Acc: 0.6667\n",
      "Epoch 117/499\n",
      "----------\n",
      "train Loss: 0.8017 Acc: 0.6889\n",
      "val Loss: 0.8188 Acc: 0.6667\n",
      "test Loss: 0.7947 Acc: 0.6667\n",
      "Epoch 118/499\n",
      "----------\n",
      "train Loss: 0.8040 Acc: 0.6556\n",
      "val Loss: 0.7937 Acc: 0.7333\n",
      "test Loss: 0.7960 Acc: 0.6667\n",
      "Epoch 119/499\n",
      "----------\n",
      "train Loss: 0.7967 Acc: 0.7556\n",
      "val Loss: 0.7871 Acc: 0.7667\n",
      "test Loss: 0.8058 Acc: 0.6667\n",
      "Epoch 120/499\n",
      "----------\n",
      "train Loss: 0.8025 Acc: 0.7111\n",
      "val Loss: 0.7928 Acc: 0.7333\n",
      "test Loss: 0.7787 Acc: 0.7667\n",
      "Epoch 121/499\n",
      "----------\n",
      "train Loss: 0.7965 Acc: 0.6889\n",
      "val Loss: 0.7958 Acc: 0.7000\n",
      "test Loss: 0.8027 Acc: 0.7000\n",
      "Epoch 122/499\n",
      "----------\n",
      "train Loss: 0.8013 Acc: 0.6444\n",
      "val Loss: 0.8009 Acc: 0.6667\n",
      "test Loss: 0.7887 Acc: 0.7000\n",
      "Epoch 123/499\n",
      "----------\n",
      "train Loss: 0.8143 Acc: 0.6333\n",
      "val Loss: 0.7873 Acc: 0.7000\n",
      "test Loss: 0.7859 Acc: 0.6667\n",
      "Epoch 124/499\n",
      "----------\n",
      "train Loss: 0.8033 Acc: 0.6667\n",
      "val Loss: 0.7997 Acc: 0.7333\n",
      "test Loss: 0.7869 Acc: 0.6333\n",
      "Epoch 125/499\n",
      "----------\n",
      "train Loss: 0.7957 Acc: 0.7111\n",
      "val Loss: 0.7989 Acc: 0.7000\n",
      "test Loss: 0.7888 Acc: 0.6333\n",
      "Epoch 126/499\n",
      "----------\n",
      "train Loss: 0.7916 Acc: 0.6667\n",
      "val Loss: 0.7838 Acc: 0.7333\n",
      "test Loss: 0.7937 Acc: 0.7000\n",
      "Epoch 127/499\n",
      "----------\n",
      "train Loss: 0.8007 Acc: 0.6778\n",
      "val Loss: 0.7901 Acc: 0.7333\n",
      "test Loss: 0.7924 Acc: 0.7333\n",
      "Epoch 128/499\n",
      "----------\n",
      "train Loss: 0.7965 Acc: 0.6889\n",
      "val Loss: 0.7905 Acc: 0.7333\n",
      "test Loss: 0.7876 Acc: 0.7333\n",
      "Epoch 129/499\n",
      "----------\n",
      "train Loss: 0.7989 Acc: 0.6667\n",
      "val Loss: 0.7917 Acc: 0.7000\n",
      "test Loss: 0.7905 Acc: 0.6333\n",
      "Epoch 130/499\n",
      "----------\n",
      "train Loss: 0.7925 Acc: 0.7444\n",
      "val Loss: 0.7757 Acc: 0.7333\n",
      "test Loss: 0.7956 Acc: 0.6333\n",
      "Epoch 131/499\n",
      "----------\n",
      "train Loss: 0.7944 Acc: 0.6778\n",
      "val Loss: 0.7922 Acc: 0.7333\n",
      "test Loss: 0.8037 Acc: 0.6000\n",
      "Epoch 132/499\n",
      "----------\n",
      "train Loss: 0.7950 Acc: 0.6778\n",
      "val Loss: 0.8040 Acc: 0.7000\n",
      "test Loss: 0.7855 Acc: 0.6667\n",
      "Epoch 133/499\n",
      "----------\n",
      "train Loss: 0.7957 Acc: 0.6667\n",
      "val Loss: 0.8060 Acc: 0.6667\n",
      "test Loss: 0.7888 Acc: 0.6667\n",
      "Epoch 134/499\n",
      "----------\n",
      "train Loss: 0.7938 Acc: 0.6667\n",
      "val Loss: 0.7877 Acc: 0.7333\n",
      "test Loss: 0.7753 Acc: 0.6667\n",
      "Epoch 135/499\n",
      "----------\n",
      "train Loss: 0.7837 Acc: 0.7556\n",
      "val Loss: 0.7899 Acc: 0.7333\n",
      "test Loss: 0.7806 Acc: 0.7333\n",
      "Epoch 136/499\n",
      "----------\n",
      "train Loss: 0.7957 Acc: 0.7111\n",
      "val Loss: 0.8092 Acc: 0.6667\n",
      "test Loss: 0.7750 Acc: 0.7000\n",
      "Epoch 137/499\n",
      "----------\n",
      "train Loss: 0.7993 Acc: 0.6556\n",
      "val Loss: 0.7818 Acc: 0.6667\n",
      "test Loss: 0.7883 Acc: 0.6667\n",
      "Epoch 138/499\n",
      "----------\n",
      "train Loss: 0.7921 Acc: 0.7222\n",
      "val Loss: 0.7813 Acc: 0.7000\n",
      "test Loss: 0.7807 Acc: 0.7000\n",
      "Epoch 139/499\n",
      "----------\n",
      "train Loss: 0.7858 Acc: 0.7111\n",
      "val Loss: 0.7796 Acc: 0.8000\n",
      "test Loss: 0.7863 Acc: 0.6000\n",
      "Epoch 140/499\n",
      "----------\n",
      "train Loss: 0.7928 Acc: 0.7000\n",
      "val Loss: 0.7836 Acc: 0.7667\n",
      "test Loss: 0.7711 Acc: 0.7000\n",
      "Epoch 141/499\n",
      "----------\n",
      "train Loss: 0.7925 Acc: 0.7444\n",
      "val Loss: 0.8063 Acc: 0.7000\n",
      "test Loss: 0.7786 Acc: 0.6667\n",
      "Epoch 142/499\n",
      "----------\n",
      "train Loss: 0.7970 Acc: 0.6778\n",
      "val Loss: 0.7867 Acc: 0.7333\n",
      "test Loss: 0.7720 Acc: 0.7000\n",
      "Epoch 143/499\n",
      "----------\n",
      "train Loss: 0.7839 Acc: 0.7000\n",
      "val Loss: 0.7774 Acc: 0.7333\n",
      "test Loss: 0.7975 Acc: 0.7000\n",
      "Epoch 144/499\n",
      "----------\n",
      "train Loss: 0.7826 Acc: 0.7333\n",
      "val Loss: 0.7797 Acc: 0.7333\n",
      "test Loss: 0.7872 Acc: 0.7333\n",
      "Epoch 145/499\n",
      "----------\n",
      "train Loss: 0.7805 Acc: 0.7222\n",
      "val Loss: 0.7898 Acc: 0.7667\n",
      "test Loss: 0.7833 Acc: 0.7000\n",
      "Epoch 146/499\n",
      "----------\n",
      "train Loss: 0.7803 Acc: 0.7333\n",
      "val Loss: 0.7687 Acc: 0.8000\n",
      "test Loss: 0.7875 Acc: 0.7333\n",
      "Epoch 147/499\n",
      "----------\n",
      "train Loss: 0.7839 Acc: 0.7444\n",
      "val Loss: 0.7782 Acc: 0.8000\n",
      "test Loss: 0.7994 Acc: 0.7000\n",
      "Epoch 148/499\n",
      "----------\n",
      "train Loss: 0.7865 Acc: 0.7111\n",
      "val Loss: 0.7773 Acc: 0.7667\n",
      "test Loss: 0.7923 Acc: 0.8333\n",
      "Epoch 149/499\n",
      "----------\n",
      "train Loss: 0.7908 Acc: 0.7000\n",
      "val Loss: 0.7682 Acc: 0.8333\n",
      "test Loss: 0.7710 Acc: 0.8333\n",
      "Epoch 150/499\n",
      "----------\n",
      "train Loss: 0.7831 Acc: 0.7222\n",
      "val Loss: 0.7686 Acc: 0.7667\n",
      "test Loss: 0.7778 Acc: 0.7333\n",
      "Epoch 151/499\n",
      "----------\n",
      "train Loss: 0.7887 Acc: 0.7222\n",
      "val Loss: 0.7874 Acc: 0.7333\n",
      "test Loss: 0.7795 Acc: 0.7667\n",
      "Epoch 152/499\n",
      "----------\n",
      "train Loss: 0.7749 Acc: 0.8000\n",
      "val Loss: 0.7782 Acc: 0.7667\n",
      "test Loss: 0.8010 Acc: 0.7667\n",
      "Epoch 153/499\n",
      "----------\n",
      "train Loss: 0.7870 Acc: 0.7444\n",
      "val Loss: 0.7747 Acc: 0.8000\n",
      "test Loss: 0.7931 Acc: 0.7333\n",
      "Epoch 154/499\n",
      "----------\n",
      "train Loss: 0.7753 Acc: 0.7778\n",
      "val Loss: 0.7771 Acc: 0.8333\n",
      "test Loss: 0.7684 Acc: 0.8333\n",
      "Epoch 155/499\n",
      "----------\n",
      "train Loss: 0.7736 Acc: 0.7889\n",
      "val Loss: 0.7688 Acc: 0.8333\n",
      "test Loss: 0.7812 Acc: 0.8333\n",
      "Epoch 156/499\n",
      "----------\n",
      "train Loss: 0.7704 Acc: 0.8444\n",
      "val Loss: 0.7759 Acc: 0.8000\n",
      "test Loss: 0.7680 Acc: 0.8000\n",
      "Epoch 157/499\n",
      "----------\n",
      "train Loss: 0.7780 Acc: 0.8333\n",
      "val Loss: 0.7664 Acc: 0.8667\n",
      "test Loss: 0.7657 Acc: 0.8667\n",
      "Epoch 158/499\n",
      "----------\n",
      "train Loss: 0.7743 Acc: 0.8556\n",
      "val Loss: 0.7694 Acc: 0.8333\n",
      "test Loss: 0.7747 Acc: 0.8667\n",
      "Epoch 159/499\n",
      "----------\n",
      "train Loss: 0.7747 Acc: 0.8444\n",
      "val Loss: 0.7788 Acc: 0.8667\n",
      "test Loss: 0.7780 Acc: 0.8000\n",
      "Epoch 160/499\n",
      "----------\n",
      "train Loss: 0.7745 Acc: 0.8333\n",
      "val Loss: 0.7645 Acc: 0.9333\n",
      "test Loss: 0.7765 Acc: 0.8333\n",
      "Epoch 161/499\n",
      "----------\n",
      "train Loss: 0.7739 Acc: 0.8444\n",
      "val Loss: 0.7647 Acc: 0.9333\n",
      "test Loss: 0.7662 Acc: 0.8333\n",
      "Epoch 162/499\n",
      "----------\n",
      "train Loss: 0.7770 Acc: 0.8667\n",
      "val Loss: 0.7698 Acc: 0.9000\n",
      "test Loss: 0.7802 Acc: 0.8000\n",
      "Epoch 163/499\n",
      "----------\n",
      "train Loss: 0.7681 Acc: 0.9111\n",
      "val Loss: 0.7761 Acc: 0.8667\n",
      "test Loss: 0.7605 Acc: 0.9333\n",
      "Epoch 164/499\n",
      "----------\n",
      "train Loss: 0.7669 Acc: 0.9000\n",
      "val Loss: 0.7794 Acc: 0.9000\n",
      "test Loss: 0.7703 Acc: 0.8667\n",
      "Epoch 165/499\n",
      "----------\n",
      "train Loss: 0.7695 Acc: 0.8333\n",
      "val Loss: 0.7543 Acc: 1.0000\n",
      "test Loss: 0.7695 Acc: 0.8000\n",
      "Epoch 166/499\n",
      "----------\n",
      "train Loss: 0.7823 Acc: 0.8222\n",
      "val Loss: 0.7679 Acc: 0.8333\n",
      "test Loss: 0.7645 Acc: 0.8000\n",
      "Epoch 167/499\n",
      "----------\n",
      "train Loss: 0.7702 Acc: 0.7778\n",
      "val Loss: 0.7624 Acc: 0.8000\n",
      "test Loss: 0.7645 Acc: 0.8000\n",
      "Epoch 168/499\n",
      "----------\n",
      "train Loss: 0.7778 Acc: 0.7556\n",
      "val Loss: 0.7677 Acc: 0.6667\n",
      "test Loss: 0.7672 Acc: 0.7000\n",
      "Epoch 169/499\n",
      "----------\n",
      "train Loss: 0.7680 Acc: 0.6889\n",
      "val Loss: 0.7620 Acc: 0.7000\n",
      "test Loss: 0.7583 Acc: 0.7000\n",
      "Epoch 170/499\n",
      "----------\n",
      "train Loss: 0.7756 Acc: 0.6667\n",
      "val Loss: 0.7613 Acc: 0.7000\n",
      "test Loss: 0.7842 Acc: 0.6667\n",
      "Epoch 171/499\n",
      "----------\n",
      "train Loss: 0.7665 Acc: 0.6667\n",
      "val Loss: 0.7517 Acc: 0.7000\n",
      "test Loss: 0.7745 Acc: 0.6667\n",
      "Epoch 172/499\n",
      "----------\n",
      "train Loss: 0.7644 Acc: 0.6778\n",
      "val Loss: 0.7784 Acc: 0.6667\n",
      "test Loss: 0.7690 Acc: 0.6333\n",
      "Epoch 173/499\n",
      "----------\n",
      "train Loss: 0.7631 Acc: 0.7000\n",
      "val Loss: 0.7602 Acc: 0.6667\n",
      "test Loss: 0.7753 Acc: 0.6667\n",
      "Epoch 174/499\n",
      "----------\n",
      "train Loss: 0.7649 Acc: 0.7000\n",
      "val Loss: 0.7731 Acc: 0.6333\n",
      "test Loss: 0.7660 Acc: 0.6333\n",
      "Epoch 175/499\n",
      "----------\n",
      "train Loss: 0.7730 Acc: 0.6333\n",
      "val Loss: 0.7607 Acc: 0.6667\n",
      "test Loss: 0.7636 Acc: 0.6333\n",
      "Epoch 176/499\n",
      "----------\n",
      "train Loss: 0.7611 Acc: 0.6667\n",
      "val Loss: 0.7647 Acc: 0.7000\n",
      "test Loss: 0.7781 Acc: 0.6667\n",
      "Epoch 177/499\n",
      "----------\n",
      "train Loss: 0.7671 Acc: 0.6667\n",
      "val Loss: 0.7531 Acc: 0.7000\n",
      "test Loss: 0.7667 Acc: 0.6667\n",
      "Epoch 178/499\n",
      "----------\n",
      "train Loss: 0.7596 Acc: 0.6667\n",
      "val Loss: 0.7494 Acc: 0.7000\n",
      "test Loss: 0.7674 Acc: 0.6667\n",
      "Epoch 179/499\n",
      "----------\n",
      "train Loss: 0.7649 Acc: 0.6778\n",
      "val Loss: 0.7664 Acc: 0.6333\n",
      "test Loss: 0.7753 Acc: 0.6000\n",
      "Epoch 180/499\n",
      "----------\n",
      "train Loss: 0.7636 Acc: 0.7111\n",
      "val Loss: 0.7655 Acc: 0.6667\n",
      "test Loss: 0.7621 Acc: 0.7000\n",
      "Epoch 181/499\n",
      "----------\n",
      "train Loss: 0.7620 Acc: 0.6778\n",
      "val Loss: 0.7713 Acc: 0.6333\n",
      "test Loss: 0.7467 Acc: 0.8000\n",
      "Epoch 182/499\n",
      "----------\n",
      "train Loss: 0.7621 Acc: 0.6778\n",
      "val Loss: 0.7584 Acc: 0.7000\n",
      "test Loss: 0.7665 Acc: 0.6667\n",
      "Epoch 183/499\n",
      "----------\n",
      "train Loss: 0.7638 Acc: 0.6778\n",
      "val Loss: 0.7416 Acc: 0.6667\n",
      "test Loss: 0.7925 Acc: 0.6000\n",
      "Epoch 184/499\n",
      "----------\n",
      "train Loss: 0.7579 Acc: 0.6667\n",
      "val Loss: 0.7702 Acc: 0.6333\n",
      "test Loss: 0.7638 Acc: 0.6667\n",
      "Epoch 185/499\n",
      "----------\n",
      "train Loss: 0.7588 Acc: 0.6889\n",
      "val Loss: 0.7461 Acc: 0.7333\n",
      "test Loss: 0.7681 Acc: 0.7000\n",
      "Epoch 186/499\n",
      "----------\n",
      "train Loss: 0.7722 Acc: 0.6889\n",
      "val Loss: 0.7556 Acc: 0.6667\n",
      "test Loss: 0.7607 Acc: 0.6667\n",
      "Epoch 187/499\n",
      "----------\n",
      "train Loss: 0.7488 Acc: 0.6778\n",
      "val Loss: 0.7404 Acc: 0.6667\n",
      "test Loss: 0.7643 Acc: 0.6333\n",
      "Epoch 188/499\n",
      "----------\n",
      "train Loss: 0.7560 Acc: 0.7000\n",
      "val Loss: 0.7566 Acc: 0.7000\n",
      "test Loss: 0.7557 Acc: 0.7000\n",
      "Epoch 189/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.7595 Acc: 0.6889\n",
      "val Loss: 0.7402 Acc: 0.7333\n",
      "test Loss: 0.7590 Acc: 0.7000\n",
      "Epoch 190/499\n",
      "----------\n",
      "train Loss: 0.7608 Acc: 0.6556\n",
      "val Loss: 0.7387 Acc: 0.7000\n",
      "test Loss: 0.7636 Acc: 0.6667\n",
      "Epoch 191/499\n",
      "----------\n",
      "train Loss: 0.7611 Acc: 0.6778\n",
      "val Loss: 0.7439 Acc: 0.7000\n",
      "test Loss: 0.7562 Acc: 0.6667\n",
      "Epoch 192/499\n",
      "----------\n",
      "train Loss: 0.7566 Acc: 0.6778\n",
      "val Loss: 0.7293 Acc: 0.7333\n",
      "test Loss: 0.7526 Acc: 0.6000\n",
      "Epoch 193/499\n",
      "----------\n",
      "train Loss: 0.7746 Acc: 0.6444\n",
      "val Loss: 0.7674 Acc: 0.6667\n",
      "test Loss: 0.7618 Acc: 0.6000\n",
      "Epoch 194/499\n",
      "----------\n",
      "train Loss: 0.7551 Acc: 0.6889\n",
      "val Loss: 0.7468 Acc: 0.7000\n",
      "test Loss: 0.7513 Acc: 0.6667\n",
      "Epoch 195/499\n",
      "----------\n",
      "train Loss: 0.7610 Acc: 0.6333\n",
      "val Loss: 0.7580 Acc: 0.7000\n",
      "test Loss: 0.7541 Acc: 0.7000\n",
      "Epoch 196/499\n",
      "----------\n",
      "train Loss: 0.7539 Acc: 0.6778\n",
      "val Loss: 0.7463 Acc: 0.6667\n",
      "test Loss: 0.7641 Acc: 0.6333\n",
      "Epoch 197/499\n",
      "----------\n",
      "train Loss: 0.7515 Acc: 0.6889\n",
      "val Loss: 0.7494 Acc: 0.7333\n",
      "test Loss: 0.7569 Acc: 0.6667\n",
      "Epoch 198/499\n",
      "----------\n",
      "train Loss: 0.7500 Acc: 0.6667\n",
      "val Loss: 0.7418 Acc: 0.7000\n",
      "test Loss: 0.7417 Acc: 0.7000\n",
      "Epoch 199/499\n",
      "----------\n",
      "train Loss: 0.7480 Acc: 0.6667\n",
      "val Loss: 0.7327 Acc: 0.7000\n",
      "test Loss: 0.7698 Acc: 0.6333\n",
      "Epoch 200/499\n",
      "----------\n",
      "train Loss: 0.7481 Acc: 0.7111\n",
      "val Loss: 0.7531 Acc: 0.7333\n",
      "test Loss: 0.7578 Acc: 0.6667\n",
      "Epoch 201/499\n",
      "----------\n",
      "train Loss: 0.7457 Acc: 0.6667\n",
      "val Loss: 0.7608 Acc: 0.6333\n",
      "test Loss: 0.7432 Acc: 0.6667\n",
      "Epoch 202/499\n",
      "----------\n",
      "train Loss: 0.7642 Acc: 0.6889\n",
      "val Loss: 0.7494 Acc: 0.6333\n",
      "test Loss: 0.7520 Acc: 0.6333\n",
      "Epoch 203/499\n",
      "----------\n",
      "train Loss: 0.7515 Acc: 0.6778\n",
      "val Loss: 0.7378 Acc: 0.7000\n",
      "test Loss: 0.7461 Acc: 0.6667\n",
      "Epoch 204/499\n",
      "----------\n",
      "train Loss: 0.7493 Acc: 0.6889\n",
      "val Loss: 0.7192 Acc: 0.7667\n",
      "test Loss: 0.7458 Acc: 0.6667\n",
      "Epoch 205/499\n",
      "----------\n",
      "train Loss: 0.7425 Acc: 0.7222\n",
      "val Loss: 0.7316 Acc: 0.6667\n",
      "test Loss: 0.7406 Acc: 0.6667\n",
      "Epoch 206/499\n",
      "----------\n",
      "train Loss: 0.7458 Acc: 0.6889\n",
      "val Loss: 0.7315 Acc: 0.6667\n",
      "test Loss: 0.7520 Acc: 0.6667\n",
      "Epoch 207/499\n",
      "----------\n",
      "train Loss: 0.7368 Acc: 0.6667\n",
      "val Loss: 0.7428 Acc: 0.7000\n",
      "test Loss: 0.7601 Acc: 0.6333\n",
      "Epoch 208/499\n",
      "----------\n",
      "train Loss: 0.7456 Acc: 0.7111\n",
      "val Loss: 0.7407 Acc: 0.6333\n",
      "test Loss: 0.7422 Acc: 0.6667\n",
      "Epoch 209/499\n",
      "----------\n",
      "train Loss: 0.7414 Acc: 0.6667\n",
      "val Loss: 0.7295 Acc: 0.7333\n",
      "test Loss: 0.7611 Acc: 0.6667\n",
      "Epoch 210/499\n",
      "----------\n",
      "train Loss: 0.7421 Acc: 0.7000\n",
      "val Loss: 0.7224 Acc: 0.6667\n",
      "test Loss: 0.7450 Acc: 0.7000\n",
      "Epoch 211/499\n",
      "----------\n",
      "train Loss: 0.7486 Acc: 0.6889\n",
      "val Loss: 0.7389 Acc: 0.7667\n",
      "test Loss: 0.7452 Acc: 0.6667\n",
      "Epoch 212/499\n",
      "----------\n",
      "train Loss: 0.7418 Acc: 0.6889\n",
      "val Loss: 0.7181 Acc: 0.7000\n",
      "test Loss: 0.7369 Acc: 0.7000\n",
      "Epoch 213/499\n",
      "----------\n",
      "train Loss: 0.7423 Acc: 0.6667\n",
      "val Loss: 0.7384 Acc: 0.7000\n",
      "test Loss: 0.7340 Acc: 0.6667\n",
      "Epoch 214/499\n",
      "----------\n",
      "train Loss: 0.7331 Acc: 0.6667\n",
      "val Loss: 0.7317 Acc: 0.7333\n",
      "test Loss: 0.7332 Acc: 0.7333\n",
      "Epoch 215/499\n",
      "----------\n",
      "train Loss: 0.7408 Acc: 0.7111\n",
      "val Loss: 0.7339 Acc: 0.7333\n",
      "test Loss: 0.7586 Acc: 0.6333\n",
      "Epoch 216/499\n",
      "----------\n",
      "train Loss: 0.7325 Acc: 0.7000\n",
      "val Loss: 0.7494 Acc: 0.6333\n",
      "test Loss: 0.7322 Acc: 0.6667\n",
      "Epoch 217/499\n",
      "----------\n",
      "train Loss: 0.7323 Acc: 0.7222\n",
      "val Loss: 0.7332 Acc: 0.7000\n",
      "test Loss: 0.7434 Acc: 0.6667\n",
      "Epoch 218/499\n",
      "----------\n",
      "train Loss: 0.7424 Acc: 0.6778\n",
      "val Loss: 0.7307 Acc: 0.7333\n",
      "test Loss: 0.7518 Acc: 0.6333\n",
      "Epoch 219/499\n",
      "----------\n",
      "train Loss: 0.7415 Acc: 0.7222\n",
      "val Loss: 0.7459 Acc: 0.6667\n",
      "test Loss: 0.7342 Acc: 0.7000\n",
      "Epoch 220/499\n",
      "----------\n",
      "train Loss: 0.7417 Acc: 0.6667\n",
      "val Loss: 0.7369 Acc: 0.6667\n",
      "test Loss: 0.7516 Acc: 0.6333\n",
      "Epoch 221/499\n",
      "----------\n",
      "train Loss: 0.7297 Acc: 0.6778\n",
      "val Loss: 0.7146 Acc: 0.7333\n",
      "test Loss: 0.7260 Acc: 0.6667\n",
      "Epoch 222/499\n",
      "----------\n",
      "train Loss: 0.7443 Acc: 0.6778\n",
      "val Loss: 0.7256 Acc: 0.7000\n",
      "test Loss: 0.7368 Acc: 0.7000\n",
      "Epoch 223/499\n",
      "----------\n",
      "train Loss: 0.7345 Acc: 0.7000\n",
      "val Loss: 0.7112 Acc: 0.7000\n",
      "test Loss: 0.7180 Acc: 0.7000\n",
      "Epoch 224/499\n",
      "----------\n",
      "train Loss: 0.7246 Acc: 0.7000\n",
      "val Loss: 0.7131 Acc: 0.7333\n",
      "test Loss: 0.7428 Acc: 0.6667\n",
      "Epoch 225/499\n",
      "----------\n",
      "train Loss: 0.7381 Acc: 0.7000\n",
      "val Loss: 0.7143 Acc: 0.7000\n",
      "test Loss: 0.7494 Acc: 0.6667\n",
      "Epoch 226/499\n",
      "----------\n",
      "train Loss: 0.7273 Acc: 0.7222\n",
      "val Loss: 0.7217 Acc: 0.7000\n",
      "test Loss: 0.7326 Acc: 0.7000\n",
      "Epoch 227/499\n",
      "----------\n",
      "train Loss: 0.7414 Acc: 0.6778\n",
      "val Loss: 0.7196 Acc: 0.7000\n",
      "test Loss: 0.7373 Acc: 0.6667\n",
      "Epoch 228/499\n",
      "----------\n",
      "train Loss: 0.7240 Acc: 0.7000\n",
      "val Loss: 0.7128 Acc: 0.7000\n",
      "test Loss: 0.7496 Acc: 0.7000\n",
      "Epoch 229/499\n",
      "----------\n",
      "train Loss: 0.7251 Acc: 0.6778\n",
      "val Loss: 0.7462 Acc: 0.6667\n",
      "test Loss: 0.7257 Acc: 0.7000\n",
      "Epoch 230/499\n",
      "----------\n",
      "train Loss: 0.7353 Acc: 0.6778\n",
      "val Loss: 0.7260 Acc: 0.7000\n",
      "test Loss: 0.7300 Acc: 0.7000\n",
      "Epoch 231/499\n",
      "----------\n",
      "train Loss: 0.7240 Acc: 0.6667\n",
      "val Loss: 0.7243 Acc: 0.6333\n",
      "test Loss: 0.7351 Acc: 0.7333\n",
      "Epoch 232/499\n",
      "----------\n",
      "train Loss: 0.7345 Acc: 0.6889\n",
      "val Loss: 0.7033 Acc: 0.7000\n",
      "test Loss: 0.7334 Acc: 0.7667\n",
      "Epoch 233/499\n",
      "----------\n",
      "train Loss: 0.7336 Acc: 0.6889\n",
      "val Loss: 0.7119 Acc: 0.6667\n",
      "test Loss: 0.7306 Acc: 0.7000\n",
      "Epoch 234/499\n",
      "----------\n",
      "train Loss: 0.7252 Acc: 0.7111\n",
      "val Loss: 0.7463 Acc: 0.6000\n",
      "test Loss: 0.7246 Acc: 0.6667\n",
      "Epoch 235/499\n",
      "----------\n",
      "train Loss: 0.7178 Acc: 0.7000\n",
      "val Loss: 0.7160 Acc: 0.7000\n",
      "test Loss: 0.7152 Acc: 0.6667\n",
      "Epoch 236/499\n",
      "----------\n",
      "train Loss: 0.7277 Acc: 0.6667\n",
      "val Loss: 0.7050 Acc: 0.7000\n",
      "test Loss: 0.7267 Acc: 0.7000\n",
      "Epoch 237/499\n",
      "----------\n",
      "train Loss: 0.7471 Acc: 0.6556\n",
      "val Loss: 0.7228 Acc: 0.7000\n",
      "test Loss: 0.7316 Acc: 0.7000\n",
      "Epoch 238/499\n",
      "----------\n",
      "train Loss: 0.7234 Acc: 0.6667\n",
      "val Loss: 0.7045 Acc: 0.6667\n",
      "test Loss: 0.7464 Acc: 0.7333\n",
      "Epoch 239/499\n",
      "----------\n",
      "train Loss: 0.7142 Acc: 0.6889\n",
      "val Loss: 0.7120 Acc: 0.7000\n",
      "test Loss: 0.7480 Acc: 0.6667\n",
      "Epoch 240/499\n",
      "----------\n",
      "train Loss: 0.7205 Acc: 0.6667\n",
      "val Loss: 0.7087 Acc: 0.6667\n",
      "test Loss: 0.7356 Acc: 0.7667\n",
      "Epoch 241/499\n",
      "----------\n",
      "train Loss: 0.7349 Acc: 0.7000\n",
      "val Loss: 0.7048 Acc: 0.6667\n",
      "test Loss: 0.7198 Acc: 0.7667\n",
      "Epoch 242/499\n",
      "----------\n",
      "train Loss: 0.7276 Acc: 0.7000\n",
      "val Loss: 0.7042 Acc: 0.6667\n",
      "test Loss: 0.7253 Acc: 0.7000\n",
      "Epoch 243/499\n",
      "----------\n",
      "train Loss: 0.7219 Acc: 0.6889\n",
      "val Loss: 0.7004 Acc: 0.7000\n",
      "test Loss: 0.7211 Acc: 0.6667\n",
      "Epoch 244/499\n",
      "----------\n",
      "train Loss: 0.7226 Acc: 0.7000\n",
      "val Loss: 0.7123 Acc: 0.6667\n",
      "test Loss: 0.7191 Acc: 0.6667\n",
      "Epoch 245/499\n",
      "----------\n",
      "train Loss: 0.7246 Acc: 0.6667\n",
      "val Loss: 0.7109 Acc: 0.7333\n",
      "test Loss: 0.7511 Acc: 0.7000\n",
      "Epoch 246/499\n",
      "----------\n",
      "train Loss: 0.7157 Acc: 0.6889\n",
      "val Loss: 0.7039 Acc: 0.6667\n",
      "test Loss: 0.7294 Acc: 0.7000\n",
      "Epoch 247/499\n",
      "----------\n",
      "train Loss: 0.7275 Acc: 0.6556\n",
      "val Loss: 0.6913 Acc: 0.7000\n",
      "test Loss: 0.7157 Acc: 0.6667\n",
      "Epoch 248/499\n",
      "----------\n",
      "train Loss: 0.7107 Acc: 0.6778\n",
      "val Loss: 0.7111 Acc: 0.6667\n",
      "test Loss: 0.7465 Acc: 0.6667\n",
      "Epoch 249/499\n",
      "----------\n",
      "train Loss: 0.7117 Acc: 0.6889\n",
      "val Loss: 0.7005 Acc: 0.7000\n",
      "test Loss: 0.7142 Acc: 0.7000\n",
      "Epoch 250/499\n",
      "----------\n",
      "train Loss: 0.7146 Acc: 0.6667\n",
      "val Loss: 0.7131 Acc: 0.6667\n",
      "test Loss: 0.7162 Acc: 0.6667\n",
      "Epoch 251/499\n",
      "----------\n",
      "train Loss: 0.7196 Acc: 0.6778\n",
      "val Loss: 0.6965 Acc: 0.6667\n",
      "test Loss: 0.7188 Acc: 0.6667\n",
      "Epoch 252/499\n",
      "----------\n",
      "train Loss: 0.7219 Acc: 0.6444\n",
      "val Loss: 0.7056 Acc: 0.7000\n",
      "test Loss: 0.7473 Acc: 0.7000\n",
      "Epoch 253/499\n",
      "----------\n",
      "train Loss: 0.7242 Acc: 0.6667\n",
      "val Loss: 0.6973 Acc: 0.6667\n",
      "test Loss: 0.7238 Acc: 0.6667\n",
      "Epoch 254/499\n",
      "----------\n",
      "train Loss: 0.7068 Acc: 0.6778\n",
      "val Loss: 0.6905 Acc: 0.6667\n",
      "test Loss: 0.7128 Acc: 0.6667\n",
      "Epoch 255/499\n",
      "----------\n",
      "train Loss: 0.7125 Acc: 0.6667\n",
      "val Loss: 0.7186 Acc: 0.6333\n",
      "test Loss: 0.7378 Acc: 0.6333\n",
      "Epoch 256/499\n",
      "----------\n",
      "train Loss: 0.7092 Acc: 0.6556\n",
      "val Loss: 0.6935 Acc: 0.6667\n",
      "test Loss: 0.7140 Acc: 0.6667\n",
      "Epoch 257/499\n",
      "----------\n",
      "train Loss: 0.7154 Acc: 0.6556\n",
      "val Loss: 0.7044 Acc: 0.6667\n",
      "test Loss: 0.7420 Acc: 0.6000\n",
      "Epoch 258/499\n",
      "----------\n",
      "train Loss: 0.7060 Acc: 0.6667\n",
      "val Loss: 0.7053 Acc: 0.6667\n",
      "test Loss: 0.7198 Acc: 0.6667\n",
      "Epoch 259/499\n",
      "----------\n",
      "train Loss: 0.7128 Acc: 0.6667\n",
      "val Loss: 0.6916 Acc: 0.6667\n",
      "test Loss: 0.7154 Acc: 0.6667\n",
      "Epoch 260/499\n",
      "----------\n",
      "train Loss: 0.7142 Acc: 0.6556\n",
      "val Loss: 0.6983 Acc: 0.6667\n",
      "test Loss: 0.7148 Acc: 0.6667\n",
      "Epoch 261/499\n",
      "----------\n",
      "train Loss: 0.7108 Acc: 0.6667\n",
      "val Loss: 0.7017 Acc: 0.6667\n",
      "test Loss: 0.7312 Acc: 0.6333\n",
      "Epoch 262/499\n",
      "----------\n",
      "train Loss: 0.7060 Acc: 0.6667\n",
      "val Loss: 0.6945 Acc: 0.6667\n",
      "test Loss: 0.7138 Acc: 0.6667\n",
      "Epoch 263/499\n",
      "----------\n",
      "train Loss: 0.7043 Acc: 0.6556\n",
      "val Loss: 0.7037 Acc: 0.6667\n",
      "test Loss: 0.7163 Acc: 0.6667\n",
      "Epoch 264/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.7146 Acc: 0.6667\n",
      "val Loss: 0.6983 Acc: 0.6667\n",
      "test Loss: 0.7324 Acc: 0.6333\n",
      "Epoch 265/499\n",
      "----------\n",
      "train Loss: 0.7038 Acc: 0.6667\n",
      "val Loss: 0.6995 Acc: 0.6667\n",
      "test Loss: 0.7203 Acc: 0.6667\n",
      "Epoch 266/499\n",
      "----------\n",
      "train Loss: 0.7133 Acc: 0.6556\n",
      "val Loss: 0.7023 Acc: 0.6667\n",
      "test Loss: 0.7311 Acc: 0.6333\n",
      "Epoch 267/499\n",
      "----------\n",
      "train Loss: 0.7090 Acc: 0.6667\n",
      "val Loss: 0.6937 Acc: 0.6667\n",
      "test Loss: 0.7177 Acc: 0.6667\n",
      "Epoch 268/499\n",
      "----------\n",
      "train Loss: 0.7155 Acc: 0.6444\n",
      "val Loss: 0.6910 Acc: 0.6667\n",
      "test Loss: 0.7113 Acc: 0.6667\n",
      "Epoch 269/499\n",
      "----------\n",
      "train Loss: 0.7070 Acc: 0.6556\n",
      "val Loss: 0.6909 Acc: 0.6667\n",
      "test Loss: 0.7177 Acc: 0.6667\n",
      "Epoch 270/499\n",
      "----------\n",
      "train Loss: 0.7117 Acc: 0.6444\n",
      "val Loss: 0.6874 Acc: 0.6667\n",
      "test Loss: 0.7080 Acc: 0.6667\n",
      "Epoch 271/499\n",
      "----------\n",
      "train Loss: 0.7131 Acc: 0.6556\n",
      "val Loss: 0.6842 Acc: 0.6667\n",
      "test Loss: 0.7453 Acc: 0.6333\n",
      "Epoch 272/499\n",
      "----------\n",
      "train Loss: 0.6979 Acc: 0.6667\n",
      "val Loss: 0.6832 Acc: 0.6667\n",
      "test Loss: 0.7253 Acc: 0.6667\n",
      "Epoch 273/499\n",
      "----------\n",
      "train Loss: 0.7025 Acc: 0.6667\n",
      "val Loss: 0.6947 Acc: 0.6667\n",
      "test Loss: 0.7073 Acc: 0.6667\n",
      "Epoch 274/499\n",
      "----------\n",
      "train Loss: 0.7047 Acc: 0.6667\n",
      "val Loss: 0.6946 Acc: 0.6667\n",
      "test Loss: 0.7172 Acc: 0.6667\n",
      "Epoch 275/499\n",
      "----------\n",
      "train Loss: 0.7101 Acc: 0.6556\n",
      "val Loss: 0.6850 Acc: 0.6667\n",
      "test Loss: 0.7293 Acc: 0.6333\n",
      "Epoch 276/499\n",
      "----------\n",
      "train Loss: 0.7114 Acc: 0.6444\n",
      "val Loss: 0.6820 Acc: 0.6667\n",
      "test Loss: 0.7144 Acc: 0.6667\n",
      "Epoch 277/499\n",
      "----------\n",
      "train Loss: 0.6921 Acc: 0.6667\n",
      "val Loss: 0.7091 Acc: 0.6333\n",
      "test Loss: 0.7209 Acc: 0.6667\n",
      "Epoch 278/499\n",
      "----------\n",
      "train Loss: 0.7046 Acc: 0.6556\n",
      "val Loss: 0.6865 Acc: 0.6667\n",
      "test Loss: 0.7110 Acc: 0.6667\n",
      "Epoch 279/499\n",
      "----------\n",
      "train Loss: 0.7035 Acc: 0.6556\n",
      "val Loss: 0.7032 Acc: 0.6667\n",
      "test Loss: 0.7246 Acc: 0.6667\n",
      "Epoch 280/499\n",
      "----------\n",
      "train Loss: 0.7311 Acc: 0.6444\n",
      "val Loss: 0.6796 Acc: 0.6667\n",
      "test Loss: 0.7178 Acc: 0.6667\n",
      "Epoch 281/499\n",
      "----------\n",
      "train Loss: 0.7130 Acc: 0.6444\n",
      "val Loss: 0.7109 Acc: 0.6333\n",
      "test Loss: 0.7144 Acc: 0.6667\n",
      "Epoch 282/499\n",
      "----------\n",
      "train Loss: 0.6965 Acc: 0.6667\n",
      "val Loss: 0.6921 Acc: 0.6667\n",
      "test Loss: 0.7252 Acc: 0.6333\n",
      "Epoch 283/499\n",
      "----------\n",
      "train Loss: 0.7029 Acc: 0.6444\n",
      "val Loss: 0.6903 Acc: 0.6667\n",
      "test Loss: 0.7073 Acc: 0.6667\n",
      "Epoch 284/499\n",
      "----------\n",
      "train Loss: 0.7031 Acc: 0.6667\n",
      "val Loss: 0.6969 Acc: 0.6333\n",
      "test Loss: 0.7200 Acc: 0.6333\n",
      "Epoch 285/499\n",
      "----------\n",
      "train Loss: 0.7004 Acc: 0.6667\n",
      "val Loss: 0.6757 Acc: 0.6667\n",
      "test Loss: 0.6998 Acc: 0.6667\n",
      "Epoch 286/499\n",
      "----------\n",
      "train Loss: 0.7114 Acc: 0.6444\n",
      "val Loss: 0.6895 Acc: 0.6667\n",
      "test Loss: 0.7325 Acc: 0.6667\n",
      "Epoch 287/499\n",
      "----------\n",
      "train Loss: 0.7134 Acc: 0.6556\n",
      "val Loss: 0.6823 Acc: 0.6667\n",
      "test Loss: 0.7110 Acc: 0.6667\n",
      "Epoch 288/499\n",
      "----------\n",
      "train Loss: 0.7113 Acc: 0.6556\n",
      "val Loss: 0.6982 Acc: 0.6667\n",
      "test Loss: 0.7147 Acc: 0.6667\n",
      "Epoch 289/499\n",
      "----------\n",
      "train Loss: 0.7056 Acc: 0.6556\n",
      "val Loss: 0.6781 Acc: 0.6667\n",
      "test Loss: 0.7129 Acc: 0.6667\n",
      "Epoch 290/499\n",
      "----------\n",
      "train Loss: 0.7051 Acc: 0.6556\n",
      "val Loss: 0.6863 Acc: 0.6667\n",
      "test Loss: 0.7070 Acc: 0.6667\n",
      "Epoch 291/499\n",
      "----------\n",
      "train Loss: 0.7013 Acc: 0.6667\n",
      "val Loss: 0.6888 Acc: 0.6667\n",
      "test Loss: 0.7153 Acc: 0.6667\n",
      "Epoch 292/499\n",
      "----------\n",
      "train Loss: 0.7009 Acc: 0.6556\n",
      "val Loss: 0.6797 Acc: 0.6667\n",
      "test Loss: 0.7132 Acc: 0.6667\n",
      "Epoch 293/499\n",
      "----------\n",
      "train Loss: 0.7058 Acc: 0.6556\n",
      "val Loss: 0.6771 Acc: 0.6667\n",
      "test Loss: 0.7224 Acc: 0.6667\n",
      "Epoch 294/499\n",
      "----------\n",
      "train Loss: 0.7035 Acc: 0.6667\n",
      "val Loss: 0.6885 Acc: 0.6667\n",
      "test Loss: 0.7166 Acc: 0.6667\n",
      "Epoch 295/499\n",
      "----------\n",
      "train Loss: 0.6871 Acc: 0.6667\n",
      "val Loss: 0.6822 Acc: 0.6667\n",
      "test Loss: 0.6989 Acc: 0.6667\n",
      "Epoch 296/499\n",
      "----------\n",
      "train Loss: 0.6894 Acc: 0.6667\n",
      "val Loss: 0.6883 Acc: 0.6667\n",
      "test Loss: 0.7286 Acc: 0.6333\n",
      "Epoch 297/499\n",
      "----------\n",
      "train Loss: 0.7028 Acc: 0.6556\n",
      "val Loss: 0.6796 Acc: 0.6667\n",
      "test Loss: 0.7152 Acc: 0.6667\n",
      "Epoch 298/499\n",
      "----------\n",
      "train Loss: 0.7276 Acc: 0.6222\n",
      "val Loss: 0.7050 Acc: 0.6667\n",
      "test Loss: 0.7433 Acc: 0.6000\n",
      "Epoch 299/499\n",
      "----------\n",
      "train Loss: 0.7118 Acc: 0.6333\n",
      "val Loss: 0.6935 Acc: 0.6667\n",
      "test Loss: 0.7114 Acc: 0.6667\n",
      "Epoch 300/499\n",
      "----------\n",
      "train Loss: 0.6864 Acc: 0.6667\n",
      "val Loss: 0.6787 Acc: 0.6667\n",
      "test Loss: 0.6918 Acc: 0.6667\n",
      "Epoch 301/499\n",
      "----------\n",
      "train Loss: 0.7016 Acc: 0.6667\n",
      "val Loss: 0.6968 Acc: 0.6667\n",
      "test Loss: 0.7349 Acc: 0.6333\n",
      "Epoch 302/499\n",
      "----------\n",
      "train Loss: 0.7014 Acc: 0.6556\n",
      "val Loss: 0.6988 Acc: 0.6333\n",
      "test Loss: 0.7025 Acc: 0.6667\n",
      "Epoch 303/499\n",
      "----------\n",
      "train Loss: 0.6875 Acc: 0.6667\n",
      "val Loss: 0.6706 Acc: 0.6667\n",
      "test Loss: 0.7108 Acc: 0.6667\n",
      "Epoch 304/499\n",
      "----------\n",
      "train Loss: 0.7018 Acc: 0.6667\n",
      "val Loss: 0.6713 Acc: 0.6667\n",
      "test Loss: 0.7023 Acc: 0.6667\n",
      "Epoch 305/499\n",
      "----------\n",
      "train Loss: 0.6995 Acc: 0.6667\n",
      "val Loss: 0.6769 Acc: 0.6667\n",
      "test Loss: 0.7093 Acc: 0.6667\n",
      "Epoch 306/499\n",
      "----------\n",
      "train Loss: 0.6975 Acc: 0.6556\n",
      "val Loss: 0.6872 Acc: 0.6667\n",
      "test Loss: 0.7120 Acc: 0.6333\n",
      "Epoch 307/499\n",
      "----------\n",
      "train Loss: 0.7007 Acc: 0.6556\n",
      "val Loss: 0.6847 Acc: 0.6667\n",
      "test Loss: 0.7177 Acc: 0.6667\n",
      "Epoch 308/499\n",
      "----------\n",
      "train Loss: 0.7067 Acc: 0.6444\n",
      "val Loss: 0.6749 Acc: 0.6667\n",
      "test Loss: 0.7065 Acc: 0.6667\n",
      "Epoch 309/499\n",
      "----------\n",
      "train Loss: 0.7117 Acc: 0.6556\n",
      "val Loss: 0.6791 Acc: 0.6667\n",
      "test Loss: 0.7262 Acc: 0.6333\n",
      "Epoch 310/499\n",
      "----------\n",
      "train Loss: 0.7036 Acc: 0.6556\n",
      "val Loss: 0.6732 Acc: 0.6667\n",
      "test Loss: 0.6991 Acc: 0.6667\n",
      "Epoch 311/499\n",
      "----------\n",
      "train Loss: 0.7066 Acc: 0.6444\n",
      "val Loss: 0.6938 Acc: 0.6667\n",
      "test Loss: 0.7004 Acc: 0.6667\n",
      "Epoch 312/499\n",
      "----------\n",
      "train Loss: 0.6916 Acc: 0.6667\n",
      "val Loss: 0.6778 Acc: 0.6667\n",
      "test Loss: 0.7039 Acc: 0.6667\n",
      "Epoch 313/499\n",
      "----------\n",
      "train Loss: 0.6967 Acc: 0.6556\n",
      "val Loss: 0.7000 Acc: 0.6667\n",
      "test Loss: 0.7042 Acc: 0.6667\n",
      "Epoch 314/499\n",
      "----------\n",
      "train Loss: 0.6894 Acc: 0.6667\n",
      "val Loss: 0.6739 Acc: 0.6667\n",
      "test Loss: 0.7177 Acc: 0.6333\n",
      "Epoch 315/499\n",
      "----------\n",
      "train Loss: 0.6922 Acc: 0.6667\n",
      "val Loss: 0.6858 Acc: 0.6667\n",
      "test Loss: 0.7048 Acc: 0.6667\n",
      "Epoch 316/499\n",
      "----------\n",
      "train Loss: 0.6971 Acc: 0.6556\n",
      "val Loss: 0.6771 Acc: 0.6667\n",
      "test Loss: 0.7040 Acc: 0.6667\n",
      "Epoch 317/499\n",
      "----------\n",
      "train Loss: 0.6956 Acc: 0.6667\n",
      "val Loss: 0.6810 Acc: 0.6667\n",
      "test Loss: 0.6976 Acc: 0.6667\n",
      "Epoch 318/499\n",
      "----------\n",
      "train Loss: 0.6942 Acc: 0.6556\n",
      "val Loss: 0.6815 Acc: 0.6667\n",
      "test Loss: 0.7131 Acc: 0.6667\n",
      "Epoch 319/499\n",
      "----------\n",
      "train Loss: 0.6910 Acc: 0.6667\n",
      "val Loss: 0.6834 Acc: 0.6667\n",
      "test Loss: 0.7034 Acc: 0.6667\n",
      "Epoch 320/499\n",
      "----------\n",
      "train Loss: 0.6943 Acc: 0.6556\n",
      "val Loss: 0.6985 Acc: 0.6333\n",
      "test Loss: 0.7254 Acc: 0.6333\n",
      "Epoch 321/499\n",
      "----------\n",
      "train Loss: 0.6901 Acc: 0.6667\n",
      "val Loss: 0.6721 Acc: 0.6667\n",
      "test Loss: 0.7065 Acc: 0.6667\n",
      "Epoch 322/499\n",
      "----------\n",
      "train Loss: 0.7113 Acc: 0.6444\n",
      "val Loss: 0.6836 Acc: 0.6667\n",
      "test Loss: 0.6935 Acc: 0.6667\n",
      "Epoch 323/499\n",
      "----------\n",
      "train Loss: 0.6997 Acc: 0.6444\n",
      "val Loss: 0.6826 Acc: 0.6667\n",
      "test Loss: 0.6892 Acc: 0.6667\n",
      "Epoch 324/499\n",
      "----------\n",
      "train Loss: 0.6887 Acc: 0.6556\n",
      "val Loss: 0.6786 Acc: 0.6667\n",
      "test Loss: 0.6842 Acc: 0.6667\n",
      "Epoch 325/499\n",
      "----------\n",
      "train Loss: 0.6896 Acc: 0.6667\n",
      "val Loss: 0.6766 Acc: 0.6667\n",
      "test Loss: 0.7213 Acc: 0.6667\n",
      "Epoch 326/499\n",
      "----------\n",
      "train Loss: 0.6927 Acc: 0.6556\n",
      "val Loss: 0.6733 Acc: 0.6667\n",
      "test Loss: 0.7206 Acc: 0.6667\n",
      "Epoch 327/499\n",
      "----------\n",
      "train Loss: 0.7051 Acc: 0.6556\n",
      "val Loss: 0.6689 Acc: 0.6667\n",
      "test Loss: 0.7106 Acc: 0.6667\n",
      "Epoch 328/499\n",
      "----------\n",
      "train Loss: 0.6856 Acc: 0.6667\n",
      "val Loss: 0.6723 Acc: 0.6667\n",
      "test Loss: 0.7037 Acc: 0.6667\n",
      "Epoch 329/499\n",
      "----------\n",
      "train Loss: 0.6855 Acc: 0.6667\n",
      "val Loss: 0.6755 Acc: 0.6667\n",
      "test Loss: 0.7092 Acc: 0.6667\n",
      "Epoch 330/499\n",
      "----------\n",
      "train Loss: 0.6858 Acc: 0.6556\n",
      "val Loss: 0.6809 Acc: 0.6667\n",
      "test Loss: 0.7046 Acc: 0.6667\n",
      "Epoch 331/499\n",
      "----------\n",
      "train Loss: 0.6931 Acc: 0.6556\n",
      "val Loss: 0.6821 Acc: 0.6667\n",
      "test Loss: 0.7269 Acc: 0.6333\n",
      "Epoch 332/499\n",
      "----------\n",
      "train Loss: 0.7034 Acc: 0.6444\n",
      "val Loss: 0.6636 Acc: 0.6667\n",
      "test Loss: 0.7196 Acc: 0.6667\n",
      "Epoch 333/499\n",
      "----------\n",
      "train Loss: 0.6805 Acc: 0.6667\n",
      "val Loss: 0.6953 Acc: 0.6333\n",
      "test Loss: 0.7091 Acc: 0.6667\n",
      "Epoch 334/499\n",
      "----------\n",
      "train Loss: 0.6931 Acc: 0.6667\n",
      "val Loss: 0.6783 Acc: 0.6667\n",
      "test Loss: 0.6890 Acc: 0.6667\n",
      "Epoch 335/499\n",
      "----------\n",
      "train Loss: 0.7081 Acc: 0.6333\n",
      "val Loss: 0.6979 Acc: 0.6667\n",
      "test Loss: 0.7082 Acc: 0.6667\n",
      "Epoch 336/499\n",
      "----------\n",
      "train Loss: 0.6890 Acc: 0.6667\n",
      "val Loss: 0.6799 Acc: 0.6667\n",
      "test Loss: 0.7273 Acc: 0.6333\n",
      "Epoch 337/499\n",
      "----------\n",
      "train Loss: 0.6920 Acc: 0.6556\n",
      "val Loss: 0.6727 Acc: 0.6667\n",
      "test Loss: 0.7021 Acc: 0.6667\n",
      "Epoch 338/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.7023 Acc: 0.6444\n",
      "val Loss: 0.6696 Acc: 0.6667\n",
      "test Loss: 0.6990 Acc: 0.6667\n",
      "Epoch 339/499\n",
      "----------\n",
      "train Loss: 0.6904 Acc: 0.6556\n",
      "val Loss: 0.6851 Acc: 0.6667\n",
      "test Loss: 0.7364 Acc: 0.6000\n",
      "Epoch 340/499\n",
      "----------\n",
      "train Loss: 0.6927 Acc: 0.6556\n",
      "val Loss: 0.6820 Acc: 0.6667\n",
      "test Loss: 0.6947 Acc: 0.6667\n",
      "Epoch 341/499\n",
      "----------\n",
      "train Loss: 0.6876 Acc: 0.6556\n",
      "val Loss: 0.7120 Acc: 0.6333\n",
      "test Loss: 0.7142 Acc: 0.6333\n",
      "Epoch 342/499\n",
      "----------\n",
      "train Loss: 0.7066 Acc: 0.6444\n",
      "val Loss: 0.6708 Acc: 0.6667\n",
      "test Loss: 0.6926 Acc: 0.6667\n",
      "Epoch 343/499\n",
      "----------\n",
      "train Loss: 0.6818 Acc: 0.6667\n",
      "val Loss: 0.6877 Acc: 0.6667\n",
      "test Loss: 0.7012 Acc: 0.6667\n",
      "Epoch 344/499\n",
      "----------\n",
      "train Loss: 0.6949 Acc: 0.6444\n",
      "val Loss: 0.7079 Acc: 0.6333\n",
      "test Loss: 0.7133 Acc: 0.6667\n",
      "Epoch 345/499\n",
      "----------\n",
      "train Loss: 0.6913 Acc: 0.6556\n",
      "val Loss: 0.6770 Acc: 0.6667\n",
      "test Loss: 0.6954 Acc: 0.6667\n",
      "Epoch 346/499\n",
      "----------\n",
      "train Loss: 0.6905 Acc: 0.6556\n",
      "val Loss: 0.6895 Acc: 0.6667\n",
      "test Loss: 0.6988 Acc: 0.6667\n",
      "Epoch 347/499\n",
      "----------\n",
      "train Loss: 0.6830 Acc: 0.6667\n",
      "val Loss: 0.6732 Acc: 0.6667\n",
      "test Loss: 0.7017 Acc: 0.6667\n",
      "Epoch 348/499\n",
      "----------\n",
      "train Loss: 0.6937 Acc: 0.6556\n",
      "val Loss: 0.6816 Acc: 0.6667\n",
      "test Loss: 0.6903 Acc: 0.6667\n",
      "Epoch 349/499\n",
      "----------\n",
      "train Loss: 0.7106 Acc: 0.6444\n",
      "val Loss: 0.6807 Acc: 0.6667\n",
      "test Loss: 0.7046 Acc: 0.6667\n",
      "Epoch 350/499\n",
      "----------\n",
      "train Loss: 0.6855 Acc: 0.6667\n",
      "val Loss: 0.6928 Acc: 0.6667\n",
      "test Loss: 0.7114 Acc: 0.6667\n",
      "Epoch 351/499\n",
      "----------\n",
      "train Loss: 0.6831 Acc: 0.6556\n",
      "val Loss: 0.6773 Acc: 0.6667\n",
      "test Loss: 0.7043 Acc: 0.6667\n",
      "Epoch 352/499\n",
      "----------\n",
      "train Loss: 0.7076 Acc: 0.6333\n",
      "val Loss: 0.6718 Acc: 0.6667\n",
      "test Loss: 0.6933 Acc: 0.6667\n",
      "Epoch 353/499\n",
      "----------\n",
      "train Loss: 0.6954 Acc: 0.6444\n",
      "val Loss: 0.6749 Acc: 0.6667\n",
      "test Loss: 0.7083 Acc: 0.6667\n",
      "Epoch 354/499\n",
      "----------\n",
      "train Loss: 0.6872 Acc: 0.6667\n",
      "val Loss: 0.6712 Acc: 0.6667\n",
      "test Loss: 0.7172 Acc: 0.6667\n",
      "Epoch 355/499\n",
      "----------\n",
      "train Loss: 0.6855 Acc: 0.6667\n",
      "val Loss: 0.6725 Acc: 0.6667\n",
      "test Loss: 0.7024 Acc: 0.6667\n",
      "Epoch 356/499\n",
      "----------\n",
      "train Loss: 0.6840 Acc: 0.6667\n",
      "val Loss: 0.6803 Acc: 0.6667\n",
      "test Loss: 0.7048 Acc: 0.6667\n",
      "Epoch 357/499\n",
      "----------\n",
      "train Loss: 0.6918 Acc: 0.6556\n",
      "val Loss: 0.6671 Acc: 0.6667\n",
      "test Loss: 0.7161 Acc: 0.6333\n",
      "Epoch 358/499\n",
      "----------\n",
      "train Loss: 0.6867 Acc: 0.6556\n",
      "val Loss: 0.6750 Acc: 0.6667\n",
      "test Loss: 0.6936 Acc: 0.6667\n",
      "Epoch 359/499\n",
      "----------\n",
      "train Loss: 0.6854 Acc: 0.6667\n",
      "val Loss: 0.6614 Acc: 0.6667\n",
      "test Loss: 0.7072 Acc: 0.6667\n",
      "Epoch 360/499\n",
      "----------\n",
      "train Loss: 0.6816 Acc: 0.6556\n",
      "val Loss: 0.6797 Acc: 0.6667\n",
      "test Loss: 0.7101 Acc: 0.6667\n",
      "Epoch 361/499\n",
      "----------\n",
      "train Loss: 0.6857 Acc: 0.6667\n",
      "val Loss: 0.6766 Acc: 0.6667\n",
      "test Loss: 0.6928 Acc: 0.6667\n",
      "Epoch 362/499\n",
      "----------\n",
      "train Loss: 0.6817 Acc: 0.6667\n",
      "val Loss: 0.6805 Acc: 0.6667\n",
      "test Loss: 0.6932 Acc: 0.6667\n",
      "Epoch 363/499\n",
      "----------\n",
      "train Loss: 0.6790 Acc: 0.6667\n",
      "val Loss: 0.6698 Acc: 0.6667\n",
      "test Loss: 0.7059 Acc: 0.6667\n",
      "Epoch 364/499\n",
      "----------\n",
      "train Loss: 0.6865 Acc: 0.6556\n",
      "val Loss: 0.6704 Acc: 0.6667\n",
      "test Loss: 0.7073 Acc: 0.6667\n",
      "Epoch 365/499\n",
      "----------\n",
      "train Loss: 0.6844 Acc: 0.6556\n",
      "val Loss: 0.6791 Acc: 0.6667\n",
      "test Loss: 0.6974 Acc: 0.6667\n",
      "Epoch 366/499\n",
      "----------\n",
      "train Loss: 0.6874 Acc: 0.6556\n",
      "val Loss: 0.6785 Acc: 0.6667\n",
      "test Loss: 0.6999 Acc: 0.6667\n",
      "Epoch 367/499\n",
      "----------\n",
      "train Loss: 0.6888 Acc: 0.6556\n",
      "val Loss: 0.6707 Acc: 0.6667\n",
      "test Loss: 0.6985 Acc: 0.6667\n",
      "Epoch 368/499\n",
      "----------\n",
      "train Loss: 0.6907 Acc: 0.6556\n",
      "val Loss: 0.6797 Acc: 0.6667\n",
      "test Loss: 0.7004 Acc: 0.6667\n",
      "Epoch 369/499\n",
      "----------\n",
      "train Loss: 0.6867 Acc: 0.6556\n",
      "val Loss: 0.6727 Acc: 0.6667\n",
      "test Loss: 0.7100 Acc: 0.6667\n",
      "Epoch 370/499\n",
      "----------\n",
      "train Loss: 0.6761 Acc: 0.6667\n",
      "val Loss: 0.6655 Acc: 0.6667\n",
      "test Loss: 0.7076 Acc: 0.6667\n",
      "Epoch 371/499\n",
      "----------\n",
      "train Loss: 0.6793 Acc: 0.6667\n",
      "val Loss: 0.6786 Acc: 0.6667\n",
      "test Loss: 0.6842 Acc: 0.6667\n",
      "Epoch 372/499\n",
      "----------\n",
      "train Loss: 0.6825 Acc: 0.6556\n",
      "val Loss: 0.6783 Acc: 0.6667\n",
      "test Loss: 0.7032 Acc: 0.6667\n",
      "Epoch 373/499\n",
      "----------\n",
      "train Loss: 0.6879 Acc: 0.6444\n",
      "val Loss: 0.6921 Acc: 0.6333\n",
      "test Loss: 0.6920 Acc: 0.6667\n",
      "Epoch 374/499\n",
      "----------\n",
      "train Loss: 0.6971 Acc: 0.6333\n",
      "val Loss: 0.6715 Acc: 0.6667\n",
      "test Loss: 0.7111 Acc: 0.6333\n",
      "Epoch 375/499\n",
      "----------\n",
      "train Loss: 0.6881 Acc: 0.6556\n",
      "val Loss: 0.6929 Acc: 0.6333\n",
      "test Loss: 0.7052 Acc: 0.6333\n",
      "Epoch 376/499\n",
      "----------\n",
      "train Loss: 0.6865 Acc: 0.6556\n",
      "val Loss: 0.6826 Acc: 0.6667\n",
      "test Loss: 0.6874 Acc: 0.6667\n",
      "Epoch 377/499\n",
      "----------\n",
      "train Loss: 0.6858 Acc: 0.6556\n",
      "val Loss: 0.6703 Acc: 0.6667\n",
      "test Loss: 0.6994 Acc: 0.6667\n",
      "Epoch 378/499\n",
      "----------\n",
      "train Loss: 0.6739 Acc: 0.6667\n",
      "val Loss: 0.6864 Acc: 0.6333\n",
      "test Loss: 0.6935 Acc: 0.6667\n",
      "Epoch 379/499\n",
      "----------\n",
      "train Loss: 0.6789 Acc: 0.6667\n",
      "val Loss: 0.6687 Acc: 0.6667\n",
      "test Loss: 0.6942 Acc: 0.6667\n",
      "Epoch 380/499\n",
      "----------\n",
      "train Loss: 0.6800 Acc: 0.6667\n",
      "val Loss: 0.7024 Acc: 0.6333\n",
      "test Loss: 0.6926 Acc: 0.6667\n",
      "Epoch 381/499\n",
      "----------\n",
      "train Loss: 0.6789 Acc: 0.6556\n",
      "val Loss: 0.6860 Acc: 0.6667\n",
      "test Loss: 0.6964 Acc: 0.6667\n",
      "Epoch 382/499\n",
      "----------\n",
      "train Loss: 0.6866 Acc: 0.6667\n",
      "val Loss: 0.6660 Acc: 0.6667\n",
      "test Loss: 0.6913 Acc: 0.6667\n",
      "Epoch 383/499\n",
      "----------\n",
      "train Loss: 0.6800 Acc: 0.6667\n",
      "val Loss: 0.6793 Acc: 0.6667\n",
      "test Loss: 0.7061 Acc: 0.6667\n",
      "Epoch 384/499\n",
      "----------\n",
      "train Loss: 0.6820 Acc: 0.6667\n",
      "val Loss: 0.6734 Acc: 0.6667\n",
      "test Loss: 0.6997 Acc: 0.6667\n",
      "Epoch 385/499\n",
      "----------\n",
      "train Loss: 0.6863 Acc: 0.6667\n",
      "val Loss: 0.6849 Acc: 0.6667\n",
      "test Loss: 0.7118 Acc: 0.6333\n",
      "Epoch 386/499\n",
      "----------\n",
      "train Loss: 0.6951 Acc: 0.6333\n",
      "val Loss: 0.6873 Acc: 0.6667\n",
      "test Loss: 0.6906 Acc: 0.6667\n",
      "Epoch 387/499\n",
      "----------\n",
      "train Loss: 0.6830 Acc: 0.6556\n",
      "val Loss: 0.6847 Acc: 0.6667\n",
      "test Loss: 0.6956 Acc: 0.6667\n",
      "Epoch 388/499\n",
      "----------\n",
      "train Loss: 0.6803 Acc: 0.6556\n",
      "val Loss: 0.6747 Acc: 0.6667\n",
      "test Loss: 0.6824 Acc: 0.6667\n",
      "Epoch 389/499\n",
      "----------\n",
      "train Loss: 0.6771 Acc: 0.6667\n",
      "val Loss: 0.7403 Acc: 0.5667\n",
      "test Loss: 0.6933 Acc: 0.6667\n",
      "Epoch 390/499\n",
      "----------\n",
      "train Loss: 0.6858 Acc: 0.6556\n",
      "val Loss: 0.6727 Acc: 0.6667\n",
      "test Loss: 0.6978 Acc: 0.6667\n",
      "Epoch 391/499\n",
      "----------\n",
      "train Loss: 0.6830 Acc: 0.6556\n",
      "val Loss: 0.6620 Acc: 0.6667\n",
      "test Loss: 0.7103 Acc: 0.6667\n",
      "Epoch 392/499\n",
      "----------\n",
      "train Loss: 0.6728 Acc: 0.6667\n",
      "val Loss: 0.6725 Acc: 0.6667\n",
      "test Loss: 0.7242 Acc: 0.6333\n",
      "Epoch 393/499\n",
      "----------\n",
      "train Loss: 0.6884 Acc: 0.6667\n",
      "val Loss: 0.6788 Acc: 0.6667\n",
      "test Loss: 0.6997 Acc: 0.6667\n",
      "Epoch 394/499\n",
      "----------\n",
      "train Loss: 0.6793 Acc: 0.6667\n",
      "val Loss: 0.6737 Acc: 0.6667\n",
      "test Loss: 0.6952 Acc: 0.6667\n",
      "Epoch 395/499\n",
      "----------\n",
      "train Loss: 0.6776 Acc: 0.6667\n",
      "val Loss: 0.6757 Acc: 0.6667\n",
      "test Loss: 0.6899 Acc: 0.6667\n",
      "Epoch 396/499\n",
      "----------\n",
      "train Loss: 0.6805 Acc: 0.6667\n",
      "val Loss: 0.6868 Acc: 0.6667\n",
      "test Loss: 0.7045 Acc: 0.6667\n",
      "Epoch 397/499\n",
      "----------\n",
      "train Loss: 0.6790 Acc: 0.6667\n",
      "val Loss: 0.6706 Acc: 0.6667\n",
      "test Loss: 0.6909 Acc: 0.6667\n",
      "Epoch 398/499\n",
      "----------\n",
      "train Loss: 0.6834 Acc: 0.6444\n",
      "val Loss: 0.6726 Acc: 0.6667\n",
      "test Loss: 0.6921 Acc: 0.6667\n",
      "Epoch 399/499\n",
      "----------\n",
      "train Loss: 0.6813 Acc: 0.6667\n",
      "val Loss: 0.6799 Acc: 0.6667\n",
      "test Loss: 0.6931 Acc: 0.6667\n",
      "Epoch 400/499\n",
      "----------\n",
      "train Loss: 0.6794 Acc: 0.6667\n",
      "val Loss: 0.6706 Acc: 0.6667\n",
      "test Loss: 0.6994 Acc: 0.6667\n",
      "Epoch 401/499\n",
      "----------\n",
      "train Loss: 0.6827 Acc: 0.6667\n",
      "val Loss: 0.6625 Acc: 0.6667\n",
      "test Loss: 0.7108 Acc: 0.6333\n",
      "Epoch 402/499\n",
      "----------\n",
      "train Loss: 0.6868 Acc: 0.6556\n",
      "val Loss: 0.6650 Acc: 0.6667\n",
      "test Loss: 0.6878 Acc: 0.6667\n",
      "Epoch 403/499\n",
      "----------\n",
      "train Loss: 0.6772 Acc: 0.6667\n",
      "val Loss: 0.6773 Acc: 0.6333\n",
      "test Loss: 0.6839 Acc: 0.6667\n",
      "Epoch 404/499\n",
      "----------\n",
      "train Loss: 0.6820 Acc: 0.6667\n",
      "val Loss: 0.6743 Acc: 0.6667\n",
      "test Loss: 0.7001 Acc: 0.6667\n",
      "Epoch 405/499\n",
      "----------\n",
      "train Loss: 0.6849 Acc: 0.6444\n",
      "val Loss: 0.6720 Acc: 0.6667\n",
      "test Loss: 0.6900 Acc: 0.6667\n",
      "Epoch 406/499\n",
      "----------\n",
      "train Loss: 0.6734 Acc: 0.6667\n",
      "val Loss: 0.6751 Acc: 0.6667\n",
      "test Loss: 0.6847 Acc: 0.6667\n",
      "Epoch 407/499\n",
      "----------\n",
      "train Loss: 0.6915 Acc: 0.6444\n",
      "val Loss: 0.6796 Acc: 0.6667\n",
      "test Loss: 0.6910 Acc: 0.6667\n",
      "Epoch 408/499\n",
      "----------\n",
      "train Loss: 0.6806 Acc: 0.6556\n",
      "val Loss: 0.6753 Acc: 0.6667\n",
      "test Loss: 0.6835 Acc: 0.6667\n",
      "Epoch 409/499\n",
      "----------\n",
      "train Loss: 0.6854 Acc: 0.6667\n",
      "val Loss: 0.6694 Acc: 0.6667\n",
      "test Loss: 0.6941 Acc: 0.6667\n",
      "Epoch 410/499\n",
      "----------\n",
      "train Loss: 0.6759 Acc: 0.6667\n",
      "val Loss: 0.7261 Acc: 0.6000\n",
      "test Loss: 0.6846 Acc: 0.6667\n",
      "Epoch 411/499\n",
      "----------\n",
      "train Loss: 0.6737 Acc: 0.6667\n",
      "val Loss: 0.6719 Acc: 0.6667\n",
      "test Loss: 0.7168 Acc: 0.6333\n",
      "Epoch 412/499\n",
      "----------\n",
      "train Loss: 0.6790 Acc: 0.6667\n",
      "val Loss: 0.6803 Acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6846 Acc: 0.6667\n",
      "Epoch 413/499\n",
      "----------\n",
      "train Loss: 0.6773 Acc: 0.6667\n",
      "val Loss: 0.6681 Acc: 0.6667\n",
      "test Loss: 0.7077 Acc: 0.6333\n",
      "Epoch 414/499\n",
      "----------\n",
      "train Loss: 0.6774 Acc: 0.6667\n",
      "val Loss: 0.6818 Acc: 0.6667\n",
      "test Loss: 0.7067 Acc: 0.6667\n",
      "Epoch 415/499\n",
      "----------\n",
      "train Loss: 0.6806 Acc: 0.6556\n",
      "val Loss: 0.6719 Acc: 0.6667\n",
      "test Loss: 0.6918 Acc: 0.6667\n",
      "Epoch 416/499\n",
      "----------\n",
      "train Loss: 0.6698 Acc: 0.6667\n",
      "val Loss: 0.6691 Acc: 0.6667\n",
      "test Loss: 0.6968 Acc: 0.6667\n",
      "Epoch 417/499\n",
      "----------\n",
      "train Loss: 0.6756 Acc: 0.6667\n",
      "val Loss: 0.6761 Acc: 0.6667\n",
      "test Loss: 0.6947 Acc: 0.6667\n",
      "Epoch 418/499\n",
      "----------\n",
      "train Loss: 0.6772 Acc: 0.6556\n",
      "val Loss: 0.6761 Acc: 0.6667\n",
      "test Loss: 0.7124 Acc: 0.6333\n",
      "Epoch 419/499\n",
      "----------\n",
      "train Loss: 0.6819 Acc: 0.6667\n",
      "val Loss: 0.6728 Acc: 0.6667\n",
      "test Loss: 0.7128 Acc: 0.6333\n",
      "Epoch 420/499\n",
      "----------\n",
      "train Loss: 0.6757 Acc: 0.6667\n",
      "val Loss: 0.6702 Acc: 0.6667\n",
      "test Loss: 0.7153 Acc: 0.6667\n",
      "Epoch 421/499\n",
      "----------\n",
      "train Loss: 0.6780 Acc: 0.6667\n",
      "val Loss: 0.6757 Acc: 0.6667\n",
      "test Loss: 0.7088 Acc: 0.6667\n",
      "Epoch 422/499\n",
      "----------\n",
      "train Loss: 0.6708 Acc: 0.6667\n",
      "val Loss: 0.6908 Acc: 0.6333\n",
      "test Loss: 0.6954 Acc: 0.6667\n",
      "Epoch 423/499\n",
      "----------\n",
      "train Loss: 0.6798 Acc: 0.6667\n",
      "val Loss: 0.6851 Acc: 0.6667\n",
      "test Loss: 0.6828 Acc: 0.6667\n",
      "Epoch 424/499\n",
      "----------\n",
      "train Loss: 0.6867 Acc: 0.6556\n",
      "val Loss: 0.6672 Acc: 0.6667\n",
      "test Loss: 0.7207 Acc: 0.6667\n",
      "Epoch 425/499\n",
      "----------\n",
      "train Loss: 0.6817 Acc: 0.6556\n",
      "val Loss: 0.6855 Acc: 0.6667\n",
      "test Loss: 0.7006 Acc: 0.6667\n",
      "Epoch 426/499\n",
      "----------\n",
      "train Loss: 0.6778 Acc: 0.6667\n",
      "val Loss: 0.6720 Acc: 0.6667\n",
      "test Loss: 0.6967 Acc: 0.6667\n",
      "Epoch 427/499\n",
      "----------\n",
      "train Loss: 0.6871 Acc: 0.6444\n",
      "val Loss: 0.6682 Acc: 0.6667\n",
      "test Loss: 0.7182 Acc: 0.6667\n",
      "Epoch 428/499\n",
      "----------\n",
      "train Loss: 0.6749 Acc: 0.6556\n",
      "val Loss: 0.6689 Acc: 0.6667\n",
      "test Loss: 0.6900 Acc: 0.6667\n",
      "Epoch 429/499\n",
      "----------\n",
      "train Loss: 0.6726 Acc: 0.6667\n",
      "val Loss: 0.6691 Acc: 0.6667\n",
      "test Loss: 0.6816 Acc: 0.6667\n",
      "Epoch 430/499\n",
      "----------\n",
      "train Loss: 0.6797 Acc: 0.6556\n",
      "val Loss: 0.6697 Acc: 0.6667\n",
      "test Loss: 0.6958 Acc: 0.6667\n",
      "Epoch 431/499\n",
      "----------\n",
      "train Loss: 0.6994 Acc: 0.6333\n",
      "val Loss: 0.6907 Acc: 0.6667\n",
      "test Loss: 0.6852 Acc: 0.6667\n",
      "Epoch 432/499\n",
      "----------\n",
      "train Loss: 0.6845 Acc: 0.6444\n",
      "val Loss: 0.6651 Acc: 0.6667\n",
      "test Loss: 0.6942 Acc: 0.6667\n",
      "Epoch 433/499\n",
      "----------\n",
      "train Loss: 0.6788 Acc: 0.6556\n",
      "val Loss: 0.6931 Acc: 0.6333\n",
      "test Loss: 0.6936 Acc: 0.6667\n",
      "Epoch 434/499\n",
      "----------\n",
      "train Loss: 0.6898 Acc: 0.6444\n",
      "val Loss: 0.6733 Acc: 0.6667\n",
      "test Loss: 0.6909 Acc: 0.6667\n",
      "Epoch 435/499\n",
      "----------\n",
      "train Loss: 0.6678 Acc: 0.6667\n",
      "val Loss: 0.6702 Acc: 0.6667\n",
      "test Loss: 0.7075 Acc: 0.6333\n",
      "Epoch 436/499\n",
      "----------\n",
      "train Loss: 0.7025 Acc: 0.6333\n",
      "val Loss: 0.6697 Acc: 0.6667\n",
      "test Loss: 0.7070 Acc: 0.6333\n",
      "Epoch 437/499\n",
      "----------\n",
      "train Loss: 0.6811 Acc: 0.6667\n",
      "val Loss: 0.6668 Acc: 0.6667\n",
      "test Loss: 0.6940 Acc: 0.6667\n",
      "Epoch 438/499\n",
      "----------\n",
      "train Loss: 0.6809 Acc: 0.6556\n",
      "val Loss: 0.6646 Acc: 0.6667\n",
      "test Loss: 0.7017 Acc: 0.6667\n",
      "Epoch 439/499\n",
      "----------\n",
      "train Loss: 0.7012 Acc: 0.6333\n",
      "val Loss: 0.6779 Acc: 0.6667\n",
      "test Loss: 0.7051 Acc: 0.6667\n",
      "Epoch 440/499\n",
      "----------\n",
      "train Loss: 0.6866 Acc: 0.6556\n",
      "val Loss: 0.6737 Acc: 0.6667\n",
      "test Loss: 0.6874 Acc: 0.6667\n",
      "Epoch 441/499\n",
      "----------\n",
      "train Loss: 0.6894 Acc: 0.6333\n",
      "val Loss: 0.6688 Acc: 0.6667\n",
      "test Loss: 0.6945 Acc: 0.6667\n",
      "Epoch 442/499\n",
      "----------\n",
      "train Loss: 0.6787 Acc: 0.6556\n",
      "val Loss: 0.6786 Acc: 0.6667\n",
      "test Loss: 0.7115 Acc: 0.6333\n",
      "Epoch 443/499\n",
      "----------\n",
      "train Loss: 0.6789 Acc: 0.6667\n",
      "val Loss: 0.6845 Acc: 0.6333\n",
      "test Loss: 0.6865 Acc: 0.6667\n",
      "Epoch 444/499\n",
      "----------\n",
      "train Loss: 0.6895 Acc: 0.6444\n",
      "val Loss: 0.6657 Acc: 0.6667\n",
      "test Loss: 0.7060 Acc: 0.6667\n",
      "Epoch 445/499\n",
      "----------\n",
      "train Loss: 0.6783 Acc: 0.6556\n",
      "val Loss: 0.6659 Acc: 0.6667\n",
      "test Loss: 0.6954 Acc: 0.6667\n",
      "Epoch 446/499\n",
      "----------\n",
      "train Loss: 0.6711 Acc: 0.6667\n",
      "val Loss: 0.6780 Acc: 0.6667\n",
      "test Loss: 0.6810 Acc: 0.6667\n",
      "Epoch 447/499\n",
      "----------\n",
      "train Loss: 0.6817 Acc: 0.6556\n",
      "val Loss: 0.6600 Acc: 0.6667\n",
      "test Loss: 0.6904 Acc: 0.6667\n",
      "Epoch 448/499\n",
      "----------\n",
      "train Loss: 0.6850 Acc: 0.6444\n",
      "val Loss: 0.6711 Acc: 0.6667\n",
      "test Loss: 0.6934 Acc: 0.6667\n",
      "Epoch 449/499\n",
      "----------\n",
      "train Loss: 0.6845 Acc: 0.6556\n",
      "val Loss: 0.6868 Acc: 0.6333\n",
      "test Loss: 0.7018 Acc: 0.6667\n",
      "Epoch 450/499\n",
      "----------\n",
      "train Loss: 0.6801 Acc: 0.6667\n",
      "val Loss: 0.6836 Acc: 0.6333\n",
      "test Loss: 0.7159 Acc: 0.6333\n",
      "Epoch 451/499\n",
      "----------\n",
      "train Loss: 0.6742 Acc: 0.6667\n",
      "val Loss: 0.6717 Acc: 0.6667\n",
      "test Loss: 0.7152 Acc: 0.6667\n",
      "Epoch 452/499\n",
      "----------\n",
      "train Loss: 0.6875 Acc: 0.6556\n",
      "val Loss: 0.6638 Acc: 0.6667\n",
      "test Loss: 0.6843 Acc: 0.6667\n",
      "Epoch 453/499\n",
      "----------\n",
      "train Loss: 0.6831 Acc: 0.6667\n",
      "val Loss: 0.6742 Acc: 0.6667\n",
      "test Loss: 0.7103 Acc: 0.6333\n",
      "Epoch 454/499\n",
      "----------\n",
      "train Loss: 0.6891 Acc: 0.6444\n",
      "val Loss: 0.6662 Acc: 0.6667\n",
      "test Loss: 0.6919 Acc: 0.6667\n",
      "Epoch 455/499\n",
      "----------\n",
      "train Loss: 0.6668 Acc: 0.6667\n",
      "val Loss: 0.6701 Acc: 0.6667\n",
      "test Loss: 0.6846 Acc: 0.6667\n",
      "Epoch 456/499\n",
      "----------\n",
      "train Loss: 0.6742 Acc: 0.6667\n",
      "val Loss: 0.6728 Acc: 0.6667\n",
      "test Loss: 0.6857 Acc: 0.6667\n",
      "Epoch 457/499\n",
      "----------\n",
      "train Loss: 0.6752 Acc: 0.6556\n",
      "val Loss: 0.6660 Acc: 0.6667\n",
      "test Loss: 0.7010 Acc: 0.6333\n",
      "Epoch 458/499\n",
      "----------\n",
      "train Loss: 0.6734 Acc: 0.6667\n",
      "val Loss: 0.6847 Acc: 0.6333\n",
      "test Loss: 0.6977 Acc: 0.6667\n",
      "Epoch 459/499\n",
      "----------\n",
      "train Loss: 0.6719 Acc: 0.6556\n",
      "val Loss: 0.6653 Acc: 0.6667\n",
      "test Loss: 0.6932 Acc: 0.6667\n",
      "Epoch 460/499\n",
      "----------\n",
      "train Loss: 0.6746 Acc: 0.6556\n",
      "val Loss: 0.6673 Acc: 0.6667\n",
      "test Loss: 0.6906 Acc: 0.6667\n",
      "Epoch 461/499\n",
      "----------\n",
      "train Loss: 0.6784 Acc: 0.6556\n",
      "val Loss: 0.6970 Acc: 0.6333\n",
      "test Loss: 0.6912 Acc: 0.6667\n",
      "Epoch 462/499\n",
      "----------\n",
      "train Loss: 0.6736 Acc: 0.6556\n",
      "val Loss: 0.6747 Acc: 0.6667\n",
      "test Loss: 0.6900 Acc: 0.6667\n",
      "Epoch 463/499\n",
      "----------\n",
      "train Loss: 0.6696 Acc: 0.6667\n",
      "val Loss: 0.6670 Acc: 0.6667\n",
      "test Loss: 0.6884 Acc: 0.6667\n",
      "Epoch 464/499\n",
      "----------\n",
      "train Loss: 0.6726 Acc: 0.6667\n",
      "val Loss: 0.6898 Acc: 0.6333\n",
      "test Loss: 0.6809 Acc: 0.6667\n",
      "Epoch 465/499\n",
      "----------\n",
      "train Loss: 0.6847 Acc: 0.6667\n",
      "val Loss: 0.6657 Acc: 0.6667\n",
      "test Loss: 0.7140 Acc: 0.6333\n",
      "Epoch 466/499\n",
      "----------\n",
      "train Loss: 0.6842 Acc: 0.6556\n",
      "val Loss: 0.6685 Acc: 0.6667\n",
      "test Loss: 0.6909 Acc: 0.6667\n",
      "Epoch 467/499\n",
      "----------\n",
      "train Loss: 0.6712 Acc: 0.6667\n",
      "val Loss: 0.6752 Acc: 0.6667\n",
      "test Loss: 0.6820 Acc: 0.6667\n",
      "Epoch 468/499\n",
      "----------\n",
      "train Loss: 0.6706 Acc: 0.6667\n",
      "val Loss: 0.6741 Acc: 0.6667\n",
      "test Loss: 0.6890 Acc: 0.6667\n",
      "Epoch 469/499\n",
      "----------\n",
      "train Loss: 0.6735 Acc: 0.6667\n",
      "val Loss: 0.6806 Acc: 0.6667\n",
      "test Loss: 0.7075 Acc: 0.6333\n",
      "Epoch 470/499\n",
      "----------\n",
      "train Loss: 0.6765 Acc: 0.6667\n",
      "val Loss: 0.6626 Acc: 0.6667\n",
      "test Loss: 0.7041 Acc: 0.6333\n",
      "Epoch 471/499\n",
      "----------\n",
      "train Loss: 0.6778 Acc: 0.6556\n",
      "val Loss: 0.7036 Acc: 0.6000\n",
      "test Loss: 0.6965 Acc: 0.6667\n",
      "Epoch 472/499\n",
      "----------\n",
      "train Loss: 0.6927 Acc: 0.6444\n",
      "val Loss: 0.6649 Acc: 0.6667\n",
      "test Loss: 0.6807 Acc: 0.6667\n",
      "Epoch 473/499\n",
      "----------\n",
      "train Loss: 0.6797 Acc: 0.6556\n",
      "val Loss: 0.6951 Acc: 0.6333\n",
      "test Loss: 0.6869 Acc: 0.6667\n",
      "Epoch 474/499\n",
      "----------\n",
      "train Loss: 0.6802 Acc: 0.6444\n",
      "val Loss: 0.6647 Acc: 0.6667\n",
      "test Loss: 0.6931 Acc: 0.6667\n",
      "Epoch 475/499\n",
      "----------\n",
      "train Loss: 0.6680 Acc: 0.6667\n",
      "val Loss: 0.6691 Acc: 0.6667\n",
      "test Loss: 0.6883 Acc: 0.6667\n",
      "Epoch 476/499\n",
      "----------\n",
      "train Loss: 0.6716 Acc: 0.6667\n",
      "val Loss: 0.6715 Acc: 0.6667\n",
      "test Loss: 0.6941 Acc: 0.6667\n",
      "Epoch 477/499\n",
      "----------\n",
      "train Loss: 0.6781 Acc: 0.6556\n",
      "val Loss: 0.6608 Acc: 0.6667\n",
      "test Loss: 0.7061 Acc: 0.6667\n",
      "Epoch 478/499\n",
      "----------\n",
      "train Loss: 0.6737 Acc: 0.6667\n",
      "val Loss: 0.6809 Acc: 0.6667\n",
      "test Loss: 0.6865 Acc: 0.6667\n",
      "Epoch 479/499\n",
      "----------\n",
      "train Loss: 0.6658 Acc: 0.6667\n",
      "val Loss: 0.6659 Acc: 0.6667\n",
      "test Loss: 0.6863 Acc: 0.6667\n",
      "Epoch 480/499\n",
      "----------\n",
      "train Loss: 0.6902 Acc: 0.6444\n",
      "val Loss: 0.6655 Acc: 0.6667\n",
      "test Loss: 0.6973 Acc: 0.6667\n",
      "Epoch 481/499\n",
      "----------\n",
      "train Loss: 0.6703 Acc: 0.6667\n",
      "val Loss: 0.6777 Acc: 0.6667\n",
      "test Loss: 0.6933 Acc: 0.6667\n",
      "Epoch 482/499\n",
      "----------\n",
      "train Loss: 0.6752 Acc: 0.6667\n",
      "val Loss: 0.6771 Acc: 0.6667\n",
      "test Loss: 0.6924 Acc: 0.6667\n",
      "Epoch 483/499\n",
      "----------\n",
      "train Loss: 0.6676 Acc: 0.6667\n",
      "val Loss: 0.6676 Acc: 0.6667\n",
      "test Loss: 0.7187 Acc: 0.6333\n",
      "Epoch 484/499\n",
      "----------\n",
      "train Loss: 0.6716 Acc: 0.6667\n",
      "val Loss: 0.6804 Acc: 0.6667\n",
      "test Loss: 0.7215 Acc: 0.6333\n",
      "Epoch 485/499\n",
      "----------\n",
      "train Loss: 0.6676 Acc: 0.6667\n",
      "val Loss: 0.6637 Acc: 0.6667\n",
      "test Loss: 0.7083 Acc: 0.6667\n",
      "Epoch 486/499\n",
      "----------\n",
      "train Loss: 0.6660 Acc: 0.6667\n",
      "val Loss: 0.6670 Acc: 0.6667\n",
      "test Loss: 0.6861 Acc: 0.6667\n",
      "Epoch 487/499\n",
      "----------\n",
      "train Loss: 0.6801 Acc: 0.6556\n",
      "val Loss: 0.6909 Acc: 0.6333\n",
      "test Loss: 0.7022 Acc: 0.6667\n",
      "Epoch 488/499\n",
      "----------\n",
      "train Loss: 0.6777 Acc: 0.6667\n",
      "val Loss: 0.6795 Acc: 0.6333\n",
      "test Loss: 0.7001 Acc: 0.6667\n",
      "Epoch 489/499\n",
      "----------\n",
      "train Loss: 0.6678 Acc: 0.6667\n",
      "val Loss: 0.6733 Acc: 0.6667\n",
      "test Loss: 0.6886 Acc: 0.6667\n",
      "Epoch 490/499\n",
      "----------\n",
      "train Loss: 0.6732 Acc: 0.6667\n",
      "val Loss: 0.6686 Acc: 0.6667\n",
      "test Loss: 0.6965 Acc: 0.6667\n",
      "Epoch 491/499\n",
      "----------\n",
      "train Loss: 0.6835 Acc: 0.6556\n",
      "val Loss: 0.6750 Acc: 0.6667\n",
      "test Loss: 0.6783 Acc: 0.6667\n",
      "Epoch 492/499\n",
      "----------\n",
      "train Loss: 0.6824 Acc: 0.6444\n",
      "val Loss: 0.6707 Acc: 0.6667\n",
      "test Loss: 0.6850 Acc: 0.6667\n",
      "Epoch 493/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6796 Acc: 0.6556\n",
      "val Loss: 0.6639 Acc: 0.6667\n",
      "test Loss: 0.6878 Acc: 0.6667\n",
      "Epoch 494/499\n",
      "----------\n",
      "train Loss: 0.6644 Acc: 0.6667\n",
      "val Loss: 0.6629 Acc: 0.6667\n",
      "test Loss: 0.6947 Acc: 0.6667\n",
      "Epoch 495/499\n",
      "----------\n",
      "train Loss: 0.6919 Acc: 0.6333\n",
      "val Loss: 0.6886 Acc: 0.6333\n",
      "test Loss: 0.6974 Acc: 0.6667\n",
      "Epoch 496/499\n",
      "----------\n",
      "train Loss: 0.6668 Acc: 0.6667\n",
      "val Loss: 0.6698 Acc: 0.6667\n",
      "test Loss: 0.6792 Acc: 0.6667\n",
      "Epoch 497/499\n",
      "----------\n",
      "train Loss: 0.6747 Acc: 0.6667\n",
      "val Loss: 0.6757 Acc: 0.6667\n",
      "test Loss: 0.7154 Acc: 0.6333\n",
      "Epoch 498/499\n",
      "----------\n",
      "train Loss: 0.6724 Acc: 0.6556\n",
      "val Loss: 0.6637 Acc: 0.6667\n",
      "test Loss: 0.6923 Acc: 0.6667\n",
      "Epoch 499/499\n",
      "----------\n",
      "train Loss: 0.6856 Acc: 0.6444\n",
      "val Loss: 0.6666 Acc: 0.6667\n",
      "test Loss: 0.6973 Acc: 0.6667\n",
      "Training complete in 0m 6s\n",
      "Best test Acc: 0.933333\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 1.1001 Acc: 0.3333\n",
      "val Loss: 1.0980 Acc: 0.3333\n",
      "test Loss: 1.0982 Acc: 0.3333\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 1.0979 Acc: 0.3333\n",
      "val Loss: 1.0957 Acc: 0.3333\n",
      "test Loss: 1.0968 Acc: 0.3333\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 1.0975 Acc: 0.3333\n",
      "val Loss: 1.0944 Acc: 0.3333\n",
      "test Loss: 1.0943 Acc: 0.3333\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 1.0950 Acc: 0.3333\n",
      "val Loss: 1.0959 Acc: 0.3333\n",
      "test Loss: 1.0930 Acc: 0.3333\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 1.0949 Acc: 0.3333\n",
      "val Loss: 1.0919 Acc: 0.3333\n",
      "test Loss: 1.0917 Acc: 0.3333\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 1.0926 Acc: 0.3333\n",
      "val Loss: 1.0928 Acc: 0.3333\n",
      "test Loss: 1.0908 Acc: 0.3333\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 1.0909 Acc: 0.3333\n",
      "val Loss: 1.0908 Acc: 0.3333\n",
      "test Loss: 1.0886 Acc: 0.3333\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 1.0909 Acc: 0.3333\n",
      "val Loss: 1.0912 Acc: 0.3333\n",
      "test Loss: 1.0890 Acc: 0.3333\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 1.0889 Acc: 0.3333\n",
      "val Loss: 1.0878 Acc: 0.3333\n",
      "test Loss: 1.0871 Acc: 0.3333\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 1.0882 Acc: 0.3333\n",
      "val Loss: 1.0859 Acc: 0.3333\n",
      "test Loss: 1.0824 Acc: 0.3333\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 1.0844 Acc: 0.3333\n",
      "val Loss: 1.0841 Acc: 0.3333\n",
      "test Loss: 1.0811 Acc: 0.3333\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 1.0842 Acc: 0.3333\n",
      "val Loss: 1.0784 Acc: 0.3667\n",
      "test Loss: 1.0813 Acc: 0.3667\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 1.0807 Acc: 0.3333\n",
      "val Loss: 1.0770 Acc: 0.5000\n",
      "test Loss: 1.0777 Acc: 0.4333\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 1.0770 Acc: 0.4556\n",
      "val Loss: 1.0733 Acc: 0.6333\n",
      "test Loss: 1.0725 Acc: 0.6000\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 1.0756 Acc: 0.5778\n",
      "val Loss: 1.0722 Acc: 0.6333\n",
      "test Loss: 1.0729 Acc: 0.6000\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 1.0714 Acc: 0.6444\n",
      "val Loss: 1.0668 Acc: 0.6667\n",
      "test Loss: 1.0726 Acc: 0.5667\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 1.0712 Acc: 0.5889\n",
      "val Loss: 1.0607 Acc: 0.6667\n",
      "test Loss: 1.0643 Acc: 0.6333\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 1.0665 Acc: 0.6222\n",
      "val Loss: 1.0628 Acc: 0.6000\n",
      "test Loss: 1.0618 Acc: 0.6000\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 1.0600 Acc: 0.6333\n",
      "val Loss: 1.0521 Acc: 0.6667\n",
      "test Loss: 1.0550 Acc: 0.6333\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 1.0571 Acc: 0.6222\n",
      "val Loss: 1.0458 Acc: 0.6667\n",
      "test Loss: 1.0455 Acc: 0.6667\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 1.0488 Acc: 0.6444\n",
      "val Loss: 1.0412 Acc: 0.6667\n",
      "test Loss: 1.0383 Acc: 0.6667\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 1.0465 Acc: 0.6111\n",
      "val Loss: 1.0353 Acc: 0.6667\n",
      "test Loss: 1.0372 Acc: 0.6333\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 1.0343 Acc: 0.6667\n",
      "val Loss: 1.0304 Acc: 0.6667\n",
      "test Loss: 1.0311 Acc: 0.6667\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 1.0291 Acc: 0.6667\n",
      "val Loss: 1.0223 Acc: 0.6333\n",
      "test Loss: 1.0153 Acc: 0.6667\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 1.0296 Acc: 0.6556\n",
      "val Loss: 1.0166 Acc: 0.6667\n",
      "test Loss: 1.0145 Acc: 0.6667\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 1.0140 Acc: 0.6667\n",
      "val Loss: 1.0025 Acc: 0.6667\n",
      "test Loss: 0.9999 Acc: 0.6667\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 1.0047 Acc: 0.6667\n",
      "val Loss: 1.0002 Acc: 0.6667\n",
      "test Loss: 0.9978 Acc: 0.6667\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.9972 Acc: 0.6667\n",
      "val Loss: 0.9843 Acc: 0.6667\n",
      "test Loss: 0.9855 Acc: 0.6667\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.9842 Acc: 0.6667\n",
      "val Loss: 0.9762 Acc: 0.6667\n",
      "test Loss: 0.9649 Acc: 0.6667\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.9738 Acc: 0.6667\n",
      "val Loss: 0.9656 Acc: 0.6667\n",
      "test Loss: 0.9640 Acc: 0.7000\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.9643 Acc: 0.6778\n",
      "val Loss: 0.9710 Acc: 0.6667\n",
      "test Loss: 0.9537 Acc: 0.6667\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.9535 Acc: 0.6889\n",
      "val Loss: 0.9366 Acc: 0.6667\n",
      "test Loss: 0.9454 Acc: 0.6667\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.9419 Acc: 0.6667\n",
      "val Loss: 0.9293 Acc: 0.6667\n",
      "test Loss: 0.9325 Acc: 0.6667\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.9352 Acc: 0.6667\n",
      "val Loss: 0.9286 Acc: 0.7000\n",
      "test Loss: 0.9204 Acc: 0.6667\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.9204 Acc: 0.7000\n",
      "val Loss: 0.9287 Acc: 0.6667\n",
      "test Loss: 0.9213 Acc: 0.6667\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.9052 Acc: 0.6889\n",
      "val Loss: 0.9082 Acc: 0.6667\n",
      "test Loss: 0.9127 Acc: 0.6667\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.8966 Acc: 0.7111\n",
      "val Loss: 0.8951 Acc: 0.6667\n",
      "test Loss: 0.8769 Acc: 0.7667\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.8911 Acc: 0.7000\n",
      "val Loss: 0.8830 Acc: 0.8000\n",
      "test Loss: 0.9013 Acc: 0.6667\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.8901 Acc: 0.7778\n",
      "val Loss: 0.8732 Acc: 0.8333\n",
      "test Loss: 0.8640 Acc: 0.8333\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.8757 Acc: 0.7889\n",
      "val Loss: 0.8958 Acc: 0.8667\n",
      "test Loss: 0.8557 Acc: 0.8667\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.8687 Acc: 0.8222\n",
      "val Loss: 0.8532 Acc: 0.9333\n",
      "test Loss: 0.8551 Acc: 0.7667\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.8574 Acc: 0.8333\n",
      "val Loss: 0.8417 Acc: 0.7667\n",
      "test Loss: 0.8390 Acc: 0.8333\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.8504 Acc: 0.8556\n",
      "val Loss: 0.8565 Acc: 0.8667\n",
      "test Loss: 0.8302 Acc: 0.9000\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.8342 Acc: 0.8778\n",
      "val Loss: 0.8217 Acc: 0.8667\n",
      "test Loss: 0.8402 Acc: 0.7667\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.8405 Acc: 0.8444\n",
      "val Loss: 0.8268 Acc: 0.8333\n",
      "test Loss: 0.8325 Acc: 0.8667\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.8291 Acc: 0.8778\n",
      "val Loss: 0.8336 Acc: 0.8667\n",
      "test Loss: 0.8206 Acc: 0.8333\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.8186 Acc: 0.7889\n",
      "val Loss: 0.8152 Acc: 0.8333\n",
      "test Loss: 0.8054 Acc: 0.8000\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.8215 Acc: 0.8111\n",
      "val Loss: 0.8202 Acc: 0.8333\n",
      "test Loss: 0.8120 Acc: 0.8333\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.8138 Acc: 0.8111\n",
      "val Loss: 0.8165 Acc: 0.8333\n",
      "test Loss: 0.8117 Acc: 0.7333\n",
      "Epoch 49/499\n",
      "----------\n",
      "train Loss: 0.8082 Acc: 0.7444\n",
      "val Loss: 0.7999 Acc: 0.7667\n",
      "test Loss: 0.7992 Acc: 0.8667\n",
      "Epoch 50/499\n",
      "----------\n",
      "train Loss: 0.8024 Acc: 0.7889\n",
      "val Loss: 0.7987 Acc: 0.7333\n",
      "test Loss: 0.7940 Acc: 0.8333\n",
      "Epoch 51/499\n",
      "----------\n",
      "train Loss: 0.7992 Acc: 0.7444\n",
      "val Loss: 0.7903 Acc: 0.7667\n",
      "test Loss: 0.7988 Acc: 0.8000\n",
      "Epoch 52/499\n",
      "----------\n",
      "train Loss: 0.8010 Acc: 0.7556\n",
      "val Loss: 0.7891 Acc: 0.8000\n",
      "test Loss: 0.7896 Acc: 0.8333\n",
      "Epoch 53/499\n",
      "----------\n",
      "train Loss: 0.7946 Acc: 0.7889\n",
      "val Loss: 0.7945 Acc: 0.7667\n",
      "test Loss: 0.7931 Acc: 0.7333\n",
      "Epoch 54/499\n",
      "----------\n",
      "train Loss: 0.7873 Acc: 0.7667\n",
      "val Loss: 0.7870 Acc: 0.7667\n",
      "test Loss: 0.7842 Acc: 0.7333\n",
      "Epoch 55/499\n",
      "----------\n",
      "train Loss: 0.7852 Acc: 0.7667\n",
      "val Loss: 0.7845 Acc: 0.8000\n",
      "test Loss: 0.7859 Acc: 0.7000\n",
      "Epoch 56/499\n",
      "----------\n",
      "train Loss: 0.7948 Acc: 0.7333\n",
      "val Loss: 0.7704 Acc: 0.8667\n",
      "test Loss: 0.7876 Acc: 0.7333\n",
      "Epoch 57/499\n",
      "----------\n",
      "train Loss: 0.7854 Acc: 0.7667\n",
      "val Loss: 0.7790 Acc: 0.8667\n",
      "test Loss: 0.7828 Acc: 0.8333\n",
      "Epoch 58/499\n",
      "----------\n",
      "train Loss: 0.7821 Acc: 0.7556\n",
      "val Loss: 0.7933 Acc: 0.7667\n",
      "test Loss: 0.7867 Acc: 0.7667\n",
      "Epoch 59/499\n",
      "----------\n",
      "train Loss: 0.7781 Acc: 0.7778\n",
      "val Loss: 0.7682 Acc: 0.8333\n",
      "test Loss: 0.7807 Acc: 0.8000\n",
      "Epoch 60/499\n",
      "----------\n",
      "train Loss: 0.7788 Acc: 0.7778\n",
      "val Loss: 0.7875 Acc: 0.8000\n",
      "test Loss: 0.7935 Acc: 0.7333\n",
      "Epoch 61/499\n",
      "----------\n",
      "train Loss: 0.7762 Acc: 0.7444\n",
      "val Loss: 0.7666 Acc: 0.8333\n",
      "test Loss: 0.7803 Acc: 0.7333\n",
      "Epoch 62/499\n",
      "----------\n",
      "train Loss: 0.7722 Acc: 0.8111\n",
      "val Loss: 0.7688 Acc: 0.8333\n",
      "test Loss: 0.7765 Acc: 0.8333\n",
      "Epoch 63/499\n",
      "----------\n",
      "train Loss: 0.7752 Acc: 0.7556\n",
      "val Loss: 0.7664 Acc: 0.8667\n",
      "test Loss: 0.7722 Acc: 0.8000\n",
      "Epoch 64/499\n",
      "----------\n",
      "train Loss: 0.7709 Acc: 0.8222\n",
      "val Loss: 0.7624 Acc: 0.8667\n",
      "test Loss: 0.7798 Acc: 0.8333\n",
      "Epoch 65/499\n",
      "----------\n",
      "train Loss: 0.7673 Acc: 0.8222\n",
      "val Loss: 0.7592 Acc: 0.8667\n",
      "test Loss: 0.7690 Acc: 0.8333\n",
      "Epoch 66/499\n",
      "----------\n",
      "train Loss: 0.7698 Acc: 0.8778\n",
      "val Loss: 0.7653 Acc: 0.8333\n",
      "test Loss: 0.7656 Acc: 0.8333\n",
      "Epoch 67/499\n",
      "----------\n",
      "train Loss: 0.7708 Acc: 0.8111\n",
      "val Loss: 0.7608 Acc: 0.9000\n",
      "test Loss: 0.7609 Acc: 0.8667\n",
      "Epoch 68/499\n",
      "----------\n",
      "train Loss: 0.7645 Acc: 0.8333\n",
      "val Loss: 0.7537 Acc: 0.9000\n",
      "test Loss: 0.7738 Acc: 0.8333\n",
      "Epoch 69/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.7619 Acc: 0.8444\n",
      "val Loss: 0.7638 Acc: 0.8667\n",
      "test Loss: 0.7683 Acc: 0.8667\n",
      "Epoch 70/499\n",
      "----------\n",
      "train Loss: 0.7646 Acc: 0.8333\n",
      "val Loss: 0.7573 Acc: 0.9000\n",
      "test Loss: 0.7641 Acc: 0.8333\n",
      "Epoch 71/499\n",
      "----------\n",
      "train Loss: 0.7590 Acc: 0.8444\n",
      "val Loss: 0.7540 Acc: 0.9000\n",
      "test Loss: 0.7567 Acc: 0.8333\n",
      "Epoch 72/499\n",
      "----------\n",
      "train Loss: 0.7621 Acc: 0.8556\n",
      "val Loss: 0.7577 Acc: 0.8667\n",
      "test Loss: 0.7602 Acc: 0.8333\n",
      "Epoch 73/499\n",
      "----------\n",
      "train Loss: 0.7561 Acc: 0.8444\n",
      "val Loss: 0.7498 Acc: 0.9333\n",
      "test Loss: 0.7481 Acc: 0.8333\n",
      "Epoch 74/499\n",
      "----------\n",
      "train Loss: 0.7524 Acc: 0.8667\n",
      "val Loss: 0.7547 Acc: 0.8667\n",
      "test Loss: 0.7471 Acc: 0.9333\n",
      "Epoch 75/499\n",
      "----------\n",
      "train Loss: 0.7482 Acc: 0.9222\n",
      "val Loss: 0.7417 Acc: 0.8667\n",
      "test Loss: 0.7566 Acc: 0.8333\n",
      "Epoch 76/499\n",
      "----------\n",
      "train Loss: 0.7497 Acc: 0.9222\n",
      "val Loss: 0.7392 Acc: 0.9667\n",
      "test Loss: 0.7697 Acc: 0.8333\n",
      "Epoch 77/499\n",
      "----------\n",
      "train Loss: 0.7450 Acc: 0.9000\n",
      "val Loss: 0.7340 Acc: 0.9667\n",
      "test Loss: 0.7586 Acc: 0.8333\n",
      "Epoch 78/499\n",
      "----------\n",
      "train Loss: 0.7437 Acc: 0.9000\n",
      "val Loss: 0.7301 Acc: 0.9000\n",
      "test Loss: 0.7574 Acc: 0.8000\n",
      "Epoch 79/499\n",
      "----------\n",
      "train Loss: 0.7458 Acc: 0.9000\n",
      "val Loss: 0.7251 Acc: 0.9333\n",
      "test Loss: 0.7334 Acc: 0.9000\n",
      "Epoch 80/499\n",
      "----------\n",
      "train Loss: 0.7411 Acc: 0.9222\n",
      "val Loss: 0.7364 Acc: 0.9000\n",
      "test Loss: 0.7407 Acc: 0.8333\n",
      "Epoch 81/499\n",
      "----------\n",
      "train Loss: 0.7367 Acc: 0.9000\n",
      "val Loss: 0.7288 Acc: 0.9000\n",
      "test Loss: 0.7459 Acc: 0.9000\n",
      "Epoch 82/499\n",
      "----------\n",
      "train Loss: 0.7323 Acc: 0.9111\n",
      "val Loss: 0.7111 Acc: 0.9333\n",
      "test Loss: 0.7440 Acc: 0.8333\n",
      "Epoch 83/499\n",
      "----------\n",
      "train Loss: 0.7383 Acc: 0.9111\n",
      "val Loss: 0.7146 Acc: 0.9333\n",
      "test Loss: 0.7410 Acc: 0.8333\n",
      "Epoch 84/499\n",
      "----------\n",
      "train Loss: 0.7260 Acc: 0.9333\n",
      "val Loss: 0.7132 Acc: 1.0000\n",
      "test Loss: 0.7238 Acc: 0.8667\n",
      "Epoch 85/499\n",
      "----------\n",
      "train Loss: 0.7130 Acc: 0.9222\n",
      "val Loss: 0.7042 Acc: 1.0000\n",
      "test Loss: 0.7323 Acc: 0.8000\n",
      "Epoch 86/499\n",
      "----------\n",
      "train Loss: 0.7121 Acc: 0.9556\n",
      "val Loss: 0.7037 Acc: 0.9667\n",
      "test Loss: 0.7268 Acc: 0.8333\n",
      "Epoch 87/499\n",
      "----------\n",
      "train Loss: 0.7257 Acc: 0.9000\n",
      "val Loss: 0.6956 Acc: 0.9667\n",
      "test Loss: 0.7225 Acc: 0.8667\n",
      "Epoch 88/499\n",
      "----------\n",
      "train Loss: 0.6983 Acc: 0.9444\n",
      "val Loss: 0.6900 Acc: 1.0000\n",
      "test Loss: 0.7216 Acc: 0.8667\n",
      "Epoch 89/499\n",
      "----------\n",
      "train Loss: 0.7027 Acc: 0.9333\n",
      "val Loss: 0.6809 Acc: 1.0000\n",
      "test Loss: 0.6979 Acc: 0.9000\n",
      "Epoch 90/499\n",
      "----------\n",
      "train Loss: 0.7040 Acc: 0.9111\n",
      "val Loss: 0.6817 Acc: 0.9333\n",
      "test Loss: 0.7227 Acc: 0.8333\n",
      "Epoch 91/499\n",
      "----------\n",
      "train Loss: 0.6955 Acc: 0.9222\n",
      "val Loss: 0.6765 Acc: 0.9667\n",
      "test Loss: 0.7051 Acc: 0.9000\n",
      "Epoch 92/499\n",
      "----------\n",
      "train Loss: 0.6930 Acc: 0.9556\n",
      "val Loss: 0.6638 Acc: 0.9667\n",
      "test Loss: 0.7067 Acc: 0.9333\n",
      "Epoch 93/499\n",
      "----------\n",
      "train Loss: 0.6842 Acc: 0.9667\n",
      "val Loss: 0.6637 Acc: 0.9667\n",
      "test Loss: 0.7113 Acc: 0.8667\n",
      "Epoch 94/499\n",
      "----------\n",
      "train Loss: 0.6837 Acc: 0.9667\n",
      "val Loss: 0.6547 Acc: 0.9667\n",
      "test Loss: 0.7048 Acc: 0.8667\n",
      "Epoch 95/499\n",
      "----------\n",
      "train Loss: 0.6775 Acc: 0.9556\n",
      "val Loss: 0.6490 Acc: 0.9667\n",
      "test Loss: 0.7056 Acc: 0.8667\n",
      "Epoch 96/499\n",
      "----------\n",
      "train Loss: 0.6722 Acc: 0.9556\n",
      "val Loss: 0.6511 Acc: 0.9333\n",
      "test Loss: 0.6906 Acc: 0.8667\n",
      "Epoch 97/499\n",
      "----------\n",
      "train Loss: 0.6644 Acc: 0.9667\n",
      "val Loss: 0.6648 Acc: 1.0000\n",
      "test Loss: 0.6793 Acc: 0.9333\n",
      "Epoch 98/499\n",
      "----------\n",
      "train Loss: 0.6669 Acc: 0.9778\n",
      "val Loss: 0.6380 Acc: 0.9667\n",
      "test Loss: 0.6924 Acc: 0.9667\n",
      "Epoch 99/499\n",
      "----------\n",
      "train Loss: 0.6674 Acc: 0.9333\n",
      "val Loss: 0.6399 Acc: 1.0000\n",
      "test Loss: 0.6817 Acc: 0.9333\n",
      "Epoch 100/499\n",
      "----------\n",
      "train Loss: 0.6576 Acc: 0.9778\n",
      "val Loss: 0.6315 Acc: 1.0000\n",
      "test Loss: 0.6745 Acc: 0.9000\n",
      "Epoch 101/499\n",
      "----------\n",
      "train Loss: 0.6592 Acc: 0.9778\n",
      "val Loss: 0.6247 Acc: 1.0000\n",
      "test Loss: 0.6839 Acc: 0.9000\n",
      "Epoch 102/499\n",
      "----------\n",
      "train Loss: 0.6544 Acc: 0.9667\n",
      "val Loss: 0.6154 Acc: 1.0000\n",
      "test Loss: 0.6811 Acc: 0.8667\n",
      "Epoch 103/499\n",
      "----------\n",
      "train Loss: 0.6576 Acc: 0.9556\n",
      "val Loss: 0.6267 Acc: 1.0000\n",
      "test Loss: 0.6927 Acc: 0.9000\n",
      "Epoch 104/499\n",
      "----------\n",
      "train Loss: 0.6531 Acc: 0.9556\n",
      "val Loss: 0.6200 Acc: 1.0000\n",
      "test Loss: 0.6839 Acc: 0.9333\n",
      "Epoch 105/499\n",
      "----------\n",
      "train Loss: 0.6421 Acc: 0.9667\n",
      "val Loss: 0.6206 Acc: 0.9667\n",
      "test Loss: 0.6792 Acc: 0.9000\n",
      "Epoch 106/499\n",
      "----------\n",
      "train Loss: 0.6393 Acc: 0.9667\n",
      "val Loss: 0.6215 Acc: 1.0000\n",
      "test Loss: 0.6722 Acc: 0.9667\n",
      "Epoch 107/499\n",
      "----------\n",
      "train Loss: 0.6311 Acc: 0.9778\n",
      "val Loss: 0.6048 Acc: 1.0000\n",
      "test Loss: 0.6670 Acc: 0.9333\n",
      "Epoch 108/499\n",
      "----------\n",
      "train Loss: 0.6332 Acc: 0.9778\n",
      "val Loss: 0.6086 Acc: 1.0000\n",
      "test Loss: 0.6706 Acc: 0.9000\n",
      "Epoch 109/499\n",
      "----------\n",
      "train Loss: 0.6339 Acc: 0.9889\n",
      "val Loss: 0.6166 Acc: 0.9667\n",
      "test Loss: 0.6600 Acc: 0.9333\n",
      "Epoch 110/499\n",
      "----------\n",
      "train Loss: 0.6242 Acc: 0.9778\n",
      "val Loss: 0.6073 Acc: 1.0000\n",
      "test Loss: 0.6711 Acc: 0.9333\n",
      "Epoch 111/499\n",
      "----------\n",
      "train Loss: 0.6216 Acc: 0.9778\n",
      "val Loss: 0.6089 Acc: 1.0000\n",
      "test Loss: 0.6529 Acc: 0.9333\n",
      "Epoch 112/499\n",
      "----------\n",
      "train Loss: 0.6359 Acc: 0.9667\n",
      "val Loss: 0.6161 Acc: 0.9667\n",
      "test Loss: 0.6513 Acc: 0.9000\n",
      "Epoch 113/499\n",
      "----------\n",
      "train Loss: 0.6226 Acc: 0.9667\n",
      "val Loss: 0.5933 Acc: 1.0000\n",
      "test Loss: 0.6397 Acc: 0.9667\n",
      "Epoch 114/499\n",
      "----------\n",
      "train Loss: 0.6168 Acc: 0.9889\n",
      "val Loss: 0.5936 Acc: 1.0000\n",
      "test Loss: 0.6664 Acc: 0.9000\n",
      "Epoch 115/499\n",
      "----------\n",
      "train Loss: 0.6127 Acc: 0.9778\n",
      "val Loss: 0.5883 Acc: 1.0000\n",
      "test Loss: 0.6440 Acc: 0.9667\n",
      "Epoch 116/499\n",
      "----------\n",
      "train Loss: 0.6191 Acc: 0.9778\n",
      "val Loss: 0.5948 Acc: 0.9667\n",
      "test Loss: 0.6783 Acc: 0.9000\n",
      "Epoch 117/499\n",
      "----------\n",
      "train Loss: 0.6174 Acc: 0.9556\n",
      "val Loss: 0.5877 Acc: 1.0000\n",
      "test Loss: 0.6485 Acc: 0.9333\n",
      "Epoch 118/499\n",
      "----------\n",
      "train Loss: 0.6136 Acc: 0.9778\n",
      "val Loss: 0.5962 Acc: 1.0000\n",
      "test Loss: 0.6512 Acc: 0.9000\n",
      "Epoch 119/499\n",
      "----------\n",
      "train Loss: 0.6172 Acc: 0.9778\n",
      "val Loss: 0.5859 Acc: 1.0000\n",
      "test Loss: 0.6350 Acc: 0.9333\n",
      "Epoch 120/499\n",
      "----------\n",
      "train Loss: 0.6120 Acc: 0.9667\n",
      "val Loss: 0.5877 Acc: 0.9667\n",
      "test Loss: 0.6597 Acc: 0.9000\n",
      "Epoch 121/499\n",
      "----------\n",
      "train Loss: 0.6135 Acc: 0.9667\n",
      "val Loss: 0.6171 Acc: 0.9333\n",
      "test Loss: 0.6474 Acc: 0.9667\n",
      "Epoch 122/499\n",
      "----------\n",
      "train Loss: 0.6097 Acc: 0.9889\n",
      "val Loss: 0.6017 Acc: 0.9667\n",
      "test Loss: 0.6495 Acc: 0.9667\n",
      "Epoch 123/499\n",
      "----------\n",
      "train Loss: 0.6140 Acc: 0.9778\n",
      "val Loss: 0.5781 Acc: 1.0000\n",
      "test Loss: 0.6344 Acc: 0.9667\n",
      "Epoch 124/499\n",
      "----------\n",
      "train Loss: 0.6049 Acc: 0.9889\n",
      "val Loss: 0.5743 Acc: 1.0000\n",
      "test Loss: 0.6386 Acc: 0.9333\n",
      "Epoch 125/499\n",
      "----------\n",
      "train Loss: 0.5979 Acc: 0.9778\n",
      "val Loss: 0.5903 Acc: 1.0000\n",
      "test Loss: 0.6516 Acc: 0.9667\n",
      "Epoch 126/499\n",
      "----------\n",
      "train Loss: 0.5999 Acc: 0.9778\n",
      "val Loss: 0.5857 Acc: 0.9667\n",
      "test Loss: 0.6353 Acc: 0.9667\n",
      "Epoch 127/499\n",
      "----------\n",
      "train Loss: 0.6056 Acc: 0.9556\n",
      "val Loss: 0.5775 Acc: 1.0000\n",
      "test Loss: 0.6385 Acc: 0.9667\n",
      "Epoch 128/499\n",
      "----------\n",
      "train Loss: 0.6014 Acc: 0.9889\n",
      "val Loss: 0.5853 Acc: 1.0000\n",
      "test Loss: 0.6546 Acc: 0.9333\n",
      "Epoch 129/499\n",
      "----------\n",
      "train Loss: 0.5998 Acc: 0.9889\n",
      "val Loss: 0.5808 Acc: 1.0000\n",
      "test Loss: 0.6463 Acc: 0.9333\n",
      "Epoch 130/499\n",
      "----------\n",
      "train Loss: 0.5971 Acc: 0.9778\n",
      "val Loss: 0.5732 Acc: 1.0000\n",
      "test Loss: 0.6484 Acc: 0.9000\n",
      "Epoch 131/499\n",
      "----------\n",
      "train Loss: 0.6041 Acc: 0.9889\n",
      "val Loss: 0.5733 Acc: 1.0000\n",
      "test Loss: 0.6436 Acc: 0.9333\n",
      "Epoch 132/499\n",
      "----------\n",
      "train Loss: 0.5966 Acc: 0.9778\n",
      "val Loss: 0.5868 Acc: 1.0000\n",
      "test Loss: 0.6403 Acc: 0.9333\n",
      "Epoch 133/499\n",
      "----------\n",
      "train Loss: 0.5925 Acc: 0.9889\n",
      "val Loss: 0.5752 Acc: 1.0000\n",
      "test Loss: 0.6284 Acc: 0.9667\n",
      "Epoch 134/499\n",
      "----------\n",
      "train Loss: 0.5990 Acc: 0.9889\n",
      "val Loss: 0.5723 Acc: 1.0000\n",
      "test Loss: 0.6333 Acc: 0.9333\n",
      "Epoch 135/499\n",
      "----------\n",
      "train Loss: 0.6100 Acc: 0.9667\n",
      "val Loss: 0.5700 Acc: 1.0000\n",
      "test Loss: 0.6495 Acc: 0.8667\n",
      "Epoch 136/499\n",
      "----------\n",
      "train Loss: 0.6009 Acc: 0.9778\n",
      "val Loss: 0.5728 Acc: 1.0000\n",
      "test Loss: 0.6429 Acc: 0.9333\n",
      "Epoch 137/499\n",
      "----------\n",
      "train Loss: 0.5916 Acc: 0.9778\n",
      "val Loss: 0.5703 Acc: 1.0000\n",
      "test Loss: 0.6244 Acc: 0.9333\n",
      "Epoch 138/499\n",
      "----------\n",
      "train Loss: 0.5839 Acc: 0.9889\n",
      "val Loss: 0.5767 Acc: 1.0000\n",
      "test Loss: 0.6249 Acc: 0.9333\n",
      "Epoch 139/499\n",
      "----------\n",
      "train Loss: 0.5915 Acc: 0.9889\n",
      "val Loss: 0.5689 Acc: 1.0000\n",
      "test Loss: 0.6432 Acc: 0.9000\n",
      "Epoch 140/499\n",
      "----------\n",
      "train Loss: 0.5887 Acc: 0.9889\n",
      "val Loss: 0.5663 Acc: 1.0000\n",
      "test Loss: 0.6219 Acc: 0.9667\n",
      "Epoch 141/499\n",
      "----------\n",
      "train Loss: 0.5944 Acc: 0.9778\n",
      "val Loss: 0.5703 Acc: 1.0000\n",
      "test Loss: 0.6326 Acc: 0.9333\n",
      "Epoch 142/499\n",
      "----------\n",
      "train Loss: 0.5932 Acc: 0.9667\n",
      "val Loss: 0.5689 Acc: 1.0000\n",
      "test Loss: 0.6450 Acc: 0.9333\n",
      "Epoch 143/499\n",
      "----------\n",
      "train Loss: 0.5829 Acc: 0.9889\n",
      "val Loss: 0.5640 Acc: 1.0000\n",
      "test Loss: 0.6318 Acc: 0.9667\n",
      "Epoch 144/499\n",
      "----------\n",
      "train Loss: 0.5856 Acc: 0.9889\n",
      "val Loss: 0.5699 Acc: 1.0000\n",
      "test Loss: 0.6272 Acc: 0.9667\n",
      "Epoch 145/499\n",
      "----------\n",
      "train Loss: 0.5882 Acc: 0.9778\n",
      "val Loss: 0.5807 Acc: 1.0000\n",
      "test Loss: 0.6218 Acc: 0.9667\n",
      "Epoch 146/499\n",
      "----------\n",
      "train Loss: 0.5913 Acc: 0.9778\n",
      "val Loss: 0.5729 Acc: 1.0000\n",
      "test Loss: 0.6170 Acc: 0.9667\n",
      "Epoch 147/499\n",
      "----------\n",
      "train Loss: 0.5807 Acc: 0.9889\n",
      "val Loss: 0.5643 Acc: 1.0000\n",
      "test Loss: 0.6303 Acc: 0.9333\n",
      "Epoch 148/499\n",
      "----------\n",
      "train Loss: 0.5859 Acc: 0.9778\n",
      "val Loss: 0.5653 Acc: 1.0000\n",
      "test Loss: 0.6298 Acc: 0.9667\n",
      "Epoch 149/499\n",
      "----------\n",
      "train Loss: 0.5854 Acc: 0.9889\n",
      "val Loss: 0.5669 Acc: 1.0000\n",
      "test Loss: 0.6136 Acc: 0.9667\n",
      "Epoch 150/499\n",
      "----------\n",
      "train Loss: 0.5870 Acc: 0.9778\n",
      "val Loss: 0.5598 Acc: 1.0000\n",
      "test Loss: 0.6311 Acc: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/499\n",
      "----------\n",
      "train Loss: 0.5849 Acc: 0.9778\n",
      "val Loss: 0.5737 Acc: 1.0000\n",
      "test Loss: 0.6148 Acc: 0.9667\n",
      "Epoch 152/499\n",
      "----------\n",
      "train Loss: 0.5867 Acc: 0.9889\n",
      "val Loss: 0.5674 Acc: 1.0000\n",
      "test Loss: 0.6267 Acc: 0.9333\n",
      "Epoch 153/499\n",
      "----------\n",
      "train Loss: 0.5758 Acc: 0.9889\n",
      "val Loss: 0.5656 Acc: 1.0000\n",
      "test Loss: 0.6193 Acc: 0.9667\n",
      "Epoch 154/499\n",
      "----------\n",
      "train Loss: 0.5856 Acc: 0.9889\n",
      "val Loss: 0.5697 Acc: 1.0000\n",
      "test Loss: 0.6183 Acc: 0.9333\n",
      "Epoch 155/499\n",
      "----------\n",
      "train Loss: 0.5838 Acc: 0.9889\n",
      "val Loss: 0.5670 Acc: 1.0000\n",
      "test Loss: 0.6230 Acc: 0.9667\n",
      "Epoch 156/499\n",
      "----------\n",
      "train Loss: 0.5844 Acc: 0.9889\n",
      "val Loss: 0.5827 Acc: 1.0000\n",
      "test Loss: 0.6165 Acc: 0.9667\n",
      "Epoch 157/499\n",
      "----------\n",
      "train Loss: 0.5793 Acc: 0.9889\n",
      "val Loss: 0.5626 Acc: 1.0000\n",
      "test Loss: 0.6180 Acc: 0.9667\n",
      "Epoch 158/499\n",
      "----------\n",
      "train Loss: 0.5797 Acc: 0.9889\n",
      "val Loss: 0.5633 Acc: 1.0000\n",
      "test Loss: 0.6211 Acc: 0.9667\n",
      "Epoch 159/499\n",
      "----------\n",
      "train Loss: 0.5925 Acc: 0.9667\n",
      "val Loss: 0.5671 Acc: 1.0000\n",
      "test Loss: 0.6208 Acc: 0.9667\n",
      "Epoch 160/499\n",
      "----------\n",
      "train Loss: 0.5754 Acc: 0.9889\n",
      "val Loss: 0.5630 Acc: 1.0000\n",
      "test Loss: 0.6181 Acc: 0.9667\n",
      "Epoch 161/499\n",
      "----------\n",
      "train Loss: 0.5843 Acc: 0.9889\n",
      "val Loss: 0.5650 Acc: 1.0000\n",
      "test Loss: 0.6254 Acc: 0.9667\n",
      "Epoch 162/499\n",
      "----------\n",
      "train Loss: 0.5804 Acc: 0.9889\n",
      "val Loss: 0.5627 Acc: 1.0000\n",
      "test Loss: 0.6200 Acc: 0.9667\n",
      "Epoch 163/499\n",
      "----------\n",
      "train Loss: 0.5832 Acc: 0.9889\n",
      "val Loss: 0.5643 Acc: 1.0000\n",
      "test Loss: 0.6143 Acc: 0.9667\n",
      "Epoch 164/499\n",
      "----------\n",
      "train Loss: 0.5875 Acc: 0.9778\n",
      "val Loss: 0.5591 Acc: 1.0000\n",
      "test Loss: 0.6379 Acc: 0.9333\n",
      "Epoch 165/499\n",
      "----------\n",
      "train Loss: 0.5799 Acc: 0.9889\n",
      "val Loss: 0.5625 Acc: 1.0000\n",
      "test Loss: 0.6089 Acc: 0.9667\n",
      "Epoch 166/499\n",
      "----------\n",
      "train Loss: 0.5815 Acc: 0.9889\n",
      "val Loss: 0.5598 Acc: 1.0000\n",
      "test Loss: 0.6234 Acc: 0.9333\n",
      "Epoch 167/499\n",
      "----------\n",
      "train Loss: 0.5734 Acc: 0.9889\n",
      "val Loss: 0.5614 Acc: 1.0000\n",
      "test Loss: 0.6175 Acc: 0.9000\n",
      "Epoch 168/499\n",
      "----------\n",
      "train Loss: 0.5804 Acc: 0.9889\n",
      "val Loss: 0.5623 Acc: 1.0000\n",
      "test Loss: 0.6307 Acc: 0.9333\n",
      "Epoch 169/499\n",
      "----------\n",
      "train Loss: 0.5744 Acc: 0.9889\n",
      "val Loss: 0.5666 Acc: 1.0000\n",
      "test Loss: 0.6328 Acc: 0.9333\n",
      "Epoch 170/499\n",
      "----------\n",
      "train Loss: 0.5795 Acc: 0.9889\n",
      "val Loss: 0.5632 Acc: 1.0000\n",
      "test Loss: 0.6148 Acc: 0.9667\n",
      "Epoch 171/499\n",
      "----------\n",
      "train Loss: 0.5724 Acc: 0.9889\n",
      "val Loss: 0.5621 Acc: 1.0000\n",
      "test Loss: 0.6183 Acc: 0.9333\n",
      "Epoch 172/499\n",
      "----------\n",
      "train Loss: 0.5798 Acc: 0.9889\n",
      "val Loss: 0.5673 Acc: 1.0000\n",
      "test Loss: 0.6179 Acc: 0.9333\n",
      "Epoch 173/499\n",
      "----------\n",
      "train Loss: 0.5767 Acc: 0.9889\n",
      "val Loss: 0.5589 Acc: 1.0000\n",
      "test Loss: 0.6167 Acc: 0.9667\n",
      "Epoch 174/499\n",
      "----------\n",
      "train Loss: 0.5843 Acc: 0.9889\n",
      "val Loss: 0.5603 Acc: 1.0000\n",
      "test Loss: 0.6394 Acc: 0.9333\n",
      "Epoch 175/499\n",
      "----------\n",
      "train Loss: 0.5828 Acc: 0.9778\n",
      "val Loss: 0.5626 Acc: 1.0000\n",
      "test Loss: 0.6411 Acc: 0.9000\n",
      "Epoch 176/499\n",
      "----------\n",
      "train Loss: 0.5830 Acc: 0.9667\n",
      "val Loss: 0.5587 Acc: 1.0000\n",
      "test Loss: 0.6237 Acc: 0.9667\n",
      "Epoch 177/499\n",
      "----------\n",
      "train Loss: 0.5830 Acc: 0.9778\n",
      "val Loss: 0.5590 Acc: 1.0000\n",
      "test Loss: 0.6194 Acc: 0.9333\n",
      "Epoch 178/499\n",
      "----------\n",
      "train Loss: 0.5801 Acc: 0.9778\n",
      "val Loss: 0.5593 Acc: 1.0000\n",
      "test Loss: 0.6058 Acc: 0.9667\n",
      "Epoch 179/499\n",
      "----------\n",
      "train Loss: 0.5745 Acc: 0.9889\n",
      "val Loss: 0.5584 Acc: 1.0000\n",
      "test Loss: 0.6242 Acc: 0.9333\n",
      "Epoch 180/499\n",
      "----------\n",
      "train Loss: 0.5757 Acc: 0.9889\n",
      "val Loss: 0.5585 Acc: 1.0000\n",
      "test Loss: 0.6272 Acc: 0.9333\n",
      "Epoch 181/499\n",
      "----------\n",
      "train Loss: 0.5805 Acc: 0.9778\n",
      "val Loss: 0.5574 Acc: 1.0000\n",
      "test Loss: 0.6178 Acc: 0.9667\n",
      "Epoch 182/499\n",
      "----------\n",
      "train Loss: 0.5800 Acc: 0.9889\n",
      "val Loss: 0.5578 Acc: 1.0000\n",
      "test Loss: 0.6186 Acc: 0.9667\n",
      "Epoch 183/499\n",
      "----------\n",
      "train Loss: 0.5751 Acc: 0.9889\n",
      "val Loss: 0.5603 Acc: 1.0000\n",
      "test Loss: 0.6253 Acc: 0.9333\n",
      "Epoch 184/499\n",
      "----------\n",
      "train Loss: 0.5707 Acc: 0.9889\n",
      "val Loss: 0.5601 Acc: 1.0000\n",
      "test Loss: 0.6258 Acc: 0.9333\n",
      "Epoch 185/499\n",
      "----------\n",
      "train Loss: 0.5737 Acc: 0.9889\n",
      "val Loss: 0.5618 Acc: 1.0000\n",
      "test Loss: 0.6316 Acc: 0.9333\n",
      "Epoch 186/499\n",
      "----------\n",
      "train Loss: 0.5778 Acc: 0.9889\n",
      "val Loss: 0.5600 Acc: 1.0000\n",
      "test Loss: 0.6211 Acc: 0.9667\n",
      "Epoch 187/499\n",
      "----------\n",
      "train Loss: 0.5703 Acc: 0.9889\n",
      "val Loss: 0.5567 Acc: 1.0000\n",
      "test Loss: 0.6194 Acc: 0.9667\n",
      "Epoch 188/499\n",
      "----------\n",
      "train Loss: 0.5840 Acc: 0.9667\n",
      "val Loss: 0.5566 Acc: 1.0000\n",
      "test Loss: 0.6192 Acc: 0.9667\n",
      "Epoch 189/499\n",
      "----------\n",
      "train Loss: 0.5746 Acc: 0.9889\n",
      "val Loss: 0.5663 Acc: 1.0000\n",
      "test Loss: 0.6073 Acc: 0.9667\n",
      "Epoch 190/499\n",
      "----------\n",
      "train Loss: 0.5768 Acc: 0.9889\n",
      "val Loss: 0.5641 Acc: 1.0000\n",
      "test Loss: 0.6411 Acc: 0.9333\n",
      "Epoch 191/499\n",
      "----------\n",
      "train Loss: 0.5784 Acc: 0.9778\n",
      "val Loss: 0.5592 Acc: 1.0000\n",
      "test Loss: 0.6138 Acc: 0.9333\n",
      "Epoch 192/499\n",
      "----------\n",
      "train Loss: 0.5719 Acc: 0.9889\n",
      "val Loss: 0.5773 Acc: 0.9667\n",
      "test Loss: 0.6174 Acc: 0.9667\n",
      "Epoch 193/499\n",
      "----------\n",
      "train Loss: 0.5707 Acc: 0.9889\n",
      "val Loss: 0.5573 Acc: 1.0000\n",
      "test Loss: 0.6111 Acc: 0.9667\n",
      "Epoch 194/499\n",
      "----------\n",
      "train Loss: 0.5738 Acc: 0.9889\n",
      "val Loss: 0.5708 Acc: 1.0000\n",
      "test Loss: 0.6239 Acc: 0.9000\n",
      "Epoch 195/499\n",
      "----------\n",
      "train Loss: 0.5781 Acc: 0.9889\n",
      "val Loss: 0.5578 Acc: 1.0000\n",
      "test Loss: 0.6277 Acc: 0.9333\n",
      "Epoch 196/499\n",
      "----------\n",
      "train Loss: 0.5760 Acc: 0.9778\n",
      "val Loss: 0.5601 Acc: 1.0000\n",
      "test Loss: 0.6038 Acc: 0.9667\n",
      "Epoch 197/499\n",
      "----------\n",
      "train Loss: 0.5740 Acc: 0.9889\n",
      "val Loss: 0.5789 Acc: 0.9667\n",
      "test Loss: 0.6149 Acc: 0.9333\n",
      "Epoch 198/499\n",
      "----------\n",
      "train Loss: 0.5878 Acc: 0.9667\n",
      "val Loss: 0.5746 Acc: 0.9667\n",
      "test Loss: 0.6051 Acc: 0.9667\n",
      "Epoch 199/499\n",
      "----------\n",
      "train Loss: 0.5818 Acc: 0.9889\n",
      "val Loss: 0.5557 Acc: 1.0000\n",
      "test Loss: 0.6150 Acc: 0.9667\n",
      "Epoch 200/499\n",
      "----------\n",
      "train Loss: 0.5749 Acc: 0.9778\n",
      "val Loss: 0.5559 Acc: 1.0000\n",
      "test Loss: 0.6511 Acc: 0.9000\n",
      "Epoch 201/499\n",
      "----------\n",
      "train Loss: 0.5782 Acc: 0.9889\n",
      "val Loss: 0.5735 Acc: 1.0000\n",
      "test Loss: 0.6133 Acc: 0.9667\n",
      "Epoch 202/499\n",
      "----------\n",
      "train Loss: 0.5748 Acc: 0.9778\n",
      "val Loss: 0.5580 Acc: 1.0000\n",
      "test Loss: 0.6423 Acc: 0.8667\n",
      "Epoch 203/499\n",
      "----------\n",
      "train Loss: 0.5808 Acc: 0.9778\n",
      "val Loss: 0.5577 Acc: 1.0000\n",
      "test Loss: 0.6127 Acc: 0.9667\n",
      "Epoch 204/499\n",
      "----------\n",
      "train Loss: 0.5819 Acc: 0.9778\n",
      "val Loss: 0.5582 Acc: 1.0000\n",
      "test Loss: 0.6252 Acc: 0.9667\n",
      "Epoch 205/499\n",
      "----------\n",
      "train Loss: 0.5729 Acc: 0.9889\n",
      "val Loss: 0.5604 Acc: 1.0000\n",
      "test Loss: 0.6176 Acc: 0.9333\n",
      "Epoch 206/499\n",
      "----------\n",
      "train Loss: 0.5760 Acc: 0.9778\n",
      "val Loss: 0.5575 Acc: 1.0000\n",
      "test Loss: 0.6234 Acc: 0.9333\n",
      "Epoch 207/499\n",
      "----------\n",
      "train Loss: 0.5749 Acc: 0.9889\n",
      "val Loss: 0.5579 Acc: 1.0000\n",
      "test Loss: 0.6069 Acc: 0.9667\n",
      "Epoch 208/499\n",
      "----------\n",
      "train Loss: 0.5845 Acc: 0.9667\n",
      "val Loss: 0.5643 Acc: 1.0000\n",
      "test Loss: 0.6110 Acc: 0.9333\n",
      "Epoch 209/499\n",
      "----------\n",
      "train Loss: 0.5717 Acc: 0.9889\n",
      "val Loss: 0.5590 Acc: 1.0000\n",
      "test Loss: 0.6229 Acc: 0.9333\n",
      "Epoch 210/499\n",
      "----------\n",
      "train Loss: 0.5732 Acc: 0.9889\n",
      "val Loss: 0.5746 Acc: 1.0000\n",
      "test Loss: 0.6159 Acc: 0.9667\n",
      "Epoch 211/499\n",
      "----------\n",
      "train Loss: 0.5720 Acc: 0.9889\n",
      "val Loss: 0.5714 Acc: 0.9667\n",
      "test Loss: 0.6200 Acc: 0.9333\n",
      "Epoch 212/499\n",
      "----------\n",
      "train Loss: 0.5739 Acc: 0.9889\n",
      "val Loss: 0.5564 Acc: 1.0000\n",
      "test Loss: 0.6111 Acc: 0.9667\n",
      "Epoch 213/499\n",
      "----------\n",
      "train Loss: 0.5720 Acc: 0.9889\n",
      "val Loss: 0.5665 Acc: 1.0000\n",
      "test Loss: 0.6192 Acc: 0.9333\n",
      "Epoch 214/499\n",
      "----------\n",
      "train Loss: 0.5733 Acc: 0.9778\n",
      "val Loss: 0.5606 Acc: 1.0000\n",
      "test Loss: 0.6178 Acc: 0.9000\n",
      "Epoch 215/499\n",
      "----------\n",
      "train Loss: 0.5741 Acc: 0.9778\n",
      "val Loss: 0.5552 Acc: 1.0000\n",
      "test Loss: 0.6216 Acc: 0.9333\n",
      "Epoch 216/499\n",
      "----------\n",
      "train Loss: 0.5690 Acc: 0.9889\n",
      "val Loss: 0.5563 Acc: 1.0000\n",
      "test Loss: 0.6420 Acc: 0.9000\n",
      "Epoch 217/499\n",
      "----------\n",
      "train Loss: 0.5671 Acc: 0.9889\n",
      "val Loss: 0.5557 Acc: 1.0000\n",
      "test Loss: 0.6306 Acc: 0.9000\n",
      "Epoch 218/499\n",
      "----------\n",
      "train Loss: 0.5686 Acc: 0.9889\n",
      "val Loss: 0.5565 Acc: 1.0000\n",
      "test Loss: 0.6129 Acc: 0.9667\n",
      "Epoch 219/499\n",
      "----------\n",
      "train Loss: 0.5797 Acc: 0.9889\n",
      "val Loss: 0.5685 Acc: 1.0000\n",
      "test Loss: 0.6125 Acc: 0.9667\n",
      "Epoch 220/499\n",
      "----------\n",
      "train Loss: 0.5705 Acc: 0.9778\n",
      "val Loss: 0.5559 Acc: 1.0000\n",
      "test Loss: 0.6272 Acc: 0.9667\n",
      "Epoch 221/499\n",
      "----------\n",
      "train Loss: 0.5681 Acc: 0.9889\n",
      "val Loss: 0.5605 Acc: 1.0000\n",
      "test Loss: 0.6336 Acc: 0.9333\n",
      "Epoch 222/499\n",
      "----------\n",
      "train Loss: 0.5721 Acc: 0.9889\n",
      "val Loss: 0.5550 Acc: 1.0000\n",
      "test Loss: 0.6052 Acc: 0.9667\n",
      "Epoch 223/499\n",
      "----------\n",
      "train Loss: 0.5721 Acc: 0.9778\n",
      "val Loss: 0.5597 Acc: 1.0000\n",
      "test Loss: 0.6096 Acc: 0.9667\n",
      "Epoch 224/499\n",
      "----------\n",
      "train Loss: 0.5705 Acc: 0.9889\n",
      "val Loss: 0.5596 Acc: 1.0000\n",
      "test Loss: 0.6204 Acc: 0.9333\n",
      "Epoch 225/499\n",
      "----------\n",
      "train Loss: 0.5742 Acc: 0.9778\n",
      "val Loss: 0.5560 Acc: 1.0000\n",
      "test Loss: 0.6127 Acc: 0.9667\n",
      "Epoch 226/499\n",
      "----------\n",
      "train Loss: 0.5669 Acc: 0.9889\n",
      "val Loss: 0.5577 Acc: 1.0000\n",
      "test Loss: 0.6157 Acc: 0.9667\n",
      "Epoch 227/499\n",
      "----------\n",
      "train Loss: 0.5725 Acc: 0.9889\n",
      "val Loss: 0.5557 Acc: 1.0000\n",
      "test Loss: 0.6088 Acc: 0.9667\n",
      "Epoch 228/499\n",
      "----------\n",
      "train Loss: 0.5737 Acc: 0.9889\n",
      "val Loss: 0.5558 Acc: 1.0000\n",
      "test Loss: 0.6157 Acc: 0.9333\n",
      "Epoch 229/499\n",
      "----------\n",
      "train Loss: 0.5773 Acc: 0.9778\n",
      "val Loss: 0.5569 Acc: 1.0000\n",
      "test Loss: 0.6287 Acc: 0.9333\n",
      "Epoch 230/499\n",
      "----------\n",
      "train Loss: 0.5760 Acc: 0.9778\n",
      "val Loss: 0.5581 Acc: 1.0000\n",
      "test Loss: 0.6229 Acc: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 231/499\n",
      "----------\n",
      "train Loss: 0.5781 Acc: 0.9778\n",
      "val Loss: 0.5576 Acc: 1.0000\n",
      "test Loss: 0.6459 Acc: 0.9000\n",
      "Epoch 232/499\n",
      "----------\n",
      "train Loss: 0.5684 Acc: 0.9889\n",
      "val Loss: 0.5563 Acc: 1.0000\n",
      "test Loss: 0.6281 Acc: 0.9000\n",
      "Epoch 233/499\n",
      "----------\n",
      "train Loss: 0.5688 Acc: 0.9889\n",
      "val Loss: 0.5558 Acc: 1.0000\n",
      "test Loss: 0.6124 Acc: 0.9333\n",
      "Epoch 234/499\n",
      "----------\n",
      "train Loss: 0.5722 Acc: 0.9889\n",
      "val Loss: 0.5584 Acc: 1.0000\n",
      "test Loss: 0.6081 Acc: 0.9333\n",
      "Epoch 235/499\n",
      "----------\n",
      "train Loss: 0.5697 Acc: 0.9889\n",
      "val Loss: 0.5553 Acc: 1.0000\n",
      "test Loss: 0.6188 Acc: 0.9333\n",
      "Epoch 236/499\n",
      "----------\n",
      "train Loss: 0.5676 Acc: 0.9889\n",
      "val Loss: 0.5566 Acc: 1.0000\n",
      "test Loss: 0.6157 Acc: 0.9333\n",
      "Epoch 237/499\n",
      "----------\n",
      "train Loss: 0.5683 Acc: 0.9889\n",
      "val Loss: 0.5758 Acc: 0.9667\n",
      "test Loss: 0.6157 Acc: 0.9333\n",
      "Epoch 238/499\n",
      "----------\n",
      "train Loss: 0.5767 Acc: 0.9778\n",
      "val Loss: 0.5573 Acc: 1.0000\n",
      "test Loss: 0.6385 Acc: 0.9000\n",
      "Epoch 239/499\n",
      "----------\n",
      "train Loss: 0.5734 Acc: 0.9889\n",
      "val Loss: 0.5558 Acc: 1.0000\n",
      "test Loss: 0.6223 Acc: 0.9333\n",
      "Epoch 240/499\n",
      "----------\n",
      "train Loss: 0.5738 Acc: 0.9889\n",
      "val Loss: 0.5543 Acc: 1.0000\n",
      "test Loss: 0.6090 Acc: 0.9333\n",
      "Epoch 241/499\n",
      "----------\n",
      "train Loss: 0.5717 Acc: 0.9889\n",
      "val Loss: 0.5570 Acc: 1.0000\n",
      "test Loss: 0.6011 Acc: 0.9667\n",
      "Epoch 242/499\n",
      "----------\n",
      "train Loss: 0.5719 Acc: 0.9778\n",
      "val Loss: 0.5557 Acc: 1.0000\n",
      "test Loss: 0.6088 Acc: 0.9333\n",
      "Epoch 243/499\n",
      "----------\n",
      "train Loss: 0.5704 Acc: 0.9889\n",
      "val Loss: 0.5540 Acc: 1.0000\n",
      "test Loss: 0.6215 Acc: 0.9000\n",
      "Epoch 244/499\n",
      "----------\n",
      "train Loss: 0.5679 Acc: 0.9889\n",
      "val Loss: 0.5556 Acc: 1.0000\n",
      "test Loss: 0.6106 Acc: 0.9667\n",
      "Epoch 245/499\n",
      "----------\n",
      "train Loss: 0.5682 Acc: 0.9889\n",
      "val Loss: 0.5561 Acc: 1.0000\n",
      "test Loss: 0.6158 Acc: 0.9333\n",
      "Epoch 246/499\n",
      "----------\n",
      "train Loss: 0.5736 Acc: 0.9778\n",
      "val Loss: 0.5547 Acc: 1.0000\n",
      "test Loss: 0.6210 Acc: 0.9000\n",
      "Epoch 247/499\n",
      "----------\n",
      "train Loss: 0.5700 Acc: 0.9889\n",
      "val Loss: 0.5582 Acc: 1.0000\n",
      "test Loss: 0.6095 Acc: 0.9667\n",
      "Epoch 248/499\n",
      "----------\n",
      "train Loss: 0.5779 Acc: 0.9778\n",
      "val Loss: 0.5540 Acc: 1.0000\n",
      "test Loss: 0.6213 Acc: 0.9333\n",
      "Epoch 249/499\n",
      "----------\n",
      "train Loss: 0.5724 Acc: 0.9889\n",
      "val Loss: 0.5588 Acc: 1.0000\n",
      "test Loss: 0.6495 Acc: 0.8667\n",
      "Epoch 250/499\n",
      "----------\n",
      "train Loss: 0.5690 Acc: 0.9889\n",
      "val Loss: 0.5583 Acc: 1.0000\n",
      "test Loss: 0.6221 Acc: 0.9333\n",
      "Epoch 251/499\n",
      "----------\n",
      "train Loss: 0.5693 Acc: 0.9889\n",
      "val Loss: 0.5539 Acc: 1.0000\n",
      "test Loss: 0.6084 Acc: 0.9333\n",
      "Epoch 252/499\n",
      "----------\n",
      "train Loss: 0.5680 Acc: 0.9889\n",
      "val Loss: 0.5535 Acc: 1.0000\n",
      "test Loss: 0.6075 Acc: 0.9667\n",
      "Epoch 253/499\n",
      "----------\n",
      "train Loss: 0.5723 Acc: 0.9778\n",
      "val Loss: 0.5554 Acc: 1.0000\n",
      "test Loss: 0.6023 Acc: 0.9333\n",
      "Epoch 254/499\n",
      "----------\n",
      "train Loss: 0.5676 Acc: 0.9889\n",
      "val Loss: 0.5543 Acc: 1.0000\n",
      "test Loss: 0.6120 Acc: 0.9333\n",
      "Epoch 255/499\n",
      "----------\n",
      "train Loss: 0.5691 Acc: 0.9889\n",
      "val Loss: 0.5544 Acc: 1.0000\n",
      "test Loss: 0.6202 Acc: 0.9333\n",
      "Epoch 256/499\n",
      "----------\n",
      "train Loss: 0.5705 Acc: 0.9889\n",
      "val Loss: 0.5540 Acc: 1.0000\n",
      "test Loss: 0.6428 Acc: 0.9000\n",
      "Epoch 257/499\n",
      "----------\n",
      "train Loss: 0.5703 Acc: 0.9889\n",
      "val Loss: 0.5759 Acc: 0.9667\n",
      "test Loss: 0.6187 Acc: 0.9333\n",
      "Epoch 258/499\n",
      "----------\n",
      "train Loss: 0.5671 Acc: 0.9889\n",
      "val Loss: 0.5654 Acc: 1.0000\n",
      "test Loss: 0.6136 Acc: 0.9333\n",
      "Epoch 259/499\n",
      "----------\n",
      "train Loss: 0.5649 Acc: 0.9889\n",
      "val Loss: 0.5542 Acc: 1.0000\n",
      "test Loss: 0.5984 Acc: 0.9667\n",
      "Epoch 260/499\n",
      "----------\n",
      "train Loss: 0.5699 Acc: 0.9889\n",
      "val Loss: 0.5553 Acc: 1.0000\n",
      "test Loss: 0.6183 Acc: 0.9667\n",
      "Epoch 261/499\n",
      "----------\n",
      "train Loss: 0.5706 Acc: 0.9778\n",
      "val Loss: 0.5595 Acc: 1.0000\n",
      "test Loss: 0.6265 Acc: 0.9333\n",
      "Epoch 262/499\n",
      "----------\n",
      "train Loss: 0.5660 Acc: 0.9889\n",
      "val Loss: 0.5540 Acc: 1.0000\n",
      "test Loss: 0.6205 Acc: 0.9333\n",
      "Epoch 263/499\n",
      "----------\n",
      "train Loss: 0.5689 Acc: 0.9778\n",
      "val Loss: 0.5544 Acc: 1.0000\n",
      "test Loss: 0.6184 Acc: 0.9333\n",
      "Epoch 264/499\n",
      "----------\n",
      "train Loss: 0.5766 Acc: 0.9667\n",
      "val Loss: 0.5546 Acc: 1.0000\n",
      "test Loss: 0.6141 Acc: 0.9333\n",
      "Epoch 265/499\n",
      "----------\n",
      "train Loss: 0.5670 Acc: 0.9889\n",
      "val Loss: 0.5536 Acc: 1.0000\n",
      "test Loss: 0.5992 Acc: 0.9667\n",
      "Epoch 266/499\n",
      "----------\n",
      "train Loss: 0.5674 Acc: 0.9889\n",
      "val Loss: 0.5552 Acc: 1.0000\n",
      "test Loss: 0.6244 Acc: 0.9333\n",
      "Epoch 267/499\n",
      "----------\n",
      "train Loss: 0.5667 Acc: 0.9889\n",
      "val Loss: 0.5539 Acc: 1.0000\n",
      "test Loss: 0.6091 Acc: 0.9333\n",
      "Epoch 268/499\n",
      "----------\n",
      "train Loss: 0.5694 Acc: 0.9889\n",
      "val Loss: 0.5531 Acc: 1.0000\n",
      "test Loss: 0.6067 Acc: 0.9333\n",
      "Epoch 269/499\n",
      "----------\n",
      "train Loss: 0.5698 Acc: 0.9889\n",
      "val Loss: 0.5535 Acc: 1.0000\n",
      "test Loss: 0.6172 Acc: 0.9333\n",
      "Epoch 270/499\n",
      "----------\n",
      "train Loss: 0.5684 Acc: 0.9889\n",
      "val Loss: 0.5536 Acc: 1.0000\n",
      "test Loss: 0.6126 Acc: 0.9333\n",
      "Epoch 271/499\n",
      "----------\n",
      "train Loss: 0.5803 Acc: 0.9889\n",
      "val Loss: 0.5543 Acc: 1.0000\n",
      "test Loss: 0.6069 Acc: 0.9333\n",
      "Epoch 272/499\n",
      "----------\n",
      "train Loss: 0.5650 Acc: 0.9889\n",
      "val Loss: 0.5529 Acc: 1.0000\n",
      "test Loss: 0.6108 Acc: 0.9333\n",
      "Epoch 273/499\n",
      "----------\n",
      "train Loss: 0.5664 Acc: 0.9889\n",
      "val Loss: 0.5561 Acc: 1.0000\n",
      "test Loss: 0.5983 Acc: 0.9667\n",
      "Epoch 274/499\n",
      "----------\n",
      "train Loss: 0.5698 Acc: 0.9889\n",
      "val Loss: 0.5534 Acc: 1.0000\n",
      "test Loss: 0.6117 Acc: 0.9333\n",
      "Epoch 275/499\n",
      "----------\n",
      "train Loss: 0.5680 Acc: 0.9889\n",
      "val Loss: 0.5539 Acc: 1.0000\n",
      "test Loss: 0.6160 Acc: 0.9333\n",
      "Epoch 276/499\n",
      "----------\n",
      "train Loss: 0.5621 Acc: 0.9889\n",
      "val Loss: 0.5529 Acc: 1.0000\n",
      "test Loss: 0.6090 Acc: 0.9333\n",
      "Epoch 277/499\n",
      "----------\n",
      "train Loss: 0.5651 Acc: 0.9889\n",
      "val Loss: 0.5537 Acc: 1.0000\n",
      "test Loss: 0.6112 Acc: 0.9333\n",
      "Epoch 278/499\n",
      "----------\n",
      "train Loss: 0.5672 Acc: 0.9889\n",
      "val Loss: 0.5523 Acc: 1.0000\n",
      "test Loss: 0.6008 Acc: 0.9667\n",
      "Epoch 279/499\n",
      "----------\n",
      "train Loss: 0.5715 Acc: 0.9889\n",
      "val Loss: 0.5528 Acc: 1.0000\n",
      "test Loss: 0.6167 Acc: 0.9333\n",
      "Epoch 280/499\n",
      "----------\n",
      "train Loss: 0.5692 Acc: 0.9889\n",
      "val Loss: 0.5528 Acc: 1.0000\n",
      "test Loss: 0.6169 Acc: 0.9333\n",
      "Epoch 281/499\n",
      "----------\n",
      "train Loss: 0.5642 Acc: 0.9889\n",
      "val Loss: 0.5538 Acc: 1.0000\n",
      "test Loss: 0.6127 Acc: 0.9333\n",
      "Epoch 282/499\n",
      "----------\n",
      "train Loss: 0.5628 Acc: 0.9889\n",
      "val Loss: 0.5527 Acc: 1.0000\n",
      "test Loss: 0.6406 Acc: 0.9000\n",
      "Epoch 283/499\n",
      "----------\n",
      "train Loss: 0.5653 Acc: 0.9889\n",
      "val Loss: 0.5570 Acc: 1.0000\n",
      "test Loss: 0.6268 Acc: 0.9333\n",
      "Epoch 284/499\n",
      "----------\n",
      "train Loss: 0.5686 Acc: 0.9889\n",
      "val Loss: 0.5528 Acc: 1.0000\n",
      "test Loss: 0.6035 Acc: 0.9667\n",
      "Epoch 285/499\n",
      "----------\n",
      "train Loss: 0.5667 Acc: 0.9889\n",
      "val Loss: 0.5548 Acc: 1.0000\n",
      "test Loss: 0.6066 Acc: 0.9333\n",
      "Epoch 286/499\n",
      "----------\n",
      "train Loss: 0.5641 Acc: 0.9889\n",
      "val Loss: 0.5529 Acc: 1.0000\n",
      "test Loss: 0.6379 Acc: 0.8667\n",
      "Epoch 287/499\n",
      "----------\n",
      "train Loss: 0.5709 Acc: 0.9889\n",
      "val Loss: 0.5528 Acc: 1.0000\n",
      "test Loss: 0.6371 Acc: 0.9333\n",
      "Epoch 288/499\n",
      "----------\n",
      "train Loss: 0.5658 Acc: 0.9889\n",
      "val Loss: 0.5563 Acc: 1.0000\n",
      "test Loss: 0.6220 Acc: 0.9333\n",
      "Epoch 289/499\n",
      "----------\n",
      "train Loss: 0.5641 Acc: 0.9889\n",
      "val Loss: 0.5534 Acc: 1.0000\n",
      "test Loss: 0.6090 Acc: 0.9333\n",
      "Epoch 290/499\n",
      "----------\n",
      "train Loss: 0.5641 Acc: 0.9889\n",
      "val Loss: 0.5524 Acc: 1.0000\n",
      "test Loss: 0.6098 Acc: 0.9333\n",
      "Epoch 291/499\n",
      "----------\n",
      "train Loss: 0.5709 Acc: 0.9778\n",
      "val Loss: 0.5535 Acc: 1.0000\n",
      "test Loss: 0.6067 Acc: 0.9333\n",
      "Epoch 292/499\n",
      "----------\n",
      "train Loss: 0.5685 Acc: 0.9778\n",
      "val Loss: 0.5545 Acc: 1.0000\n",
      "test Loss: 0.6073 Acc: 0.9667\n",
      "Epoch 293/499\n",
      "----------\n",
      "train Loss: 0.5636 Acc: 0.9889\n",
      "val Loss: 0.5526 Acc: 1.0000\n",
      "test Loss: 0.6111 Acc: 0.9333\n",
      "Epoch 294/499\n",
      "----------\n",
      "train Loss: 0.5629 Acc: 0.9889\n",
      "val Loss: 0.5539 Acc: 1.0000\n",
      "test Loss: 0.6210 Acc: 0.9333\n",
      "Epoch 295/499\n",
      "----------\n",
      "train Loss: 0.5644 Acc: 0.9889\n",
      "val Loss: 0.5529 Acc: 1.0000\n",
      "test Loss: 0.5917 Acc: 0.9667\n",
      "Epoch 296/499\n",
      "----------\n",
      "train Loss: 0.5698 Acc: 0.9778\n",
      "val Loss: 0.5538 Acc: 1.0000\n",
      "test Loss: 0.6097 Acc: 0.9333\n",
      "Epoch 297/499\n",
      "----------\n",
      "train Loss: 0.5740 Acc: 0.9778\n",
      "val Loss: 0.5532 Acc: 1.0000\n",
      "test Loss: 0.6235 Acc: 0.9333\n",
      "Epoch 298/499\n",
      "----------\n",
      "train Loss: 0.5627 Acc: 0.9889\n",
      "val Loss: 0.5525 Acc: 1.0000\n",
      "test Loss: 0.6171 Acc: 0.9333\n",
      "Epoch 299/499\n",
      "----------\n",
      "train Loss: 0.5637 Acc: 0.9889\n",
      "val Loss: 0.5582 Acc: 1.0000\n",
      "test Loss: 0.6172 Acc: 0.9000\n",
      "Epoch 300/499\n",
      "----------\n",
      "train Loss: 0.5655 Acc: 0.9778\n",
      "val Loss: 0.5522 Acc: 1.0000\n",
      "test Loss: 0.6133 Acc: 0.9333\n",
      "Epoch 301/499\n",
      "----------\n",
      "train Loss: 0.5651 Acc: 0.9889\n",
      "val Loss: 0.5526 Acc: 1.0000\n",
      "test Loss: 0.6141 Acc: 0.9333\n",
      "Epoch 302/499\n",
      "----------\n",
      "train Loss: 0.5653 Acc: 0.9889\n",
      "val Loss: 0.5530 Acc: 1.0000\n",
      "test Loss: 0.6246 Acc: 0.9333\n",
      "Epoch 303/499\n",
      "----------\n",
      "train Loss: 0.5679 Acc: 0.9889\n",
      "val Loss: 0.5583 Acc: 1.0000\n",
      "test Loss: 0.6121 Acc: 0.9667\n",
      "Epoch 304/499\n",
      "----------\n",
      "train Loss: 0.5649 Acc: 0.9889\n",
      "val Loss: 0.5525 Acc: 1.0000\n",
      "test Loss: 0.6199 Acc: 0.9333\n",
      "Epoch 305/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5652 Acc: 0.9889\n",
      "val Loss: 0.5525 Acc: 1.0000\n",
      "test Loss: 0.6106 Acc: 0.9333\n",
      "Epoch 306/499\n",
      "----------\n",
      "train Loss: 0.5668 Acc: 0.9778\n",
      "val Loss: 0.5536 Acc: 1.0000\n",
      "test Loss: 0.6215 Acc: 0.9333\n",
      "Epoch 307/499\n",
      "----------\n",
      "train Loss: 0.5617 Acc: 0.9889\n",
      "val Loss: 0.5551 Acc: 1.0000\n",
      "test Loss: 0.6198 Acc: 0.9333\n",
      "Epoch 308/499\n",
      "----------\n",
      "train Loss: 0.5726 Acc: 0.9889\n",
      "val Loss: 0.5525 Acc: 1.0000\n",
      "test Loss: 0.6081 Acc: 0.9667\n",
      "Epoch 309/499\n",
      "----------\n",
      "train Loss: 0.5647 Acc: 1.0000\n",
      "val Loss: 0.5522 Acc: 1.0000\n",
      "test Loss: 0.6272 Acc: 0.9000\n",
      "Epoch 310/499\n",
      "----------\n",
      "train Loss: 0.5628 Acc: 0.9889\n",
      "val Loss: 0.5531 Acc: 1.0000\n",
      "test Loss: 0.6173 Acc: 0.9333\n",
      "Epoch 311/499\n",
      "----------\n",
      "train Loss: 0.5616 Acc: 1.0000\n",
      "val Loss: 0.5533 Acc: 1.0000\n",
      "test Loss: 0.6123 Acc: 0.9333\n",
      "Epoch 312/499\n",
      "----------\n",
      "train Loss: 0.5676 Acc: 0.9889\n",
      "val Loss: 0.5529 Acc: 1.0000\n",
      "test Loss: 0.6126 Acc: 0.9333\n",
      "Epoch 313/499\n",
      "----------\n",
      "train Loss: 0.5605 Acc: 1.0000\n",
      "val Loss: 0.5547 Acc: 1.0000\n",
      "test Loss: 0.6141 Acc: 0.9333\n",
      "Epoch 314/499\n",
      "----------\n",
      "train Loss: 0.5656 Acc: 0.9889\n",
      "val Loss: 0.5526 Acc: 1.0000\n",
      "test Loss: 0.6242 Acc: 0.9333\n",
      "Epoch 315/499\n",
      "----------\n",
      "train Loss: 0.5615 Acc: 0.9889\n",
      "val Loss: 0.5542 Acc: 1.0000\n",
      "test Loss: 0.6122 Acc: 0.9333\n",
      "Epoch 316/499\n",
      "----------\n",
      "train Loss: 0.5603 Acc: 0.9889\n",
      "val Loss: 0.5601 Acc: 1.0000\n",
      "test Loss: 0.6209 Acc: 0.9333\n",
      "Epoch 317/499\n",
      "----------\n",
      "train Loss: 0.5641 Acc: 0.9889\n",
      "val Loss: 0.5521 Acc: 1.0000\n",
      "test Loss: 0.6182 Acc: 0.9333\n",
      "Epoch 318/499\n",
      "----------\n",
      "train Loss: 0.5629 Acc: 0.9778\n",
      "val Loss: 0.5596 Acc: 1.0000\n",
      "test Loss: 0.6270 Acc: 0.9333\n",
      "Epoch 319/499\n",
      "----------\n",
      "train Loss: 0.5621 Acc: 1.0000\n",
      "val Loss: 0.5532 Acc: 1.0000\n",
      "test Loss: 0.6320 Acc: 0.9333\n",
      "Epoch 320/499\n",
      "----------\n",
      "train Loss: 0.5608 Acc: 1.0000\n",
      "val Loss: 0.5628 Acc: 1.0000\n",
      "test Loss: 0.6233 Acc: 0.9000\n",
      "Epoch 321/499\n",
      "----------\n",
      "train Loss: 0.5622 Acc: 1.0000\n",
      "val Loss: 0.5525 Acc: 1.0000\n",
      "test Loss: 0.6510 Acc: 0.9000\n",
      "Epoch 322/499\n",
      "----------\n",
      "train Loss: 0.5631 Acc: 1.0000\n",
      "val Loss: 0.5523 Acc: 1.0000\n",
      "test Loss: 0.6141 Acc: 0.9333\n",
      "Epoch 323/499\n",
      "----------\n",
      "train Loss: 0.5639 Acc: 1.0000\n",
      "val Loss: 0.5531 Acc: 1.0000\n",
      "test Loss: 0.6348 Acc: 0.9000\n",
      "Epoch 324/499\n",
      "----------\n",
      "train Loss: 0.5609 Acc: 1.0000\n",
      "val Loss: 0.5524 Acc: 1.0000\n",
      "test Loss: 0.6168 Acc: 0.9333\n",
      "Epoch 325/499\n",
      "----------\n",
      "train Loss: 0.5660 Acc: 1.0000\n",
      "val Loss: 0.5529 Acc: 1.0000\n",
      "test Loss: 0.6170 Acc: 0.9333\n",
      "Epoch 326/499\n",
      "----------\n",
      "train Loss: 0.5687 Acc: 0.9889\n",
      "val Loss: 0.5533 Acc: 1.0000\n",
      "test Loss: 0.6173 Acc: 0.9333\n",
      "Epoch 327/499\n",
      "----------\n",
      "train Loss: 0.5673 Acc: 0.9889\n",
      "val Loss: 0.5529 Acc: 1.0000\n",
      "test Loss: 0.6387 Acc: 0.9000\n",
      "Epoch 328/499\n",
      "----------\n",
      "train Loss: 0.5646 Acc: 0.9889\n",
      "val Loss: 0.5527 Acc: 1.0000\n",
      "test Loss: 0.6408 Acc: 0.9000\n",
      "Epoch 329/499\n",
      "----------\n",
      "train Loss: 0.5740 Acc: 0.9889\n",
      "val Loss: 0.5528 Acc: 1.0000\n",
      "test Loss: 0.6187 Acc: 0.9333\n",
      "Epoch 330/499\n",
      "----------\n",
      "train Loss: 0.5708 Acc: 0.9889\n",
      "val Loss: 0.5522 Acc: 1.0000\n",
      "test Loss: 0.6057 Acc: 0.9667\n",
      "Epoch 331/499\n",
      "----------\n",
      "train Loss: 0.5619 Acc: 1.0000\n",
      "val Loss: 0.5537 Acc: 1.0000\n",
      "test Loss: 0.6280 Acc: 0.9333\n",
      "Epoch 332/499\n",
      "----------\n",
      "train Loss: 0.5597 Acc: 1.0000\n",
      "val Loss: 0.5522 Acc: 1.0000\n",
      "test Loss: 0.6164 Acc: 0.9333\n",
      "Epoch 333/499\n",
      "----------\n",
      "train Loss: 0.5667 Acc: 1.0000\n",
      "val Loss: 0.5534 Acc: 1.0000\n",
      "test Loss: 0.6379 Acc: 0.9000\n",
      "Epoch 334/499\n",
      "----------\n",
      "train Loss: 0.5652 Acc: 1.0000\n",
      "val Loss: 0.5536 Acc: 1.0000\n",
      "test Loss: 0.6188 Acc: 0.9333\n",
      "Epoch 335/499\n",
      "----------\n",
      "train Loss: 0.5606 Acc: 1.0000\n",
      "val Loss: 0.5523 Acc: 1.0000\n",
      "test Loss: 0.6080 Acc: 0.9333\n",
      "Epoch 336/499\n",
      "----------\n",
      "train Loss: 0.5627 Acc: 1.0000\n",
      "val Loss: 0.5532 Acc: 1.0000\n",
      "test Loss: 0.6301 Acc: 0.9333\n",
      "Epoch 337/499\n",
      "----------\n",
      "train Loss: 0.5681 Acc: 0.9778\n",
      "val Loss: 0.5529 Acc: 1.0000\n",
      "test Loss: 0.6266 Acc: 0.9000\n",
      "Epoch 338/499\n",
      "----------\n",
      "train Loss: 0.5677 Acc: 1.0000\n",
      "val Loss: 0.5527 Acc: 1.0000\n",
      "test Loss: 0.6265 Acc: 0.9000\n",
      "Epoch 339/499\n",
      "----------\n",
      "train Loss: 0.5659 Acc: 1.0000\n",
      "val Loss: 0.5524 Acc: 1.0000\n",
      "test Loss: 0.6003 Acc: 0.9667\n",
      "Epoch 340/499\n",
      "----------\n",
      "train Loss: 0.5629 Acc: 1.0000\n",
      "val Loss: 0.5529 Acc: 1.0000\n",
      "test Loss: 0.6239 Acc: 0.9333\n",
      "Epoch 341/499\n",
      "----------\n",
      "train Loss: 0.5595 Acc: 1.0000\n",
      "val Loss: 0.5530 Acc: 1.0000\n",
      "test Loss: 0.6165 Acc: 0.9333\n",
      "Epoch 342/499\n",
      "----------\n",
      "train Loss: 0.5577 Acc: 1.0000\n",
      "val Loss: 0.5525 Acc: 1.0000\n",
      "test Loss: 0.6181 Acc: 0.9000\n",
      "Epoch 343/499\n",
      "----------\n",
      "train Loss: 0.5608 Acc: 1.0000\n",
      "val Loss: 0.5523 Acc: 1.0000\n",
      "test Loss: 0.6293 Acc: 0.9333\n",
      "Epoch 344/499\n",
      "----------\n",
      "train Loss: 0.5625 Acc: 1.0000\n",
      "val Loss: 0.5531 Acc: 1.0000\n",
      "test Loss: 0.6104 Acc: 0.9667\n",
      "Epoch 345/499\n",
      "----------\n",
      "train Loss: 0.5606 Acc: 1.0000\n",
      "val Loss: 0.5532 Acc: 1.0000\n",
      "test Loss: 0.6167 Acc: 0.9333\n",
      "Epoch 346/499\n",
      "----------\n",
      "train Loss: 0.5700 Acc: 0.9889\n",
      "val Loss: 0.5540 Acc: 1.0000\n",
      "test Loss: 0.6201 Acc: 0.9333\n",
      "Epoch 347/499\n",
      "----------\n",
      "train Loss: 0.5647 Acc: 1.0000\n",
      "val Loss: 0.5530 Acc: 1.0000\n",
      "test Loss: 0.6057 Acc: 0.9667\n",
      "Epoch 348/499\n",
      "----------\n",
      "train Loss: 0.5603 Acc: 1.0000\n",
      "val Loss: 0.5518 Acc: 1.0000\n",
      "test Loss: 0.6235 Acc: 0.9333\n",
      "Epoch 349/499\n",
      "----------\n",
      "train Loss: 0.5625 Acc: 0.9889\n",
      "val Loss: 0.5525 Acc: 1.0000\n",
      "test Loss: 0.6316 Acc: 0.9333\n",
      "Epoch 350/499\n",
      "----------\n",
      "train Loss: 0.5649 Acc: 0.9889\n",
      "val Loss: 0.5519 Acc: 1.0000\n",
      "test Loss: 0.6253 Acc: 0.9333\n",
      "Epoch 351/499\n",
      "----------\n",
      "train Loss: 0.5627 Acc: 0.9889\n",
      "val Loss: 0.5528 Acc: 1.0000\n",
      "test Loss: 0.6356 Acc: 0.9333\n",
      "Epoch 352/499\n",
      "----------\n",
      "train Loss: 0.5628 Acc: 0.9889\n",
      "val Loss: 0.5518 Acc: 1.0000\n",
      "test Loss: 0.6157 Acc: 0.9333\n",
      "Epoch 353/499\n",
      "----------\n",
      "train Loss: 0.5620 Acc: 1.0000\n",
      "val Loss: 0.5635 Acc: 1.0000\n",
      "test Loss: 0.6164 Acc: 0.9333\n",
      "Epoch 354/499\n",
      "----------\n",
      "train Loss: 0.5645 Acc: 0.9889\n",
      "val Loss: 0.5522 Acc: 1.0000\n",
      "test Loss: 0.6256 Acc: 0.9333\n",
      "Epoch 355/499\n",
      "----------\n",
      "train Loss: 0.5573 Acc: 1.0000\n",
      "val Loss: 0.5563 Acc: 1.0000\n",
      "test Loss: 0.6183 Acc: 0.9333\n",
      "Epoch 356/499\n",
      "----------\n",
      "train Loss: 0.5605 Acc: 1.0000\n",
      "val Loss: 0.5522 Acc: 1.0000\n",
      "test Loss: 0.6053 Acc: 0.9667\n",
      "Epoch 357/499\n",
      "----------\n",
      "train Loss: 0.5585 Acc: 1.0000\n",
      "val Loss: 0.5521 Acc: 1.0000\n",
      "test Loss: 0.6197 Acc: 0.9333\n",
      "Epoch 358/499\n",
      "----------\n",
      "train Loss: 0.5586 Acc: 1.0000\n",
      "val Loss: 0.5524 Acc: 1.0000\n",
      "test Loss: 0.6283 Acc: 0.9000\n",
      "Epoch 359/499\n",
      "----------\n",
      "train Loss: 0.5696 Acc: 0.9889\n",
      "val Loss: 0.5526 Acc: 1.0000\n",
      "test Loss: 0.6244 Acc: 0.9000\n",
      "Epoch 360/499\n",
      "----------\n",
      "train Loss: 0.5612 Acc: 1.0000\n",
      "val Loss: 0.5529 Acc: 1.0000\n",
      "test Loss: 0.6261 Acc: 0.9333\n",
      "Epoch 361/499\n",
      "----------\n",
      "train Loss: 0.5596 Acc: 1.0000\n",
      "val Loss: 0.5534 Acc: 1.0000\n",
      "test Loss: 0.5982 Acc: 0.9667\n",
      "Epoch 362/499\n",
      "----------\n",
      "train Loss: 0.5571 Acc: 1.0000\n",
      "val Loss: 0.5539 Acc: 1.0000\n",
      "test Loss: 0.6175 Acc: 0.9333\n",
      "Epoch 363/499\n",
      "----------\n",
      "train Loss: 0.5609 Acc: 0.9889\n",
      "val Loss: 0.5523 Acc: 1.0000\n",
      "test Loss: 0.6194 Acc: 0.9333\n",
      "Epoch 364/499\n",
      "----------\n",
      "train Loss: 0.5589 Acc: 1.0000\n",
      "val Loss: 0.5525 Acc: 1.0000\n",
      "test Loss: 0.6304 Acc: 0.9333\n",
      "Epoch 365/499\n",
      "----------\n",
      "train Loss: 0.5605 Acc: 1.0000\n",
      "val Loss: 0.5535 Acc: 1.0000\n",
      "test Loss: 0.6271 Acc: 0.9333\n",
      "Epoch 366/499\n",
      "----------\n",
      "train Loss: 0.5618 Acc: 0.9889\n",
      "val Loss: 0.5530 Acc: 1.0000\n",
      "test Loss: 0.6139 Acc: 0.9333\n",
      "Epoch 367/499\n",
      "----------\n",
      "train Loss: 0.5656 Acc: 0.9889\n",
      "val Loss: 0.5524 Acc: 1.0000\n",
      "test Loss: 0.6179 Acc: 0.9333\n",
      "Epoch 368/499\n",
      "----------\n",
      "train Loss: 0.5682 Acc: 0.9778\n",
      "val Loss: 0.5534 Acc: 1.0000\n",
      "test Loss: 0.6241 Acc: 0.9333\n",
      "Epoch 369/499\n",
      "----------\n",
      "train Loss: 0.5656 Acc: 1.0000\n",
      "val Loss: 0.5535 Acc: 1.0000\n",
      "test Loss: 0.6238 Acc: 0.9333\n",
      "Epoch 370/499\n",
      "----------\n",
      "train Loss: 0.5612 Acc: 1.0000\n",
      "val Loss: 0.5524 Acc: 1.0000\n",
      "test Loss: 0.6232 Acc: 0.9333\n",
      "Epoch 371/499\n",
      "----------\n",
      "train Loss: 0.5586 Acc: 1.0000\n",
      "val Loss: 0.5522 Acc: 1.0000\n",
      "test Loss: 0.6219 Acc: 0.9333\n",
      "Epoch 372/499\n",
      "----------\n",
      "train Loss: 0.5695 Acc: 1.0000\n",
      "val Loss: 0.5520 Acc: 1.0000\n",
      "test Loss: 0.6193 Acc: 0.9333\n",
      "Epoch 373/499\n",
      "----------\n",
      "train Loss: 0.5633 Acc: 1.0000\n",
      "val Loss: 0.5542 Acc: 1.0000\n",
      "test Loss: 0.6228 Acc: 0.9333\n",
      "Epoch 374/499\n",
      "----------\n",
      "train Loss: 0.5648 Acc: 0.9889\n",
      "val Loss: 0.5520 Acc: 1.0000\n",
      "test Loss: 0.6145 Acc: 0.9333\n",
      "Epoch 375/499\n",
      "----------\n",
      "train Loss: 0.5576 Acc: 1.0000\n",
      "val Loss: 0.5540 Acc: 1.0000\n",
      "test Loss: 0.6253 Acc: 0.9333\n",
      "Epoch 376/499\n",
      "----------\n",
      "train Loss: 0.5599 Acc: 1.0000\n",
      "val Loss: 0.5532 Acc: 1.0000\n",
      "test Loss: 0.6134 Acc: 0.9333\n",
      "Epoch 377/499\n",
      "----------\n",
      "train Loss: 0.5600 Acc: 1.0000\n",
      "val Loss: 0.5530 Acc: 1.0000\n",
      "test Loss: 0.6209 Acc: 0.9333\n",
      "Epoch 378/499\n",
      "----------\n",
      "train Loss: 0.5622 Acc: 1.0000\n",
      "val Loss: 0.5593 Acc: 1.0000\n",
      "test Loss: 0.6002 Acc: 0.9667\n",
      "Epoch 379/499\n",
      "----------\n",
      "train Loss: 0.5568 Acc: 1.0000\n",
      "val Loss: 0.5527 Acc: 1.0000\n",
      "test Loss: 0.6228 Acc: 0.9333\n",
      "Epoch 380/499\n",
      "----------\n",
      "train Loss: 0.5662 Acc: 0.9889\n",
      "val Loss: 0.5529 Acc: 1.0000\n",
      "test Loss: 0.6213 Acc: 0.9333\n",
      "Epoch 381/499\n",
      "----------\n",
      "train Loss: 0.5608 Acc: 1.0000\n",
      "val Loss: 0.5620 Acc: 1.0000\n",
      "test Loss: 0.6333 Acc: 0.9000\n",
      "Epoch 382/499\n",
      "----------\n",
      "train Loss: 0.5566 Acc: 1.0000\n",
      "val Loss: 0.5529 Acc: 1.0000\n",
      "test Loss: 0.6218 Acc: 0.9333\n",
      "Epoch 383/499\n",
      "----------\n",
      "train Loss: 0.5629 Acc: 0.9889\n",
      "val Loss: 0.5532 Acc: 1.0000\n",
      "test Loss: 0.6334 Acc: 0.9333\n",
      "Epoch 384/499\n",
      "----------\n",
      "train Loss: 0.5604 Acc: 1.0000\n",
      "val Loss: 0.5527 Acc: 1.0000\n",
      "test Loss: 0.6281 Acc: 0.9000\n",
      "Epoch 385/499\n",
      "----------\n",
      "train Loss: 0.5635 Acc: 0.9889\n",
      "val Loss: 0.5530 Acc: 1.0000\n",
      "test Loss: 0.6168 Acc: 0.9333\n",
      "Epoch 386/499\n",
      "----------\n",
      "train Loss: 0.5596 Acc: 1.0000\n",
      "val Loss: 0.5522 Acc: 1.0000\n",
      "test Loss: 0.6245 Acc: 0.9333\n",
      "Epoch 387/499\n",
      "----------\n",
      "train Loss: 0.5602 Acc: 1.0000\n",
      "val Loss: 0.5531 Acc: 1.0000\n",
      "test Loss: 0.6007 Acc: 0.9667\n",
      "Epoch 388/499\n",
      "----------\n",
      "train Loss: 0.5571 Acc: 1.0000\n",
      "val Loss: 0.5522 Acc: 1.0000\n",
      "test Loss: 0.6292 Acc: 0.9000\n",
      "Epoch 389/499\n",
      "----------\n",
      "train Loss: 0.5595 Acc: 1.0000\n",
      "val Loss: 0.5533 Acc: 1.0000\n",
      "test Loss: 0.6265 Acc: 0.9333\n",
      "Epoch 390/499\n",
      "----------\n",
      "train Loss: 0.5581 Acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.5523 Acc: 1.0000\n",
      "test Loss: 0.6401 Acc: 0.9000\n",
      "Epoch 391/499\n",
      "----------\n",
      "train Loss: 0.5572 Acc: 1.0000\n",
      "val Loss: 0.5520 Acc: 1.0000\n",
      "test Loss: 0.6386 Acc: 0.9000\n",
      "Epoch 392/499\n",
      "----------\n",
      "train Loss: 0.5583 Acc: 1.0000\n",
      "val Loss: 0.5521 Acc: 1.0000\n",
      "test Loss: 0.6227 Acc: 0.9333\n",
      "Epoch 393/499\n",
      "----------\n",
      "train Loss: 0.5619 Acc: 1.0000\n",
      "val Loss: 0.5518 Acc: 1.0000\n",
      "test Loss: 0.6270 Acc: 0.9333\n",
      "Epoch 394/499\n",
      "----------\n",
      "train Loss: 0.5619 Acc: 1.0000\n",
      "val Loss: 0.5517 Acc: 1.0000\n",
      "test Loss: 0.6241 Acc: 0.9333\n",
      "Epoch 395/499\n",
      "----------\n",
      "train Loss: 0.5644 Acc: 0.9889\n",
      "val Loss: 0.5524 Acc: 1.0000\n",
      "test Loss: 0.6320 Acc: 0.9333\n",
      "Epoch 396/499\n",
      "----------\n",
      "train Loss: 0.5555 Acc: 1.0000\n",
      "val Loss: 0.5521 Acc: 1.0000\n",
      "test Loss: 0.6190 Acc: 0.9000\n",
      "Epoch 397/499\n",
      "----------\n",
      "train Loss: 0.5604 Acc: 1.0000\n",
      "val Loss: 0.5519 Acc: 1.0000\n",
      "test Loss: 0.6434 Acc: 0.9000\n",
      "Epoch 398/499\n",
      "----------\n",
      "train Loss: 0.5582 Acc: 1.0000\n",
      "val Loss: 0.5530 Acc: 1.0000\n",
      "test Loss: 0.6218 Acc: 0.9333\n",
      "Epoch 399/499\n",
      "----------\n",
      "train Loss: 0.5595 Acc: 1.0000\n",
      "val Loss: 0.5527 Acc: 1.0000\n",
      "test Loss: 0.6258 Acc: 0.9333\n",
      "Epoch 400/499\n",
      "----------\n",
      "train Loss: 0.5579 Acc: 1.0000\n",
      "val Loss: 0.5670 Acc: 1.0000\n",
      "test Loss: 0.6272 Acc: 0.9333\n",
      "Epoch 401/499\n",
      "----------\n",
      "train Loss: 0.5637 Acc: 0.9889\n",
      "val Loss: 0.5532 Acc: 1.0000\n",
      "test Loss: 0.6250 Acc: 0.9333\n",
      "Epoch 402/499\n",
      "----------\n",
      "train Loss: 0.5611 Acc: 1.0000\n",
      "val Loss: 0.5578 Acc: 1.0000\n",
      "test Loss: 0.6256 Acc: 0.9333\n",
      "Epoch 403/499\n",
      "----------\n",
      "train Loss: 0.5610 Acc: 1.0000\n",
      "val Loss: 0.5518 Acc: 1.0000\n",
      "test Loss: 0.6318 Acc: 0.9333\n",
      "Epoch 404/499\n",
      "----------\n",
      "train Loss: 0.5587 Acc: 1.0000\n",
      "val Loss: 0.5522 Acc: 1.0000\n",
      "test Loss: 0.6258 Acc: 0.9333\n",
      "Epoch 405/499\n",
      "----------\n",
      "train Loss: 0.5584 Acc: 1.0000\n",
      "val Loss: 0.5542 Acc: 1.0000\n",
      "test Loss: 0.6305 Acc: 0.9000\n",
      "Epoch 406/499\n",
      "----------\n",
      "train Loss: 0.5597 Acc: 1.0000\n",
      "val Loss: 0.5528 Acc: 1.0000\n",
      "test Loss: 0.6230 Acc: 0.9333\n",
      "Epoch 407/499\n",
      "----------\n",
      "train Loss: 0.5582 Acc: 1.0000\n",
      "val Loss: 0.5535 Acc: 1.0000\n",
      "test Loss: 0.6297 Acc: 0.9000\n",
      "Epoch 408/499\n",
      "----------\n",
      "train Loss: 0.5589 Acc: 1.0000\n",
      "val Loss: 0.5528 Acc: 1.0000\n",
      "test Loss: 0.6313 Acc: 0.9000\n",
      "Epoch 409/499\n",
      "----------\n",
      "train Loss: 0.5569 Acc: 1.0000\n",
      "val Loss: 0.5529 Acc: 1.0000\n",
      "test Loss: 0.6201 Acc: 0.9333\n",
      "Epoch 410/499\n",
      "----------\n",
      "train Loss: 0.5633 Acc: 1.0000\n",
      "val Loss: 0.5527 Acc: 1.0000\n",
      "test Loss: 0.6163 Acc: 0.9333\n",
      "Epoch 411/499\n",
      "----------\n",
      "train Loss: 0.5575 Acc: 1.0000\n",
      "val Loss: 0.5519 Acc: 1.0000\n",
      "test Loss: 0.6412 Acc: 0.9000\n",
      "Epoch 412/499\n",
      "----------\n",
      "train Loss: 0.5650 Acc: 0.9889\n",
      "val Loss: 0.5518 Acc: 1.0000\n",
      "test Loss: 0.6247 Acc: 0.9333\n",
      "Epoch 413/499\n",
      "----------\n",
      "train Loss: 0.5568 Acc: 1.0000\n",
      "val Loss: 0.5530 Acc: 1.0000\n",
      "test Loss: 0.6230 Acc: 0.9333\n",
      "Epoch 414/499\n",
      "----------\n",
      "train Loss: 0.5595 Acc: 1.0000\n",
      "val Loss: 0.5527 Acc: 1.0000\n",
      "test Loss: 0.6331 Acc: 0.9000\n",
      "Epoch 415/499\n",
      "----------\n",
      "train Loss: 0.5574 Acc: 1.0000\n",
      "val Loss: 0.5517 Acc: 1.0000\n",
      "test Loss: 0.6219 Acc: 0.9333\n",
      "Epoch 416/499\n",
      "----------\n",
      "train Loss: 0.5592 Acc: 1.0000\n",
      "val Loss: 0.5525 Acc: 1.0000\n",
      "test Loss: 0.6235 Acc: 0.9333\n",
      "Epoch 417/499\n",
      "----------\n",
      "train Loss: 0.5569 Acc: 1.0000\n",
      "val Loss: 0.5531 Acc: 1.0000\n",
      "test Loss: 0.6251 Acc: 0.9333\n",
      "Epoch 418/499\n",
      "----------\n",
      "train Loss: 0.5582 Acc: 1.0000\n",
      "val Loss: 0.5520 Acc: 1.0000\n",
      "test Loss: 0.6251 Acc: 0.9333\n",
      "Epoch 419/499\n",
      "----------\n",
      "train Loss: 0.5588 Acc: 1.0000\n",
      "val Loss: 0.5566 Acc: 1.0000\n",
      "test Loss: 0.6311 Acc: 0.9333\n",
      "Epoch 420/499\n",
      "----------\n",
      "train Loss: 0.5620 Acc: 1.0000\n",
      "val Loss: 0.5519 Acc: 1.0000\n",
      "test Loss: 0.6247 Acc: 0.9333\n",
      "Epoch 421/499\n",
      "----------\n",
      "train Loss: 0.5576 Acc: 1.0000\n",
      "val Loss: 0.5521 Acc: 1.0000\n",
      "test Loss: 0.6380 Acc: 0.9000\n",
      "Epoch 422/499\n",
      "----------\n",
      "train Loss: 0.5585 Acc: 1.0000\n",
      "val Loss: 0.5520 Acc: 1.0000\n",
      "test Loss: 0.6315 Acc: 0.9000\n",
      "Epoch 423/499\n",
      "----------\n",
      "train Loss: 0.5660 Acc: 0.9889\n",
      "val Loss: 0.5569 Acc: 1.0000\n",
      "test Loss: 0.6236 Acc: 0.9333\n",
      "Epoch 424/499\n",
      "----------\n",
      "train Loss: 0.5560 Acc: 1.0000\n",
      "val Loss: 0.5720 Acc: 0.9667\n",
      "test Loss: 0.6233 Acc: 0.9333\n",
      "Epoch 425/499\n",
      "----------\n",
      "train Loss: 0.5554 Acc: 1.0000\n",
      "val Loss: 0.5516 Acc: 1.0000\n",
      "test Loss: 0.6242 Acc: 0.9333\n",
      "Epoch 426/499\n",
      "----------\n",
      "train Loss: 0.5575 Acc: 1.0000\n",
      "val Loss: 0.5520 Acc: 1.0000\n",
      "test Loss: 0.6253 Acc: 0.9333\n",
      "Epoch 427/499\n",
      "----------\n",
      "train Loss: 0.5586 Acc: 1.0000\n",
      "val Loss: 0.5521 Acc: 1.0000\n",
      "test Loss: 0.6317 Acc: 0.9000\n",
      "Epoch 428/499\n",
      "----------\n",
      "train Loss: 0.5564 Acc: 1.0000\n",
      "val Loss: 0.5582 Acc: 1.0000\n",
      "test Loss: 0.6269 Acc: 0.9333\n",
      "Epoch 429/499\n",
      "----------\n",
      "train Loss: 0.5618 Acc: 1.0000\n",
      "val Loss: 0.5516 Acc: 1.0000\n",
      "test Loss: 0.6178 Acc: 0.9333\n",
      "Epoch 430/499\n",
      "----------\n",
      "train Loss: 0.5594 Acc: 1.0000\n",
      "val Loss: 0.5518 Acc: 1.0000\n",
      "test Loss: 0.6078 Acc: 0.9333\n",
      "Epoch 431/499\n",
      "----------\n",
      "train Loss: 0.5580 Acc: 1.0000\n",
      "val Loss: 0.5520 Acc: 1.0000\n",
      "test Loss: 0.6385 Acc: 0.9000\n",
      "Epoch 432/499\n",
      "----------\n",
      "train Loss: 0.5573 Acc: 1.0000\n",
      "val Loss: 0.5516 Acc: 1.0000\n",
      "test Loss: 0.6236 Acc: 0.9333\n",
      "Epoch 433/499\n",
      "----------\n",
      "train Loss: 0.5599 Acc: 1.0000\n",
      "val Loss: 0.5520 Acc: 1.0000\n",
      "test Loss: 0.6243 Acc: 0.9333\n",
      "Epoch 434/499\n",
      "----------\n",
      "train Loss: 0.5576 Acc: 1.0000\n",
      "val Loss: 0.5529 Acc: 1.0000\n",
      "test Loss: 0.6161 Acc: 0.9333\n",
      "Epoch 435/499\n",
      "----------\n",
      "train Loss: 0.5614 Acc: 1.0000\n",
      "val Loss: 0.5567 Acc: 1.0000\n",
      "test Loss: 0.6216 Acc: 0.9333\n",
      "Epoch 436/499\n",
      "----------\n",
      "train Loss: 0.5644 Acc: 0.9889\n",
      "val Loss: 0.5671 Acc: 1.0000\n",
      "test Loss: 0.6267 Acc: 0.9333\n",
      "Epoch 437/499\n",
      "----------\n",
      "train Loss: 0.5596 Acc: 1.0000\n",
      "val Loss: 0.5520 Acc: 1.0000\n",
      "test Loss: 0.6253 Acc: 0.9333\n",
      "Epoch 438/499\n",
      "----------\n",
      "train Loss: 0.5584 Acc: 1.0000\n",
      "val Loss: 0.5529 Acc: 1.0000\n",
      "test Loss: 0.6334 Acc: 0.9000\n",
      "Epoch 439/499\n",
      "----------\n",
      "train Loss: 0.5615 Acc: 1.0000\n",
      "val Loss: 0.5525 Acc: 1.0000\n",
      "test Loss: 0.6240 Acc: 0.9333\n",
      "Epoch 440/499\n",
      "----------\n",
      "train Loss: 0.5557 Acc: 1.0000\n",
      "val Loss: 0.5520 Acc: 1.0000\n",
      "test Loss: 0.6221 Acc: 0.9333\n",
      "Epoch 441/499\n",
      "----------\n",
      "train Loss: 0.5582 Acc: 1.0000\n",
      "val Loss: 0.5520 Acc: 1.0000\n",
      "test Loss: 0.6213 Acc: 0.9333\n",
      "Epoch 442/499\n",
      "----------\n",
      "train Loss: 0.5586 Acc: 1.0000\n",
      "val Loss: 0.5520 Acc: 1.0000\n",
      "test Loss: 0.6314 Acc: 0.9000\n",
      "Epoch 443/499\n",
      "----------\n",
      "train Loss: 0.5560 Acc: 1.0000\n",
      "val Loss: 0.5574 Acc: 1.0000\n",
      "test Loss: 0.6371 Acc: 0.9000\n",
      "Epoch 444/499\n",
      "----------\n",
      "train Loss: 0.5575 Acc: 1.0000\n",
      "val Loss: 0.5529 Acc: 1.0000\n",
      "test Loss: 0.6247 Acc: 0.9333\n",
      "Epoch 445/499\n",
      "----------\n",
      "train Loss: 0.5671 Acc: 0.9889\n",
      "val Loss: 0.5518 Acc: 1.0000\n",
      "test Loss: 0.6257 Acc: 0.9333\n",
      "Epoch 446/499\n",
      "----------\n",
      "train Loss: 0.5606 Acc: 0.9889\n",
      "val Loss: 0.5521 Acc: 1.0000\n",
      "test Loss: 0.6252 Acc: 0.9333\n",
      "Epoch 447/499\n",
      "----------\n",
      "train Loss: 0.5640 Acc: 0.9889\n",
      "val Loss: 0.5525 Acc: 1.0000\n",
      "test Loss: 0.6218 Acc: 0.9333\n",
      "Epoch 448/499\n",
      "----------\n",
      "train Loss: 0.5569 Acc: 1.0000\n",
      "val Loss: 0.5522 Acc: 1.0000\n",
      "test Loss: 0.6308 Acc: 0.9333\n",
      "Epoch 449/499\n",
      "----------\n",
      "train Loss: 0.5552 Acc: 1.0000\n",
      "val Loss: 0.5528 Acc: 1.0000\n",
      "test Loss: 0.6280 Acc: 0.9333\n",
      "Epoch 450/499\n",
      "----------\n",
      "train Loss: 0.5566 Acc: 1.0000\n",
      "val Loss: 0.5519 Acc: 1.0000\n",
      "test Loss: 0.6262 Acc: 0.9333\n",
      "Epoch 451/499\n",
      "----------\n",
      "train Loss: 0.5597 Acc: 1.0000\n",
      "val Loss: 0.5517 Acc: 1.0000\n",
      "test Loss: 0.6226 Acc: 0.9333\n",
      "Epoch 452/499\n",
      "----------\n",
      "train Loss: 0.5566 Acc: 1.0000\n",
      "val Loss: 0.5554 Acc: 1.0000\n",
      "test Loss: 0.6365 Acc: 0.9000\n",
      "Epoch 453/499\n",
      "----------\n",
      "train Loss: 0.5579 Acc: 1.0000\n",
      "val Loss: 0.5522 Acc: 1.0000\n",
      "test Loss: 0.6321 Acc: 0.9000\n",
      "Epoch 454/499\n",
      "----------\n",
      "train Loss: 0.5571 Acc: 1.0000\n",
      "val Loss: 0.5516 Acc: 1.0000\n",
      "test Loss: 0.6279 Acc: 0.9333\n",
      "Epoch 455/499\n",
      "----------\n",
      "train Loss: 0.5629 Acc: 0.9889\n",
      "val Loss: 0.5527 Acc: 1.0000\n",
      "test Loss: 0.6167 Acc: 0.9333\n",
      "Epoch 456/499\n",
      "----------\n",
      "train Loss: 0.5560 Acc: 1.0000\n",
      "val Loss: 0.5518 Acc: 1.0000\n",
      "test Loss: 0.6235 Acc: 0.9333\n",
      "Epoch 457/499\n",
      "----------\n",
      "train Loss: 0.5554 Acc: 1.0000\n",
      "val Loss: 0.5719 Acc: 0.9667\n",
      "test Loss: 0.6210 Acc: 0.9333\n",
      "Epoch 458/499\n",
      "----------\n",
      "train Loss: 0.5614 Acc: 0.9889\n",
      "val Loss: 0.5517 Acc: 1.0000\n",
      "test Loss: 0.6236 Acc: 0.9333\n",
      "Epoch 459/499\n",
      "----------\n",
      "train Loss: 0.5586 Acc: 1.0000\n",
      "val Loss: 0.5546 Acc: 1.0000\n",
      "test Loss: 0.6267 Acc: 0.9333\n",
      "Epoch 460/499\n",
      "----------\n",
      "train Loss: 0.5577 Acc: 1.0000\n",
      "val Loss: 0.5516 Acc: 1.0000\n",
      "test Loss: 0.6214 Acc: 0.9333\n",
      "Epoch 461/499\n",
      "----------\n",
      "train Loss: 0.5548 Acc: 1.0000\n",
      "val Loss: 0.5517 Acc: 1.0000\n",
      "test Loss: 0.6166 Acc: 0.9333\n",
      "Epoch 462/499\n",
      "----------\n",
      "train Loss: 0.5580 Acc: 1.0000\n",
      "val Loss: 0.5568 Acc: 1.0000\n",
      "test Loss: 0.6252 Acc: 0.9333\n",
      "Epoch 463/499\n",
      "----------\n",
      "train Loss: 0.5633 Acc: 0.9889\n",
      "val Loss: 0.5523 Acc: 1.0000\n",
      "test Loss: 0.6264 Acc: 0.9333\n",
      "Epoch 464/499\n",
      "----------\n",
      "train Loss: 0.5567 Acc: 1.0000\n",
      "val Loss: 0.5524 Acc: 1.0000\n",
      "test Loss: 0.6284 Acc: 0.9000\n",
      "Epoch 465/499\n",
      "----------\n",
      "train Loss: 0.5580 Acc: 1.0000\n",
      "val Loss: 0.5519 Acc: 1.0000\n",
      "test Loss: 0.6238 Acc: 0.9333\n",
      "Epoch 466/499\n",
      "----------\n",
      "train Loss: 0.5598 Acc: 0.9889\n",
      "val Loss: 0.5516 Acc: 1.0000\n",
      "test Loss: 0.6165 Acc: 0.9333\n",
      "Epoch 467/499\n",
      "----------\n",
      "train Loss: 0.5581 Acc: 1.0000\n",
      "val Loss: 0.5518 Acc: 1.0000\n",
      "test Loss: 0.6222 Acc: 0.9333\n",
      "Epoch 468/499\n",
      "----------\n",
      "train Loss: 0.5594 Acc: 1.0000\n",
      "val Loss: 0.5524 Acc: 1.0000\n",
      "test Loss: 0.6293 Acc: 0.9333\n",
      "Epoch 469/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5559 Acc: 1.0000\n",
      "val Loss: 0.5523 Acc: 1.0000\n",
      "test Loss: 0.6236 Acc: 0.9333\n",
      "Epoch 470/499\n",
      "----------\n",
      "train Loss: 0.5556 Acc: 1.0000\n",
      "val Loss: 0.5525 Acc: 1.0000\n",
      "test Loss: 0.6327 Acc: 0.9000\n",
      "Epoch 471/499\n",
      "----------\n",
      "train Loss: 0.5552 Acc: 1.0000\n",
      "val Loss: 0.5518 Acc: 1.0000\n",
      "test Loss: 0.6270 Acc: 0.9333\n",
      "Epoch 472/499\n",
      "----------\n",
      "train Loss: 0.5584 Acc: 1.0000\n",
      "val Loss: 0.5536 Acc: 1.0000\n",
      "test Loss: 0.6264 Acc: 0.9333\n",
      "Epoch 473/499\n",
      "----------\n",
      "train Loss: 0.5551 Acc: 1.0000\n",
      "val Loss: 0.5521 Acc: 1.0000\n",
      "test Loss: 0.6255 Acc: 0.9333\n",
      "Epoch 474/499\n",
      "----------\n",
      "train Loss: 0.5569 Acc: 1.0000\n",
      "val Loss: 0.5517 Acc: 1.0000\n",
      "test Loss: 0.6237 Acc: 0.9333\n",
      "Epoch 475/499\n",
      "----------\n",
      "train Loss: 0.5568 Acc: 1.0000\n",
      "val Loss: 0.5523 Acc: 1.0000\n",
      "test Loss: 0.6067 Acc: 0.9333\n",
      "Epoch 476/499\n",
      "----------\n",
      "train Loss: 0.5561 Acc: 1.0000\n",
      "val Loss: 0.5518 Acc: 1.0000\n",
      "test Loss: 0.6175 Acc: 0.9333\n",
      "Epoch 477/499\n",
      "----------\n",
      "train Loss: 0.5550 Acc: 1.0000\n",
      "val Loss: 0.5535 Acc: 1.0000\n",
      "test Loss: 0.6276 Acc: 0.9333\n",
      "Epoch 478/499\n",
      "----------\n",
      "train Loss: 0.5553 Acc: 1.0000\n",
      "val Loss: 0.5520 Acc: 1.0000\n",
      "test Loss: 0.6090 Acc: 0.9667\n",
      "Epoch 479/499\n",
      "----------\n",
      "train Loss: 0.5554 Acc: 1.0000\n",
      "val Loss: 0.5519 Acc: 1.0000\n",
      "test Loss: 0.6164 Acc: 0.9333\n",
      "Epoch 480/499\n",
      "----------\n",
      "train Loss: 0.5557 Acc: 1.0000\n",
      "val Loss: 0.5624 Acc: 1.0000\n",
      "test Loss: 0.6329 Acc: 0.9000\n",
      "Epoch 481/499\n",
      "----------\n",
      "train Loss: 0.5564 Acc: 1.0000\n",
      "val Loss: 0.5517 Acc: 1.0000\n",
      "test Loss: 0.6349 Acc: 0.9000\n",
      "Epoch 482/499\n",
      "----------\n",
      "train Loss: 0.5565 Acc: 1.0000\n",
      "val Loss: 0.5516 Acc: 1.0000\n",
      "test Loss: 0.6320 Acc: 0.9000\n",
      "Epoch 483/499\n",
      "----------\n",
      "train Loss: 0.5558 Acc: 1.0000\n",
      "val Loss: 0.5519 Acc: 1.0000\n",
      "test Loss: 0.6114 Acc: 0.9333\n",
      "Epoch 484/499\n",
      "----------\n",
      "train Loss: 0.5584 Acc: 1.0000\n",
      "val Loss: 0.5524 Acc: 1.0000\n",
      "test Loss: 0.6213 Acc: 0.9333\n",
      "Epoch 485/499\n",
      "----------\n",
      "train Loss: 0.5596 Acc: 0.9889\n",
      "val Loss: 0.5535 Acc: 1.0000\n",
      "test Loss: 0.6283 Acc: 0.9000\n",
      "Epoch 486/499\n",
      "----------\n",
      "train Loss: 0.5632 Acc: 0.9889\n",
      "val Loss: 0.5521 Acc: 1.0000\n",
      "test Loss: 0.6304 Acc: 0.9000\n",
      "Epoch 487/499\n",
      "----------\n",
      "train Loss: 0.5655 Acc: 0.9889\n",
      "val Loss: 0.5521 Acc: 1.0000\n",
      "test Loss: 0.6345 Acc: 0.9000\n",
      "Epoch 488/499\n",
      "----------\n",
      "train Loss: 0.5561 Acc: 1.0000\n",
      "val Loss: 0.5517 Acc: 1.0000\n",
      "test Loss: 0.6229 Acc: 0.9333\n",
      "Epoch 489/499\n",
      "----------\n",
      "train Loss: 0.5571 Acc: 1.0000\n",
      "val Loss: 0.5521 Acc: 1.0000\n",
      "test Loss: 0.6263 Acc: 0.9333\n",
      "Epoch 490/499\n",
      "----------\n",
      "train Loss: 0.5574 Acc: 1.0000\n",
      "val Loss: 0.5520 Acc: 1.0000\n",
      "test Loss: 0.6233 Acc: 0.9333\n",
      "Epoch 491/499\n",
      "----------\n",
      "train Loss: 0.5555 Acc: 1.0000\n",
      "val Loss: 0.5528 Acc: 1.0000\n",
      "test Loss: 0.6219 Acc: 0.9333\n",
      "Epoch 492/499\n",
      "----------\n",
      "train Loss: 0.5566 Acc: 1.0000\n",
      "val Loss: 0.5522 Acc: 1.0000\n",
      "test Loss: 0.6302 Acc: 0.9333\n",
      "Epoch 493/499\n",
      "----------\n",
      "train Loss: 0.5549 Acc: 1.0000\n",
      "val Loss: 0.5519 Acc: 1.0000\n",
      "test Loss: 0.6231 Acc: 0.9000\n",
      "Epoch 494/499\n",
      "----------\n",
      "train Loss: 0.5589 Acc: 1.0000\n",
      "val Loss: 0.5521 Acc: 1.0000\n",
      "test Loss: 0.6307 Acc: 0.9333\n",
      "Epoch 495/499\n",
      "----------\n",
      "train Loss: 0.5584 Acc: 1.0000\n",
      "val Loss: 0.5519 Acc: 1.0000\n",
      "test Loss: 0.6205 Acc: 0.9333\n",
      "Epoch 496/499\n",
      "----------\n",
      "train Loss: 0.5559 Acc: 1.0000\n",
      "val Loss: 0.5518 Acc: 1.0000\n",
      "test Loss: 0.6210 Acc: 0.9333\n",
      "Epoch 497/499\n",
      "----------\n",
      "train Loss: 0.5563 Acc: 1.0000\n",
      "val Loss: 0.5520 Acc: 1.0000\n",
      "test Loss: 0.6374 Acc: 0.9000\n",
      "Epoch 498/499\n",
      "----------\n",
      "train Loss: 0.5580 Acc: 1.0000\n",
      "val Loss: 0.5517 Acc: 1.0000\n",
      "test Loss: 0.6335 Acc: 0.9000\n",
      "Epoch 499/499\n",
      "----------\n",
      "train Loss: 0.5568 Acc: 1.0000\n",
      "val Loss: 0.5518 Acc: 1.0000\n",
      "test Loss: 0.6311 Acc: 0.9333\n",
      "Training complete in 0m 6s\n",
      "Best test Acc: 0.966667\n"
     ]
    }
   ],
   "source": [
    "# iris\n",
    "num_epochs = 500\n",
    "\n",
    "params_to_update310 = model_iris_3_10.parameters()\n",
    "params_to_update110 = model_iris_1_10.parameters()\n",
    "params_to_update510 = model_iris_5_10.parameters()\n",
    "params_to_update305 = model_iris_3_05.parameters()\n",
    "params_to_update315 = model_iris_3_15.parameters()\n",
    "\n",
    "optimizer_ft310 = optim.Adam(params_to_update310, lr=0.001)\n",
    "optimizer_ft110 = optim.Adam(params_to_update110, lr=0.001)\n",
    "optimizer_ft510 = optim.Adam(params_to_update510, lr=0.001)\n",
    "optimizer_ft305 = optim.Adam(params_to_update305, lr=0.001)\n",
    "optimizer_ft315 = optim.Adam(params_to_update315, lr=0.001)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model_ft310, hist310, loss310, f1_310 = train_model(model_iris_3_10, loader, criterion, optimizer_ft310, num_epochs=num_epochs)\n",
    "model_ft110, hist110, loss110, f1_110 = train_model(model_iris_1_10, loader, criterion, optimizer_ft110, num_epochs=num_epochs)\n",
    "model_ft510, hist510, loss510, f1_510 = train_model(model_iris_5_10, loader, criterion, optimizer_ft510, num_epochs=num_epochs)\n",
    "model_ft305, hist305, loss305, f1_305 = train_model(model_iris_3_05, loader, criterion, optimizer_ft305, num_epochs=num_epochs)\n",
    "model_ft315, hist315, loss315, f1_315 = train_model(model_iris_3_15, loader, criterion, optimizer_ft315, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1499\n",
      "----------\n",
      "train Loss: 1.1009 Acc: 0.2391\n",
      "val Loss: 1.0998 Acc: 0.2440\n",
      "test Loss: 1.1024 Acc: 0.2240\n",
      "Epoch 1/1499\n",
      "----------\n",
      "train Loss: 1.1007 Acc: 0.2493\n",
      "val Loss: 1.0990 Acc: 0.2280\n",
      "test Loss: 1.1014 Acc: 0.2480\n",
      "Epoch 2/1499\n",
      "----------\n",
      "train Loss: 1.1004 Acc: 0.2549\n",
      "val Loss: 1.0989 Acc: 0.2680\n",
      "test Loss: 1.1010 Acc: 0.2520\n",
      "Epoch 3/1499\n",
      "----------\n",
      "train Loss: 1.1002 Acc: 0.2604\n",
      "val Loss: 1.0989 Acc: 0.2240\n",
      "test Loss: 1.1011 Acc: 0.2360\n",
      "Epoch 4/1499\n",
      "----------\n",
      "train Loss: 1.1000 Acc: 0.2633\n",
      "val Loss: 1.0997 Acc: 0.2440\n",
      "test Loss: 1.1006 Acc: 0.2440\n",
      "Epoch 5/1499\n",
      "----------\n",
      "train Loss: 1.0998 Acc: 0.2704\n",
      "val Loss: 1.0990 Acc: 0.2440\n",
      "test Loss: 1.1008 Acc: 0.2560\n",
      "Epoch 6/1499\n",
      "----------\n",
      "train Loss: 1.0996 Acc: 0.2720\n",
      "val Loss: 1.0993 Acc: 0.2520\n",
      "test Loss: 1.1000 Acc: 0.2640\n",
      "Epoch 7/1499\n",
      "----------\n",
      "train Loss: 1.0993 Acc: 0.2822\n",
      "val Loss: 1.0982 Acc: 0.2880\n",
      "test Loss: 1.1006 Acc: 0.2560\n",
      "Epoch 8/1499\n",
      "----------\n",
      "train Loss: 1.0991 Acc: 0.2891\n",
      "val Loss: 1.0980 Acc: 0.2680\n",
      "test Loss: 1.1000 Acc: 0.2760\n",
      "Epoch 9/1499\n",
      "----------\n",
      "train Loss: 1.0990 Acc: 0.2987\n",
      "val Loss: 1.0985 Acc: 0.2760\n",
      "test Loss: 1.0999 Acc: 0.2760\n",
      "Epoch 10/1499\n",
      "----------\n",
      "train Loss: 1.0988 Acc: 0.3027\n",
      "val Loss: 1.0985 Acc: 0.2640\n",
      "test Loss: 1.0995 Acc: 0.3240\n",
      "Epoch 11/1499\n",
      "----------\n",
      "train Loss: 1.0987 Acc: 0.3024\n",
      "val Loss: 1.0979 Acc: 0.3040\n",
      "test Loss: 1.1000 Acc: 0.2720\n",
      "Epoch 12/1499\n",
      "----------\n",
      "train Loss: 1.0985 Acc: 0.3138\n",
      "val Loss: 1.0976 Acc: 0.3080\n",
      "test Loss: 1.0991 Acc: 0.3120\n",
      "Epoch 13/1499\n",
      "----------\n",
      "train Loss: 1.0983 Acc: 0.3151\n",
      "val Loss: 1.0977 Acc: 0.3080\n",
      "test Loss: 1.0989 Acc: 0.3160\n",
      "Epoch 14/1499\n",
      "----------\n",
      "train Loss: 1.0981 Acc: 0.3318\n",
      "val Loss: 1.0976 Acc: 0.3000\n",
      "test Loss: 1.0999 Acc: 0.3080\n",
      "Epoch 15/1499\n",
      "----------\n",
      "train Loss: 1.0981 Acc: 0.3376\n",
      "val Loss: 1.0971 Acc: 0.3440\n",
      "test Loss: 1.0986 Acc: 0.3520\n",
      "Epoch 16/1499\n",
      "----------\n",
      "train Loss: 1.0979 Acc: 0.3527\n",
      "val Loss: 1.0969 Acc: 0.3680\n",
      "test Loss: 1.0985 Acc: 0.3600\n",
      "Epoch 17/1499\n",
      "----------\n",
      "train Loss: 1.0976 Acc: 0.3520\n",
      "val Loss: 1.0970 Acc: 0.3160\n",
      "test Loss: 1.0987 Acc: 0.3400\n",
      "Epoch 18/1499\n",
      "----------\n",
      "train Loss: 1.0974 Acc: 0.3560\n",
      "val Loss: 1.0969 Acc: 0.3200\n",
      "test Loss: 1.0985 Acc: 0.3680\n",
      "Epoch 19/1499\n",
      "----------\n",
      "train Loss: 1.0973 Acc: 0.3700\n",
      "val Loss: 1.0969 Acc: 0.3280\n",
      "test Loss: 1.0983 Acc: 0.3520\n",
      "Epoch 20/1499\n",
      "----------\n",
      "train Loss: 1.0971 Acc: 0.3749\n",
      "val Loss: 1.0965 Acc: 0.3800\n",
      "test Loss: 1.0979 Acc: 0.3640\n",
      "Epoch 21/1499\n",
      "----------\n",
      "train Loss: 1.0969 Acc: 0.3762\n",
      "val Loss: 1.0967 Acc: 0.3240\n",
      "test Loss: 1.0977 Acc: 0.3880\n",
      "Epoch 22/1499\n",
      "----------\n",
      "train Loss: 1.0968 Acc: 0.3864\n",
      "val Loss: 1.0961 Acc: 0.3760\n",
      "test Loss: 1.0975 Acc: 0.3680\n",
      "Epoch 23/1499\n",
      "----------\n",
      "train Loss: 1.0967 Acc: 0.3947\n",
      "val Loss: 1.0957 Acc: 0.3680\n",
      "test Loss: 1.0976 Acc: 0.3960\n",
      "Epoch 24/1499\n",
      "----------\n",
      "train Loss: 1.0964 Acc: 0.4087\n",
      "val Loss: 1.0964 Acc: 0.3520\n",
      "test Loss: 1.0975 Acc: 0.4000\n",
      "Epoch 25/1499\n",
      "----------\n",
      "train Loss: 1.0965 Acc: 0.4053\n",
      "val Loss: 1.0959 Acc: 0.3800\n",
      "test Loss: 1.0975 Acc: 0.4000\n",
      "Epoch 26/1499\n",
      "----------\n",
      "train Loss: 1.0961 Acc: 0.4164\n",
      "val Loss: 1.0955 Acc: 0.3720\n",
      "test Loss: 1.0966 Acc: 0.4160\n",
      "Epoch 27/1499\n",
      "----------\n",
      "train Loss: 1.0959 Acc: 0.4244\n",
      "val Loss: 1.0956 Acc: 0.3960\n",
      "test Loss: 1.0967 Acc: 0.4000\n",
      "Epoch 28/1499\n",
      "----------\n",
      "train Loss: 1.0959 Acc: 0.4304\n",
      "val Loss: 1.0953 Acc: 0.4000\n",
      "test Loss: 1.0964 Acc: 0.3720\n",
      "Epoch 29/1499\n",
      "----------\n",
      "train Loss: 1.0955 Acc: 0.4413\n",
      "val Loss: 1.0948 Acc: 0.3920\n",
      "test Loss: 1.0962 Acc: 0.4120\n",
      "Epoch 30/1499\n",
      "----------\n",
      "train Loss: 1.0954 Acc: 0.4382\n",
      "val Loss: 1.0952 Acc: 0.4000\n",
      "test Loss: 1.0976 Acc: 0.3640\n",
      "Epoch 31/1499\n",
      "----------\n",
      "train Loss: 1.0952 Acc: 0.4391\n",
      "val Loss: 1.0951 Acc: 0.3840\n",
      "test Loss: 1.0958 Acc: 0.4280\n",
      "Epoch 32/1499\n",
      "----------\n",
      "train Loss: 1.0952 Acc: 0.4400\n",
      "val Loss: 1.0941 Acc: 0.4400\n",
      "test Loss: 1.0957 Acc: 0.4240\n",
      "Epoch 33/1499\n",
      "----------\n",
      "train Loss: 1.0950 Acc: 0.4424\n",
      "val Loss: 1.0945 Acc: 0.3880\n",
      "test Loss: 1.0956 Acc: 0.4360\n",
      "Epoch 34/1499\n",
      "----------\n",
      "train Loss: 1.0949 Acc: 0.4520\n",
      "val Loss: 1.0938 Acc: 0.4480\n",
      "test Loss: 1.0959 Acc: 0.4040\n",
      "Epoch 35/1499\n",
      "----------\n",
      "train Loss: 1.0946 Acc: 0.4584\n",
      "val Loss: 1.0939 Acc: 0.4080\n",
      "test Loss: 1.0954 Acc: 0.4520\n",
      "Epoch 36/1499\n",
      "----------\n",
      "train Loss: 1.0945 Acc: 0.4551\n",
      "val Loss: 1.0939 Acc: 0.4320\n",
      "test Loss: 1.0953 Acc: 0.4240\n",
      "Epoch 37/1499\n",
      "----------\n",
      "train Loss: 1.0942 Acc: 0.4604\n",
      "val Loss: 1.0937 Acc: 0.4600\n",
      "test Loss: 1.0946 Acc: 0.4480\n",
      "Epoch 38/1499\n",
      "----------\n",
      "train Loss: 1.0940 Acc: 0.4582\n",
      "val Loss: 1.0928 Acc: 0.4240\n",
      "test Loss: 1.0943 Acc: 0.4400\n",
      "Epoch 39/1499\n",
      "----------\n",
      "train Loss: 1.0937 Acc: 0.4596\n",
      "val Loss: 1.0938 Acc: 0.4120\n",
      "test Loss: 1.0946 Acc: 0.4480\n",
      "Epoch 40/1499\n",
      "----------\n",
      "train Loss: 1.0935 Acc: 0.4591\n",
      "val Loss: 1.0931 Acc: 0.4320\n",
      "test Loss: 1.0942 Acc: 0.4320\n",
      "Epoch 41/1499\n",
      "----------\n",
      "train Loss: 1.0936 Acc: 0.4642\n",
      "val Loss: 1.0934 Acc: 0.4280\n",
      "test Loss: 1.0933 Acc: 0.4760\n",
      "Epoch 42/1499\n",
      "----------\n",
      "train Loss: 1.0932 Acc: 0.4736\n",
      "val Loss: 1.0928 Acc: 0.4600\n",
      "test Loss: 1.0938 Acc: 0.4600\n",
      "Epoch 43/1499\n",
      "----------\n",
      "train Loss: 1.0929 Acc: 0.4640\n",
      "val Loss: 1.0926 Acc: 0.4480\n",
      "test Loss: 1.0937 Acc: 0.4520\n",
      "Epoch 44/1499\n",
      "----------\n",
      "train Loss: 1.0927 Acc: 0.4691\n",
      "val Loss: 1.0922 Acc: 0.4640\n",
      "test Loss: 1.0927 Acc: 0.4920\n",
      "Epoch 45/1499\n",
      "----------\n",
      "train Loss: 1.0925 Acc: 0.4664\n",
      "val Loss: 1.0920 Acc: 0.4280\n",
      "test Loss: 1.0928 Acc: 0.4800\n",
      "Epoch 46/1499\n",
      "----------\n",
      "train Loss: 1.0921 Acc: 0.4813\n",
      "val Loss: 1.0919 Acc: 0.4440\n",
      "test Loss: 1.0921 Acc: 0.4840\n",
      "Epoch 47/1499\n",
      "----------\n",
      "train Loss: 1.0918 Acc: 0.4793\n",
      "val Loss: 1.0917 Acc: 0.4520\n",
      "test Loss: 1.0919 Acc: 0.5040\n",
      "Epoch 48/1499\n",
      "----------\n",
      "train Loss: 1.0914 Acc: 0.4869\n",
      "val Loss: 1.0915 Acc: 0.4480\n",
      "test Loss: 1.0920 Acc: 0.4480\n",
      "Epoch 49/1499\n",
      "----------\n",
      "train Loss: 1.0913 Acc: 0.4807\n",
      "val Loss: 1.0908 Acc: 0.4640\n",
      "test Loss: 1.0917 Acc: 0.4840\n",
      "Epoch 50/1499\n",
      "----------\n",
      "train Loss: 1.0908 Acc: 0.4918\n",
      "val Loss: 1.0907 Acc: 0.4680\n",
      "test Loss: 1.0916 Acc: 0.4560\n",
      "Epoch 51/1499\n",
      "----------\n",
      "train Loss: 1.0907 Acc: 0.4822\n",
      "val Loss: 1.0908 Acc: 0.4400\n",
      "test Loss: 1.0907 Acc: 0.5080\n",
      "Epoch 52/1499\n",
      "----------\n",
      "train Loss: 1.0903 Acc: 0.4860\n",
      "val Loss: 1.0892 Acc: 0.4840\n",
      "test Loss: 1.0902 Acc: 0.4800\n",
      "Epoch 53/1499\n",
      "----------\n",
      "train Loss: 1.0899 Acc: 0.4833\n",
      "val Loss: 1.0898 Acc: 0.4680\n",
      "test Loss: 1.0909 Acc: 0.4440\n",
      "Epoch 54/1499\n",
      "----------\n",
      "train Loss: 1.0896 Acc: 0.4807\n",
      "val Loss: 1.0895 Acc: 0.5160\n",
      "test Loss: 1.0891 Acc: 0.4920\n",
      "Epoch 55/1499\n",
      "----------\n",
      "train Loss: 1.0894 Acc: 0.4831\n",
      "val Loss: 1.0888 Acc: 0.4680\n",
      "test Loss: 1.0901 Acc: 0.4720\n",
      "Epoch 56/1499\n",
      "----------\n",
      "train Loss: 1.0888 Acc: 0.4893\n",
      "val Loss: 1.0894 Acc: 0.4560\n",
      "test Loss: 1.0892 Acc: 0.4840\n",
      "Epoch 57/1499\n",
      "----------\n",
      "train Loss: 1.0885 Acc: 0.4882\n",
      "val Loss: 1.0884 Acc: 0.4640\n",
      "test Loss: 1.0878 Acc: 0.5040\n",
      "Epoch 58/1499\n",
      "----------\n",
      "train Loss: 1.0882 Acc: 0.4833\n",
      "val Loss: 1.0879 Acc: 0.4600\n",
      "test Loss: 1.0880 Acc: 0.4760\n",
      "Epoch 59/1499\n",
      "----------\n",
      "train Loss: 1.0879 Acc: 0.4876\n",
      "val Loss: 1.0869 Acc: 0.5120\n",
      "test Loss: 1.0880 Acc: 0.4640\n",
      "Epoch 60/1499\n",
      "----------\n",
      "train Loss: 1.0873 Acc: 0.4920\n",
      "val Loss: 1.0866 Acc: 0.5040\n",
      "test Loss: 1.0887 Acc: 0.4480\n",
      "Epoch 61/1499\n",
      "----------\n",
      "train Loss: 1.0867 Acc: 0.4973\n",
      "val Loss: 1.0865 Acc: 0.5040\n",
      "test Loss: 1.0868 Acc: 0.4680\n",
      "Epoch 62/1499\n",
      "----------\n",
      "train Loss: 1.0865 Acc: 0.4920\n",
      "val Loss: 1.0852 Acc: 0.5040\n",
      "test Loss: 1.0867 Acc: 0.4680\n",
      "Epoch 63/1499\n",
      "----------\n",
      "train Loss: 1.0859 Acc: 0.4947\n",
      "val Loss: 1.0857 Acc: 0.4880\n",
      "test Loss: 1.0868 Acc: 0.4800\n",
      "Epoch 64/1499\n",
      "----------\n",
      "train Loss: 1.0855 Acc: 0.4880\n",
      "val Loss: 1.0852 Acc: 0.4960\n",
      "test Loss: 1.0856 Acc: 0.4880\n",
      "Epoch 65/1499\n",
      "----------\n",
      "train Loss: 1.0851 Acc: 0.4982\n",
      "val Loss: 1.0847 Acc: 0.5040\n",
      "test Loss: 1.0848 Acc: 0.4680\n",
      "Epoch 66/1499\n",
      "----------\n",
      "train Loss: 1.0845 Acc: 0.4982\n",
      "val Loss: 1.0841 Acc: 0.4960\n",
      "test Loss: 1.0842 Acc: 0.4920\n",
      "Epoch 67/1499\n",
      "----------\n",
      "train Loss: 1.0839 Acc: 0.4964\n",
      "val Loss: 1.0836 Acc: 0.5000\n",
      "test Loss: 1.0843 Acc: 0.4680\n",
      "Epoch 68/1499\n",
      "----------\n",
      "train Loss: 1.0834 Acc: 0.4951\n",
      "val Loss: 1.0831 Acc: 0.4960\n",
      "test Loss: 1.0830 Acc: 0.4920\n",
      "Epoch 69/1499\n",
      "----------\n",
      "train Loss: 1.0828 Acc: 0.4989\n",
      "val Loss: 1.0820 Acc: 0.5160\n",
      "test Loss: 1.0835 Acc: 0.4400\n",
      "Epoch 70/1499\n",
      "----------\n",
      "train Loss: 1.0823 Acc: 0.5022\n",
      "val Loss: 1.0824 Acc: 0.5000\n",
      "test Loss: 1.0822 Acc: 0.4800\n",
      "Epoch 71/1499\n",
      "----------\n",
      "train Loss: 1.0816 Acc: 0.5018\n",
      "val Loss: 1.0815 Acc: 0.4960\n",
      "test Loss: 1.0822 Acc: 0.4920\n",
      "Epoch 72/1499\n",
      "----------\n",
      "train Loss: 1.0808 Acc: 0.5020\n",
      "val Loss: 1.0813 Acc: 0.4880\n",
      "test Loss: 1.0809 Acc: 0.4880\n",
      "Epoch 73/1499\n",
      "----------\n",
      "train Loss: 1.0806 Acc: 0.4964\n",
      "val Loss: 1.0799 Acc: 0.4960\n",
      "test Loss: 1.0808 Acc: 0.4800\n",
      "Epoch 74/1499\n",
      "----------\n",
      "train Loss: 1.0800 Acc: 0.4971\n",
      "val Loss: 1.0800 Acc: 0.4800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.0799 Acc: 0.4720\n",
      "Epoch 75/1499\n",
      "----------\n",
      "train Loss: 1.0794 Acc: 0.4962\n",
      "val Loss: 1.0783 Acc: 0.5200\n",
      "test Loss: 1.0792 Acc: 0.4800\n",
      "Epoch 76/1499\n",
      "----------\n",
      "train Loss: 1.0785 Acc: 0.5036\n",
      "val Loss: 1.0775 Acc: 0.5160\n",
      "test Loss: 1.0791 Acc: 0.5000\n",
      "Epoch 77/1499\n",
      "----------\n",
      "train Loss: 1.0780 Acc: 0.4987\n",
      "val Loss: 1.0776 Acc: 0.4920\n",
      "test Loss: 1.0772 Acc: 0.5000\n",
      "Epoch 78/1499\n",
      "----------\n",
      "train Loss: 1.0772 Acc: 0.5062\n",
      "val Loss: 1.0771 Acc: 0.5320\n",
      "test Loss: 1.0767 Acc: 0.5080\n",
      "Epoch 79/1499\n",
      "----------\n",
      "train Loss: 1.0768 Acc: 0.5016\n",
      "val Loss: 1.0748 Acc: 0.5320\n",
      "test Loss: 1.0759 Acc: 0.5120\n",
      "Epoch 80/1499\n",
      "----------\n",
      "train Loss: 1.0759 Acc: 0.5024\n",
      "val Loss: 1.0750 Acc: 0.5320\n",
      "test Loss: 1.0763 Acc: 0.4960\n",
      "Epoch 81/1499\n",
      "----------\n",
      "train Loss: 1.0752 Acc: 0.5060\n",
      "val Loss: 1.0738 Acc: 0.5200\n",
      "test Loss: 1.0760 Acc: 0.4760\n",
      "Epoch 82/1499\n",
      "----------\n",
      "train Loss: 1.0742 Acc: 0.5180\n",
      "val Loss: 1.0731 Acc: 0.5240\n",
      "test Loss: 1.0749 Acc: 0.5120\n",
      "Epoch 83/1499\n",
      "----------\n",
      "train Loss: 1.0733 Acc: 0.5107\n",
      "val Loss: 1.0743 Acc: 0.5080\n",
      "test Loss: 1.0725 Acc: 0.5120\n",
      "Epoch 84/1499\n",
      "----------\n",
      "train Loss: 1.0730 Acc: 0.5109\n",
      "val Loss: 1.0724 Acc: 0.5120\n",
      "test Loss: 1.0731 Acc: 0.4880\n",
      "Epoch 85/1499\n",
      "----------\n",
      "train Loss: 1.0718 Acc: 0.5260\n",
      "val Loss: 1.0712 Acc: 0.5280\n",
      "test Loss: 1.0717 Acc: 0.5240\n",
      "Epoch 86/1499\n",
      "----------\n",
      "train Loss: 1.0710 Acc: 0.5287\n",
      "val Loss: 1.0700 Acc: 0.5520\n",
      "test Loss: 1.0711 Acc: 0.5000\n",
      "Epoch 87/1499\n",
      "----------\n",
      "train Loss: 1.0702 Acc: 0.5362\n",
      "val Loss: 1.0696 Acc: 0.5520\n",
      "test Loss: 1.0701 Acc: 0.5160\n",
      "Epoch 88/1499\n",
      "----------\n",
      "train Loss: 1.0694 Acc: 0.5349\n",
      "val Loss: 1.0686 Acc: 0.5720\n",
      "test Loss: 1.0685 Acc: 0.5360\n",
      "Epoch 89/1499\n",
      "----------\n",
      "train Loss: 1.0686 Acc: 0.5469\n",
      "val Loss: 1.0695 Acc: 0.5560\n",
      "test Loss: 1.0681 Acc: 0.5640\n",
      "Epoch 90/1499\n",
      "----------\n",
      "train Loss: 1.0678 Acc: 0.5498\n",
      "val Loss: 1.0673 Acc: 0.5480\n",
      "test Loss: 1.0660 Acc: 0.5480\n",
      "Epoch 91/1499\n",
      "----------\n",
      "train Loss: 1.0668 Acc: 0.5487\n",
      "val Loss: 1.0662 Acc: 0.5400\n",
      "test Loss: 1.0667 Acc: 0.5360\n",
      "Epoch 92/1499\n",
      "----------\n",
      "train Loss: 1.0654 Acc: 0.5593\n",
      "val Loss: 1.0644 Acc: 0.5720\n",
      "test Loss: 1.0642 Acc: 0.5840\n",
      "Epoch 93/1499\n",
      "----------\n",
      "train Loss: 1.0640 Acc: 0.5633\n",
      "val Loss: 1.0620 Acc: 0.5800\n",
      "test Loss: 1.0646 Acc: 0.5680\n",
      "Epoch 94/1499\n",
      "----------\n",
      "train Loss: 1.0635 Acc: 0.5693\n",
      "val Loss: 1.0616 Acc: 0.5680\n",
      "test Loss: 1.0643 Acc: 0.5560\n",
      "Epoch 95/1499\n",
      "----------\n",
      "train Loss: 1.0621 Acc: 0.5784\n",
      "val Loss: 1.0611 Acc: 0.5760\n",
      "test Loss: 1.0622 Acc: 0.5560\n",
      "Epoch 96/1499\n",
      "----------\n",
      "train Loss: 1.0613 Acc: 0.5809\n",
      "val Loss: 1.0602 Acc: 0.5760\n",
      "test Loss: 1.0638 Acc: 0.5400\n",
      "Epoch 97/1499\n",
      "----------\n",
      "train Loss: 1.0598 Acc: 0.5927\n",
      "val Loss: 1.0600 Acc: 0.6120\n",
      "test Loss: 1.0633 Acc: 0.5760\n",
      "Epoch 98/1499\n",
      "----------\n",
      "train Loss: 1.0592 Acc: 0.5869\n",
      "val Loss: 1.0571 Acc: 0.6320\n",
      "test Loss: 1.0562 Acc: 0.5920\n",
      "Epoch 99/1499\n",
      "----------\n",
      "train Loss: 1.0576 Acc: 0.5978\n",
      "val Loss: 1.0561 Acc: 0.6240\n",
      "test Loss: 1.0585 Acc: 0.6000\n",
      "Epoch 100/1499\n",
      "----------\n",
      "train Loss: 1.0563 Acc: 0.5993\n",
      "val Loss: 1.0556 Acc: 0.6080\n",
      "test Loss: 1.0574 Acc: 0.5720\n",
      "Epoch 101/1499\n",
      "----------\n",
      "train Loss: 1.0557 Acc: 0.5989\n",
      "val Loss: 1.0534 Acc: 0.6160\n",
      "test Loss: 1.0556 Acc: 0.6040\n",
      "Epoch 102/1499\n",
      "----------\n",
      "train Loss: 1.0537 Acc: 0.6076\n",
      "val Loss: 1.0534 Acc: 0.6080\n",
      "test Loss: 1.0515 Acc: 0.6280\n",
      "Epoch 103/1499\n",
      "----------\n",
      "train Loss: 1.0529 Acc: 0.6056\n",
      "val Loss: 1.0503 Acc: 0.6440\n",
      "test Loss: 1.0543 Acc: 0.6040\n",
      "Epoch 104/1499\n",
      "----------\n",
      "train Loss: 1.0517 Acc: 0.6176\n",
      "val Loss: 1.0479 Acc: 0.6640\n",
      "test Loss: 1.0501 Acc: 0.6320\n",
      "Epoch 105/1499\n",
      "----------\n",
      "train Loss: 1.0501 Acc: 0.6207\n",
      "val Loss: 1.0488 Acc: 0.6280\n",
      "test Loss: 1.0500 Acc: 0.6200\n",
      "Epoch 106/1499\n",
      "----------\n",
      "train Loss: 1.0483 Acc: 0.6264\n",
      "val Loss: 1.0458 Acc: 0.6600\n",
      "test Loss: 1.0461 Acc: 0.6280\n",
      "Epoch 107/1499\n",
      "----------\n",
      "train Loss: 1.0479 Acc: 0.6231\n",
      "val Loss: 1.0445 Acc: 0.6600\n",
      "test Loss: 1.0501 Acc: 0.5920\n",
      "Epoch 108/1499\n",
      "----------\n",
      "train Loss: 1.0459 Acc: 0.6373\n",
      "val Loss: 1.0422 Acc: 0.6720\n",
      "test Loss: 1.0460 Acc: 0.6320\n",
      "Epoch 109/1499\n",
      "----------\n",
      "train Loss: 1.0440 Acc: 0.6340\n",
      "val Loss: 1.0422 Acc: 0.6800\n",
      "test Loss: 1.0443 Acc: 0.6280\n",
      "Epoch 110/1499\n",
      "----------\n",
      "train Loss: 1.0430 Acc: 0.6433\n",
      "val Loss: 1.0419 Acc: 0.6720\n",
      "test Loss: 1.0430 Acc: 0.6400\n",
      "Epoch 111/1499\n",
      "----------\n",
      "train Loss: 1.0416 Acc: 0.6396\n",
      "val Loss: 1.0415 Acc: 0.6840\n",
      "test Loss: 1.0403 Acc: 0.6400\n",
      "Epoch 112/1499\n",
      "----------\n",
      "train Loss: 1.0403 Acc: 0.6391\n",
      "val Loss: 1.0368 Acc: 0.7160\n",
      "test Loss: 1.0395 Acc: 0.6480\n",
      "Epoch 113/1499\n",
      "----------\n",
      "train Loss: 1.0389 Acc: 0.6456\n",
      "val Loss: 1.0347 Acc: 0.7080\n",
      "test Loss: 1.0393 Acc: 0.6320\n",
      "Epoch 114/1499\n",
      "----------\n",
      "train Loss: 1.0368 Acc: 0.6564\n",
      "val Loss: 1.0340 Acc: 0.7200\n",
      "test Loss: 1.0348 Acc: 0.6640\n",
      "Epoch 115/1499\n",
      "----------\n",
      "train Loss: 1.0352 Acc: 0.6584\n",
      "val Loss: 1.0312 Acc: 0.7160\n",
      "test Loss: 1.0366 Acc: 0.6440\n",
      "Epoch 116/1499\n",
      "----------\n",
      "train Loss: 1.0339 Acc: 0.6602\n",
      "val Loss: 1.0292 Acc: 0.7200\n",
      "test Loss: 1.0335 Acc: 0.6520\n",
      "Epoch 117/1499\n",
      "----------\n",
      "train Loss: 1.0321 Acc: 0.6636\n",
      "val Loss: 1.0277 Acc: 0.7120\n",
      "test Loss: 1.0299 Acc: 0.6640\n",
      "Epoch 118/1499\n",
      "----------\n",
      "train Loss: 1.0312 Acc: 0.6676\n",
      "val Loss: 1.0281 Acc: 0.7160\n",
      "test Loss: 1.0324 Acc: 0.6680\n",
      "Epoch 119/1499\n",
      "----------\n",
      "train Loss: 1.0283 Acc: 0.6684\n",
      "val Loss: 1.0262 Acc: 0.7080\n",
      "test Loss: 1.0307 Acc: 0.6320\n",
      "Epoch 120/1499\n",
      "----------\n",
      "train Loss: 1.0275 Acc: 0.6718\n",
      "val Loss: 1.0207 Acc: 0.7320\n",
      "test Loss: 1.0249 Acc: 0.6400\n",
      "Epoch 121/1499\n",
      "----------\n",
      "train Loss: 1.0254 Acc: 0.6693\n",
      "val Loss: 1.0215 Acc: 0.6920\n",
      "test Loss: 1.0277 Acc: 0.6520\n",
      "Epoch 122/1499\n",
      "----------\n",
      "train Loss: 1.0233 Acc: 0.6836\n",
      "val Loss: 1.0192 Acc: 0.7320\n",
      "test Loss: 1.0243 Acc: 0.6720\n",
      "Epoch 123/1499\n",
      "----------\n",
      "train Loss: 1.0225 Acc: 0.6753\n",
      "val Loss: 1.0185 Acc: 0.7160\n",
      "test Loss: 1.0221 Acc: 0.6480\n",
      "Epoch 124/1499\n",
      "----------\n",
      "train Loss: 1.0207 Acc: 0.6844\n",
      "val Loss: 1.0205 Acc: 0.7000\n",
      "test Loss: 1.0215 Acc: 0.6440\n",
      "Epoch 125/1499\n",
      "----------\n",
      "train Loss: 1.0193 Acc: 0.6727\n",
      "val Loss: 1.0144 Acc: 0.7400\n",
      "test Loss: 1.0170 Acc: 0.6720\n",
      "Epoch 126/1499\n",
      "----------\n",
      "train Loss: 1.0174 Acc: 0.6827\n",
      "val Loss: 1.0158 Acc: 0.7080\n",
      "test Loss: 1.0186 Acc: 0.6440\n",
      "Epoch 127/1499\n",
      "----------\n",
      "train Loss: 1.0160 Acc: 0.6907\n",
      "val Loss: 1.0084 Acc: 0.7280\n",
      "test Loss: 1.0130 Acc: 0.6640\n",
      "Epoch 128/1499\n",
      "----------\n",
      "train Loss: 1.0143 Acc: 0.6824\n",
      "val Loss: 1.0082 Acc: 0.7680\n",
      "test Loss: 1.0154 Acc: 0.6480\n",
      "Epoch 129/1499\n",
      "----------\n",
      "train Loss: 1.0120 Acc: 0.6847\n",
      "val Loss: 1.0066 Acc: 0.7480\n",
      "test Loss: 1.0124 Acc: 0.6800\n",
      "Epoch 130/1499\n",
      "----------\n",
      "train Loss: 1.0108 Acc: 0.6889\n",
      "val Loss: 1.0043 Acc: 0.7400\n",
      "test Loss: 1.0098 Acc: 0.6720\n",
      "Epoch 131/1499\n",
      "----------\n",
      "train Loss: 1.0092 Acc: 0.6869\n",
      "val Loss: 1.0020 Acc: 0.7520\n",
      "test Loss: 1.0069 Acc: 0.6760\n",
      "Epoch 132/1499\n",
      "----------\n",
      "train Loss: 1.0066 Acc: 0.6927\n",
      "val Loss: 1.0048 Acc: 0.7360\n",
      "test Loss: 1.0062 Acc: 0.7040\n",
      "Epoch 133/1499\n",
      "----------\n",
      "train Loss: 1.0046 Acc: 0.6940\n",
      "val Loss: 0.9984 Acc: 0.7480\n",
      "test Loss: 1.0082 Acc: 0.6640\n",
      "Epoch 134/1499\n",
      "----------\n",
      "train Loss: 1.0029 Acc: 0.6953\n",
      "val Loss: 1.0011 Acc: 0.7400\n",
      "test Loss: 1.0019 Acc: 0.6840\n",
      "Epoch 135/1499\n",
      "----------\n",
      "train Loss: 1.0012 Acc: 0.6991\n",
      "val Loss: 0.9995 Acc: 0.7440\n",
      "test Loss: 1.0022 Acc: 0.6600\n",
      "Epoch 136/1499\n",
      "----------\n",
      "train Loss: 0.9986 Acc: 0.7069\n",
      "val Loss: 0.9990 Acc: 0.7280\n",
      "test Loss: 1.0038 Acc: 0.6240\n",
      "Epoch 137/1499\n",
      "----------\n",
      "train Loss: 0.9993 Acc: 0.7007\n",
      "val Loss: 0.9932 Acc: 0.7640\n",
      "test Loss: 0.9939 Acc: 0.7000\n",
      "Epoch 138/1499\n",
      "----------\n",
      "train Loss: 0.9958 Acc: 0.7042\n",
      "val Loss: 0.9912 Acc: 0.7800\n",
      "test Loss: 0.9996 Acc: 0.6640\n",
      "Epoch 139/1499\n",
      "----------\n",
      "train Loss: 0.9944 Acc: 0.7084\n",
      "val Loss: 0.9893 Acc: 0.7560\n",
      "test Loss: 0.9939 Acc: 0.6720\n",
      "Epoch 140/1499\n",
      "----------\n",
      "train Loss: 0.9927 Acc: 0.7173\n",
      "val Loss: 0.9903 Acc: 0.7440\n",
      "test Loss: 0.9888 Acc: 0.7000\n",
      "Epoch 141/1499\n",
      "----------\n",
      "train Loss: 0.9911 Acc: 0.7109\n",
      "val Loss: 0.9890 Acc: 0.7560\n",
      "test Loss: 0.9911 Acc: 0.6960\n",
      "Epoch 142/1499\n",
      "----------\n",
      "train Loss: 0.9894 Acc: 0.7087\n",
      "val Loss: 0.9864 Acc: 0.7200\n",
      "test Loss: 0.9891 Acc: 0.6880\n",
      "Epoch 143/1499\n",
      "----------\n",
      "train Loss: 0.9873 Acc: 0.7122\n",
      "val Loss: 0.9799 Acc: 0.7400\n",
      "test Loss: 0.9874 Acc: 0.6720\n",
      "Epoch 144/1499\n",
      "----------\n",
      "train Loss: 0.9858 Acc: 0.7140\n",
      "val Loss: 0.9855 Acc: 0.7440\n",
      "test Loss: 0.9881 Acc: 0.6840\n",
      "Epoch 145/1499\n",
      "----------\n",
      "train Loss: 0.9844 Acc: 0.7244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.9807 Acc: 0.7640\n",
      "test Loss: 0.9860 Acc: 0.6760\n",
      "Epoch 146/1499\n",
      "----------\n",
      "train Loss: 0.9830 Acc: 0.7218\n",
      "val Loss: 0.9796 Acc: 0.7320\n",
      "test Loss: 0.9819 Acc: 0.7080\n",
      "Epoch 147/1499\n",
      "----------\n",
      "train Loss: 0.9814 Acc: 0.7182\n",
      "val Loss: 0.9758 Acc: 0.7720\n",
      "test Loss: 0.9779 Acc: 0.7240\n",
      "Epoch 148/1499\n",
      "----------\n",
      "train Loss: 0.9792 Acc: 0.7202\n",
      "val Loss: 0.9722 Acc: 0.7480\n",
      "test Loss: 0.9758 Acc: 0.7360\n",
      "Epoch 149/1499\n",
      "----------\n",
      "train Loss: 0.9782 Acc: 0.7240\n",
      "val Loss: 0.9792 Acc: 0.7720\n",
      "test Loss: 0.9764 Acc: 0.7360\n",
      "Epoch 150/1499\n",
      "----------\n",
      "train Loss: 0.9758 Acc: 0.7213\n",
      "val Loss: 0.9738 Acc: 0.7400\n",
      "test Loss: 0.9705 Acc: 0.7320\n",
      "Epoch 151/1499\n",
      "----------\n",
      "train Loss: 0.9736 Acc: 0.7242\n",
      "val Loss: 0.9713 Acc: 0.7480\n",
      "test Loss: 0.9735 Acc: 0.7160\n",
      "Epoch 152/1499\n",
      "----------\n",
      "train Loss: 0.9727 Acc: 0.7242\n",
      "val Loss: 0.9653 Acc: 0.7760\n",
      "test Loss: 0.9763 Acc: 0.7320\n",
      "Epoch 153/1499\n",
      "----------\n",
      "train Loss: 0.9702 Acc: 0.7300\n",
      "val Loss: 0.9647 Acc: 0.7640\n",
      "test Loss: 0.9717 Acc: 0.7160\n",
      "Epoch 154/1499\n",
      "----------\n",
      "train Loss: 0.9689 Acc: 0.7322\n",
      "val Loss: 0.9635 Acc: 0.7720\n",
      "test Loss: 0.9724 Acc: 0.7240\n",
      "Epoch 155/1499\n",
      "----------\n",
      "train Loss: 0.9675 Acc: 0.7280\n",
      "val Loss: 0.9597 Acc: 0.7800\n",
      "test Loss: 0.9666 Acc: 0.7280\n",
      "Epoch 156/1499\n",
      "----------\n",
      "train Loss: 0.9654 Acc: 0.7356\n",
      "val Loss: 0.9685 Acc: 0.7280\n",
      "test Loss: 0.9642 Acc: 0.7320\n",
      "Epoch 157/1499\n",
      "----------\n",
      "train Loss: 0.9644 Acc: 0.7380\n",
      "val Loss: 0.9635 Acc: 0.7560\n",
      "test Loss: 0.9632 Acc: 0.7120\n",
      "Epoch 158/1499\n",
      "----------\n",
      "train Loss: 0.9633 Acc: 0.7362\n",
      "val Loss: 0.9583 Acc: 0.7640\n",
      "test Loss: 0.9680 Acc: 0.7360\n",
      "Epoch 159/1499\n",
      "----------\n",
      "train Loss: 0.9601 Acc: 0.7424\n",
      "val Loss: 0.9567 Acc: 0.7560\n",
      "test Loss: 0.9609 Acc: 0.7200\n",
      "Epoch 160/1499\n",
      "----------\n",
      "train Loss: 0.9582 Acc: 0.7411\n",
      "val Loss: 0.9540 Acc: 0.7560\n",
      "test Loss: 0.9557 Acc: 0.7440\n",
      "Epoch 161/1499\n",
      "----------\n",
      "train Loss: 0.9575 Acc: 0.7402\n",
      "val Loss: 0.9534 Acc: 0.7680\n",
      "test Loss: 0.9546 Acc: 0.7600\n",
      "Epoch 162/1499\n",
      "----------\n",
      "train Loss: 0.9558 Acc: 0.7444\n",
      "val Loss: 0.9498 Acc: 0.7840\n",
      "test Loss: 0.9509 Acc: 0.7480\n",
      "Epoch 163/1499\n",
      "----------\n",
      "train Loss: 0.9539 Acc: 0.7436\n",
      "val Loss: 0.9530 Acc: 0.7560\n",
      "test Loss: 0.9569 Acc: 0.7400\n",
      "Epoch 164/1499\n",
      "----------\n",
      "train Loss: 0.9525 Acc: 0.7456\n",
      "val Loss: 0.9472 Acc: 0.7880\n",
      "test Loss: 0.9488 Acc: 0.7680\n",
      "Epoch 165/1499\n",
      "----------\n",
      "train Loss: 0.9512 Acc: 0.7536\n",
      "val Loss: 0.9495 Acc: 0.7800\n",
      "test Loss: 0.9471 Acc: 0.7600\n",
      "Epoch 166/1499\n",
      "----------\n",
      "train Loss: 0.9489 Acc: 0.7513\n",
      "val Loss: 0.9480 Acc: 0.7520\n",
      "test Loss: 0.9473 Acc: 0.7840\n",
      "Epoch 167/1499\n",
      "----------\n",
      "train Loss: 0.9482 Acc: 0.7500\n",
      "val Loss: 0.9407 Acc: 0.7600\n",
      "test Loss: 0.9450 Acc: 0.7840\n",
      "Epoch 168/1499\n",
      "----------\n",
      "train Loss: 0.9446 Acc: 0.7636\n",
      "val Loss: 0.9468 Acc: 0.7680\n",
      "test Loss: 0.9482 Acc: 0.7600\n",
      "Epoch 169/1499\n",
      "----------\n",
      "train Loss: 0.9442 Acc: 0.7509\n",
      "val Loss: 0.9424 Acc: 0.7400\n",
      "test Loss: 0.9477 Acc: 0.7760\n",
      "Epoch 170/1499\n",
      "----------\n",
      "train Loss: 0.9424 Acc: 0.7562\n",
      "val Loss: 0.9393 Acc: 0.7680\n",
      "test Loss: 0.9407 Acc: 0.7800\n",
      "Epoch 171/1499\n",
      "----------\n",
      "train Loss: 0.9414 Acc: 0.7598\n",
      "val Loss: 0.9444 Acc: 0.7280\n",
      "test Loss: 0.9397 Acc: 0.8000\n",
      "Epoch 172/1499\n",
      "----------\n",
      "train Loss: 0.9399 Acc: 0.7631\n",
      "val Loss: 0.9359 Acc: 0.7480\n",
      "test Loss: 0.9405 Acc: 0.7560\n",
      "Epoch 173/1499\n",
      "----------\n",
      "train Loss: 0.9388 Acc: 0.7553\n",
      "val Loss: 0.9350 Acc: 0.7840\n",
      "test Loss: 0.9342 Acc: 0.7840\n",
      "Epoch 174/1499\n",
      "----------\n",
      "train Loss: 0.9354 Acc: 0.7642\n",
      "val Loss: 0.9306 Acc: 0.7720\n",
      "test Loss: 0.9322 Acc: 0.7720\n",
      "Epoch 175/1499\n",
      "----------\n",
      "train Loss: 0.9344 Acc: 0.7649\n",
      "val Loss: 0.9330 Acc: 0.7600\n",
      "test Loss: 0.9241 Acc: 0.8000\n",
      "Epoch 176/1499\n",
      "----------\n",
      "train Loss: 0.9333 Acc: 0.7660\n",
      "val Loss: 0.9324 Acc: 0.7600\n",
      "test Loss: 0.9330 Acc: 0.7600\n",
      "Epoch 177/1499\n",
      "----------\n",
      "train Loss: 0.9306 Acc: 0.7720\n",
      "val Loss: 0.9338 Acc: 0.7560\n",
      "test Loss: 0.9329 Acc: 0.7720\n",
      "Epoch 178/1499\n",
      "----------\n",
      "train Loss: 0.9302 Acc: 0.7689\n",
      "val Loss: 0.9235 Acc: 0.8000\n",
      "test Loss: 0.9286 Acc: 0.8080\n",
      "Epoch 179/1499\n",
      "----------\n",
      "train Loss: 0.9292 Acc: 0.7689\n",
      "val Loss: 0.9284 Acc: 0.7760\n",
      "test Loss: 0.9266 Acc: 0.7800\n",
      "Epoch 180/1499\n",
      "----------\n",
      "train Loss: 0.9286 Acc: 0.7662\n",
      "val Loss: 0.9326 Acc: 0.7600\n",
      "test Loss: 0.9228 Acc: 0.8040\n",
      "Epoch 181/1499\n",
      "----------\n",
      "train Loss: 0.9254 Acc: 0.7736\n",
      "val Loss: 0.9170 Acc: 0.7800\n",
      "test Loss: 0.9207 Acc: 0.8120\n",
      "Epoch 182/1499\n",
      "----------\n",
      "train Loss: 0.9229 Acc: 0.7771\n",
      "val Loss: 0.9236 Acc: 0.7840\n",
      "test Loss: 0.9226 Acc: 0.7920\n",
      "Epoch 183/1499\n",
      "----------\n",
      "train Loss: 0.9226 Acc: 0.7760\n",
      "val Loss: 0.9200 Acc: 0.7600\n",
      "test Loss: 0.9219 Acc: 0.8080\n",
      "Epoch 184/1499\n",
      "----------\n",
      "train Loss: 0.9208 Acc: 0.7729\n",
      "val Loss: 0.9233 Acc: 0.7880\n",
      "test Loss: 0.9235 Acc: 0.7920\n",
      "Epoch 185/1499\n",
      "----------\n",
      "train Loss: 0.9187 Acc: 0.7798\n",
      "val Loss: 0.9187 Acc: 0.7880\n",
      "test Loss: 0.9180 Acc: 0.8160\n",
      "Epoch 186/1499\n",
      "----------\n",
      "train Loss: 0.9169 Acc: 0.7820\n",
      "val Loss: 0.9216 Acc: 0.7600\n",
      "test Loss: 0.9181 Acc: 0.7840\n",
      "Epoch 187/1499\n",
      "----------\n",
      "train Loss: 0.9157 Acc: 0.7744\n",
      "val Loss: 0.9112 Acc: 0.7680\n",
      "test Loss: 0.9113 Acc: 0.8080\n",
      "Epoch 188/1499\n",
      "----------\n",
      "train Loss: 0.9146 Acc: 0.7802\n",
      "val Loss: 0.9216 Acc: 0.7440\n",
      "test Loss: 0.9170 Acc: 0.7920\n",
      "Epoch 189/1499\n",
      "----------\n",
      "train Loss: 0.9126 Acc: 0.7780\n",
      "val Loss: 0.9143 Acc: 0.7920\n",
      "test Loss: 0.9112 Acc: 0.8000\n",
      "Epoch 190/1499\n",
      "----------\n",
      "train Loss: 0.9124 Acc: 0.7778\n",
      "val Loss: 0.9125 Acc: 0.7600\n",
      "test Loss: 0.9052 Acc: 0.8040\n",
      "Epoch 191/1499\n",
      "----------\n",
      "train Loss: 0.9094 Acc: 0.7776\n",
      "val Loss: 0.9191 Acc: 0.7440\n",
      "test Loss: 0.9069 Acc: 0.8040\n",
      "Epoch 192/1499\n",
      "----------\n",
      "train Loss: 0.9074 Acc: 0.7791\n",
      "val Loss: 0.8986 Acc: 0.8080\n",
      "test Loss: 0.9064 Acc: 0.8040\n",
      "Epoch 193/1499\n",
      "----------\n",
      "train Loss: 0.9064 Acc: 0.7800\n",
      "val Loss: 0.9085 Acc: 0.7560\n",
      "test Loss: 0.9077 Acc: 0.8120\n",
      "Epoch 194/1499\n",
      "----------\n",
      "train Loss: 0.9045 Acc: 0.7876\n",
      "val Loss: 0.9026 Acc: 0.7680\n",
      "test Loss: 0.9050 Acc: 0.7920\n",
      "Epoch 195/1499\n",
      "----------\n",
      "train Loss: 0.9034 Acc: 0.7816\n",
      "val Loss: 0.9005 Acc: 0.7840\n",
      "test Loss: 0.9055 Acc: 0.7960\n",
      "Epoch 196/1499\n",
      "----------\n",
      "train Loss: 0.9000 Acc: 0.7816\n",
      "val Loss: 0.8933 Acc: 0.7880\n",
      "test Loss: 0.8942 Acc: 0.8080\n",
      "Epoch 197/1499\n",
      "----------\n",
      "train Loss: 0.8990 Acc: 0.7862\n",
      "val Loss: 0.9003 Acc: 0.8000\n",
      "test Loss: 0.8985 Acc: 0.8040\n",
      "Epoch 198/1499\n",
      "----------\n",
      "train Loss: 0.8976 Acc: 0.7820\n",
      "val Loss: 0.9035 Acc: 0.7720\n",
      "test Loss: 0.8916 Acc: 0.8040\n",
      "Epoch 199/1499\n",
      "----------\n",
      "train Loss: 0.8965 Acc: 0.7820\n",
      "val Loss: 0.8956 Acc: 0.7960\n",
      "test Loss: 0.8965 Acc: 0.7920\n",
      "Epoch 200/1499\n",
      "----------\n",
      "train Loss: 0.8961 Acc: 0.7773\n",
      "val Loss: 0.8912 Acc: 0.7720\n",
      "test Loss: 0.8839 Acc: 0.8240\n",
      "Epoch 201/1499\n",
      "----------\n",
      "train Loss: 0.8933 Acc: 0.7873\n",
      "val Loss: 0.8874 Acc: 0.8000\n",
      "test Loss: 0.8903 Acc: 0.8320\n",
      "Epoch 202/1499\n",
      "----------\n",
      "train Loss: 0.8934 Acc: 0.7833\n",
      "val Loss: 0.8911 Acc: 0.7720\n",
      "test Loss: 0.8902 Acc: 0.8040\n",
      "Epoch 203/1499\n",
      "----------\n",
      "train Loss: 0.8920 Acc: 0.7849\n",
      "val Loss: 0.8850 Acc: 0.8000\n",
      "test Loss: 0.8895 Acc: 0.7920\n",
      "Epoch 204/1499\n",
      "----------\n",
      "train Loss: 0.8892 Acc: 0.7882\n",
      "val Loss: 0.8932 Acc: 0.7680\n",
      "test Loss: 0.8823 Acc: 0.8200\n",
      "Epoch 205/1499\n",
      "----------\n",
      "train Loss: 0.8887 Acc: 0.7816\n",
      "val Loss: 0.8912 Acc: 0.7720\n",
      "test Loss: 0.8842 Acc: 0.8000\n",
      "Epoch 206/1499\n",
      "----------\n",
      "train Loss: 0.8883 Acc: 0.7791\n",
      "val Loss: 0.8892 Acc: 0.7920\n",
      "test Loss: 0.8795 Acc: 0.8280\n",
      "Epoch 207/1499\n",
      "----------\n",
      "train Loss: 0.8845 Acc: 0.7853\n",
      "val Loss: 0.8840 Acc: 0.7680\n",
      "test Loss: 0.8880 Acc: 0.7640\n",
      "Epoch 208/1499\n",
      "----------\n",
      "train Loss: 0.8823 Acc: 0.7911\n",
      "val Loss: 0.8947 Acc: 0.7560\n",
      "test Loss: 0.8853 Acc: 0.8000\n",
      "Epoch 209/1499\n",
      "----------\n",
      "train Loss: 0.8821 Acc: 0.7856\n",
      "val Loss: 0.8830 Acc: 0.7840\n",
      "test Loss: 0.8729 Acc: 0.8080\n",
      "Epoch 210/1499\n",
      "----------\n",
      "train Loss: 0.8817 Acc: 0.7798\n",
      "val Loss: 0.8855 Acc: 0.7840\n",
      "test Loss: 0.8770 Acc: 0.8120\n",
      "Epoch 211/1499\n",
      "----------\n",
      "train Loss: 0.8800 Acc: 0.7798\n",
      "val Loss: 0.8891 Acc: 0.7440\n",
      "test Loss: 0.8804 Acc: 0.7920\n",
      "Epoch 212/1499\n",
      "----------\n",
      "train Loss: 0.8771 Acc: 0.7898\n",
      "val Loss: 0.8794 Acc: 0.7800\n",
      "test Loss: 0.8659 Acc: 0.8040\n",
      "Epoch 213/1499\n",
      "----------\n",
      "train Loss: 0.8776 Acc: 0.7844\n",
      "val Loss: 0.8853 Acc: 0.7520\n",
      "test Loss: 0.8736 Acc: 0.8000\n",
      "Epoch 214/1499\n",
      "----------\n",
      "train Loss: 0.8762 Acc: 0.7787\n",
      "val Loss: 0.8764 Acc: 0.7760\n",
      "test Loss: 0.8717 Acc: 0.8080\n",
      "Epoch 215/1499\n",
      "----------\n",
      "train Loss: 0.8721 Acc: 0.7893\n",
      "val Loss: 0.8705 Acc: 0.7960\n",
      "test Loss: 0.8680 Acc: 0.8120\n",
      "Epoch 216/1499\n",
      "----------\n",
      "train Loss: 0.8734 Acc: 0.7791\n",
      "val Loss: 0.8624 Acc: 0.7880\n",
      "test Loss: 0.8705 Acc: 0.8120\n",
      "Epoch 217/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.8722 Acc: 0.7789\n",
      "val Loss: 0.8771 Acc: 0.7680\n",
      "test Loss: 0.8732 Acc: 0.7680\n",
      "Epoch 218/1499\n",
      "----------\n",
      "train Loss: 0.8706 Acc: 0.7864\n",
      "val Loss: 0.8800 Acc: 0.7560\n",
      "test Loss: 0.8600 Acc: 0.8080\n",
      "Epoch 219/1499\n",
      "----------\n",
      "train Loss: 0.8664 Acc: 0.7878\n",
      "val Loss: 0.8693 Acc: 0.7840\n",
      "test Loss: 0.8618 Acc: 0.7960\n",
      "Epoch 220/1499\n",
      "----------\n",
      "train Loss: 0.8643 Acc: 0.7904\n",
      "val Loss: 0.8720 Acc: 0.7640\n",
      "test Loss: 0.8571 Acc: 0.8160\n",
      "Epoch 221/1499\n",
      "----------\n",
      "train Loss: 0.8656 Acc: 0.7811\n",
      "val Loss: 0.8727 Acc: 0.7720\n",
      "test Loss: 0.8598 Acc: 0.7960\n",
      "Epoch 222/1499\n",
      "----------\n",
      "train Loss: 0.8638 Acc: 0.7849\n",
      "val Loss: 0.8685 Acc: 0.7800\n",
      "test Loss: 0.8637 Acc: 0.7880\n",
      "Epoch 223/1499\n",
      "----------\n",
      "train Loss: 0.8622 Acc: 0.7869\n",
      "val Loss: 0.8599 Acc: 0.8000\n",
      "test Loss: 0.8588 Acc: 0.7960\n",
      "Epoch 224/1499\n",
      "----------\n",
      "train Loss: 0.8612 Acc: 0.7871\n",
      "val Loss: 0.8800 Acc: 0.7480\n",
      "test Loss: 0.8543 Acc: 0.8240\n",
      "Epoch 225/1499\n",
      "----------\n",
      "train Loss: 0.8590 Acc: 0.7860\n",
      "val Loss: 0.8573 Acc: 0.7800\n",
      "test Loss: 0.8570 Acc: 0.8080\n",
      "Epoch 226/1499\n",
      "----------\n",
      "train Loss: 0.8573 Acc: 0.7876\n",
      "val Loss: 0.8642 Acc: 0.7640\n",
      "test Loss: 0.8461 Acc: 0.8000\n",
      "Epoch 227/1499\n",
      "----------\n",
      "train Loss: 0.8556 Acc: 0.7942\n",
      "val Loss: 0.8621 Acc: 0.7680\n",
      "test Loss: 0.8559 Acc: 0.8120\n",
      "Epoch 228/1499\n",
      "----------\n",
      "train Loss: 0.8564 Acc: 0.7893\n",
      "val Loss: 0.8585 Acc: 0.7840\n",
      "test Loss: 0.8508 Acc: 0.8040\n",
      "Epoch 229/1499\n",
      "----------\n",
      "train Loss: 0.8529 Acc: 0.7884\n",
      "val Loss: 0.8523 Acc: 0.7800\n",
      "test Loss: 0.8589 Acc: 0.8080\n",
      "Epoch 230/1499\n",
      "----------\n",
      "train Loss: 0.8528 Acc: 0.7864\n",
      "val Loss: 0.8572 Acc: 0.7680\n",
      "test Loss: 0.8390 Acc: 0.8160\n",
      "Epoch 231/1499\n",
      "----------\n",
      "train Loss: 0.8517 Acc: 0.7818\n",
      "val Loss: 0.8623 Acc: 0.7720\n",
      "test Loss: 0.8382 Acc: 0.8240\n",
      "Epoch 232/1499\n",
      "----------\n",
      "train Loss: 0.8505 Acc: 0.7851\n",
      "val Loss: 0.8495 Acc: 0.7840\n",
      "test Loss: 0.8433 Acc: 0.8080\n",
      "Epoch 233/1499\n",
      "----------\n",
      "train Loss: 0.8484 Acc: 0.7860\n",
      "val Loss: 0.8585 Acc: 0.7520\n",
      "test Loss: 0.8448 Acc: 0.8120\n",
      "Epoch 234/1499\n",
      "----------\n",
      "train Loss: 0.8465 Acc: 0.7878\n",
      "val Loss: 0.8553 Acc: 0.7600\n",
      "test Loss: 0.8419 Acc: 0.8080\n",
      "Epoch 235/1499\n",
      "----------\n",
      "train Loss: 0.8450 Acc: 0.7916\n",
      "val Loss: 0.8492 Acc: 0.7840\n",
      "test Loss: 0.8329 Acc: 0.8320\n",
      "Epoch 236/1499\n",
      "----------\n",
      "train Loss: 0.8449 Acc: 0.7891\n",
      "val Loss: 0.8498 Acc: 0.7600\n",
      "test Loss: 0.8361 Acc: 0.8240\n",
      "Epoch 237/1499\n",
      "----------\n",
      "train Loss: 0.8429 Acc: 0.7900\n",
      "val Loss: 0.8398 Acc: 0.8040\n",
      "test Loss: 0.8357 Acc: 0.8120\n",
      "Epoch 238/1499\n",
      "----------\n",
      "train Loss: 0.8418 Acc: 0.7876\n",
      "val Loss: 0.8539 Acc: 0.7560\n",
      "test Loss: 0.8424 Acc: 0.7920\n",
      "Epoch 239/1499\n",
      "----------\n",
      "train Loss: 0.8403 Acc: 0.7911\n",
      "val Loss: 0.8441 Acc: 0.7680\n",
      "test Loss: 0.8410 Acc: 0.8080\n",
      "Epoch 240/1499\n",
      "----------\n",
      "train Loss: 0.8374 Acc: 0.7920\n",
      "val Loss: 0.8370 Acc: 0.7680\n",
      "test Loss: 0.8325 Acc: 0.8200\n",
      "Epoch 241/1499\n",
      "----------\n",
      "train Loss: 0.8383 Acc: 0.7878\n",
      "val Loss: 0.8381 Acc: 0.7760\n",
      "test Loss: 0.8344 Acc: 0.7920\n",
      "Epoch 242/1499\n",
      "----------\n",
      "train Loss: 0.8363 Acc: 0.7880\n",
      "val Loss: 0.8508 Acc: 0.7520\n",
      "test Loss: 0.8209 Acc: 0.8320\n",
      "Epoch 243/1499\n",
      "----------\n",
      "train Loss: 0.8358 Acc: 0.7902\n",
      "val Loss: 0.8338 Acc: 0.7920\n",
      "test Loss: 0.8294 Acc: 0.8040\n",
      "Epoch 244/1499\n",
      "----------\n",
      "train Loss: 0.8353 Acc: 0.7876\n",
      "val Loss: 0.8354 Acc: 0.7920\n",
      "test Loss: 0.8258 Acc: 0.8320\n",
      "Epoch 245/1499\n",
      "----------\n",
      "train Loss: 0.8337 Acc: 0.7951\n",
      "val Loss: 0.8430 Acc: 0.7800\n",
      "test Loss: 0.8314 Acc: 0.8240\n",
      "Epoch 246/1499\n",
      "----------\n",
      "train Loss: 0.8323 Acc: 0.7889\n",
      "val Loss: 0.8254 Acc: 0.7760\n",
      "test Loss: 0.8143 Acc: 0.8400\n",
      "Epoch 247/1499\n",
      "----------\n",
      "train Loss: 0.8295 Acc: 0.7956\n",
      "val Loss: 0.8315 Acc: 0.7760\n",
      "test Loss: 0.8234 Acc: 0.8160\n",
      "Epoch 248/1499\n",
      "----------\n",
      "train Loss: 0.8281 Acc: 0.7953\n",
      "val Loss: 0.8391 Acc: 0.7520\n",
      "test Loss: 0.8175 Acc: 0.8200\n",
      "Epoch 249/1499\n",
      "----------\n",
      "train Loss: 0.8263 Acc: 0.7967\n",
      "val Loss: 0.8279 Acc: 0.7680\n",
      "test Loss: 0.8220 Acc: 0.8080\n",
      "Epoch 250/1499\n",
      "----------\n",
      "train Loss: 0.8264 Acc: 0.7920\n",
      "val Loss: 0.8309 Acc: 0.7520\n",
      "test Loss: 0.8159 Acc: 0.8200\n",
      "Epoch 251/1499\n",
      "----------\n",
      "train Loss: 0.8270 Acc: 0.7904\n",
      "val Loss: 0.8191 Acc: 0.7920\n",
      "test Loss: 0.8202 Acc: 0.8200\n",
      "Epoch 252/1499\n",
      "----------\n",
      "train Loss: 0.8236 Acc: 0.7933\n",
      "val Loss: 0.8390 Acc: 0.7760\n",
      "test Loss: 0.8186 Acc: 0.8200\n",
      "Epoch 253/1499\n",
      "----------\n",
      "train Loss: 0.8224 Acc: 0.7969\n",
      "val Loss: 0.8269 Acc: 0.7720\n",
      "test Loss: 0.8147 Acc: 0.8080\n",
      "Epoch 254/1499\n",
      "----------\n",
      "train Loss: 0.8226 Acc: 0.7958\n",
      "val Loss: 0.8263 Acc: 0.7840\n",
      "test Loss: 0.8180 Acc: 0.8120\n",
      "Epoch 255/1499\n",
      "----------\n",
      "train Loss: 0.8231 Acc: 0.7891\n",
      "val Loss: 0.8327 Acc: 0.7560\n",
      "test Loss: 0.8044 Acc: 0.8320\n",
      "Epoch 256/1499\n",
      "----------\n",
      "train Loss: 0.8203 Acc: 0.7929\n",
      "val Loss: 0.8255 Acc: 0.7840\n",
      "test Loss: 0.8113 Acc: 0.8240\n",
      "Epoch 257/1499\n",
      "----------\n",
      "train Loss: 0.8197 Acc: 0.7953\n",
      "val Loss: 0.8268 Acc: 0.7600\n",
      "test Loss: 0.8127 Acc: 0.8320\n",
      "Epoch 258/1499\n",
      "----------\n",
      "train Loss: 0.8175 Acc: 0.7944\n",
      "val Loss: 0.8215 Acc: 0.7760\n",
      "test Loss: 0.8065 Acc: 0.8480\n",
      "Epoch 259/1499\n",
      "----------\n",
      "train Loss: 0.8163 Acc: 0.7918\n",
      "val Loss: 0.8215 Acc: 0.7760\n",
      "test Loss: 0.8136 Acc: 0.8040\n",
      "Epoch 260/1499\n",
      "----------\n",
      "train Loss: 0.8182 Acc: 0.7922\n",
      "val Loss: 0.8208 Acc: 0.7680\n",
      "test Loss: 0.8145 Acc: 0.7920\n",
      "Epoch 261/1499\n",
      "----------\n",
      "train Loss: 0.8132 Acc: 0.7944\n",
      "val Loss: 0.8240 Acc: 0.7760\n",
      "test Loss: 0.8152 Acc: 0.8080\n",
      "Epoch 262/1499\n",
      "----------\n",
      "train Loss: 0.8144 Acc: 0.7876\n",
      "val Loss: 0.8201 Acc: 0.7600\n",
      "test Loss: 0.8144 Acc: 0.8080\n",
      "Epoch 263/1499\n",
      "----------\n",
      "train Loss: 0.8148 Acc: 0.7962\n",
      "val Loss: 0.8134 Acc: 0.7920\n",
      "test Loss: 0.8039 Acc: 0.8240\n",
      "Epoch 264/1499\n",
      "----------\n",
      "train Loss: 0.8108 Acc: 0.7980\n",
      "val Loss: 0.8118 Acc: 0.7760\n",
      "test Loss: 0.8054 Acc: 0.8240\n",
      "Epoch 265/1499\n",
      "----------\n",
      "train Loss: 0.8110 Acc: 0.7891\n",
      "val Loss: 0.8153 Acc: 0.7720\n",
      "test Loss: 0.8101 Acc: 0.8040\n",
      "Epoch 266/1499\n",
      "----------\n",
      "train Loss: 0.8082 Acc: 0.8002\n",
      "val Loss: 0.8118 Acc: 0.7760\n",
      "test Loss: 0.8002 Acc: 0.8280\n",
      "Epoch 267/1499\n",
      "----------\n",
      "train Loss: 0.8096 Acc: 0.7938\n",
      "val Loss: 0.8127 Acc: 0.7960\n",
      "test Loss: 0.7965 Acc: 0.8240\n",
      "Epoch 268/1499\n",
      "----------\n",
      "train Loss: 0.8062 Acc: 0.8007\n",
      "val Loss: 0.8121 Acc: 0.7800\n",
      "test Loss: 0.8027 Acc: 0.8040\n",
      "Epoch 269/1499\n",
      "----------\n",
      "train Loss: 0.8048 Acc: 0.7947\n",
      "val Loss: 0.8208 Acc: 0.7600\n",
      "test Loss: 0.8053 Acc: 0.8080\n",
      "Epoch 270/1499\n",
      "----------\n",
      "train Loss: 0.8032 Acc: 0.7976\n",
      "val Loss: 0.8112 Acc: 0.7760\n",
      "test Loss: 0.7992 Acc: 0.8200\n",
      "Epoch 271/1499\n",
      "----------\n",
      "train Loss: 0.8039 Acc: 0.7967\n",
      "val Loss: 0.8066 Acc: 0.7800\n",
      "test Loss: 0.7984 Acc: 0.8040\n",
      "Epoch 272/1499\n",
      "----------\n",
      "train Loss: 0.8014 Acc: 0.7984\n",
      "val Loss: 0.8021 Acc: 0.7880\n",
      "test Loss: 0.7999 Acc: 0.8200\n",
      "Epoch 273/1499\n",
      "----------\n",
      "train Loss: 0.8007 Acc: 0.8000\n",
      "val Loss: 0.8072 Acc: 0.7760\n",
      "test Loss: 0.7923 Acc: 0.8360\n",
      "Epoch 274/1499\n",
      "----------\n",
      "train Loss: 0.8027 Acc: 0.7984\n",
      "val Loss: 0.8115 Acc: 0.7440\n",
      "test Loss: 0.7925 Acc: 0.8280\n",
      "Epoch 275/1499\n",
      "----------\n",
      "train Loss: 0.8009 Acc: 0.8038\n",
      "val Loss: 0.8083 Acc: 0.7720\n",
      "test Loss: 0.7917 Acc: 0.8240\n",
      "Epoch 276/1499\n",
      "----------\n",
      "train Loss: 0.7991 Acc: 0.8082\n",
      "val Loss: 0.8012 Acc: 0.7880\n",
      "test Loss: 0.7945 Acc: 0.8240\n",
      "Epoch 277/1499\n",
      "----------\n",
      "train Loss: 0.7992 Acc: 0.8067\n",
      "val Loss: 0.8127 Acc: 0.7640\n",
      "test Loss: 0.7907 Acc: 0.8360\n",
      "Epoch 278/1499\n",
      "----------\n",
      "train Loss: 0.7964 Acc: 0.8104\n",
      "val Loss: 0.8117 Acc: 0.7840\n",
      "test Loss: 0.7930 Acc: 0.8200\n",
      "Epoch 279/1499\n",
      "----------\n",
      "train Loss: 0.7934 Acc: 0.8124\n",
      "val Loss: 0.8078 Acc: 0.7920\n",
      "test Loss: 0.7872 Acc: 0.8320\n",
      "Epoch 280/1499\n",
      "----------\n",
      "train Loss: 0.7935 Acc: 0.8096\n",
      "val Loss: 0.8054 Acc: 0.7920\n",
      "test Loss: 0.7871 Acc: 0.8320\n",
      "Epoch 281/1499\n",
      "----------\n",
      "train Loss: 0.7935 Acc: 0.8109\n",
      "val Loss: 0.7882 Acc: 0.7920\n",
      "test Loss: 0.7765 Acc: 0.8400\n",
      "Epoch 282/1499\n",
      "----------\n",
      "train Loss: 0.7917 Acc: 0.8124\n",
      "val Loss: 0.8052 Acc: 0.7920\n",
      "test Loss: 0.7839 Acc: 0.8280\n",
      "Epoch 283/1499\n",
      "----------\n",
      "train Loss: 0.7936 Acc: 0.8056\n",
      "val Loss: 0.8051 Acc: 0.7760\n",
      "test Loss: 0.7821 Acc: 0.8320\n",
      "Epoch 284/1499\n",
      "----------\n",
      "train Loss: 0.7932 Acc: 0.8116\n",
      "val Loss: 0.7954 Acc: 0.8000\n",
      "test Loss: 0.7899 Acc: 0.8280\n",
      "Epoch 285/1499\n",
      "----------\n",
      "train Loss: 0.7900 Acc: 0.8122\n",
      "val Loss: 0.8146 Acc: 0.7840\n",
      "test Loss: 0.7728 Acc: 0.8400\n",
      "Epoch 286/1499\n",
      "----------\n",
      "train Loss: 0.7869 Acc: 0.8151\n",
      "val Loss: 0.7953 Acc: 0.7880\n",
      "test Loss: 0.7799 Acc: 0.8440\n",
      "Epoch 287/1499\n",
      "----------\n",
      "train Loss: 0.7863 Acc: 0.8131\n",
      "val Loss: 0.7895 Acc: 0.7920\n",
      "test Loss: 0.7739 Acc: 0.8320\n",
      "Epoch 288/1499\n",
      "----------\n",
      "train Loss: 0.7863 Acc: 0.8113\n",
      "val Loss: 0.7810 Acc: 0.8080\n",
      "test Loss: 0.7853 Acc: 0.8240\n",
      "Epoch 289/1499\n",
      "----------\n",
      "train Loss: 0.7866 Acc: 0.8120\n",
      "val Loss: 0.7840 Acc: 0.7880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.7786 Acc: 0.8400\n",
      "Epoch 290/1499\n",
      "----------\n",
      "train Loss: 0.7837 Acc: 0.8171\n",
      "val Loss: 0.7912 Acc: 0.7960\n",
      "test Loss: 0.7706 Acc: 0.8400\n",
      "Epoch 291/1499\n",
      "----------\n",
      "train Loss: 0.7824 Acc: 0.8156\n",
      "val Loss: 0.7861 Acc: 0.8000\n",
      "test Loss: 0.7757 Acc: 0.8320\n",
      "Epoch 292/1499\n",
      "----------\n",
      "train Loss: 0.7817 Acc: 0.8158\n",
      "val Loss: 0.7926 Acc: 0.7960\n",
      "test Loss: 0.7724 Acc: 0.8320\n",
      "Epoch 293/1499\n",
      "----------\n",
      "train Loss: 0.7795 Acc: 0.8147\n",
      "val Loss: 0.7936 Acc: 0.8000\n",
      "test Loss: 0.7789 Acc: 0.8120\n",
      "Epoch 294/1499\n",
      "----------\n",
      "train Loss: 0.7823 Acc: 0.8122\n",
      "val Loss: 0.7987 Acc: 0.7840\n",
      "test Loss: 0.7644 Acc: 0.8440\n",
      "Epoch 295/1499\n",
      "----------\n",
      "train Loss: 0.7809 Acc: 0.8142\n",
      "val Loss: 0.7877 Acc: 0.7920\n",
      "test Loss: 0.7694 Acc: 0.8160\n",
      "Epoch 296/1499\n",
      "----------\n",
      "train Loss: 0.7767 Acc: 0.8187\n",
      "val Loss: 0.7880 Acc: 0.7840\n",
      "test Loss: 0.7728 Acc: 0.8480\n",
      "Epoch 297/1499\n",
      "----------\n",
      "train Loss: 0.7787 Acc: 0.8164\n",
      "val Loss: 0.7869 Acc: 0.7920\n",
      "test Loss: 0.7635 Acc: 0.8320\n",
      "Epoch 298/1499\n",
      "----------\n",
      "train Loss: 0.7772 Acc: 0.8151\n",
      "val Loss: 0.7850 Acc: 0.7880\n",
      "test Loss: 0.7684 Acc: 0.8480\n",
      "Epoch 299/1499\n",
      "----------\n",
      "train Loss: 0.7755 Acc: 0.8142\n",
      "val Loss: 0.7835 Acc: 0.8000\n",
      "test Loss: 0.7579 Acc: 0.8480\n",
      "Epoch 300/1499\n",
      "----------\n",
      "train Loss: 0.7756 Acc: 0.8180\n",
      "val Loss: 0.7776 Acc: 0.8080\n",
      "test Loss: 0.7626 Acc: 0.8440\n",
      "Epoch 301/1499\n",
      "----------\n",
      "train Loss: 0.7712 Acc: 0.8167\n",
      "val Loss: 0.7766 Acc: 0.7960\n",
      "test Loss: 0.7635 Acc: 0.8480\n",
      "Epoch 302/1499\n",
      "----------\n",
      "train Loss: 0.7746 Acc: 0.8180\n",
      "val Loss: 0.7698 Acc: 0.8000\n",
      "test Loss: 0.7632 Acc: 0.8360\n",
      "Epoch 303/1499\n",
      "----------\n",
      "train Loss: 0.7710 Acc: 0.8176\n",
      "val Loss: 0.7777 Acc: 0.8000\n",
      "test Loss: 0.7542 Acc: 0.8400\n",
      "Epoch 304/1499\n",
      "----------\n",
      "train Loss: 0.7698 Acc: 0.8164\n",
      "val Loss: 0.7795 Acc: 0.8000\n",
      "test Loss: 0.7632 Acc: 0.8320\n",
      "Epoch 305/1499\n",
      "----------\n",
      "train Loss: 0.7700 Acc: 0.8216\n",
      "val Loss: 0.7709 Acc: 0.8240\n",
      "test Loss: 0.7728 Acc: 0.8240\n",
      "Epoch 306/1499\n",
      "----------\n",
      "train Loss: 0.7700 Acc: 0.8202\n",
      "val Loss: 0.7833 Acc: 0.8000\n",
      "test Loss: 0.7644 Acc: 0.8400\n",
      "Epoch 307/1499\n",
      "----------\n",
      "train Loss: 0.7693 Acc: 0.8167\n",
      "val Loss: 0.7794 Acc: 0.7920\n",
      "test Loss: 0.7569 Acc: 0.8320\n",
      "Epoch 308/1499\n",
      "----------\n",
      "train Loss: 0.7684 Acc: 0.8162\n",
      "val Loss: 0.7872 Acc: 0.7880\n",
      "test Loss: 0.7567 Acc: 0.8360\n",
      "Epoch 309/1499\n",
      "----------\n",
      "train Loss: 0.7680 Acc: 0.8202\n",
      "val Loss: 0.7703 Acc: 0.8040\n",
      "test Loss: 0.7588 Acc: 0.8280\n",
      "Epoch 310/1499\n",
      "----------\n",
      "train Loss: 0.7679 Acc: 0.8184\n",
      "val Loss: 0.7713 Acc: 0.8080\n",
      "test Loss: 0.7550 Acc: 0.8400\n",
      "Epoch 311/1499\n",
      "----------\n",
      "train Loss: 0.7649 Acc: 0.8209\n",
      "val Loss: 0.7802 Acc: 0.7960\n",
      "test Loss: 0.7563 Acc: 0.8320\n",
      "Epoch 312/1499\n",
      "----------\n",
      "train Loss: 0.7645 Acc: 0.8222\n",
      "val Loss: 0.7777 Acc: 0.7880\n",
      "test Loss: 0.7590 Acc: 0.8360\n",
      "Epoch 313/1499\n",
      "----------\n",
      "train Loss: 0.7620 Acc: 0.8220\n",
      "val Loss: 0.7788 Acc: 0.7920\n",
      "test Loss: 0.7615 Acc: 0.8240\n",
      "Epoch 314/1499\n",
      "----------\n",
      "train Loss: 0.7657 Acc: 0.8180\n",
      "val Loss: 0.7746 Acc: 0.8000\n",
      "test Loss: 0.7439 Acc: 0.8400\n",
      "Epoch 315/1499\n",
      "----------\n",
      "train Loss: 0.7616 Acc: 0.8204\n",
      "val Loss: 0.7592 Acc: 0.8160\n",
      "test Loss: 0.7529 Acc: 0.8120\n",
      "Epoch 316/1499\n",
      "----------\n",
      "train Loss: 0.7599 Acc: 0.8202\n",
      "val Loss: 0.7770 Acc: 0.7960\n",
      "test Loss: 0.7477 Acc: 0.8440\n",
      "Epoch 317/1499\n",
      "----------\n",
      "train Loss: 0.7601 Acc: 0.8251\n",
      "val Loss: 0.7641 Acc: 0.8160\n",
      "test Loss: 0.7615 Acc: 0.8240\n",
      "Epoch 318/1499\n",
      "----------\n",
      "train Loss: 0.7625 Acc: 0.8182\n",
      "val Loss: 0.7743 Acc: 0.7920\n",
      "test Loss: 0.7464 Acc: 0.8320\n",
      "Epoch 319/1499\n",
      "----------\n",
      "train Loss: 0.7587 Acc: 0.8218\n",
      "val Loss: 0.7736 Acc: 0.8120\n",
      "test Loss: 0.7477 Acc: 0.8280\n",
      "Epoch 320/1499\n",
      "----------\n",
      "train Loss: 0.7619 Acc: 0.8160\n",
      "val Loss: 0.7689 Acc: 0.8160\n",
      "test Loss: 0.7578 Acc: 0.8360\n",
      "Epoch 321/1499\n",
      "----------\n",
      "train Loss: 0.7588 Acc: 0.8187\n",
      "val Loss: 0.7683 Acc: 0.8040\n",
      "test Loss: 0.7508 Acc: 0.8320\n",
      "Epoch 322/1499\n",
      "----------\n",
      "train Loss: 0.7543 Acc: 0.8227\n",
      "val Loss: 0.7545 Acc: 0.8160\n",
      "test Loss: 0.7506 Acc: 0.8240\n",
      "Epoch 323/1499\n",
      "----------\n",
      "train Loss: 0.7549 Acc: 0.8227\n",
      "val Loss: 0.7633 Acc: 0.8080\n",
      "test Loss: 0.7363 Acc: 0.8440\n",
      "Epoch 324/1499\n",
      "----------\n",
      "train Loss: 0.7525 Acc: 0.8258\n",
      "val Loss: 0.7659 Acc: 0.8000\n",
      "test Loss: 0.7474 Acc: 0.8360\n",
      "Epoch 325/1499\n",
      "----------\n",
      "train Loss: 0.7539 Acc: 0.8224\n",
      "val Loss: 0.7638 Acc: 0.8160\n",
      "test Loss: 0.7301 Acc: 0.8400\n",
      "Epoch 326/1499\n",
      "----------\n",
      "train Loss: 0.7514 Acc: 0.8204\n",
      "val Loss: 0.7627 Acc: 0.8080\n",
      "test Loss: 0.7493 Acc: 0.8120\n",
      "Epoch 327/1499\n",
      "----------\n",
      "train Loss: 0.7533 Acc: 0.8227\n",
      "val Loss: 0.7720 Acc: 0.7920\n",
      "test Loss: 0.7409 Acc: 0.8360\n",
      "Epoch 328/1499\n",
      "----------\n",
      "train Loss: 0.7537 Acc: 0.8189\n",
      "val Loss: 0.7572 Acc: 0.8120\n",
      "test Loss: 0.7319 Acc: 0.8360\n",
      "Epoch 329/1499\n",
      "----------\n",
      "train Loss: 0.7497 Acc: 0.8220\n",
      "val Loss: 0.7606 Acc: 0.8120\n",
      "test Loss: 0.7361 Acc: 0.8440\n",
      "Epoch 330/1499\n",
      "----------\n",
      "train Loss: 0.7518 Acc: 0.8213\n",
      "val Loss: 0.7609 Acc: 0.8160\n",
      "test Loss: 0.7340 Acc: 0.8440\n",
      "Epoch 331/1499\n",
      "----------\n",
      "train Loss: 0.7471 Acc: 0.8244\n",
      "val Loss: 0.7576 Acc: 0.8000\n",
      "test Loss: 0.7376 Acc: 0.8560\n",
      "Epoch 332/1499\n",
      "----------\n",
      "train Loss: 0.7479 Acc: 0.8218\n",
      "val Loss: 0.7571 Acc: 0.8080\n",
      "test Loss: 0.7379 Acc: 0.8400\n",
      "Epoch 333/1499\n",
      "----------\n",
      "train Loss: 0.7463 Acc: 0.8262\n",
      "val Loss: 0.7606 Acc: 0.7960\n",
      "test Loss: 0.7342 Acc: 0.8400\n",
      "Epoch 334/1499\n",
      "----------\n",
      "train Loss: 0.7478 Acc: 0.8193\n",
      "val Loss: 0.7503 Acc: 0.8160\n",
      "test Loss: 0.7303 Acc: 0.8400\n",
      "Epoch 335/1499\n",
      "----------\n",
      "train Loss: 0.7493 Acc: 0.8178\n",
      "val Loss: 0.7519 Acc: 0.8240\n",
      "test Loss: 0.7427 Acc: 0.8360\n",
      "Epoch 336/1499\n",
      "----------\n",
      "train Loss: 0.7468 Acc: 0.8196\n",
      "val Loss: 0.7576 Acc: 0.8000\n",
      "test Loss: 0.7342 Acc: 0.8400\n",
      "Epoch 337/1499\n",
      "----------\n",
      "train Loss: 0.7445 Acc: 0.8249\n",
      "val Loss: 0.7524 Acc: 0.8080\n",
      "test Loss: 0.7265 Acc: 0.8520\n",
      "Epoch 338/1499\n",
      "----------\n",
      "train Loss: 0.7463 Acc: 0.8227\n",
      "val Loss: 0.7571 Acc: 0.8080\n",
      "test Loss: 0.7264 Acc: 0.8400\n",
      "Epoch 339/1499\n",
      "----------\n",
      "train Loss: 0.7451 Acc: 0.8202\n",
      "val Loss: 0.7456 Acc: 0.8240\n",
      "test Loss: 0.7344 Acc: 0.8440\n",
      "Epoch 340/1499\n",
      "----------\n",
      "train Loss: 0.7451 Acc: 0.8242\n",
      "val Loss: 0.7542 Acc: 0.7960\n",
      "test Loss: 0.7372 Acc: 0.8400\n",
      "Epoch 341/1499\n",
      "----------\n",
      "train Loss: 0.7431 Acc: 0.8247\n",
      "val Loss: 0.7500 Acc: 0.8120\n",
      "test Loss: 0.7257 Acc: 0.8480\n",
      "Epoch 342/1499\n",
      "----------\n",
      "train Loss: 0.7408 Acc: 0.8282\n",
      "val Loss: 0.7428 Acc: 0.8320\n",
      "test Loss: 0.7356 Acc: 0.8360\n",
      "Epoch 343/1499\n",
      "----------\n",
      "train Loss: 0.7430 Acc: 0.8249\n",
      "val Loss: 0.7465 Acc: 0.8280\n",
      "test Loss: 0.7307 Acc: 0.8400\n",
      "Epoch 344/1499\n",
      "----------\n",
      "train Loss: 0.7407 Acc: 0.8264\n",
      "val Loss: 0.7540 Acc: 0.7960\n",
      "test Loss: 0.7296 Acc: 0.8480\n",
      "Epoch 345/1499\n",
      "----------\n",
      "train Loss: 0.7403 Acc: 0.8318\n",
      "val Loss: 0.7429 Acc: 0.8200\n",
      "test Loss: 0.7404 Acc: 0.8320\n",
      "Epoch 346/1499\n",
      "----------\n",
      "train Loss: 0.7425 Acc: 0.8240\n",
      "val Loss: 0.7408 Acc: 0.8360\n",
      "test Loss: 0.7373 Acc: 0.8200\n",
      "Epoch 347/1499\n",
      "----------\n",
      "train Loss: 0.7378 Acc: 0.8313\n",
      "val Loss: 0.7380 Acc: 0.8320\n",
      "test Loss: 0.7202 Acc: 0.8600\n",
      "Epoch 348/1499\n",
      "----------\n",
      "train Loss: 0.7406 Acc: 0.8289\n",
      "val Loss: 0.7504 Acc: 0.8080\n",
      "test Loss: 0.7226 Acc: 0.8440\n",
      "Epoch 349/1499\n",
      "----------\n",
      "train Loss: 0.7390 Acc: 0.8273\n",
      "val Loss: 0.7489 Acc: 0.8080\n",
      "test Loss: 0.7326 Acc: 0.8440\n",
      "Epoch 350/1499\n",
      "----------\n",
      "train Loss: 0.7420 Acc: 0.8233\n",
      "val Loss: 0.7504 Acc: 0.8080\n",
      "test Loss: 0.7238 Acc: 0.8600\n",
      "Epoch 351/1499\n",
      "----------\n",
      "train Loss: 0.7380 Acc: 0.8278\n",
      "val Loss: 0.7398 Acc: 0.8200\n",
      "test Loss: 0.7251 Acc: 0.8440\n",
      "Epoch 352/1499\n",
      "----------\n",
      "train Loss: 0.7390 Acc: 0.8229\n",
      "val Loss: 0.7494 Acc: 0.8160\n",
      "test Loss: 0.7300 Acc: 0.8480\n",
      "Epoch 353/1499\n",
      "----------\n",
      "train Loss: 0.7373 Acc: 0.8262\n",
      "val Loss: 0.7527 Acc: 0.8120\n",
      "test Loss: 0.7257 Acc: 0.8400\n",
      "Epoch 354/1499\n",
      "----------\n",
      "train Loss: 0.7374 Acc: 0.8271\n",
      "val Loss: 0.7432 Acc: 0.8160\n",
      "test Loss: 0.7244 Acc: 0.8440\n",
      "Epoch 355/1499\n",
      "----------\n",
      "train Loss: 0.7390 Acc: 0.8262\n",
      "val Loss: 0.7621 Acc: 0.7880\n",
      "test Loss: 0.7258 Acc: 0.8480\n",
      "Epoch 356/1499\n",
      "----------\n",
      "train Loss: 0.7385 Acc: 0.8236\n",
      "val Loss: 0.7434 Acc: 0.8320\n",
      "test Loss: 0.7230 Acc: 0.8560\n",
      "Epoch 357/1499\n",
      "----------\n",
      "train Loss: 0.7352 Acc: 0.8316\n",
      "val Loss: 0.7434 Acc: 0.8240\n",
      "test Loss: 0.7292 Acc: 0.8360\n",
      "Epoch 358/1499\n",
      "----------\n",
      "train Loss: 0.7364 Acc: 0.8271\n",
      "val Loss: 0.7376 Acc: 0.8240\n",
      "test Loss: 0.7373 Acc: 0.8320\n",
      "Epoch 359/1499\n",
      "----------\n",
      "train Loss: 0.7368 Acc: 0.8282\n",
      "val Loss: 0.7440 Acc: 0.8280\n",
      "test Loss: 0.7259 Acc: 0.8560\n",
      "Epoch 360/1499\n",
      "----------\n",
      "train Loss: 0.7363 Acc: 0.8269\n",
      "val Loss: 0.7397 Acc: 0.8280\n",
      "test Loss: 0.7158 Acc: 0.8520\n",
      "Epoch 361/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.7361 Acc: 0.8271\n",
      "val Loss: 0.7440 Acc: 0.8360\n",
      "test Loss: 0.7262 Acc: 0.8400\n",
      "Epoch 362/1499\n",
      "----------\n",
      "train Loss: 0.7361 Acc: 0.8251\n",
      "val Loss: 0.7470 Acc: 0.8080\n",
      "test Loss: 0.7248 Acc: 0.8320\n",
      "Epoch 363/1499\n",
      "----------\n",
      "train Loss: 0.7315 Acc: 0.8300\n",
      "val Loss: 0.7495 Acc: 0.8240\n",
      "test Loss: 0.7217 Acc: 0.8520\n",
      "Epoch 364/1499\n",
      "----------\n",
      "train Loss: 0.7328 Acc: 0.8280\n",
      "val Loss: 0.7485 Acc: 0.8040\n",
      "test Loss: 0.7329 Acc: 0.8360\n",
      "Epoch 365/1499\n",
      "----------\n",
      "train Loss: 0.7347 Acc: 0.8293\n",
      "val Loss: 0.7413 Acc: 0.8240\n",
      "test Loss: 0.7237 Acc: 0.8480\n",
      "Epoch 366/1499\n",
      "----------\n",
      "train Loss: 0.7328 Acc: 0.8278\n",
      "val Loss: 0.7402 Acc: 0.8320\n",
      "test Loss: 0.7238 Acc: 0.8480\n",
      "Epoch 367/1499\n",
      "----------\n",
      "train Loss: 0.7353 Acc: 0.8260\n",
      "val Loss: 0.7489 Acc: 0.8120\n",
      "test Loss: 0.7228 Acc: 0.8400\n",
      "Epoch 368/1499\n",
      "----------\n",
      "train Loss: 0.7319 Acc: 0.8313\n",
      "val Loss: 0.7426 Acc: 0.8280\n",
      "test Loss: 0.7265 Acc: 0.8520\n",
      "Epoch 369/1499\n",
      "----------\n",
      "train Loss: 0.7321 Acc: 0.8273\n",
      "val Loss: 0.7402 Acc: 0.8280\n",
      "test Loss: 0.7162 Acc: 0.8520\n",
      "Epoch 370/1499\n",
      "----------\n",
      "train Loss: 0.7335 Acc: 0.8249\n",
      "val Loss: 0.7369 Acc: 0.8360\n",
      "test Loss: 0.7140 Acc: 0.8480\n",
      "Epoch 371/1499\n",
      "----------\n",
      "train Loss: 0.7321 Acc: 0.8284\n",
      "val Loss: 0.7287 Acc: 0.8280\n",
      "test Loss: 0.7322 Acc: 0.8200\n",
      "Epoch 372/1499\n",
      "----------\n",
      "train Loss: 0.7313 Acc: 0.8318\n",
      "val Loss: 0.7325 Acc: 0.8320\n",
      "test Loss: 0.7150 Acc: 0.8480\n",
      "Epoch 373/1499\n",
      "----------\n",
      "train Loss: 0.7293 Acc: 0.8349\n",
      "val Loss: 0.7363 Acc: 0.8200\n",
      "test Loss: 0.7283 Acc: 0.8240\n",
      "Epoch 374/1499\n",
      "----------\n",
      "train Loss: 0.7309 Acc: 0.8293\n",
      "val Loss: 0.7356 Acc: 0.8320\n",
      "test Loss: 0.7176 Acc: 0.8400\n",
      "Epoch 375/1499\n",
      "----------\n",
      "train Loss: 0.7292 Acc: 0.8293\n",
      "val Loss: 0.7348 Acc: 0.8280\n",
      "test Loss: 0.7160 Acc: 0.8520\n",
      "Epoch 376/1499\n",
      "----------\n",
      "train Loss: 0.7283 Acc: 0.8324\n",
      "val Loss: 0.7264 Acc: 0.8360\n",
      "test Loss: 0.7251 Acc: 0.8520\n",
      "Epoch 377/1499\n",
      "----------\n",
      "train Loss: 0.7289 Acc: 0.8307\n",
      "val Loss: 0.7252 Acc: 0.8440\n",
      "test Loss: 0.7287 Acc: 0.8320\n",
      "Epoch 378/1499\n",
      "----------\n",
      "train Loss: 0.7299 Acc: 0.8333\n",
      "val Loss: 0.7323 Acc: 0.8320\n",
      "test Loss: 0.7230 Acc: 0.8400\n",
      "Epoch 379/1499\n",
      "----------\n",
      "train Loss: 0.7320 Acc: 0.8267\n",
      "val Loss: 0.7360 Acc: 0.8400\n",
      "test Loss: 0.7092 Acc: 0.8560\n",
      "Epoch 380/1499\n",
      "----------\n",
      "train Loss: 0.7296 Acc: 0.8322\n",
      "val Loss: 0.7387 Acc: 0.8240\n",
      "test Loss: 0.7257 Acc: 0.8320\n",
      "Epoch 381/1499\n",
      "----------\n",
      "train Loss: 0.7274 Acc: 0.8324\n",
      "val Loss: 0.7265 Acc: 0.8280\n",
      "test Loss: 0.7177 Acc: 0.8440\n",
      "Epoch 382/1499\n",
      "----------\n",
      "train Loss: 0.7292 Acc: 0.8276\n",
      "val Loss: 0.7458 Acc: 0.8200\n",
      "test Loss: 0.7210 Acc: 0.8400\n",
      "Epoch 383/1499\n",
      "----------\n",
      "train Loss: 0.7271 Acc: 0.8282\n",
      "val Loss: 0.7331 Acc: 0.8320\n",
      "test Loss: 0.7179 Acc: 0.8520\n",
      "Epoch 384/1499\n",
      "----------\n",
      "train Loss: 0.7268 Acc: 0.8342\n",
      "val Loss: 0.7403 Acc: 0.8160\n",
      "test Loss: 0.7124 Acc: 0.8560\n",
      "Epoch 385/1499\n",
      "----------\n",
      "train Loss: 0.7281 Acc: 0.8311\n",
      "val Loss: 0.7436 Acc: 0.8120\n",
      "test Loss: 0.7177 Acc: 0.8360\n",
      "Epoch 386/1499\n",
      "----------\n",
      "train Loss: 0.7289 Acc: 0.8300\n",
      "val Loss: 0.7333 Acc: 0.8320\n",
      "test Loss: 0.7217 Acc: 0.8400\n",
      "Epoch 387/1499\n",
      "----------\n",
      "train Loss: 0.7270 Acc: 0.8289\n",
      "val Loss: 0.7342 Acc: 0.8200\n",
      "test Loss: 0.7090 Acc: 0.8600\n",
      "Epoch 388/1499\n",
      "----------\n",
      "train Loss: 0.7282 Acc: 0.8296\n",
      "val Loss: 0.7355 Acc: 0.8160\n",
      "test Loss: 0.7075 Acc: 0.8680\n",
      "Epoch 389/1499\n",
      "----------\n",
      "train Loss: 0.7266 Acc: 0.8293\n",
      "val Loss: 0.7360 Acc: 0.8200\n",
      "test Loss: 0.7043 Acc: 0.8640\n",
      "Epoch 390/1499\n",
      "----------\n",
      "train Loss: 0.7250 Acc: 0.8360\n",
      "val Loss: 0.7236 Acc: 0.8520\n",
      "test Loss: 0.7102 Acc: 0.8600\n",
      "Epoch 391/1499\n",
      "----------\n",
      "train Loss: 0.7269 Acc: 0.8316\n",
      "val Loss: 0.7356 Acc: 0.8240\n",
      "test Loss: 0.7172 Acc: 0.8360\n",
      "Epoch 392/1499\n",
      "----------\n",
      "train Loss: 0.7252 Acc: 0.8331\n",
      "val Loss: 0.7401 Acc: 0.8240\n",
      "test Loss: 0.7166 Acc: 0.8360\n",
      "Epoch 393/1499\n",
      "----------\n",
      "train Loss: 0.7276 Acc: 0.8316\n",
      "val Loss: 0.7227 Acc: 0.8320\n",
      "test Loss: 0.7311 Acc: 0.8280\n",
      "Epoch 394/1499\n",
      "----------\n",
      "train Loss: 0.7255 Acc: 0.8336\n",
      "val Loss: 0.7263 Acc: 0.8320\n",
      "test Loss: 0.7066 Acc: 0.8480\n",
      "Epoch 395/1499\n",
      "----------\n",
      "train Loss: 0.7269 Acc: 0.8311\n",
      "val Loss: 0.7288 Acc: 0.8280\n",
      "test Loss: 0.7079 Acc: 0.8560\n",
      "Epoch 396/1499\n",
      "----------\n",
      "train Loss: 0.7239 Acc: 0.8364\n",
      "val Loss: 0.7404 Acc: 0.8200\n",
      "test Loss: 0.7206 Acc: 0.8360\n",
      "Epoch 397/1499\n",
      "----------\n",
      "train Loss: 0.7248 Acc: 0.8307\n",
      "val Loss: 0.7320 Acc: 0.8280\n",
      "test Loss: 0.7102 Acc: 0.8560\n",
      "Epoch 398/1499\n",
      "----------\n",
      "train Loss: 0.7254 Acc: 0.8307\n",
      "val Loss: 0.7233 Acc: 0.8240\n",
      "test Loss: 0.7141 Acc: 0.8480\n",
      "Epoch 399/1499\n",
      "----------\n",
      "train Loss: 0.7223 Acc: 0.8356\n",
      "val Loss: 0.7367 Acc: 0.8280\n",
      "test Loss: 0.7107 Acc: 0.8560\n",
      "Epoch 400/1499\n",
      "----------\n",
      "train Loss: 0.7231 Acc: 0.8349\n",
      "val Loss: 0.7180 Acc: 0.8400\n",
      "test Loss: 0.7146 Acc: 0.8400\n",
      "Epoch 401/1499\n",
      "----------\n",
      "train Loss: 0.7233 Acc: 0.8320\n",
      "val Loss: 0.7258 Acc: 0.8320\n",
      "test Loss: 0.7192 Acc: 0.8320\n",
      "Epoch 402/1499\n",
      "----------\n",
      "train Loss: 0.7230 Acc: 0.8338\n",
      "val Loss: 0.7290 Acc: 0.8400\n",
      "test Loss: 0.7133 Acc: 0.8560\n",
      "Epoch 403/1499\n",
      "----------\n",
      "train Loss: 0.7221 Acc: 0.8353\n",
      "val Loss: 0.7365 Acc: 0.8200\n",
      "test Loss: 0.7145 Acc: 0.8520\n",
      "Epoch 404/1499\n",
      "----------\n",
      "train Loss: 0.7241 Acc: 0.8331\n",
      "val Loss: 0.7245 Acc: 0.8360\n",
      "test Loss: 0.7057 Acc: 0.8600\n",
      "Epoch 405/1499\n",
      "----------\n",
      "train Loss: 0.7199 Acc: 0.8389\n",
      "val Loss: 0.7289 Acc: 0.8360\n",
      "test Loss: 0.7138 Acc: 0.8440\n",
      "Epoch 406/1499\n",
      "----------\n",
      "train Loss: 0.7206 Acc: 0.8387\n",
      "val Loss: 0.7295 Acc: 0.8160\n",
      "test Loss: 0.7040 Acc: 0.8520\n",
      "Epoch 407/1499\n",
      "----------\n",
      "train Loss: 0.7210 Acc: 0.8356\n",
      "val Loss: 0.7222 Acc: 0.8440\n",
      "test Loss: 0.7055 Acc: 0.8600\n",
      "Epoch 408/1499\n",
      "----------\n",
      "train Loss: 0.7199 Acc: 0.8351\n",
      "val Loss: 0.7233 Acc: 0.8400\n",
      "test Loss: 0.6969 Acc: 0.8680\n",
      "Epoch 409/1499\n",
      "----------\n",
      "train Loss: 0.7202 Acc: 0.8376\n",
      "val Loss: 0.7284 Acc: 0.8320\n",
      "test Loss: 0.7115 Acc: 0.8560\n",
      "Epoch 410/1499\n",
      "----------\n",
      "train Loss: 0.7218 Acc: 0.8322\n",
      "val Loss: 0.7273 Acc: 0.8320\n",
      "test Loss: 0.7130 Acc: 0.8440\n",
      "Epoch 411/1499\n",
      "----------\n",
      "train Loss: 0.7181 Acc: 0.8402\n",
      "val Loss: 0.7247 Acc: 0.8400\n",
      "test Loss: 0.7050 Acc: 0.8520\n",
      "Epoch 412/1499\n",
      "----------\n",
      "train Loss: 0.7200 Acc: 0.8369\n",
      "val Loss: 0.7333 Acc: 0.8200\n",
      "test Loss: 0.7097 Acc: 0.8480\n",
      "Epoch 413/1499\n",
      "----------\n",
      "train Loss: 0.7203 Acc: 0.8358\n",
      "val Loss: 0.7252 Acc: 0.8240\n",
      "test Loss: 0.6986 Acc: 0.8600\n",
      "Epoch 414/1499\n",
      "----------\n",
      "train Loss: 0.7191 Acc: 0.8369\n",
      "val Loss: 0.7310 Acc: 0.8240\n",
      "test Loss: 0.7011 Acc: 0.8440\n",
      "Epoch 415/1499\n",
      "----------\n",
      "train Loss: 0.7201 Acc: 0.8360\n",
      "val Loss: 0.7237 Acc: 0.8440\n",
      "test Loss: 0.7015 Acc: 0.8560\n",
      "Epoch 416/1499\n",
      "----------\n",
      "train Loss: 0.7184 Acc: 0.8367\n",
      "val Loss: 0.7235 Acc: 0.8360\n",
      "test Loss: 0.7136 Acc: 0.8480\n",
      "Epoch 417/1499\n",
      "----------\n",
      "train Loss: 0.7222 Acc: 0.8351\n",
      "val Loss: 0.7192 Acc: 0.8320\n",
      "test Loss: 0.6997 Acc: 0.8600\n",
      "Epoch 418/1499\n",
      "----------\n",
      "train Loss: 0.7215 Acc: 0.8364\n",
      "val Loss: 0.7311 Acc: 0.8360\n",
      "test Loss: 0.7132 Acc: 0.8480\n",
      "Epoch 419/1499\n",
      "----------\n",
      "train Loss: 0.7195 Acc: 0.8322\n",
      "val Loss: 0.7240 Acc: 0.8400\n",
      "test Loss: 0.7096 Acc: 0.8400\n",
      "Epoch 420/1499\n",
      "----------\n",
      "train Loss: 0.7199 Acc: 0.8351\n",
      "val Loss: 0.7333 Acc: 0.8320\n",
      "test Loss: 0.7054 Acc: 0.8480\n",
      "Epoch 421/1499\n",
      "----------\n",
      "train Loss: 0.7189 Acc: 0.8382\n",
      "val Loss: 0.7270 Acc: 0.8360\n",
      "test Loss: 0.6987 Acc: 0.8600\n",
      "Epoch 422/1499\n",
      "----------\n",
      "train Loss: 0.7168 Acc: 0.8407\n",
      "val Loss: 0.7238 Acc: 0.8280\n",
      "test Loss: 0.7074 Acc: 0.8440\n",
      "Epoch 423/1499\n",
      "----------\n",
      "train Loss: 0.7180 Acc: 0.8378\n",
      "val Loss: 0.7317 Acc: 0.8240\n",
      "test Loss: 0.7042 Acc: 0.8600\n",
      "Epoch 424/1499\n",
      "----------\n",
      "train Loss: 0.7153 Acc: 0.8400\n",
      "val Loss: 0.7203 Acc: 0.8360\n",
      "test Loss: 0.7137 Acc: 0.8480\n",
      "Epoch 425/1499\n",
      "----------\n",
      "train Loss: 0.7178 Acc: 0.8398\n",
      "val Loss: 0.7265 Acc: 0.8400\n",
      "test Loss: 0.7070 Acc: 0.8440\n",
      "Epoch 426/1499\n",
      "----------\n",
      "train Loss: 0.7173 Acc: 0.8371\n",
      "val Loss: 0.7252 Acc: 0.8280\n",
      "test Loss: 0.7076 Acc: 0.8480\n",
      "Epoch 427/1499\n",
      "----------\n",
      "train Loss: 0.7170 Acc: 0.8389\n",
      "val Loss: 0.7168 Acc: 0.8480\n",
      "test Loss: 0.7031 Acc: 0.8520\n",
      "Epoch 428/1499\n",
      "----------\n",
      "train Loss: 0.7173 Acc: 0.8378\n",
      "val Loss: 0.7298 Acc: 0.8360\n",
      "test Loss: 0.7006 Acc: 0.8520\n",
      "Epoch 429/1499\n",
      "----------\n",
      "train Loss: 0.7164 Acc: 0.8398\n",
      "val Loss: 0.7195 Acc: 0.8520\n",
      "test Loss: 0.6993 Acc: 0.8600\n",
      "Epoch 430/1499\n",
      "----------\n",
      "train Loss: 0.7159 Acc: 0.8416\n",
      "val Loss: 0.7283 Acc: 0.8240\n",
      "test Loss: 0.7084 Acc: 0.8440\n",
      "Epoch 431/1499\n",
      "----------\n",
      "train Loss: 0.7149 Acc: 0.8409\n",
      "val Loss: 0.7190 Acc: 0.8320\n",
      "test Loss: 0.7120 Acc: 0.8400\n",
      "Epoch 432/1499\n",
      "----------\n",
      "train Loss: 0.7146 Acc: 0.8424\n",
      "val Loss: 0.7228 Acc: 0.8360\n",
      "test Loss: 0.7037 Acc: 0.8560\n",
      "Epoch 433/1499\n",
      "----------\n",
      "train Loss: 0.7161 Acc: 0.8447\n",
      "val Loss: 0.7207 Acc: 0.8240\n",
      "test Loss: 0.7009 Acc: 0.8560\n",
      "Epoch 434/1499\n",
      "----------\n",
      "train Loss: 0.7141 Acc: 0.8422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.7099 Acc: 0.8480\n",
      "test Loss: 0.6964 Acc: 0.8640\n",
      "Epoch 435/1499\n",
      "----------\n",
      "train Loss: 0.7145 Acc: 0.8444\n",
      "val Loss: 0.7159 Acc: 0.8400\n",
      "test Loss: 0.7001 Acc: 0.8640\n",
      "Epoch 436/1499\n",
      "----------\n",
      "train Loss: 0.7146 Acc: 0.8420\n",
      "val Loss: 0.7310 Acc: 0.8120\n",
      "test Loss: 0.7029 Acc: 0.8560\n",
      "Epoch 437/1499\n",
      "----------\n",
      "train Loss: 0.7163 Acc: 0.8380\n",
      "val Loss: 0.7185 Acc: 0.8360\n",
      "test Loss: 0.7084 Acc: 0.8520\n",
      "Epoch 438/1499\n",
      "----------\n",
      "train Loss: 0.7128 Acc: 0.8431\n",
      "val Loss: 0.7226 Acc: 0.8200\n",
      "test Loss: 0.7026 Acc: 0.8520\n",
      "Epoch 439/1499\n",
      "----------\n",
      "train Loss: 0.7154 Acc: 0.8398\n",
      "val Loss: 0.7188 Acc: 0.8280\n",
      "test Loss: 0.7049 Acc: 0.8640\n",
      "Epoch 440/1499\n",
      "----------\n",
      "train Loss: 0.7140 Acc: 0.8418\n",
      "val Loss: 0.7161 Acc: 0.8320\n",
      "test Loss: 0.7002 Acc: 0.8640\n",
      "Epoch 441/1499\n",
      "----------\n",
      "train Loss: 0.7147 Acc: 0.8367\n",
      "val Loss: 0.7227 Acc: 0.8200\n",
      "test Loss: 0.6948 Acc: 0.8680\n",
      "Epoch 442/1499\n",
      "----------\n",
      "train Loss: 0.7143 Acc: 0.8398\n",
      "val Loss: 0.7180 Acc: 0.8400\n",
      "test Loss: 0.7002 Acc: 0.8640\n",
      "Epoch 443/1499\n",
      "----------\n",
      "train Loss: 0.7142 Acc: 0.8404\n",
      "val Loss: 0.7186 Acc: 0.8400\n",
      "test Loss: 0.7026 Acc: 0.8560\n",
      "Epoch 444/1499\n",
      "----------\n",
      "train Loss: 0.7141 Acc: 0.8389\n",
      "val Loss: 0.7221 Acc: 0.8400\n",
      "test Loss: 0.7032 Acc: 0.8640\n",
      "Epoch 445/1499\n",
      "----------\n",
      "train Loss: 0.7108 Acc: 0.8464\n",
      "val Loss: 0.7205 Acc: 0.8440\n",
      "test Loss: 0.7038 Acc: 0.8640\n",
      "Epoch 446/1499\n",
      "----------\n",
      "train Loss: 0.7127 Acc: 0.8442\n",
      "val Loss: 0.7157 Acc: 0.8400\n",
      "test Loss: 0.6997 Acc: 0.8520\n",
      "Epoch 447/1499\n",
      "----------\n",
      "train Loss: 0.7128 Acc: 0.8416\n",
      "val Loss: 0.7136 Acc: 0.8440\n",
      "test Loss: 0.7072 Acc: 0.8520\n",
      "Epoch 448/1499\n",
      "----------\n",
      "train Loss: 0.7128 Acc: 0.8431\n",
      "val Loss: 0.7241 Acc: 0.8360\n",
      "test Loss: 0.6987 Acc: 0.8640\n",
      "Epoch 449/1499\n",
      "----------\n",
      "train Loss: 0.7129 Acc: 0.8409\n",
      "val Loss: 0.7192 Acc: 0.8320\n",
      "test Loss: 0.7005 Acc: 0.8680\n",
      "Epoch 450/1499\n",
      "----------\n",
      "train Loss: 0.7104 Acc: 0.8442\n",
      "val Loss: 0.7222 Acc: 0.8360\n",
      "test Loss: 0.7070 Acc: 0.8440\n",
      "Epoch 451/1499\n",
      "----------\n",
      "train Loss: 0.7124 Acc: 0.8433\n",
      "val Loss: 0.7194 Acc: 0.8400\n",
      "test Loss: 0.7010 Acc: 0.8680\n",
      "Epoch 452/1499\n",
      "----------\n",
      "train Loss: 0.7121 Acc: 0.8418\n",
      "val Loss: 0.7123 Acc: 0.8320\n",
      "test Loss: 0.7089 Acc: 0.8560\n",
      "Epoch 453/1499\n",
      "----------\n",
      "train Loss: 0.7141 Acc: 0.8411\n",
      "val Loss: 0.7103 Acc: 0.8480\n",
      "test Loss: 0.7063 Acc: 0.8600\n",
      "Epoch 454/1499\n",
      "----------\n",
      "train Loss: 0.7109 Acc: 0.8449\n",
      "val Loss: 0.7035 Acc: 0.8560\n",
      "test Loss: 0.6889 Acc: 0.8800\n",
      "Epoch 455/1499\n",
      "----------\n",
      "train Loss: 0.7104 Acc: 0.8447\n",
      "val Loss: 0.7156 Acc: 0.8480\n",
      "test Loss: 0.6974 Acc: 0.8680\n",
      "Epoch 456/1499\n",
      "----------\n",
      "train Loss: 0.7110 Acc: 0.8424\n",
      "val Loss: 0.7208 Acc: 0.8240\n",
      "test Loss: 0.6935 Acc: 0.8680\n",
      "Epoch 457/1499\n",
      "----------\n",
      "train Loss: 0.7102 Acc: 0.8444\n",
      "val Loss: 0.7130 Acc: 0.8520\n",
      "test Loss: 0.6968 Acc: 0.8560\n",
      "Epoch 458/1499\n",
      "----------\n",
      "train Loss: 0.7123 Acc: 0.8424\n",
      "val Loss: 0.7184 Acc: 0.8280\n",
      "test Loss: 0.6967 Acc: 0.8720\n",
      "Epoch 459/1499\n",
      "----------\n",
      "train Loss: 0.7111 Acc: 0.8438\n",
      "val Loss: 0.7202 Acc: 0.8400\n",
      "test Loss: 0.6979 Acc: 0.8560\n",
      "Epoch 460/1499\n",
      "----------\n",
      "train Loss: 0.7081 Acc: 0.8507\n",
      "val Loss: 0.7163 Acc: 0.8280\n",
      "test Loss: 0.6924 Acc: 0.8600\n",
      "Epoch 461/1499\n",
      "----------\n",
      "train Loss: 0.7109 Acc: 0.8409\n",
      "val Loss: 0.7171 Acc: 0.8440\n",
      "test Loss: 0.7118 Acc: 0.8360\n",
      "Epoch 462/1499\n",
      "----------\n",
      "train Loss: 0.7091 Acc: 0.8469\n",
      "val Loss: 0.7174 Acc: 0.8440\n",
      "test Loss: 0.6919 Acc: 0.8720\n",
      "Epoch 463/1499\n",
      "----------\n",
      "train Loss: 0.7102 Acc: 0.8438\n",
      "val Loss: 0.7113 Acc: 0.8440\n",
      "test Loss: 0.7103 Acc: 0.8440\n",
      "Epoch 464/1499\n",
      "----------\n",
      "train Loss: 0.7093 Acc: 0.8469\n",
      "val Loss: 0.7288 Acc: 0.8080\n",
      "test Loss: 0.7077 Acc: 0.8520\n",
      "Epoch 465/1499\n",
      "----------\n",
      "train Loss: 0.7096 Acc: 0.8473\n",
      "val Loss: 0.7150 Acc: 0.8320\n",
      "test Loss: 0.6953 Acc: 0.8680\n",
      "Epoch 466/1499\n",
      "----------\n",
      "train Loss: 0.7099 Acc: 0.8449\n",
      "val Loss: 0.7129 Acc: 0.8640\n",
      "test Loss: 0.6965 Acc: 0.8600\n",
      "Epoch 467/1499\n",
      "----------\n",
      "train Loss: 0.7083 Acc: 0.8440\n",
      "val Loss: 0.7058 Acc: 0.8520\n",
      "test Loss: 0.6970 Acc: 0.8800\n",
      "Epoch 468/1499\n",
      "----------\n",
      "train Loss: 0.7067 Acc: 0.8507\n",
      "val Loss: 0.7076 Acc: 0.8520\n",
      "test Loss: 0.7104 Acc: 0.8440\n",
      "Epoch 469/1499\n",
      "----------\n",
      "train Loss: 0.7074 Acc: 0.8467\n",
      "val Loss: 0.7043 Acc: 0.8480\n",
      "test Loss: 0.6947 Acc: 0.8720\n",
      "Epoch 470/1499\n",
      "----------\n",
      "train Loss: 0.7089 Acc: 0.8458\n",
      "val Loss: 0.6991 Acc: 0.8640\n",
      "test Loss: 0.7149 Acc: 0.8360\n",
      "Epoch 471/1499\n",
      "----------\n",
      "train Loss: 0.7078 Acc: 0.8469\n",
      "val Loss: 0.7075 Acc: 0.8440\n",
      "test Loss: 0.6981 Acc: 0.8680\n",
      "Epoch 472/1499\n",
      "----------\n",
      "train Loss: 0.7043 Acc: 0.8516\n",
      "val Loss: 0.7125 Acc: 0.8440\n",
      "test Loss: 0.6935 Acc: 0.8680\n",
      "Epoch 473/1499\n",
      "----------\n",
      "train Loss: 0.7067 Acc: 0.8493\n",
      "val Loss: 0.7188 Acc: 0.8360\n",
      "test Loss: 0.7031 Acc: 0.8600\n",
      "Epoch 474/1499\n",
      "----------\n",
      "train Loss: 0.7064 Acc: 0.8467\n",
      "val Loss: 0.7108 Acc: 0.8480\n",
      "test Loss: 0.7028 Acc: 0.8600\n",
      "Epoch 475/1499\n",
      "----------\n",
      "train Loss: 0.7069 Acc: 0.8453\n",
      "val Loss: 0.7044 Acc: 0.8400\n",
      "test Loss: 0.6908 Acc: 0.8720\n",
      "Epoch 476/1499\n",
      "----------\n",
      "train Loss: 0.7083 Acc: 0.8484\n",
      "val Loss: 0.7088 Acc: 0.8480\n",
      "test Loss: 0.6859 Acc: 0.8680\n",
      "Epoch 477/1499\n",
      "----------\n",
      "train Loss: 0.7061 Acc: 0.8511\n",
      "val Loss: 0.7130 Acc: 0.8440\n",
      "test Loss: 0.6811 Acc: 0.8840\n",
      "Epoch 478/1499\n",
      "----------\n",
      "train Loss: 0.7074 Acc: 0.8476\n",
      "val Loss: 0.7119 Acc: 0.8400\n",
      "test Loss: 0.6961 Acc: 0.8680\n",
      "Epoch 479/1499\n",
      "----------\n",
      "train Loss: 0.7078 Acc: 0.8478\n",
      "val Loss: 0.7156 Acc: 0.8480\n",
      "test Loss: 0.6817 Acc: 0.8800\n",
      "Epoch 480/1499\n",
      "----------\n",
      "train Loss: 0.7071 Acc: 0.8480\n",
      "val Loss: 0.7111 Acc: 0.8440\n",
      "test Loss: 0.6966 Acc: 0.8640\n",
      "Epoch 481/1499\n",
      "----------\n",
      "train Loss: 0.7044 Acc: 0.8536\n",
      "val Loss: 0.7063 Acc: 0.8400\n",
      "test Loss: 0.7042 Acc: 0.8520\n",
      "Epoch 482/1499\n",
      "----------\n",
      "train Loss: 0.7054 Acc: 0.8502\n",
      "val Loss: 0.7030 Acc: 0.8480\n",
      "test Loss: 0.6973 Acc: 0.8720\n",
      "Epoch 483/1499\n",
      "----------\n",
      "train Loss: 0.7048 Acc: 0.8520\n",
      "val Loss: 0.7068 Acc: 0.8400\n",
      "test Loss: 0.6912 Acc: 0.8800\n",
      "Epoch 484/1499\n",
      "----------\n",
      "train Loss: 0.7044 Acc: 0.8540\n",
      "val Loss: 0.7010 Acc: 0.8480\n",
      "test Loss: 0.7003 Acc: 0.8720\n",
      "Epoch 485/1499\n",
      "----------\n",
      "train Loss: 0.7070 Acc: 0.8469\n",
      "val Loss: 0.7204 Acc: 0.8160\n",
      "test Loss: 0.7017 Acc: 0.8560\n",
      "Epoch 486/1499\n",
      "----------\n",
      "train Loss: 0.7042 Acc: 0.8507\n",
      "val Loss: 0.6990 Acc: 0.8720\n",
      "test Loss: 0.6977 Acc: 0.8640\n",
      "Epoch 487/1499\n",
      "----------\n",
      "train Loss: 0.7035 Acc: 0.8516\n",
      "val Loss: 0.7026 Acc: 0.8560\n",
      "test Loss: 0.6958 Acc: 0.8680\n",
      "Epoch 488/1499\n",
      "----------\n",
      "train Loss: 0.7037 Acc: 0.8520\n",
      "val Loss: 0.7109 Acc: 0.8400\n",
      "test Loss: 0.6998 Acc: 0.8680\n",
      "Epoch 489/1499\n",
      "----------\n",
      "train Loss: 0.7034 Acc: 0.8504\n",
      "val Loss: 0.7014 Acc: 0.8520\n",
      "test Loss: 0.6913 Acc: 0.8840\n",
      "Epoch 490/1499\n",
      "----------\n",
      "train Loss: 0.7033 Acc: 0.8511\n",
      "val Loss: 0.7082 Acc: 0.8280\n",
      "test Loss: 0.6947 Acc: 0.8720\n",
      "Epoch 491/1499\n",
      "----------\n",
      "train Loss: 0.7027 Acc: 0.8504\n",
      "val Loss: 0.7088 Acc: 0.8560\n",
      "test Loss: 0.6957 Acc: 0.8800\n",
      "Epoch 492/1499\n",
      "----------\n",
      "train Loss: 0.7050 Acc: 0.8502\n",
      "val Loss: 0.6988 Acc: 0.8520\n",
      "test Loss: 0.6938 Acc: 0.8600\n",
      "Epoch 493/1499\n",
      "----------\n",
      "train Loss: 0.7027 Acc: 0.8529\n",
      "val Loss: 0.7004 Acc: 0.8520\n",
      "test Loss: 0.6905 Acc: 0.8800\n",
      "Epoch 494/1499\n",
      "----------\n",
      "train Loss: 0.7013 Acc: 0.8527\n",
      "val Loss: 0.7028 Acc: 0.8520\n",
      "test Loss: 0.6925 Acc: 0.8760\n",
      "Epoch 495/1499\n",
      "----------\n",
      "train Loss: 0.7031 Acc: 0.8502\n",
      "val Loss: 0.7024 Acc: 0.8480\n",
      "test Loss: 0.7001 Acc: 0.8720\n",
      "Epoch 496/1499\n",
      "----------\n",
      "train Loss: 0.7034 Acc: 0.8507\n",
      "val Loss: 0.7076 Acc: 0.8360\n",
      "test Loss: 0.6890 Acc: 0.8720\n",
      "Epoch 497/1499\n",
      "----------\n",
      "train Loss: 0.7037 Acc: 0.8493\n",
      "val Loss: 0.7073 Acc: 0.8360\n",
      "test Loss: 0.6964 Acc: 0.8640\n",
      "Epoch 498/1499\n",
      "----------\n",
      "train Loss: 0.7027 Acc: 0.8489\n",
      "val Loss: 0.6980 Acc: 0.8600\n",
      "test Loss: 0.6935 Acc: 0.8680\n",
      "Epoch 499/1499\n",
      "----------\n",
      "train Loss: 0.7018 Acc: 0.8522\n",
      "val Loss: 0.7028 Acc: 0.8600\n",
      "test Loss: 0.6934 Acc: 0.8760\n",
      "Epoch 500/1499\n",
      "----------\n",
      "train Loss: 0.7024 Acc: 0.8556\n",
      "val Loss: 0.6993 Acc: 0.8440\n",
      "test Loss: 0.6875 Acc: 0.8840\n",
      "Epoch 501/1499\n",
      "----------\n",
      "train Loss: 0.7016 Acc: 0.8547\n",
      "val Loss: 0.7071 Acc: 0.8400\n",
      "test Loss: 0.6875 Acc: 0.8840\n",
      "Epoch 502/1499\n",
      "----------\n",
      "train Loss: 0.7035 Acc: 0.8498\n",
      "val Loss: 0.7084 Acc: 0.8480\n",
      "test Loss: 0.6785 Acc: 0.8920\n",
      "Epoch 503/1499\n",
      "----------\n",
      "train Loss: 0.7022 Acc: 0.8496\n",
      "val Loss: 0.6980 Acc: 0.8480\n",
      "test Loss: 0.6821 Acc: 0.8920\n",
      "Epoch 504/1499\n",
      "----------\n",
      "train Loss: 0.7019 Acc: 0.8498\n",
      "val Loss: 0.6960 Acc: 0.8520\n",
      "test Loss: 0.6959 Acc: 0.8680\n",
      "Epoch 505/1499\n",
      "----------\n",
      "train Loss: 0.6993 Acc: 0.8556\n",
      "val Loss: 0.6963 Acc: 0.8480\n",
      "test Loss: 0.6844 Acc: 0.8800\n",
      "Epoch 506/1499\n",
      "----------\n",
      "train Loss: 0.7006 Acc: 0.8542\n",
      "val Loss: 0.6964 Acc: 0.8520\n",
      "test Loss: 0.6884 Acc: 0.8840\n",
      "Epoch 507/1499\n",
      "----------\n",
      "train Loss: 0.6982 Acc: 0.8569\n",
      "val Loss: 0.6995 Acc: 0.8520\n",
      "test Loss: 0.6988 Acc: 0.8640\n",
      "Epoch 508/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.7013 Acc: 0.8540\n",
      "val Loss: 0.7048 Acc: 0.8400\n",
      "test Loss: 0.6882 Acc: 0.8760\n",
      "Epoch 509/1499\n",
      "----------\n",
      "train Loss: 0.7022 Acc: 0.8509\n",
      "val Loss: 0.6912 Acc: 0.8600\n",
      "test Loss: 0.6841 Acc: 0.8800\n",
      "Epoch 510/1499\n",
      "----------\n",
      "train Loss: 0.7004 Acc: 0.8511\n",
      "val Loss: 0.7041 Acc: 0.8480\n",
      "test Loss: 0.6854 Acc: 0.8960\n",
      "Epoch 511/1499\n",
      "----------\n",
      "train Loss: 0.6998 Acc: 0.8560\n",
      "val Loss: 0.7039 Acc: 0.8440\n",
      "test Loss: 0.6888 Acc: 0.8840\n",
      "Epoch 512/1499\n",
      "----------\n",
      "train Loss: 0.6984 Acc: 0.8576\n",
      "val Loss: 0.7082 Acc: 0.8320\n",
      "test Loss: 0.6954 Acc: 0.8640\n",
      "Epoch 513/1499\n",
      "----------\n",
      "train Loss: 0.7003 Acc: 0.8547\n",
      "val Loss: 0.6992 Acc: 0.8440\n",
      "test Loss: 0.6892 Acc: 0.8680\n",
      "Epoch 514/1499\n",
      "----------\n",
      "train Loss: 0.7001 Acc: 0.8547\n",
      "val Loss: 0.6930 Acc: 0.8640\n",
      "test Loss: 0.6912 Acc: 0.8680\n",
      "Epoch 515/1499\n",
      "----------\n",
      "train Loss: 0.6988 Acc: 0.8527\n",
      "val Loss: 0.6982 Acc: 0.8480\n",
      "test Loss: 0.6923 Acc: 0.8640\n",
      "Epoch 516/1499\n",
      "----------\n",
      "train Loss: 0.7012 Acc: 0.8522\n",
      "val Loss: 0.7042 Acc: 0.8360\n",
      "test Loss: 0.6911 Acc: 0.8760\n",
      "Epoch 517/1499\n",
      "----------\n",
      "train Loss: 0.6999 Acc: 0.8520\n",
      "val Loss: 0.7055 Acc: 0.8400\n",
      "test Loss: 0.6840 Acc: 0.8840\n",
      "Epoch 518/1499\n",
      "----------\n",
      "train Loss: 0.6979 Acc: 0.8562\n",
      "val Loss: 0.6986 Acc: 0.8400\n",
      "test Loss: 0.6861 Acc: 0.8800\n",
      "Epoch 519/1499\n",
      "----------\n",
      "train Loss: 0.7000 Acc: 0.8531\n",
      "val Loss: 0.7032 Acc: 0.8400\n",
      "test Loss: 0.6780 Acc: 0.8960\n",
      "Epoch 520/1499\n",
      "----------\n",
      "train Loss: 0.6964 Acc: 0.8569\n",
      "val Loss: 0.6989 Acc: 0.8560\n",
      "test Loss: 0.6958 Acc: 0.8680\n",
      "Epoch 521/1499\n",
      "----------\n",
      "train Loss: 0.7015 Acc: 0.8520\n",
      "val Loss: 0.6964 Acc: 0.8560\n",
      "test Loss: 0.6843 Acc: 0.8840\n",
      "Epoch 522/1499\n",
      "----------\n",
      "train Loss: 0.6988 Acc: 0.8564\n",
      "val Loss: 0.6963 Acc: 0.8560\n",
      "test Loss: 0.6907 Acc: 0.8640\n",
      "Epoch 523/1499\n",
      "----------\n",
      "train Loss: 0.6991 Acc: 0.8553\n",
      "val Loss: 0.7056 Acc: 0.8400\n",
      "test Loss: 0.6840 Acc: 0.8800\n",
      "Epoch 524/1499\n",
      "----------\n",
      "train Loss: 0.6983 Acc: 0.8538\n",
      "val Loss: 0.6965 Acc: 0.8600\n",
      "test Loss: 0.6965 Acc: 0.8640\n",
      "Epoch 525/1499\n",
      "----------\n",
      "train Loss: 0.6951 Acc: 0.8620\n",
      "val Loss: 0.6911 Acc: 0.8640\n",
      "test Loss: 0.6786 Acc: 0.8840\n",
      "Epoch 526/1499\n",
      "----------\n",
      "train Loss: 0.6969 Acc: 0.8573\n",
      "val Loss: 0.7047 Acc: 0.8480\n",
      "test Loss: 0.6899 Acc: 0.8640\n",
      "Epoch 527/1499\n",
      "----------\n",
      "train Loss: 0.6976 Acc: 0.8580\n",
      "val Loss: 0.7059 Acc: 0.8280\n",
      "test Loss: 0.6823 Acc: 0.8680\n",
      "Epoch 528/1499\n",
      "----------\n",
      "train Loss: 0.6968 Acc: 0.8569\n",
      "val Loss: 0.6951 Acc: 0.8480\n",
      "test Loss: 0.6858 Acc: 0.8760\n",
      "Epoch 529/1499\n",
      "----------\n",
      "train Loss: 0.6950 Acc: 0.8582\n",
      "val Loss: 0.7000 Acc: 0.8400\n",
      "test Loss: 0.6805 Acc: 0.8760\n",
      "Epoch 530/1499\n",
      "----------\n",
      "train Loss: 0.6956 Acc: 0.8560\n",
      "val Loss: 0.6894 Acc: 0.8640\n",
      "test Loss: 0.6903 Acc: 0.8600\n",
      "Epoch 531/1499\n",
      "----------\n",
      "train Loss: 0.6963 Acc: 0.8578\n",
      "val Loss: 0.7004 Acc: 0.8600\n",
      "test Loss: 0.6861 Acc: 0.8800\n",
      "Epoch 532/1499\n",
      "----------\n",
      "train Loss: 0.6960 Acc: 0.8576\n",
      "val Loss: 0.6970 Acc: 0.8600\n",
      "test Loss: 0.6770 Acc: 0.8800\n",
      "Epoch 533/1499\n",
      "----------\n",
      "train Loss: 0.6955 Acc: 0.8616\n",
      "val Loss: 0.6886 Acc: 0.8720\n",
      "test Loss: 0.6838 Acc: 0.8720\n",
      "Epoch 534/1499\n",
      "----------\n",
      "train Loss: 0.6942 Acc: 0.8616\n",
      "val Loss: 0.7054 Acc: 0.8440\n",
      "test Loss: 0.7016 Acc: 0.8640\n",
      "Epoch 535/1499\n",
      "----------\n",
      "train Loss: 0.6947 Acc: 0.8582\n",
      "val Loss: 0.6887 Acc: 0.8600\n",
      "test Loss: 0.6838 Acc: 0.8720\n",
      "Epoch 536/1499\n",
      "----------\n",
      "train Loss: 0.6943 Acc: 0.8602\n",
      "val Loss: 0.6937 Acc: 0.8560\n",
      "test Loss: 0.6901 Acc: 0.8720\n",
      "Epoch 537/1499\n",
      "----------\n",
      "train Loss: 0.6944 Acc: 0.8593\n",
      "val Loss: 0.6886 Acc: 0.8680\n",
      "test Loss: 0.6830 Acc: 0.8760\n",
      "Epoch 538/1499\n",
      "----------\n",
      "train Loss: 0.6948 Acc: 0.8591\n",
      "val Loss: 0.6990 Acc: 0.8520\n",
      "test Loss: 0.6893 Acc: 0.8800\n",
      "Epoch 539/1499\n",
      "----------\n",
      "train Loss: 0.6964 Acc: 0.8549\n",
      "val Loss: 0.7010 Acc: 0.8560\n",
      "test Loss: 0.6883 Acc: 0.8680\n",
      "Epoch 540/1499\n",
      "----------\n",
      "train Loss: 0.6942 Acc: 0.8604\n",
      "val Loss: 0.6950 Acc: 0.8520\n",
      "test Loss: 0.6870 Acc: 0.8760\n",
      "Epoch 541/1499\n",
      "----------\n",
      "train Loss: 0.6943 Acc: 0.8584\n",
      "val Loss: 0.6888 Acc: 0.8640\n",
      "test Loss: 0.6863 Acc: 0.8680\n",
      "Epoch 542/1499\n",
      "----------\n",
      "train Loss: 0.6955 Acc: 0.8598\n",
      "val Loss: 0.6856 Acc: 0.8680\n",
      "test Loss: 0.6875 Acc: 0.8720\n",
      "Epoch 543/1499\n",
      "----------\n",
      "train Loss: 0.6960 Acc: 0.8560\n",
      "val Loss: 0.6896 Acc: 0.8720\n",
      "test Loss: 0.6839 Acc: 0.8680\n",
      "Epoch 544/1499\n",
      "----------\n",
      "train Loss: 0.6936 Acc: 0.8596\n",
      "val Loss: 0.6916 Acc: 0.8600\n",
      "test Loss: 0.6831 Acc: 0.8720\n",
      "Epoch 545/1499\n",
      "----------\n",
      "train Loss: 0.6947 Acc: 0.8591\n",
      "val Loss: 0.6928 Acc: 0.8680\n",
      "test Loss: 0.6800 Acc: 0.8840\n",
      "Epoch 546/1499\n",
      "----------\n",
      "train Loss: 0.6935 Acc: 0.8611\n",
      "val Loss: 0.6902 Acc: 0.8720\n",
      "test Loss: 0.6833 Acc: 0.8800\n",
      "Epoch 547/1499\n",
      "----------\n",
      "train Loss: 0.6947 Acc: 0.8576\n",
      "val Loss: 0.6937 Acc: 0.8520\n",
      "test Loss: 0.6793 Acc: 0.8880\n",
      "Epoch 548/1499\n",
      "----------\n",
      "train Loss: 0.6918 Acc: 0.8593\n",
      "val Loss: 0.6927 Acc: 0.8600\n",
      "test Loss: 0.6735 Acc: 0.9000\n",
      "Epoch 549/1499\n",
      "----------\n",
      "train Loss: 0.6959 Acc: 0.8562\n",
      "val Loss: 0.6939 Acc: 0.8720\n",
      "test Loss: 0.6802 Acc: 0.8720\n",
      "Epoch 550/1499\n",
      "----------\n",
      "train Loss: 0.6929 Acc: 0.8616\n",
      "val Loss: 0.6864 Acc: 0.8680\n",
      "test Loss: 0.6799 Acc: 0.8760\n",
      "Epoch 551/1499\n",
      "----------\n",
      "train Loss: 0.6939 Acc: 0.8596\n",
      "val Loss: 0.6964 Acc: 0.8560\n",
      "test Loss: 0.6873 Acc: 0.8680\n",
      "Epoch 552/1499\n",
      "----------\n",
      "train Loss: 0.6892 Acc: 0.8678\n",
      "val Loss: 0.6956 Acc: 0.8600\n",
      "test Loss: 0.6856 Acc: 0.8800\n",
      "Epoch 553/1499\n",
      "----------\n",
      "train Loss: 0.6948 Acc: 0.8591\n",
      "val Loss: 0.6867 Acc: 0.8880\n",
      "test Loss: 0.6846 Acc: 0.8720\n",
      "Epoch 554/1499\n",
      "----------\n",
      "train Loss: 0.6952 Acc: 0.8576\n",
      "val Loss: 0.6917 Acc: 0.8680\n",
      "test Loss: 0.7048 Acc: 0.8400\n",
      "Epoch 555/1499\n",
      "----------\n",
      "train Loss: 0.6931 Acc: 0.8622\n",
      "val Loss: 0.6958 Acc: 0.8600\n",
      "test Loss: 0.6867 Acc: 0.8720\n",
      "Epoch 556/1499\n",
      "----------\n",
      "train Loss: 0.6946 Acc: 0.8573\n",
      "val Loss: 0.6902 Acc: 0.8520\n",
      "test Loss: 0.6763 Acc: 0.8920\n",
      "Epoch 557/1499\n",
      "----------\n",
      "train Loss: 0.6933 Acc: 0.8600\n",
      "val Loss: 0.6859 Acc: 0.8680\n",
      "test Loss: 0.6779 Acc: 0.8720\n",
      "Epoch 558/1499\n",
      "----------\n",
      "train Loss: 0.6920 Acc: 0.8611\n",
      "val Loss: 0.7011 Acc: 0.8320\n",
      "test Loss: 0.6845 Acc: 0.8760\n",
      "Epoch 559/1499\n",
      "----------\n",
      "train Loss: 0.6901 Acc: 0.8607\n",
      "val Loss: 0.6829 Acc: 0.8680\n",
      "test Loss: 0.6766 Acc: 0.8720\n",
      "Epoch 560/1499\n",
      "----------\n",
      "train Loss: 0.6914 Acc: 0.8627\n",
      "val Loss: 0.6934 Acc: 0.8560\n",
      "test Loss: 0.6789 Acc: 0.8760\n",
      "Epoch 561/1499\n",
      "----------\n",
      "train Loss: 0.6911 Acc: 0.8607\n",
      "val Loss: 0.6879 Acc: 0.8600\n",
      "test Loss: 0.6818 Acc: 0.8800\n",
      "Epoch 562/1499\n",
      "----------\n",
      "train Loss: 0.6923 Acc: 0.8616\n",
      "val Loss: 0.6885 Acc: 0.8680\n",
      "test Loss: 0.6816 Acc: 0.8680\n",
      "Epoch 563/1499\n",
      "----------\n",
      "train Loss: 0.6878 Acc: 0.8658\n",
      "val Loss: 0.6896 Acc: 0.8600\n",
      "test Loss: 0.6936 Acc: 0.8560\n",
      "Epoch 564/1499\n",
      "----------\n",
      "train Loss: 0.6910 Acc: 0.8649\n",
      "val Loss: 0.6961 Acc: 0.8600\n",
      "test Loss: 0.6819 Acc: 0.8680\n",
      "Epoch 565/1499\n",
      "----------\n",
      "train Loss: 0.6929 Acc: 0.8622\n",
      "val Loss: 0.6908 Acc: 0.8600\n",
      "test Loss: 0.6784 Acc: 0.8840\n",
      "Epoch 566/1499\n",
      "----------\n",
      "train Loss: 0.6924 Acc: 0.8589\n",
      "val Loss: 0.6790 Acc: 0.8720\n",
      "test Loss: 0.6680 Acc: 0.8960\n",
      "Epoch 567/1499\n",
      "----------\n",
      "train Loss: 0.6901 Acc: 0.8636\n",
      "val Loss: 0.6902 Acc: 0.8680\n",
      "test Loss: 0.6797 Acc: 0.8680\n",
      "Epoch 568/1499\n",
      "----------\n",
      "train Loss: 0.6895 Acc: 0.8651\n",
      "val Loss: 0.6956 Acc: 0.8480\n",
      "test Loss: 0.6890 Acc: 0.8800\n",
      "Epoch 569/1499\n",
      "----------\n",
      "train Loss: 0.6887 Acc: 0.8656\n",
      "val Loss: 0.6942 Acc: 0.8520\n",
      "test Loss: 0.6906 Acc: 0.8600\n",
      "Epoch 570/1499\n",
      "----------\n",
      "train Loss: 0.6914 Acc: 0.8611\n",
      "val Loss: 0.6914 Acc: 0.8480\n",
      "test Loss: 0.6885 Acc: 0.8720\n",
      "Epoch 571/1499\n",
      "----------\n",
      "train Loss: 0.6920 Acc: 0.8609\n",
      "val Loss: 0.6870 Acc: 0.8680\n",
      "test Loss: 0.6886 Acc: 0.8560\n",
      "Epoch 572/1499\n",
      "----------\n",
      "train Loss: 0.6879 Acc: 0.8649\n",
      "val Loss: 0.6843 Acc: 0.8680\n",
      "test Loss: 0.6791 Acc: 0.8680\n",
      "Epoch 573/1499\n",
      "----------\n",
      "train Loss: 0.6907 Acc: 0.8613\n",
      "val Loss: 0.6864 Acc: 0.8600\n",
      "test Loss: 0.6736 Acc: 0.8760\n",
      "Epoch 574/1499\n",
      "----------\n",
      "train Loss: 0.6920 Acc: 0.8624\n",
      "val Loss: 0.6904 Acc: 0.8640\n",
      "test Loss: 0.6755 Acc: 0.8640\n",
      "Epoch 575/1499\n",
      "----------\n",
      "train Loss: 0.6902 Acc: 0.8642\n",
      "val Loss: 0.6901 Acc: 0.8600\n",
      "test Loss: 0.6819 Acc: 0.8680\n",
      "Epoch 576/1499\n",
      "----------\n",
      "train Loss: 0.6905 Acc: 0.8636\n",
      "val Loss: 0.6914 Acc: 0.8560\n",
      "test Loss: 0.6784 Acc: 0.8720\n",
      "Epoch 577/1499\n",
      "----------\n",
      "train Loss: 0.6912 Acc: 0.8629\n",
      "val Loss: 0.6746 Acc: 0.8880\n",
      "test Loss: 0.6782 Acc: 0.8800\n",
      "Epoch 578/1499\n",
      "----------\n",
      "train Loss: 0.6906 Acc: 0.8593\n",
      "val Loss: 0.6934 Acc: 0.8600\n",
      "test Loss: 0.6729 Acc: 0.8840\n",
      "Epoch 579/1499\n",
      "----------\n",
      "train Loss: 0.6919 Acc: 0.8598\n",
      "val Loss: 0.6847 Acc: 0.8640\n",
      "test Loss: 0.6752 Acc: 0.8840\n",
      "Epoch 580/1499\n",
      "----------\n",
      "train Loss: 0.6895 Acc: 0.8636\n",
      "val Loss: 0.6900 Acc: 0.8600\n",
      "test Loss: 0.6952 Acc: 0.8520\n",
      "Epoch 581/1499\n",
      "----------\n",
      "train Loss: 0.6895 Acc: 0.8649\n",
      "val Loss: 0.6898 Acc: 0.8600\n",
      "test Loss: 0.6737 Acc: 0.8960\n",
      "Epoch 582/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6899 Acc: 0.8633\n",
      "val Loss: 0.6960 Acc: 0.8480\n",
      "test Loss: 0.6845 Acc: 0.8680\n",
      "Epoch 583/1499\n",
      "----------\n",
      "train Loss: 0.6899 Acc: 0.8638\n",
      "val Loss: 0.6966 Acc: 0.8400\n",
      "test Loss: 0.6819 Acc: 0.8800\n",
      "Epoch 584/1499\n",
      "----------\n",
      "train Loss: 0.6906 Acc: 0.8624\n",
      "val Loss: 0.6781 Acc: 0.8760\n",
      "test Loss: 0.6731 Acc: 0.8880\n",
      "Epoch 585/1499\n",
      "----------\n",
      "train Loss: 0.6883 Acc: 0.8660\n",
      "val Loss: 0.6861 Acc: 0.8560\n",
      "test Loss: 0.6849 Acc: 0.8720\n",
      "Epoch 586/1499\n",
      "----------\n",
      "train Loss: 0.6899 Acc: 0.8627\n",
      "val Loss: 0.6974 Acc: 0.8400\n",
      "test Loss: 0.6809 Acc: 0.8640\n",
      "Epoch 587/1499\n",
      "----------\n",
      "train Loss: 0.6887 Acc: 0.8613\n",
      "val Loss: 0.6879 Acc: 0.8640\n",
      "test Loss: 0.6791 Acc: 0.8680\n",
      "Epoch 588/1499\n",
      "----------\n",
      "train Loss: 0.6884 Acc: 0.8624\n",
      "val Loss: 0.6889 Acc: 0.8640\n",
      "test Loss: 0.6818 Acc: 0.8680\n",
      "Epoch 589/1499\n",
      "----------\n",
      "train Loss: 0.6884 Acc: 0.8636\n",
      "val Loss: 0.6843 Acc: 0.8720\n",
      "test Loss: 0.6808 Acc: 0.8800\n",
      "Epoch 590/1499\n",
      "----------\n",
      "train Loss: 0.6884 Acc: 0.8642\n",
      "val Loss: 0.6947 Acc: 0.8440\n",
      "test Loss: 0.6774 Acc: 0.8760\n",
      "Epoch 591/1499\n",
      "----------\n",
      "train Loss: 0.6899 Acc: 0.8616\n",
      "val Loss: 0.6864 Acc: 0.8640\n",
      "test Loss: 0.6811 Acc: 0.8760\n",
      "Epoch 592/1499\n",
      "----------\n",
      "train Loss: 0.6878 Acc: 0.8649\n",
      "val Loss: 0.6835 Acc: 0.8640\n",
      "test Loss: 0.6847 Acc: 0.8720\n",
      "Epoch 593/1499\n",
      "----------\n",
      "train Loss: 0.6894 Acc: 0.8656\n",
      "val Loss: 0.6927 Acc: 0.8520\n",
      "test Loss: 0.6834 Acc: 0.8680\n",
      "Epoch 594/1499\n",
      "----------\n",
      "train Loss: 0.6908 Acc: 0.8618\n",
      "val Loss: 0.6996 Acc: 0.8400\n",
      "test Loss: 0.6707 Acc: 0.8880\n",
      "Epoch 595/1499\n",
      "----------\n",
      "train Loss: 0.6875 Acc: 0.8667\n",
      "val Loss: 0.6899 Acc: 0.8560\n",
      "test Loss: 0.6788 Acc: 0.8800\n",
      "Epoch 596/1499\n",
      "----------\n",
      "train Loss: 0.6892 Acc: 0.8638\n",
      "val Loss: 0.6895 Acc: 0.8640\n",
      "test Loss: 0.6759 Acc: 0.8880\n",
      "Epoch 597/1499\n",
      "----------\n",
      "train Loss: 0.6896 Acc: 0.8622\n",
      "val Loss: 0.6974 Acc: 0.8480\n",
      "test Loss: 0.6864 Acc: 0.8560\n",
      "Epoch 598/1499\n",
      "----------\n",
      "train Loss: 0.6862 Acc: 0.8660\n",
      "val Loss: 0.6880 Acc: 0.8600\n",
      "test Loss: 0.6761 Acc: 0.8760\n",
      "Epoch 599/1499\n",
      "----------\n",
      "train Loss: 0.6851 Acc: 0.8671\n",
      "val Loss: 0.6849 Acc: 0.8640\n",
      "test Loss: 0.6805 Acc: 0.8800\n",
      "Epoch 600/1499\n",
      "----------\n",
      "train Loss: 0.6891 Acc: 0.8618\n",
      "val Loss: 0.6873 Acc: 0.8560\n",
      "test Loss: 0.6863 Acc: 0.8680\n",
      "Epoch 601/1499\n",
      "----------\n",
      "train Loss: 0.6876 Acc: 0.8660\n",
      "val Loss: 0.6842 Acc: 0.8680\n",
      "test Loss: 0.6776 Acc: 0.8600\n",
      "Epoch 602/1499\n",
      "----------\n",
      "train Loss: 0.6880 Acc: 0.8644\n",
      "val Loss: 0.6866 Acc: 0.8640\n",
      "test Loss: 0.6847 Acc: 0.8640\n",
      "Epoch 603/1499\n",
      "----------\n",
      "train Loss: 0.6871 Acc: 0.8678\n",
      "val Loss: 0.6831 Acc: 0.8720\n",
      "test Loss: 0.6755 Acc: 0.8800\n",
      "Epoch 604/1499\n",
      "----------\n",
      "train Loss: 0.6857 Acc: 0.8662\n",
      "val Loss: 0.6819 Acc: 0.8680\n",
      "test Loss: 0.6783 Acc: 0.8760\n",
      "Epoch 605/1499\n",
      "----------\n",
      "train Loss: 0.6878 Acc: 0.8644\n",
      "val Loss: 0.6839 Acc: 0.8600\n",
      "test Loss: 0.6903 Acc: 0.8640\n",
      "Epoch 606/1499\n",
      "----------\n",
      "train Loss: 0.6879 Acc: 0.8669\n",
      "val Loss: 0.6975 Acc: 0.8560\n",
      "test Loss: 0.6744 Acc: 0.8840\n",
      "Epoch 607/1499\n",
      "----------\n",
      "train Loss: 0.6865 Acc: 0.8660\n",
      "val Loss: 0.6815 Acc: 0.8680\n",
      "test Loss: 0.6716 Acc: 0.8840\n",
      "Epoch 608/1499\n",
      "----------\n",
      "train Loss: 0.6873 Acc: 0.8642\n",
      "val Loss: 0.6790 Acc: 0.8640\n",
      "test Loss: 0.6894 Acc: 0.8640\n",
      "Epoch 609/1499\n",
      "----------\n",
      "train Loss: 0.6863 Acc: 0.8689\n",
      "val Loss: 0.6929 Acc: 0.8520\n",
      "test Loss: 0.6842 Acc: 0.8640\n",
      "Epoch 610/1499\n",
      "----------\n",
      "train Loss: 0.6873 Acc: 0.8656\n",
      "val Loss: 0.6865 Acc: 0.8600\n",
      "test Loss: 0.6835 Acc: 0.8720\n",
      "Epoch 611/1499\n",
      "----------\n",
      "train Loss: 0.6874 Acc: 0.8642\n",
      "val Loss: 0.6867 Acc: 0.8600\n",
      "test Loss: 0.6841 Acc: 0.8600\n",
      "Epoch 612/1499\n",
      "----------\n",
      "train Loss: 0.6877 Acc: 0.8651\n",
      "val Loss: 0.6900 Acc: 0.8560\n",
      "test Loss: 0.6904 Acc: 0.8720\n",
      "Epoch 613/1499\n",
      "----------\n",
      "train Loss: 0.6859 Acc: 0.8684\n",
      "val Loss: 0.6769 Acc: 0.8680\n",
      "test Loss: 0.6829 Acc: 0.8640\n",
      "Epoch 614/1499\n",
      "----------\n",
      "train Loss: 0.6838 Acc: 0.8711\n",
      "val Loss: 0.6883 Acc: 0.8480\n",
      "test Loss: 0.6803 Acc: 0.8720\n",
      "Epoch 615/1499\n",
      "----------\n",
      "train Loss: 0.6869 Acc: 0.8662\n",
      "val Loss: 0.6892 Acc: 0.8520\n",
      "test Loss: 0.6787 Acc: 0.8720\n",
      "Epoch 616/1499\n",
      "----------\n",
      "train Loss: 0.6845 Acc: 0.8691\n",
      "val Loss: 0.6879 Acc: 0.8600\n",
      "test Loss: 0.6730 Acc: 0.8800\n",
      "Epoch 617/1499\n",
      "----------\n",
      "train Loss: 0.6862 Acc: 0.8660\n",
      "val Loss: 0.6834 Acc: 0.8560\n",
      "test Loss: 0.6747 Acc: 0.8720\n",
      "Epoch 618/1499\n",
      "----------\n",
      "train Loss: 0.6867 Acc: 0.8644\n",
      "val Loss: 0.6841 Acc: 0.8640\n",
      "test Loss: 0.6757 Acc: 0.8760\n",
      "Epoch 619/1499\n",
      "----------\n",
      "train Loss: 0.6848 Acc: 0.8673\n",
      "val Loss: 0.6911 Acc: 0.8520\n",
      "test Loss: 0.6849 Acc: 0.8680\n",
      "Epoch 620/1499\n",
      "----------\n",
      "train Loss: 0.6864 Acc: 0.8649\n",
      "val Loss: 0.6880 Acc: 0.8640\n",
      "test Loss: 0.6725 Acc: 0.8760\n",
      "Epoch 621/1499\n",
      "----------\n",
      "train Loss: 0.6843 Acc: 0.8707\n",
      "val Loss: 0.6926 Acc: 0.8520\n",
      "test Loss: 0.6644 Acc: 0.9000\n",
      "Epoch 622/1499\n",
      "----------\n",
      "train Loss: 0.6846 Acc: 0.8698\n",
      "val Loss: 0.6856 Acc: 0.8600\n",
      "test Loss: 0.6921 Acc: 0.8560\n",
      "Epoch 623/1499\n",
      "----------\n",
      "train Loss: 0.6879 Acc: 0.8658\n",
      "val Loss: 0.6718 Acc: 0.8840\n",
      "test Loss: 0.6746 Acc: 0.8760\n",
      "Epoch 624/1499\n",
      "----------\n",
      "train Loss: 0.6836 Acc: 0.8698\n",
      "val Loss: 0.6787 Acc: 0.8760\n",
      "test Loss: 0.6797 Acc: 0.8760\n",
      "Epoch 625/1499\n",
      "----------\n",
      "train Loss: 0.6838 Acc: 0.8718\n",
      "val Loss: 0.6853 Acc: 0.8640\n",
      "test Loss: 0.6781 Acc: 0.8760\n",
      "Epoch 626/1499\n",
      "----------\n",
      "train Loss: 0.6851 Acc: 0.8660\n",
      "val Loss: 0.6973 Acc: 0.8400\n",
      "test Loss: 0.6780 Acc: 0.8800\n",
      "Epoch 627/1499\n",
      "----------\n",
      "train Loss: 0.6856 Acc: 0.8664\n",
      "val Loss: 0.6874 Acc: 0.8600\n",
      "test Loss: 0.6815 Acc: 0.8680\n",
      "Epoch 628/1499\n",
      "----------\n",
      "train Loss: 0.6856 Acc: 0.8669\n",
      "val Loss: 0.6795 Acc: 0.8800\n",
      "test Loss: 0.6810 Acc: 0.8720\n",
      "Epoch 629/1499\n",
      "----------\n",
      "train Loss: 0.6827 Acc: 0.8713\n",
      "val Loss: 0.6935 Acc: 0.8480\n",
      "test Loss: 0.6776 Acc: 0.8840\n",
      "Epoch 630/1499\n",
      "----------\n",
      "train Loss: 0.6839 Acc: 0.8671\n",
      "val Loss: 0.6846 Acc: 0.8640\n",
      "test Loss: 0.6854 Acc: 0.8720\n",
      "Epoch 631/1499\n",
      "----------\n",
      "train Loss: 0.6854 Acc: 0.8678\n",
      "val Loss: 0.6795 Acc: 0.8680\n",
      "test Loss: 0.6707 Acc: 0.8920\n",
      "Epoch 632/1499\n",
      "----------\n",
      "train Loss: 0.6819 Acc: 0.8731\n",
      "val Loss: 0.6836 Acc: 0.8640\n",
      "test Loss: 0.6866 Acc: 0.8680\n",
      "Epoch 633/1499\n",
      "----------\n",
      "train Loss: 0.6871 Acc: 0.8651\n",
      "val Loss: 0.6770 Acc: 0.8880\n",
      "test Loss: 0.6812 Acc: 0.8800\n",
      "Epoch 634/1499\n",
      "----------\n",
      "train Loss: 0.6835 Acc: 0.8680\n",
      "val Loss: 0.6901 Acc: 0.8520\n",
      "test Loss: 0.6698 Acc: 0.8880\n",
      "Epoch 635/1499\n",
      "----------\n",
      "train Loss: 0.6841 Acc: 0.8682\n",
      "val Loss: 0.6814 Acc: 0.8680\n",
      "test Loss: 0.6755 Acc: 0.8840\n",
      "Epoch 636/1499\n",
      "----------\n",
      "train Loss: 0.6843 Acc: 0.8698\n",
      "val Loss: 0.6785 Acc: 0.8640\n",
      "test Loss: 0.6784 Acc: 0.8760\n",
      "Epoch 637/1499\n",
      "----------\n",
      "train Loss: 0.6825 Acc: 0.8704\n",
      "val Loss: 0.6692 Acc: 0.8800\n",
      "test Loss: 0.6780 Acc: 0.8800\n",
      "Epoch 638/1499\n",
      "----------\n",
      "train Loss: 0.6858 Acc: 0.8660\n",
      "val Loss: 0.6875 Acc: 0.8520\n",
      "test Loss: 0.6757 Acc: 0.8800\n",
      "Epoch 639/1499\n",
      "----------\n",
      "train Loss: 0.6860 Acc: 0.8676\n",
      "val Loss: 0.6867 Acc: 0.8640\n",
      "test Loss: 0.6744 Acc: 0.8840\n",
      "Epoch 640/1499\n",
      "----------\n",
      "train Loss: 0.6838 Acc: 0.8698\n",
      "val Loss: 0.6835 Acc: 0.8640\n",
      "test Loss: 0.6727 Acc: 0.8840\n",
      "Epoch 641/1499\n",
      "----------\n",
      "train Loss: 0.6836 Acc: 0.8687\n",
      "val Loss: 0.6820 Acc: 0.8640\n",
      "test Loss: 0.6818 Acc: 0.8800\n",
      "Epoch 642/1499\n",
      "----------\n",
      "train Loss: 0.6830 Acc: 0.8704\n",
      "val Loss: 0.6820 Acc: 0.8680\n",
      "test Loss: 0.6630 Acc: 0.8880\n",
      "Epoch 643/1499\n",
      "----------\n",
      "train Loss: 0.6825 Acc: 0.8718\n",
      "val Loss: 0.6780 Acc: 0.8640\n",
      "test Loss: 0.6743 Acc: 0.8880\n",
      "Epoch 644/1499\n",
      "----------\n",
      "train Loss: 0.6837 Acc: 0.8684\n",
      "val Loss: 0.6777 Acc: 0.8640\n",
      "test Loss: 0.6799 Acc: 0.8720\n",
      "Epoch 645/1499\n",
      "----------\n",
      "train Loss: 0.6844 Acc: 0.8693\n",
      "val Loss: 0.6843 Acc: 0.8560\n",
      "test Loss: 0.6694 Acc: 0.8880\n",
      "Epoch 646/1499\n",
      "----------\n",
      "train Loss: 0.6846 Acc: 0.8678\n",
      "val Loss: 0.6899 Acc: 0.8400\n",
      "test Loss: 0.6700 Acc: 0.8920\n",
      "Epoch 647/1499\n",
      "----------\n",
      "train Loss: 0.6825 Acc: 0.8678\n",
      "val Loss: 0.6843 Acc: 0.8560\n",
      "test Loss: 0.6793 Acc: 0.8760\n",
      "Epoch 648/1499\n",
      "----------\n",
      "train Loss: 0.6824 Acc: 0.8713\n",
      "val Loss: 0.6853 Acc: 0.8600\n",
      "test Loss: 0.6766 Acc: 0.8800\n",
      "Epoch 649/1499\n",
      "----------\n",
      "train Loss: 0.6821 Acc: 0.8687\n",
      "val Loss: 0.6817 Acc: 0.8720\n",
      "test Loss: 0.6798 Acc: 0.8760\n",
      "Epoch 650/1499\n",
      "----------\n",
      "train Loss: 0.6811 Acc: 0.8722\n",
      "val Loss: 0.6908 Acc: 0.8480\n",
      "test Loss: 0.6680 Acc: 0.8920\n",
      "Epoch 651/1499\n",
      "----------\n",
      "train Loss: 0.6842 Acc: 0.8656\n",
      "val Loss: 0.6848 Acc: 0.8600\n",
      "test Loss: 0.6729 Acc: 0.8840\n",
      "Epoch 652/1499\n",
      "----------\n",
      "train Loss: 0.6823 Acc: 0.8700\n",
      "val Loss: 0.6823 Acc: 0.8640\n",
      "test Loss: 0.6781 Acc: 0.8880\n",
      "Epoch 653/1499\n",
      "----------\n",
      "train Loss: 0.6837 Acc: 0.8709\n",
      "val Loss: 0.6945 Acc: 0.8440\n",
      "test Loss: 0.6698 Acc: 0.8840\n",
      "Epoch 654/1499\n",
      "----------\n",
      "train Loss: 0.6834 Acc: 0.8698\n",
      "val Loss: 0.6869 Acc: 0.8560\n",
      "test Loss: 0.6699 Acc: 0.8840\n",
      "Epoch 655/1499\n",
      "----------\n",
      "train Loss: 0.6829 Acc: 0.8676\n",
      "val Loss: 0.6825 Acc: 0.8520\n",
      "test Loss: 0.6767 Acc: 0.8760\n",
      "Epoch 656/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6824 Acc: 0.8724\n",
      "val Loss: 0.6919 Acc: 0.8560\n",
      "test Loss: 0.6812 Acc: 0.8760\n",
      "Epoch 657/1499\n",
      "----------\n",
      "train Loss: 0.6829 Acc: 0.8691\n",
      "val Loss: 0.6822 Acc: 0.8680\n",
      "test Loss: 0.6784 Acc: 0.8680\n",
      "Epoch 658/1499\n",
      "----------\n",
      "train Loss: 0.6837 Acc: 0.8700\n",
      "val Loss: 0.6890 Acc: 0.8480\n",
      "test Loss: 0.6901 Acc: 0.8600\n",
      "Epoch 659/1499\n",
      "----------\n",
      "train Loss: 0.6831 Acc: 0.8687\n",
      "val Loss: 0.6846 Acc: 0.8520\n",
      "test Loss: 0.6718 Acc: 0.8840\n",
      "Epoch 660/1499\n",
      "----------\n",
      "train Loss: 0.6802 Acc: 0.8718\n",
      "val Loss: 0.6794 Acc: 0.8560\n",
      "test Loss: 0.6741 Acc: 0.8880\n",
      "Epoch 661/1499\n",
      "----------\n",
      "train Loss: 0.6836 Acc: 0.8693\n",
      "val Loss: 0.6819 Acc: 0.8680\n",
      "test Loss: 0.6774 Acc: 0.8720\n",
      "Epoch 662/1499\n",
      "----------\n",
      "train Loss: 0.6819 Acc: 0.8713\n",
      "val Loss: 0.6887 Acc: 0.8440\n",
      "test Loss: 0.6707 Acc: 0.8840\n",
      "Epoch 663/1499\n",
      "----------\n",
      "train Loss: 0.6817 Acc: 0.8711\n",
      "val Loss: 0.6767 Acc: 0.8720\n",
      "test Loss: 0.6818 Acc: 0.8760\n",
      "Epoch 664/1499\n",
      "----------\n",
      "train Loss: 0.6848 Acc: 0.8671\n",
      "val Loss: 0.6812 Acc: 0.8640\n",
      "test Loss: 0.6784 Acc: 0.8760\n",
      "Epoch 665/1499\n",
      "----------\n",
      "train Loss: 0.6825 Acc: 0.8662\n",
      "val Loss: 0.6884 Acc: 0.8480\n",
      "test Loss: 0.6782 Acc: 0.8840\n",
      "Epoch 666/1499\n",
      "----------\n",
      "train Loss: 0.6795 Acc: 0.8722\n",
      "val Loss: 0.6790 Acc: 0.8680\n",
      "test Loss: 0.6802 Acc: 0.8760\n",
      "Epoch 667/1499\n",
      "----------\n",
      "train Loss: 0.6808 Acc: 0.8709\n",
      "val Loss: 0.6788 Acc: 0.8640\n",
      "test Loss: 0.6638 Acc: 0.8920\n",
      "Epoch 668/1499\n",
      "----------\n",
      "train Loss: 0.6839 Acc: 0.8676\n",
      "val Loss: 0.6768 Acc: 0.8720\n",
      "test Loss: 0.6660 Acc: 0.8880\n",
      "Epoch 669/1499\n",
      "----------\n",
      "train Loss: 0.6817 Acc: 0.8709\n",
      "val Loss: 0.6777 Acc: 0.8680\n",
      "test Loss: 0.6691 Acc: 0.8880\n",
      "Epoch 670/1499\n",
      "----------\n",
      "train Loss: 0.6804 Acc: 0.8713\n",
      "val Loss: 0.6987 Acc: 0.8400\n",
      "test Loss: 0.6720 Acc: 0.8960\n",
      "Epoch 671/1499\n",
      "----------\n",
      "train Loss: 0.6813 Acc: 0.8709\n",
      "val Loss: 0.6809 Acc: 0.8640\n",
      "test Loss: 0.6705 Acc: 0.8880\n",
      "Epoch 672/1499\n",
      "----------\n",
      "train Loss: 0.6817 Acc: 0.8729\n",
      "val Loss: 0.6885 Acc: 0.8440\n",
      "test Loss: 0.6726 Acc: 0.8760\n",
      "Epoch 673/1499\n",
      "----------\n",
      "train Loss: 0.6820 Acc: 0.8707\n",
      "val Loss: 0.6832 Acc: 0.8640\n",
      "test Loss: 0.6794 Acc: 0.8760\n",
      "Epoch 674/1499\n",
      "----------\n",
      "train Loss: 0.6827 Acc: 0.8684\n",
      "val Loss: 0.6820 Acc: 0.8560\n",
      "test Loss: 0.6710 Acc: 0.8920\n",
      "Epoch 675/1499\n",
      "----------\n",
      "train Loss: 0.6828 Acc: 0.8698\n",
      "val Loss: 0.6824 Acc: 0.8720\n",
      "test Loss: 0.6748 Acc: 0.8880\n",
      "Epoch 676/1499\n",
      "----------\n",
      "train Loss: 0.6828 Acc: 0.8702\n",
      "val Loss: 0.6777 Acc: 0.8680\n",
      "test Loss: 0.6786 Acc: 0.8800\n",
      "Epoch 677/1499\n",
      "----------\n",
      "train Loss: 0.6809 Acc: 0.8727\n",
      "val Loss: 0.6790 Acc: 0.8680\n",
      "test Loss: 0.6667 Acc: 0.8880\n",
      "Epoch 678/1499\n",
      "----------\n",
      "train Loss: 0.6819 Acc: 0.8707\n",
      "val Loss: 0.6801 Acc: 0.8640\n",
      "test Loss: 0.6818 Acc: 0.8720\n",
      "Epoch 679/1499\n",
      "----------\n",
      "train Loss: 0.6813 Acc: 0.8713\n",
      "val Loss: 0.6863 Acc: 0.8560\n",
      "test Loss: 0.6761 Acc: 0.8800\n",
      "Epoch 680/1499\n",
      "----------\n",
      "train Loss: 0.6787 Acc: 0.8749\n",
      "val Loss: 0.6780 Acc: 0.8680\n",
      "test Loss: 0.6710 Acc: 0.8920\n",
      "Epoch 681/1499\n",
      "----------\n",
      "train Loss: 0.6808 Acc: 0.8702\n",
      "val Loss: 0.6768 Acc: 0.8640\n",
      "test Loss: 0.6717 Acc: 0.8880\n",
      "Epoch 682/1499\n",
      "----------\n",
      "train Loss: 0.6830 Acc: 0.8673\n",
      "val Loss: 0.6824 Acc: 0.8640\n",
      "test Loss: 0.6797 Acc: 0.8760\n",
      "Epoch 683/1499\n",
      "----------\n",
      "train Loss: 0.6800 Acc: 0.8727\n",
      "val Loss: 0.6838 Acc: 0.8520\n",
      "test Loss: 0.6709 Acc: 0.8840\n",
      "Epoch 684/1499\n",
      "----------\n",
      "train Loss: 0.6815 Acc: 0.8707\n",
      "val Loss: 0.6848 Acc: 0.8520\n",
      "test Loss: 0.6722 Acc: 0.8880\n",
      "Epoch 685/1499\n",
      "----------\n",
      "train Loss: 0.6789 Acc: 0.8744\n",
      "val Loss: 0.6810 Acc: 0.8640\n",
      "test Loss: 0.6887 Acc: 0.8640\n",
      "Epoch 686/1499\n",
      "----------\n",
      "train Loss: 0.6803 Acc: 0.8698\n",
      "val Loss: 0.6804 Acc: 0.8600\n",
      "test Loss: 0.6694 Acc: 0.8920\n",
      "Epoch 687/1499\n",
      "----------\n",
      "train Loss: 0.6811 Acc: 0.8716\n",
      "val Loss: 0.6877 Acc: 0.8560\n",
      "test Loss: 0.6698 Acc: 0.8840\n",
      "Epoch 688/1499\n",
      "----------\n",
      "train Loss: 0.6795 Acc: 0.8731\n",
      "val Loss: 0.6840 Acc: 0.8600\n",
      "test Loss: 0.6706 Acc: 0.8920\n",
      "Epoch 689/1499\n",
      "----------\n",
      "train Loss: 0.6803 Acc: 0.8762\n",
      "val Loss: 0.6850 Acc: 0.8560\n",
      "test Loss: 0.6748 Acc: 0.8840\n",
      "Epoch 690/1499\n",
      "----------\n",
      "train Loss: 0.6796 Acc: 0.8738\n",
      "val Loss: 0.6813 Acc: 0.8520\n",
      "test Loss: 0.6752 Acc: 0.8840\n",
      "Epoch 691/1499\n",
      "----------\n",
      "train Loss: 0.6825 Acc: 0.8736\n",
      "val Loss: 0.6770 Acc: 0.8720\n",
      "test Loss: 0.6872 Acc: 0.8760\n",
      "Epoch 692/1499\n",
      "----------\n",
      "train Loss: 0.6800 Acc: 0.8722\n",
      "val Loss: 0.6729 Acc: 0.8680\n",
      "test Loss: 0.6688 Acc: 0.8920\n",
      "Epoch 693/1499\n",
      "----------\n",
      "train Loss: 0.6811 Acc: 0.8716\n",
      "val Loss: 0.6716 Acc: 0.8720\n",
      "test Loss: 0.6747 Acc: 0.8920\n",
      "Epoch 694/1499\n",
      "----------\n",
      "train Loss: 0.6794 Acc: 0.8729\n",
      "val Loss: 0.6800 Acc: 0.8720\n",
      "test Loss: 0.6724 Acc: 0.8880\n",
      "Epoch 695/1499\n",
      "----------\n",
      "train Loss: 0.6811 Acc: 0.8749\n",
      "val Loss: 0.6829 Acc: 0.8560\n",
      "test Loss: 0.6826 Acc: 0.8800\n",
      "Epoch 696/1499\n",
      "----------\n",
      "train Loss: 0.6803 Acc: 0.8740\n",
      "val Loss: 0.6795 Acc: 0.8680\n",
      "test Loss: 0.6703 Acc: 0.8880\n",
      "Epoch 697/1499\n",
      "----------\n",
      "train Loss: 0.6798 Acc: 0.8756\n",
      "val Loss: 0.6785 Acc: 0.8680\n",
      "test Loss: 0.6661 Acc: 0.8920\n",
      "Epoch 698/1499\n",
      "----------\n",
      "train Loss: 0.6800 Acc: 0.8738\n",
      "val Loss: 0.6787 Acc: 0.8640\n",
      "test Loss: 0.6738 Acc: 0.8960\n",
      "Epoch 699/1499\n",
      "----------\n",
      "train Loss: 0.6819 Acc: 0.8711\n",
      "val Loss: 0.6849 Acc: 0.8600\n",
      "test Loss: 0.6736 Acc: 0.8800\n",
      "Epoch 700/1499\n",
      "----------\n",
      "train Loss: 0.6798 Acc: 0.8744\n",
      "val Loss: 0.6804 Acc: 0.8720\n",
      "test Loss: 0.6673 Acc: 0.8880\n",
      "Epoch 701/1499\n",
      "----------\n",
      "train Loss: 0.6795 Acc: 0.8742\n",
      "val Loss: 0.6791 Acc: 0.8680\n",
      "test Loss: 0.6778 Acc: 0.8800\n",
      "Epoch 702/1499\n",
      "----------\n",
      "train Loss: 0.6793 Acc: 0.8753\n",
      "val Loss: 0.6751 Acc: 0.8680\n",
      "test Loss: 0.6739 Acc: 0.8800\n",
      "Epoch 703/1499\n",
      "----------\n",
      "train Loss: 0.6809 Acc: 0.8740\n",
      "val Loss: 0.6688 Acc: 0.8680\n",
      "test Loss: 0.6679 Acc: 0.8840\n",
      "Epoch 704/1499\n",
      "----------\n",
      "train Loss: 0.6771 Acc: 0.8762\n",
      "val Loss: 0.6891 Acc: 0.8560\n",
      "test Loss: 0.6697 Acc: 0.8920\n",
      "Epoch 705/1499\n",
      "----------\n",
      "train Loss: 0.6794 Acc: 0.8753\n",
      "val Loss: 0.6838 Acc: 0.8760\n",
      "test Loss: 0.6782 Acc: 0.8760\n",
      "Epoch 706/1499\n",
      "----------\n",
      "train Loss: 0.6793 Acc: 0.8744\n",
      "val Loss: 0.6751 Acc: 0.8800\n",
      "test Loss: 0.6669 Acc: 0.8920\n",
      "Epoch 707/1499\n",
      "----------\n",
      "train Loss: 0.6786 Acc: 0.8744\n",
      "val Loss: 0.6833 Acc: 0.8720\n",
      "test Loss: 0.6871 Acc: 0.8760\n",
      "Epoch 708/1499\n",
      "----------\n",
      "train Loss: 0.6796 Acc: 0.8736\n",
      "val Loss: 0.6875 Acc: 0.8680\n",
      "test Loss: 0.6645 Acc: 0.9000\n",
      "Epoch 709/1499\n",
      "----------\n",
      "train Loss: 0.6787 Acc: 0.8749\n",
      "val Loss: 0.6829 Acc: 0.8560\n",
      "test Loss: 0.6728 Acc: 0.8880\n",
      "Epoch 710/1499\n",
      "----------\n",
      "train Loss: 0.6803 Acc: 0.8733\n",
      "val Loss: 0.6720 Acc: 0.8760\n",
      "test Loss: 0.6777 Acc: 0.8800\n",
      "Epoch 711/1499\n",
      "----------\n",
      "train Loss: 0.6802 Acc: 0.8751\n",
      "val Loss: 0.6727 Acc: 0.8760\n",
      "test Loss: 0.6661 Acc: 0.8960\n",
      "Epoch 712/1499\n",
      "----------\n",
      "train Loss: 0.6806 Acc: 0.8727\n",
      "val Loss: 0.6721 Acc: 0.8880\n",
      "test Loss: 0.6675 Acc: 0.8920\n",
      "Epoch 713/1499\n",
      "----------\n",
      "train Loss: 0.6807 Acc: 0.8724\n",
      "val Loss: 0.6847 Acc: 0.8600\n",
      "test Loss: 0.6825 Acc: 0.8720\n",
      "Epoch 714/1499\n",
      "----------\n",
      "train Loss: 0.6803 Acc: 0.8736\n",
      "val Loss: 0.6762 Acc: 0.8640\n",
      "test Loss: 0.6695 Acc: 0.8960\n",
      "Epoch 715/1499\n",
      "----------\n",
      "train Loss: 0.6786 Acc: 0.8740\n",
      "val Loss: 0.6827 Acc: 0.8680\n",
      "test Loss: 0.6724 Acc: 0.8840\n",
      "Epoch 716/1499\n",
      "----------\n",
      "train Loss: 0.6806 Acc: 0.8731\n",
      "val Loss: 0.6853 Acc: 0.8560\n",
      "test Loss: 0.6786 Acc: 0.8760\n",
      "Epoch 717/1499\n",
      "----------\n",
      "train Loss: 0.6795 Acc: 0.8740\n",
      "val Loss: 0.6762 Acc: 0.8800\n",
      "test Loss: 0.6806 Acc: 0.8880\n",
      "Epoch 718/1499\n",
      "----------\n",
      "train Loss: 0.6804 Acc: 0.8747\n",
      "val Loss: 0.6732 Acc: 0.8680\n",
      "test Loss: 0.6793 Acc: 0.8760\n",
      "Epoch 719/1499\n",
      "----------\n",
      "train Loss: 0.6792 Acc: 0.8727\n",
      "val Loss: 0.6825 Acc: 0.8760\n",
      "test Loss: 0.6719 Acc: 0.8840\n",
      "Epoch 720/1499\n",
      "----------\n",
      "train Loss: 0.6798 Acc: 0.8740\n",
      "val Loss: 0.6801 Acc: 0.8760\n",
      "test Loss: 0.6686 Acc: 0.8960\n",
      "Epoch 721/1499\n",
      "----------\n",
      "train Loss: 0.6794 Acc: 0.8720\n",
      "val Loss: 0.6774 Acc: 0.8800\n",
      "test Loss: 0.6658 Acc: 0.8880\n",
      "Epoch 722/1499\n",
      "----------\n",
      "train Loss: 0.6792 Acc: 0.8731\n",
      "val Loss: 0.6761 Acc: 0.8560\n",
      "test Loss: 0.6745 Acc: 0.8840\n",
      "Epoch 723/1499\n",
      "----------\n",
      "train Loss: 0.6782 Acc: 0.8778\n",
      "val Loss: 0.6767 Acc: 0.8640\n",
      "test Loss: 0.6748 Acc: 0.8800\n",
      "Epoch 724/1499\n",
      "----------\n",
      "train Loss: 0.6786 Acc: 0.8740\n",
      "val Loss: 0.6759 Acc: 0.8800\n",
      "test Loss: 0.6781 Acc: 0.8800\n",
      "Epoch 725/1499\n",
      "----------\n",
      "train Loss: 0.6781 Acc: 0.8753\n",
      "val Loss: 0.6849 Acc: 0.8560\n",
      "test Loss: 0.6579 Acc: 0.9040\n",
      "Epoch 726/1499\n",
      "----------\n",
      "train Loss: 0.6762 Acc: 0.8778\n",
      "val Loss: 0.6801 Acc: 0.8640\n",
      "test Loss: 0.6751 Acc: 0.8840\n",
      "Epoch 727/1499\n",
      "----------\n",
      "train Loss: 0.6798 Acc: 0.8716\n",
      "val Loss: 0.6911 Acc: 0.8600\n",
      "test Loss: 0.6705 Acc: 0.8840\n",
      "Epoch 728/1499\n",
      "----------\n",
      "train Loss: 0.6779 Acc: 0.8736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.6796 Acc: 0.8520\n",
      "test Loss: 0.6686 Acc: 0.8920\n",
      "Epoch 729/1499\n",
      "----------\n",
      "train Loss: 0.6770 Acc: 0.8780\n",
      "val Loss: 0.6780 Acc: 0.8640\n",
      "test Loss: 0.6731 Acc: 0.8880\n",
      "Epoch 730/1499\n",
      "----------\n",
      "train Loss: 0.6819 Acc: 0.8696\n",
      "val Loss: 0.6755 Acc: 0.8680\n",
      "test Loss: 0.6685 Acc: 0.8880\n",
      "Epoch 731/1499\n",
      "----------\n",
      "train Loss: 0.6779 Acc: 0.8729\n",
      "val Loss: 0.6729 Acc: 0.8760\n",
      "test Loss: 0.6731 Acc: 0.8840\n",
      "Epoch 732/1499\n",
      "----------\n",
      "train Loss: 0.6789 Acc: 0.8724\n",
      "val Loss: 0.6791 Acc: 0.8720\n",
      "test Loss: 0.6735 Acc: 0.8920\n",
      "Epoch 733/1499\n",
      "----------\n",
      "train Loss: 0.6762 Acc: 0.8762\n",
      "val Loss: 0.6766 Acc: 0.8680\n",
      "test Loss: 0.6656 Acc: 0.8880\n",
      "Epoch 734/1499\n",
      "----------\n",
      "train Loss: 0.6764 Acc: 0.8762\n",
      "val Loss: 0.6751 Acc: 0.8720\n",
      "test Loss: 0.6678 Acc: 0.8880\n",
      "Epoch 735/1499\n",
      "----------\n",
      "train Loss: 0.6765 Acc: 0.8760\n",
      "val Loss: 0.6755 Acc: 0.8760\n",
      "test Loss: 0.6792 Acc: 0.8720\n",
      "Epoch 736/1499\n",
      "----------\n",
      "train Loss: 0.6754 Acc: 0.8796\n",
      "val Loss: 0.6745 Acc: 0.8720\n",
      "test Loss: 0.6754 Acc: 0.8760\n",
      "Epoch 737/1499\n",
      "----------\n",
      "train Loss: 0.6775 Acc: 0.8744\n",
      "val Loss: 0.6912 Acc: 0.8480\n",
      "test Loss: 0.6738 Acc: 0.8840\n",
      "Epoch 738/1499\n",
      "----------\n",
      "train Loss: 0.6771 Acc: 0.8767\n",
      "val Loss: 0.6832 Acc: 0.8640\n",
      "test Loss: 0.6608 Acc: 0.8920\n",
      "Epoch 739/1499\n",
      "----------\n",
      "train Loss: 0.6769 Acc: 0.8767\n",
      "val Loss: 0.6856 Acc: 0.8640\n",
      "test Loss: 0.6752 Acc: 0.8720\n",
      "Epoch 740/1499\n",
      "----------\n",
      "train Loss: 0.6773 Acc: 0.8747\n",
      "val Loss: 0.6738 Acc: 0.8720\n",
      "test Loss: 0.6673 Acc: 0.8880\n",
      "Epoch 741/1499\n",
      "----------\n",
      "train Loss: 0.6762 Acc: 0.8773\n",
      "val Loss: 0.6750 Acc: 0.8720\n",
      "test Loss: 0.6621 Acc: 0.8920\n",
      "Epoch 742/1499\n",
      "----------\n",
      "train Loss: 0.6771 Acc: 0.8749\n",
      "val Loss: 0.6807 Acc: 0.8640\n",
      "test Loss: 0.6691 Acc: 0.8880\n",
      "Epoch 743/1499\n",
      "----------\n",
      "train Loss: 0.6777 Acc: 0.8753\n",
      "val Loss: 0.6707 Acc: 0.8680\n",
      "test Loss: 0.6730 Acc: 0.8880\n",
      "Epoch 744/1499\n",
      "----------\n",
      "train Loss: 0.6789 Acc: 0.8738\n",
      "val Loss: 0.6823 Acc: 0.8600\n",
      "test Loss: 0.6647 Acc: 0.8960\n",
      "Epoch 745/1499\n",
      "----------\n",
      "train Loss: 0.6747 Acc: 0.8756\n",
      "val Loss: 0.6738 Acc: 0.8680\n",
      "test Loss: 0.6673 Acc: 0.8840\n",
      "Epoch 746/1499\n",
      "----------\n",
      "train Loss: 0.6769 Acc: 0.8764\n",
      "val Loss: 0.6762 Acc: 0.8680\n",
      "test Loss: 0.6677 Acc: 0.8920\n",
      "Epoch 747/1499\n",
      "----------\n",
      "train Loss: 0.6774 Acc: 0.8722\n",
      "val Loss: 0.6717 Acc: 0.8680\n",
      "test Loss: 0.6839 Acc: 0.8720\n",
      "Epoch 748/1499\n",
      "----------\n",
      "train Loss: 0.6777 Acc: 0.8751\n",
      "val Loss: 0.6806 Acc: 0.8600\n",
      "test Loss: 0.6705 Acc: 0.8960\n",
      "Epoch 749/1499\n",
      "----------\n",
      "train Loss: 0.6765 Acc: 0.8776\n",
      "val Loss: 0.6792 Acc: 0.8760\n",
      "test Loss: 0.6707 Acc: 0.8840\n",
      "Epoch 750/1499\n",
      "----------\n",
      "train Loss: 0.6770 Acc: 0.8749\n",
      "val Loss: 0.6724 Acc: 0.8840\n",
      "test Loss: 0.6719 Acc: 0.8880\n",
      "Epoch 751/1499\n",
      "----------\n",
      "train Loss: 0.6779 Acc: 0.8747\n",
      "val Loss: 0.6835 Acc: 0.8600\n",
      "test Loss: 0.6685 Acc: 0.8920\n",
      "Epoch 752/1499\n",
      "----------\n",
      "train Loss: 0.6755 Acc: 0.8778\n",
      "val Loss: 0.6787 Acc: 0.8600\n",
      "test Loss: 0.6652 Acc: 0.8920\n",
      "Epoch 753/1499\n",
      "----------\n",
      "train Loss: 0.6773 Acc: 0.8751\n",
      "val Loss: 0.6774 Acc: 0.8640\n",
      "test Loss: 0.6712 Acc: 0.8880\n",
      "Epoch 754/1499\n",
      "----------\n",
      "train Loss: 0.6754 Acc: 0.8780\n",
      "val Loss: 0.6724 Acc: 0.8760\n",
      "test Loss: 0.6780 Acc: 0.8680\n",
      "Epoch 755/1499\n",
      "----------\n",
      "train Loss: 0.6741 Acc: 0.8769\n",
      "val Loss: 0.6706 Acc: 0.8760\n",
      "test Loss: 0.6737 Acc: 0.8800\n",
      "Epoch 756/1499\n",
      "----------\n",
      "train Loss: 0.6771 Acc: 0.8742\n",
      "val Loss: 0.6826 Acc: 0.8600\n",
      "test Loss: 0.6674 Acc: 0.8800\n",
      "Epoch 757/1499\n",
      "----------\n",
      "train Loss: 0.6751 Acc: 0.8756\n",
      "val Loss: 0.6808 Acc: 0.8600\n",
      "test Loss: 0.6649 Acc: 0.9000\n",
      "Epoch 758/1499\n",
      "----------\n",
      "train Loss: 0.6739 Acc: 0.8789\n",
      "val Loss: 0.6785 Acc: 0.8520\n",
      "test Loss: 0.6724 Acc: 0.8840\n",
      "Epoch 759/1499\n",
      "----------\n",
      "train Loss: 0.6771 Acc: 0.8727\n",
      "val Loss: 0.6796 Acc: 0.8680\n",
      "test Loss: 0.6696 Acc: 0.8880\n",
      "Epoch 760/1499\n",
      "----------\n",
      "train Loss: 0.6750 Acc: 0.8776\n",
      "val Loss: 0.6741 Acc: 0.8640\n",
      "test Loss: 0.6758 Acc: 0.8800\n",
      "Epoch 761/1499\n",
      "----------\n",
      "train Loss: 0.6760 Acc: 0.8744\n",
      "val Loss: 0.6821 Acc: 0.8640\n",
      "test Loss: 0.6691 Acc: 0.8960\n",
      "Epoch 762/1499\n",
      "----------\n",
      "train Loss: 0.6757 Acc: 0.8722\n",
      "val Loss: 0.6759 Acc: 0.8760\n",
      "test Loss: 0.6662 Acc: 0.8800\n",
      "Epoch 763/1499\n",
      "----------\n",
      "train Loss: 0.6738 Acc: 0.8782\n",
      "val Loss: 0.6733 Acc: 0.8640\n",
      "test Loss: 0.6657 Acc: 0.8920\n",
      "Epoch 764/1499\n",
      "----------\n",
      "train Loss: 0.6752 Acc: 0.8753\n",
      "val Loss: 0.6755 Acc: 0.8760\n",
      "test Loss: 0.6725 Acc: 0.8800\n",
      "Epoch 765/1499\n",
      "----------\n",
      "train Loss: 0.6744 Acc: 0.8769\n",
      "val Loss: 0.6818 Acc: 0.8600\n",
      "test Loss: 0.6616 Acc: 0.8960\n",
      "Epoch 766/1499\n",
      "----------\n",
      "train Loss: 0.6736 Acc: 0.8816\n",
      "val Loss: 0.6767 Acc: 0.8680\n",
      "test Loss: 0.6683 Acc: 0.8920\n",
      "Epoch 767/1499\n",
      "----------\n",
      "train Loss: 0.6746 Acc: 0.8764\n",
      "val Loss: 0.6762 Acc: 0.8640\n",
      "test Loss: 0.6657 Acc: 0.8920\n",
      "Epoch 768/1499\n",
      "----------\n",
      "train Loss: 0.6730 Acc: 0.8802\n",
      "val Loss: 0.6744 Acc: 0.8800\n",
      "test Loss: 0.6735 Acc: 0.8800\n",
      "Epoch 769/1499\n",
      "----------\n",
      "train Loss: 0.6717 Acc: 0.8820\n",
      "val Loss: 0.6746 Acc: 0.8720\n",
      "test Loss: 0.6686 Acc: 0.8880\n",
      "Epoch 770/1499\n",
      "----------\n",
      "train Loss: 0.6755 Acc: 0.8751\n",
      "val Loss: 0.6671 Acc: 0.8760\n",
      "test Loss: 0.6682 Acc: 0.8880\n",
      "Epoch 771/1499\n",
      "----------\n",
      "train Loss: 0.6739 Acc: 0.8778\n",
      "val Loss: 0.6775 Acc: 0.8640\n",
      "test Loss: 0.6684 Acc: 0.8880\n",
      "Epoch 772/1499\n",
      "----------\n",
      "train Loss: 0.6761 Acc: 0.8747\n",
      "val Loss: 0.6757 Acc: 0.8680\n",
      "test Loss: 0.6627 Acc: 0.8960\n",
      "Epoch 773/1499\n",
      "----------\n",
      "train Loss: 0.6761 Acc: 0.8751\n",
      "val Loss: 0.6795 Acc: 0.8720\n",
      "test Loss: 0.6710 Acc: 0.8840\n",
      "Epoch 774/1499\n",
      "----------\n",
      "train Loss: 0.6759 Acc: 0.8760\n",
      "val Loss: 0.6818 Acc: 0.8640\n",
      "test Loss: 0.6681 Acc: 0.8920\n",
      "Epoch 775/1499\n",
      "----------\n",
      "train Loss: 0.6743 Acc: 0.8780\n",
      "val Loss: 0.6777 Acc: 0.8680\n",
      "test Loss: 0.6643 Acc: 0.8960\n",
      "Epoch 776/1499\n",
      "----------\n",
      "train Loss: 0.6733 Acc: 0.8780\n",
      "val Loss: 0.6844 Acc: 0.8480\n",
      "test Loss: 0.6726 Acc: 0.8840\n",
      "Epoch 777/1499\n",
      "----------\n",
      "train Loss: 0.6733 Acc: 0.8809\n",
      "val Loss: 0.6803 Acc: 0.8600\n",
      "test Loss: 0.6669 Acc: 0.8840\n",
      "Epoch 778/1499\n",
      "----------\n",
      "train Loss: 0.6776 Acc: 0.8729\n",
      "val Loss: 0.6777 Acc: 0.8680\n",
      "test Loss: 0.6728 Acc: 0.8840\n",
      "Epoch 779/1499\n",
      "----------\n",
      "train Loss: 0.6765 Acc: 0.8751\n",
      "val Loss: 0.6847 Acc: 0.8520\n",
      "test Loss: 0.6666 Acc: 0.8880\n",
      "Epoch 780/1499\n",
      "----------\n",
      "train Loss: 0.6742 Acc: 0.8796\n",
      "val Loss: 0.6872 Acc: 0.8560\n",
      "test Loss: 0.6667 Acc: 0.8920\n",
      "Epoch 781/1499\n",
      "----------\n",
      "train Loss: 0.6743 Acc: 0.8769\n",
      "val Loss: 0.6661 Acc: 0.8800\n",
      "test Loss: 0.6670 Acc: 0.8920\n",
      "Epoch 782/1499\n",
      "----------\n",
      "train Loss: 0.6745 Acc: 0.8771\n",
      "val Loss: 0.6601 Acc: 0.8880\n",
      "test Loss: 0.6667 Acc: 0.8880\n",
      "Epoch 783/1499\n",
      "----------\n",
      "train Loss: 0.6738 Acc: 0.8767\n",
      "val Loss: 0.6822 Acc: 0.8640\n",
      "test Loss: 0.6660 Acc: 0.8920\n",
      "Epoch 784/1499\n",
      "----------\n",
      "train Loss: 0.6756 Acc: 0.8756\n",
      "val Loss: 0.6759 Acc: 0.8640\n",
      "test Loss: 0.6708 Acc: 0.8840\n",
      "Epoch 785/1499\n",
      "----------\n",
      "train Loss: 0.6703 Acc: 0.8784\n",
      "val Loss: 0.6690 Acc: 0.8760\n",
      "test Loss: 0.6669 Acc: 0.8920\n",
      "Epoch 786/1499\n",
      "----------\n",
      "train Loss: 0.6728 Acc: 0.8778\n",
      "val Loss: 0.6742 Acc: 0.8680\n",
      "test Loss: 0.6632 Acc: 0.8880\n",
      "Epoch 787/1499\n",
      "----------\n",
      "train Loss: 0.6766 Acc: 0.8760\n",
      "val Loss: 0.6630 Acc: 0.8880\n",
      "test Loss: 0.6795 Acc: 0.8760\n",
      "Epoch 788/1499\n",
      "----------\n",
      "train Loss: 0.6735 Acc: 0.8767\n",
      "val Loss: 0.6737 Acc: 0.8760\n",
      "test Loss: 0.6626 Acc: 0.9000\n",
      "Epoch 789/1499\n",
      "----------\n",
      "train Loss: 0.6733 Acc: 0.8776\n",
      "val Loss: 0.6808 Acc: 0.8720\n",
      "test Loss: 0.6699 Acc: 0.8800\n",
      "Epoch 790/1499\n",
      "----------\n",
      "train Loss: 0.6752 Acc: 0.8760\n",
      "val Loss: 0.6711 Acc: 0.8800\n",
      "test Loss: 0.6711 Acc: 0.8840\n",
      "Epoch 791/1499\n",
      "----------\n",
      "train Loss: 0.6732 Acc: 0.8771\n",
      "val Loss: 0.6802 Acc: 0.8640\n",
      "test Loss: 0.6653 Acc: 0.8920\n",
      "Epoch 792/1499\n",
      "----------\n",
      "train Loss: 0.6730 Acc: 0.8778\n",
      "val Loss: 0.6819 Acc: 0.8600\n",
      "test Loss: 0.6711 Acc: 0.8840\n",
      "Epoch 793/1499\n",
      "----------\n",
      "train Loss: 0.6754 Acc: 0.8753\n",
      "val Loss: 0.6835 Acc: 0.8600\n",
      "test Loss: 0.6607 Acc: 0.8960\n",
      "Epoch 794/1499\n",
      "----------\n",
      "train Loss: 0.6738 Acc: 0.8764\n",
      "val Loss: 0.6700 Acc: 0.8800\n",
      "test Loss: 0.6684 Acc: 0.8760\n",
      "Epoch 795/1499\n",
      "----------\n",
      "train Loss: 0.6751 Acc: 0.8760\n",
      "val Loss: 0.6743 Acc: 0.8840\n",
      "test Loss: 0.6711 Acc: 0.8840\n",
      "Epoch 796/1499\n",
      "----------\n",
      "train Loss: 0.6725 Acc: 0.8780\n",
      "val Loss: 0.6735 Acc: 0.8640\n",
      "test Loss: 0.6685 Acc: 0.8840\n",
      "Epoch 797/1499\n",
      "----------\n",
      "train Loss: 0.6768 Acc: 0.8731\n",
      "val Loss: 0.6803 Acc: 0.8640\n",
      "test Loss: 0.6697 Acc: 0.8800\n",
      "Epoch 798/1499\n",
      "----------\n",
      "train Loss: 0.6754 Acc: 0.8751\n",
      "val Loss: 0.6712 Acc: 0.8800\n",
      "test Loss: 0.6717 Acc: 0.8840\n",
      "Epoch 799/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6735 Acc: 0.8762\n",
      "val Loss: 0.6724 Acc: 0.8760\n",
      "test Loss: 0.6762 Acc: 0.8680\n",
      "Epoch 800/1499\n",
      "----------\n",
      "train Loss: 0.6716 Acc: 0.8804\n",
      "val Loss: 0.6715 Acc: 0.8720\n",
      "test Loss: 0.6695 Acc: 0.8840\n",
      "Epoch 801/1499\n",
      "----------\n",
      "train Loss: 0.6738 Acc: 0.8780\n",
      "val Loss: 0.6750 Acc: 0.8720\n",
      "test Loss: 0.6647 Acc: 0.8960\n",
      "Epoch 802/1499\n",
      "----------\n",
      "train Loss: 0.6725 Acc: 0.8767\n",
      "val Loss: 0.6680 Acc: 0.8840\n",
      "test Loss: 0.6607 Acc: 0.8920\n",
      "Epoch 803/1499\n",
      "----------\n",
      "train Loss: 0.6723 Acc: 0.8760\n",
      "val Loss: 0.6697 Acc: 0.8800\n",
      "test Loss: 0.6706 Acc: 0.8800\n",
      "Epoch 804/1499\n",
      "----------\n",
      "train Loss: 0.6732 Acc: 0.8782\n",
      "val Loss: 0.6689 Acc: 0.8800\n",
      "test Loss: 0.6628 Acc: 0.9000\n",
      "Epoch 805/1499\n",
      "----------\n",
      "train Loss: 0.6733 Acc: 0.8769\n",
      "val Loss: 0.6697 Acc: 0.8760\n",
      "test Loss: 0.6665 Acc: 0.8880\n",
      "Epoch 806/1499\n",
      "----------\n",
      "train Loss: 0.6742 Acc: 0.8764\n",
      "val Loss: 0.6622 Acc: 0.8880\n",
      "test Loss: 0.6661 Acc: 0.8880\n",
      "Epoch 807/1499\n",
      "----------\n",
      "train Loss: 0.6717 Acc: 0.8802\n",
      "val Loss: 0.6740 Acc: 0.8720\n",
      "test Loss: 0.6670 Acc: 0.8880\n",
      "Epoch 808/1499\n",
      "----------\n",
      "train Loss: 0.6716 Acc: 0.8796\n",
      "val Loss: 0.6786 Acc: 0.8640\n",
      "test Loss: 0.6707 Acc: 0.8800\n",
      "Epoch 809/1499\n",
      "----------\n",
      "train Loss: 0.6718 Acc: 0.8776\n",
      "val Loss: 0.6754 Acc: 0.8640\n",
      "test Loss: 0.6648 Acc: 0.8920\n",
      "Epoch 810/1499\n",
      "----------\n",
      "train Loss: 0.6724 Acc: 0.8756\n",
      "val Loss: 0.6789 Acc: 0.8640\n",
      "test Loss: 0.6679 Acc: 0.8880\n",
      "Epoch 811/1499\n",
      "----------\n",
      "train Loss: 0.6722 Acc: 0.8798\n",
      "val Loss: 0.6748 Acc: 0.8680\n",
      "test Loss: 0.6613 Acc: 0.8920\n",
      "Epoch 812/1499\n",
      "----------\n",
      "train Loss: 0.6722 Acc: 0.8776\n",
      "val Loss: 0.6781 Acc: 0.8640\n",
      "test Loss: 0.6754 Acc: 0.8800\n",
      "Epoch 813/1499\n",
      "----------\n",
      "train Loss: 0.6727 Acc: 0.8764\n",
      "val Loss: 0.6788 Acc: 0.8680\n",
      "test Loss: 0.6679 Acc: 0.8920\n",
      "Epoch 814/1499\n",
      "----------\n",
      "train Loss: 0.6719 Acc: 0.8793\n",
      "val Loss: 0.6658 Acc: 0.8840\n",
      "test Loss: 0.6658 Acc: 0.8960\n",
      "Epoch 815/1499\n",
      "----------\n",
      "train Loss: 0.6732 Acc: 0.8784\n",
      "val Loss: 0.6676 Acc: 0.8760\n",
      "test Loss: 0.6690 Acc: 0.8880\n",
      "Epoch 816/1499\n",
      "----------\n",
      "train Loss: 0.6712 Acc: 0.8798\n",
      "val Loss: 0.6749 Acc: 0.8720\n",
      "test Loss: 0.6703 Acc: 0.8760\n",
      "Epoch 817/1499\n",
      "----------\n",
      "train Loss: 0.6718 Acc: 0.8796\n",
      "val Loss: 0.6761 Acc: 0.8680\n",
      "test Loss: 0.6718 Acc: 0.8840\n",
      "Epoch 818/1499\n",
      "----------\n",
      "train Loss: 0.6716 Acc: 0.8782\n",
      "val Loss: 0.6736 Acc: 0.8720\n",
      "test Loss: 0.6633 Acc: 0.8840\n",
      "Epoch 819/1499\n",
      "----------\n",
      "train Loss: 0.6701 Acc: 0.8813\n",
      "val Loss: 0.6689 Acc: 0.8720\n",
      "test Loss: 0.6672 Acc: 0.8840\n",
      "Epoch 820/1499\n",
      "----------\n",
      "train Loss: 0.6711 Acc: 0.8804\n",
      "val Loss: 0.6845 Acc: 0.8520\n",
      "test Loss: 0.6707 Acc: 0.8840\n",
      "Epoch 821/1499\n",
      "----------\n",
      "train Loss: 0.6733 Acc: 0.8767\n",
      "val Loss: 0.6860 Acc: 0.8600\n",
      "test Loss: 0.6719 Acc: 0.8800\n",
      "Epoch 822/1499\n",
      "----------\n",
      "train Loss: 0.6706 Acc: 0.8816\n",
      "val Loss: 0.6724 Acc: 0.8720\n",
      "test Loss: 0.6598 Acc: 0.9000\n",
      "Epoch 823/1499\n",
      "----------\n",
      "train Loss: 0.6725 Acc: 0.8804\n",
      "val Loss: 0.6750 Acc: 0.8680\n",
      "test Loss: 0.6635 Acc: 0.8920\n",
      "Epoch 824/1499\n",
      "----------\n",
      "train Loss: 0.6721 Acc: 0.8762\n",
      "val Loss: 0.6817 Acc: 0.8560\n",
      "test Loss: 0.6737 Acc: 0.8840\n",
      "Epoch 825/1499\n",
      "----------\n",
      "train Loss: 0.6722 Acc: 0.8776\n",
      "val Loss: 0.6801 Acc: 0.8720\n",
      "test Loss: 0.6676 Acc: 0.8840\n",
      "Epoch 826/1499\n",
      "----------\n",
      "train Loss: 0.6729 Acc: 0.8802\n",
      "val Loss: 0.6698 Acc: 0.8720\n",
      "test Loss: 0.6674 Acc: 0.8880\n",
      "Epoch 827/1499\n",
      "----------\n",
      "train Loss: 0.6705 Acc: 0.8809\n",
      "val Loss: 0.6705 Acc: 0.8720\n",
      "test Loss: 0.6679 Acc: 0.8880\n",
      "Epoch 828/1499\n",
      "----------\n",
      "train Loss: 0.6717 Acc: 0.8793\n",
      "val Loss: 0.6735 Acc: 0.8760\n",
      "test Loss: 0.6652 Acc: 0.8920\n",
      "Epoch 829/1499\n",
      "----------\n",
      "train Loss: 0.6733 Acc: 0.8749\n",
      "val Loss: 0.6802 Acc: 0.8640\n",
      "test Loss: 0.6660 Acc: 0.8920\n",
      "Epoch 830/1499\n",
      "----------\n",
      "train Loss: 0.6711 Acc: 0.8816\n",
      "val Loss: 0.6789 Acc: 0.8720\n",
      "test Loss: 0.6706 Acc: 0.8880\n",
      "Epoch 831/1499\n",
      "----------\n",
      "train Loss: 0.6723 Acc: 0.8782\n",
      "val Loss: 0.6719 Acc: 0.8760\n",
      "test Loss: 0.6711 Acc: 0.8840\n",
      "Epoch 832/1499\n",
      "----------\n",
      "train Loss: 0.6706 Acc: 0.8802\n",
      "val Loss: 0.6760 Acc: 0.8760\n",
      "test Loss: 0.6636 Acc: 0.8880\n",
      "Epoch 833/1499\n",
      "----------\n",
      "train Loss: 0.6712 Acc: 0.8780\n",
      "val Loss: 0.6755 Acc: 0.8680\n",
      "test Loss: 0.6646 Acc: 0.8920\n",
      "Epoch 834/1499\n",
      "----------\n",
      "train Loss: 0.6703 Acc: 0.8791\n",
      "val Loss: 0.6690 Acc: 0.8800\n",
      "test Loss: 0.6671 Acc: 0.8800\n",
      "Epoch 835/1499\n",
      "----------\n",
      "train Loss: 0.6702 Acc: 0.8798\n",
      "val Loss: 0.6752 Acc: 0.8640\n",
      "test Loss: 0.6621 Acc: 0.8920\n",
      "Epoch 836/1499\n",
      "----------\n",
      "train Loss: 0.6706 Acc: 0.8796\n",
      "val Loss: 0.6706 Acc: 0.8800\n",
      "test Loss: 0.6679 Acc: 0.8840\n",
      "Epoch 837/1499\n",
      "----------\n",
      "train Loss: 0.6717 Acc: 0.8793\n",
      "val Loss: 0.6719 Acc: 0.8760\n",
      "test Loss: 0.6622 Acc: 0.8960\n",
      "Epoch 838/1499\n",
      "----------\n",
      "train Loss: 0.6717 Acc: 0.8780\n",
      "val Loss: 0.6752 Acc: 0.8640\n",
      "test Loss: 0.6710 Acc: 0.8840\n",
      "Epoch 839/1499\n",
      "----------\n",
      "train Loss: 0.6724 Acc: 0.8778\n",
      "val Loss: 0.6714 Acc: 0.8720\n",
      "test Loss: 0.6664 Acc: 0.8960\n",
      "Epoch 840/1499\n",
      "----------\n",
      "train Loss: 0.6699 Acc: 0.8811\n",
      "val Loss: 0.6759 Acc: 0.8680\n",
      "test Loss: 0.6655 Acc: 0.8960\n",
      "Epoch 841/1499\n",
      "----------\n",
      "train Loss: 0.6741 Acc: 0.8756\n",
      "val Loss: 0.6748 Acc: 0.8720\n",
      "test Loss: 0.6684 Acc: 0.8840\n",
      "Epoch 842/1499\n",
      "----------\n",
      "train Loss: 0.6703 Acc: 0.8780\n",
      "val Loss: 0.6740 Acc: 0.8720\n",
      "test Loss: 0.6684 Acc: 0.8880\n",
      "Epoch 843/1499\n",
      "----------\n",
      "train Loss: 0.6707 Acc: 0.8789\n",
      "val Loss: 0.6703 Acc: 0.8760\n",
      "test Loss: 0.6637 Acc: 0.8920\n",
      "Epoch 844/1499\n",
      "----------\n",
      "train Loss: 0.6713 Acc: 0.8780\n",
      "val Loss: 0.6782 Acc: 0.8640\n",
      "test Loss: 0.6599 Acc: 0.8960\n",
      "Epoch 845/1499\n",
      "----------\n",
      "train Loss: 0.6715 Acc: 0.8789\n",
      "val Loss: 0.6645 Acc: 0.8760\n",
      "test Loss: 0.6797 Acc: 0.8760\n",
      "Epoch 846/1499\n",
      "----------\n",
      "train Loss: 0.6719 Acc: 0.8816\n",
      "val Loss: 0.6796 Acc: 0.8680\n",
      "test Loss: 0.6657 Acc: 0.8880\n",
      "Epoch 847/1499\n",
      "----------\n",
      "train Loss: 0.6719 Acc: 0.8796\n",
      "val Loss: 0.6815 Acc: 0.8600\n",
      "test Loss: 0.6587 Acc: 0.9040\n",
      "Epoch 848/1499\n",
      "----------\n",
      "train Loss: 0.6702 Acc: 0.8811\n",
      "val Loss: 0.6730 Acc: 0.8680\n",
      "test Loss: 0.6606 Acc: 0.8960\n",
      "Epoch 849/1499\n",
      "----------\n",
      "train Loss: 0.6716 Acc: 0.8791\n",
      "val Loss: 0.6774 Acc: 0.8640\n",
      "test Loss: 0.6678 Acc: 0.8880\n",
      "Epoch 850/1499\n",
      "----------\n",
      "train Loss: 0.6708 Acc: 0.8778\n",
      "val Loss: 0.6717 Acc: 0.8680\n",
      "test Loss: 0.6620 Acc: 0.8960\n",
      "Epoch 851/1499\n",
      "----------\n",
      "train Loss: 0.6715 Acc: 0.8771\n",
      "val Loss: 0.6735 Acc: 0.8720\n",
      "test Loss: 0.6648 Acc: 0.8880\n",
      "Epoch 852/1499\n",
      "----------\n",
      "train Loss: 0.6714 Acc: 0.8793\n",
      "val Loss: 0.6879 Acc: 0.8600\n",
      "test Loss: 0.6667 Acc: 0.8880\n",
      "Epoch 853/1499\n",
      "----------\n",
      "train Loss: 0.6725 Acc: 0.8764\n",
      "val Loss: 0.6766 Acc: 0.8600\n",
      "test Loss: 0.6669 Acc: 0.8880\n",
      "Epoch 854/1499\n",
      "----------\n",
      "train Loss: 0.6703 Acc: 0.8800\n",
      "val Loss: 0.6698 Acc: 0.8840\n",
      "test Loss: 0.6614 Acc: 0.8920\n",
      "Epoch 855/1499\n",
      "----------\n",
      "train Loss: 0.6708 Acc: 0.8787\n",
      "val Loss: 0.6774 Acc: 0.8640\n",
      "test Loss: 0.6636 Acc: 0.8920\n",
      "Epoch 856/1499\n",
      "----------\n",
      "train Loss: 0.6699 Acc: 0.8791\n",
      "val Loss: 0.6807 Acc: 0.8680\n",
      "test Loss: 0.6721 Acc: 0.8880\n",
      "Epoch 857/1499\n",
      "----------\n",
      "train Loss: 0.6703 Acc: 0.8773\n",
      "val Loss: 0.6730 Acc: 0.8720\n",
      "test Loss: 0.6681 Acc: 0.8880\n",
      "Epoch 858/1499\n",
      "----------\n",
      "train Loss: 0.6717 Acc: 0.8764\n",
      "val Loss: 0.6691 Acc: 0.8800\n",
      "test Loss: 0.6693 Acc: 0.8840\n",
      "Epoch 859/1499\n",
      "----------\n",
      "train Loss: 0.6700 Acc: 0.8793\n",
      "val Loss: 0.6738 Acc: 0.8720\n",
      "test Loss: 0.6571 Acc: 0.8960\n",
      "Epoch 860/1499\n",
      "----------\n",
      "train Loss: 0.6699 Acc: 0.8793\n",
      "val Loss: 0.6819 Acc: 0.8720\n",
      "test Loss: 0.6652 Acc: 0.8840\n",
      "Epoch 861/1499\n",
      "----------\n",
      "train Loss: 0.6712 Acc: 0.8760\n",
      "val Loss: 0.6768 Acc: 0.8680\n",
      "test Loss: 0.6732 Acc: 0.8800\n",
      "Epoch 862/1499\n",
      "----------\n",
      "train Loss: 0.6703 Acc: 0.8773\n",
      "val Loss: 0.6675 Acc: 0.8840\n",
      "test Loss: 0.6642 Acc: 0.8920\n",
      "Epoch 863/1499\n",
      "----------\n",
      "train Loss: 0.6707 Acc: 0.8784\n",
      "val Loss: 0.6758 Acc: 0.8720\n",
      "test Loss: 0.6651 Acc: 0.8920\n",
      "Epoch 864/1499\n",
      "----------\n",
      "train Loss: 0.6703 Acc: 0.8784\n",
      "val Loss: 0.6786 Acc: 0.8600\n",
      "test Loss: 0.6740 Acc: 0.8840\n",
      "Epoch 865/1499\n",
      "----------\n",
      "train Loss: 0.6702 Acc: 0.8789\n",
      "val Loss: 0.6681 Acc: 0.8800\n",
      "test Loss: 0.6675 Acc: 0.8760\n",
      "Epoch 866/1499\n",
      "----------\n",
      "train Loss: 0.6692 Acc: 0.8816\n",
      "val Loss: 0.6820 Acc: 0.8640\n",
      "test Loss: 0.6689 Acc: 0.8840\n",
      "Epoch 867/1499\n",
      "----------\n",
      "train Loss: 0.6708 Acc: 0.8782\n",
      "val Loss: 0.6789 Acc: 0.8680\n",
      "test Loss: 0.6649 Acc: 0.8880\n",
      "Epoch 868/1499\n",
      "----------\n",
      "train Loss: 0.6710 Acc: 0.8778\n",
      "val Loss: 0.6721 Acc: 0.8760\n",
      "test Loss: 0.6668 Acc: 0.8880\n",
      "Epoch 869/1499\n",
      "----------\n",
      "train Loss: 0.6710 Acc: 0.8784\n",
      "val Loss: 0.6703 Acc: 0.8680\n",
      "test Loss: 0.6681 Acc: 0.8840\n",
      "Epoch 870/1499\n",
      "----------\n",
      "train Loss: 0.6708 Acc: 0.8784\n",
      "val Loss: 0.6696 Acc: 0.8800\n",
      "test Loss: 0.6682 Acc: 0.8880\n",
      "Epoch 871/1499\n",
      "----------\n",
      "train Loss: 0.6698 Acc: 0.8811\n",
      "val Loss: 0.6730 Acc: 0.8760\n",
      "test Loss: 0.6786 Acc: 0.8720\n",
      "Epoch 872/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6692 Acc: 0.8778\n",
      "val Loss: 0.6835 Acc: 0.8560\n",
      "test Loss: 0.6659 Acc: 0.8920\n",
      "Epoch 873/1499\n",
      "----------\n",
      "train Loss: 0.6713 Acc: 0.8764\n",
      "val Loss: 0.6771 Acc: 0.8680\n",
      "test Loss: 0.6694 Acc: 0.8880\n",
      "Epoch 874/1499\n",
      "----------\n",
      "train Loss: 0.6697 Acc: 0.8804\n",
      "val Loss: 0.6774 Acc: 0.8640\n",
      "test Loss: 0.6730 Acc: 0.8800\n",
      "Epoch 875/1499\n",
      "----------\n",
      "train Loss: 0.6701 Acc: 0.8809\n",
      "val Loss: 0.6739 Acc: 0.8680\n",
      "test Loss: 0.6684 Acc: 0.8880\n",
      "Epoch 876/1499\n",
      "----------\n",
      "train Loss: 0.6701 Acc: 0.8791\n",
      "val Loss: 0.6651 Acc: 0.8840\n",
      "test Loss: 0.6611 Acc: 0.8960\n",
      "Epoch 877/1499\n",
      "----------\n",
      "train Loss: 0.6693 Acc: 0.8802\n",
      "val Loss: 0.6799 Acc: 0.8680\n",
      "test Loss: 0.6615 Acc: 0.8960\n",
      "Epoch 878/1499\n",
      "----------\n",
      "train Loss: 0.6698 Acc: 0.8824\n",
      "val Loss: 0.6711 Acc: 0.8760\n",
      "test Loss: 0.6557 Acc: 0.9000\n",
      "Epoch 879/1499\n",
      "----------\n",
      "train Loss: 0.6712 Acc: 0.8824\n",
      "val Loss: 0.6648 Acc: 0.8800\n",
      "test Loss: 0.6626 Acc: 0.8840\n",
      "Epoch 880/1499\n",
      "----------\n",
      "train Loss: 0.6697 Acc: 0.8798\n",
      "val Loss: 0.6751 Acc: 0.8720\n",
      "test Loss: 0.6642 Acc: 0.8920\n",
      "Epoch 881/1499\n",
      "----------\n",
      "train Loss: 0.6714 Acc: 0.8764\n",
      "val Loss: 0.6775 Acc: 0.8560\n",
      "test Loss: 0.6679 Acc: 0.8840\n",
      "Epoch 882/1499\n",
      "----------\n",
      "train Loss: 0.6694 Acc: 0.8780\n",
      "val Loss: 0.6737 Acc: 0.8640\n",
      "test Loss: 0.6608 Acc: 0.9000\n",
      "Epoch 883/1499\n",
      "----------\n",
      "train Loss: 0.6708 Acc: 0.8787\n",
      "val Loss: 0.6721 Acc: 0.8680\n",
      "test Loss: 0.6698 Acc: 0.8880\n",
      "Epoch 884/1499\n",
      "----------\n",
      "train Loss: 0.6705 Acc: 0.8780\n",
      "val Loss: 0.6680 Acc: 0.8720\n",
      "test Loss: 0.6647 Acc: 0.8880\n",
      "Epoch 885/1499\n",
      "----------\n",
      "train Loss: 0.6673 Acc: 0.8829\n",
      "val Loss: 0.6667 Acc: 0.8760\n",
      "test Loss: 0.6617 Acc: 0.8920\n",
      "Epoch 886/1499\n",
      "----------\n",
      "train Loss: 0.6678 Acc: 0.8811\n",
      "val Loss: 0.6672 Acc: 0.8760\n",
      "test Loss: 0.6618 Acc: 0.8920\n",
      "Epoch 887/1499\n",
      "----------\n",
      "train Loss: 0.6694 Acc: 0.8796\n",
      "val Loss: 0.6717 Acc: 0.8640\n",
      "test Loss: 0.6629 Acc: 0.8920\n",
      "Epoch 888/1499\n",
      "----------\n",
      "train Loss: 0.6697 Acc: 0.8789\n",
      "val Loss: 0.6725 Acc: 0.8720\n",
      "test Loss: 0.6601 Acc: 0.8920\n",
      "Epoch 889/1499\n",
      "----------\n",
      "train Loss: 0.6678 Acc: 0.8807\n",
      "val Loss: 0.6792 Acc: 0.8560\n",
      "test Loss: 0.6632 Acc: 0.8960\n",
      "Epoch 890/1499\n",
      "----------\n",
      "train Loss: 0.6692 Acc: 0.8787\n",
      "val Loss: 0.6723 Acc: 0.8720\n",
      "test Loss: 0.6696 Acc: 0.8760\n",
      "Epoch 891/1499\n",
      "----------\n",
      "train Loss: 0.6719 Acc: 0.8773\n",
      "val Loss: 0.6674 Acc: 0.8800\n",
      "test Loss: 0.6619 Acc: 0.8880\n",
      "Epoch 892/1499\n",
      "----------\n",
      "train Loss: 0.6674 Acc: 0.8798\n",
      "val Loss: 0.6810 Acc: 0.8600\n",
      "test Loss: 0.6621 Acc: 0.8960\n",
      "Epoch 893/1499\n",
      "----------\n",
      "train Loss: 0.6687 Acc: 0.8798\n",
      "val Loss: 0.6750 Acc: 0.8640\n",
      "test Loss: 0.6600 Acc: 0.8960\n",
      "Epoch 894/1499\n",
      "----------\n",
      "train Loss: 0.6708 Acc: 0.8762\n",
      "val Loss: 0.6726 Acc: 0.8800\n",
      "test Loss: 0.6611 Acc: 0.8920\n",
      "Epoch 895/1499\n",
      "----------\n",
      "train Loss: 0.6707 Acc: 0.8791\n",
      "val Loss: 0.6745 Acc: 0.8680\n",
      "test Loss: 0.6670 Acc: 0.8880\n",
      "Epoch 896/1499\n",
      "----------\n",
      "train Loss: 0.6688 Acc: 0.8789\n",
      "val Loss: 0.6635 Acc: 0.8800\n",
      "test Loss: 0.6628 Acc: 0.8880\n",
      "Epoch 897/1499\n",
      "----------\n",
      "train Loss: 0.6708 Acc: 0.8791\n",
      "val Loss: 0.6736 Acc: 0.8720\n",
      "test Loss: 0.6660 Acc: 0.8840\n",
      "Epoch 898/1499\n",
      "----------\n",
      "train Loss: 0.6680 Acc: 0.8807\n",
      "val Loss: 0.6605 Acc: 0.8880\n",
      "test Loss: 0.6631 Acc: 0.8920\n",
      "Epoch 899/1499\n",
      "----------\n",
      "train Loss: 0.6679 Acc: 0.8796\n",
      "val Loss: 0.6737 Acc: 0.8760\n",
      "test Loss: 0.6668 Acc: 0.8840\n",
      "Epoch 900/1499\n",
      "----------\n",
      "train Loss: 0.6701 Acc: 0.8780\n",
      "val Loss: 0.6687 Acc: 0.8800\n",
      "test Loss: 0.6679 Acc: 0.8920\n",
      "Epoch 901/1499\n",
      "----------\n",
      "train Loss: 0.6671 Acc: 0.8824\n",
      "val Loss: 0.6812 Acc: 0.8440\n",
      "test Loss: 0.6608 Acc: 0.8880\n",
      "Epoch 902/1499\n",
      "----------\n",
      "train Loss: 0.6696 Acc: 0.8818\n",
      "val Loss: 0.6684 Acc: 0.8760\n",
      "test Loss: 0.6647 Acc: 0.8920\n",
      "Epoch 903/1499\n",
      "----------\n",
      "train Loss: 0.6670 Acc: 0.8824\n",
      "val Loss: 0.6703 Acc: 0.8760\n",
      "test Loss: 0.6655 Acc: 0.8880\n",
      "Epoch 904/1499\n",
      "----------\n",
      "train Loss: 0.6687 Acc: 0.8782\n",
      "val Loss: 0.6698 Acc: 0.8800\n",
      "test Loss: 0.6655 Acc: 0.8840\n",
      "Epoch 905/1499\n",
      "----------\n",
      "train Loss: 0.6690 Acc: 0.8816\n",
      "val Loss: 0.6759 Acc: 0.8680\n",
      "test Loss: 0.6606 Acc: 0.8960\n",
      "Epoch 906/1499\n",
      "----------\n",
      "train Loss: 0.6701 Acc: 0.8809\n",
      "val Loss: 0.6741 Acc: 0.8720\n",
      "test Loss: 0.6667 Acc: 0.8880\n",
      "Epoch 907/1499\n",
      "----------\n",
      "train Loss: 0.6686 Acc: 0.8822\n",
      "val Loss: 0.6681 Acc: 0.8840\n",
      "test Loss: 0.6582 Acc: 0.8960\n",
      "Epoch 908/1499\n",
      "----------\n",
      "train Loss: 0.6687 Acc: 0.8798\n",
      "val Loss: 0.6750 Acc: 0.8720\n",
      "test Loss: 0.6684 Acc: 0.8840\n",
      "Epoch 909/1499\n",
      "----------\n",
      "train Loss: 0.6662 Acc: 0.8838\n",
      "val Loss: 0.6804 Acc: 0.8640\n",
      "test Loss: 0.6638 Acc: 0.8880\n",
      "Epoch 910/1499\n",
      "----------\n",
      "train Loss: 0.6677 Acc: 0.8833\n",
      "val Loss: 0.6740 Acc: 0.8720\n",
      "test Loss: 0.6660 Acc: 0.8880\n",
      "Epoch 911/1499\n",
      "----------\n",
      "train Loss: 0.6678 Acc: 0.8836\n",
      "val Loss: 0.6741 Acc: 0.8720\n",
      "test Loss: 0.6713 Acc: 0.8840\n",
      "Epoch 912/1499\n",
      "----------\n",
      "train Loss: 0.6648 Acc: 0.8838\n",
      "val Loss: 0.6803 Acc: 0.8600\n",
      "test Loss: 0.6707 Acc: 0.8840\n",
      "Epoch 913/1499\n",
      "----------\n",
      "train Loss: 0.6687 Acc: 0.8789\n",
      "val Loss: 0.6727 Acc: 0.8720\n",
      "test Loss: 0.6623 Acc: 0.8920\n",
      "Epoch 914/1499\n",
      "----------\n",
      "train Loss: 0.6695 Acc: 0.8800\n",
      "val Loss: 0.6723 Acc: 0.8720\n",
      "test Loss: 0.6628 Acc: 0.8920\n",
      "Epoch 915/1499\n",
      "----------\n",
      "train Loss: 0.6669 Acc: 0.8816\n",
      "val Loss: 0.6715 Acc: 0.8680\n",
      "test Loss: 0.6609 Acc: 0.8920\n",
      "Epoch 916/1499\n",
      "----------\n",
      "train Loss: 0.6680 Acc: 0.8804\n",
      "val Loss: 0.6738 Acc: 0.8760\n",
      "test Loss: 0.6669 Acc: 0.8840\n",
      "Epoch 917/1499\n",
      "----------\n",
      "train Loss: 0.6696 Acc: 0.8771\n",
      "val Loss: 0.6779 Acc: 0.8640\n",
      "test Loss: 0.6617 Acc: 0.8920\n",
      "Epoch 918/1499\n",
      "----------\n",
      "train Loss: 0.6687 Acc: 0.8764\n",
      "val Loss: 0.6694 Acc: 0.8880\n",
      "test Loss: 0.6677 Acc: 0.8840\n",
      "Epoch 919/1499\n",
      "----------\n",
      "train Loss: 0.6667 Acc: 0.8849\n",
      "val Loss: 0.6659 Acc: 0.8800\n",
      "test Loss: 0.6655 Acc: 0.8880\n",
      "Epoch 920/1499\n",
      "----------\n",
      "train Loss: 0.6680 Acc: 0.8809\n",
      "val Loss: 0.6616 Acc: 0.8880\n",
      "test Loss: 0.6629 Acc: 0.9000\n",
      "Epoch 921/1499\n",
      "----------\n",
      "train Loss: 0.6696 Acc: 0.8787\n",
      "val Loss: 0.6666 Acc: 0.8800\n",
      "test Loss: 0.6723 Acc: 0.8800\n",
      "Epoch 922/1499\n",
      "----------\n",
      "train Loss: 0.6682 Acc: 0.8796\n",
      "val Loss: 0.6698 Acc: 0.8800\n",
      "test Loss: 0.6605 Acc: 0.8920\n",
      "Epoch 923/1499\n",
      "----------\n",
      "train Loss: 0.6669 Acc: 0.8809\n",
      "val Loss: 0.6663 Acc: 0.8800\n",
      "test Loss: 0.6593 Acc: 0.8920\n",
      "Epoch 924/1499\n",
      "----------\n",
      "train Loss: 0.6696 Acc: 0.8769\n",
      "val Loss: 0.6761 Acc: 0.8680\n",
      "test Loss: 0.6638 Acc: 0.8920\n",
      "Epoch 925/1499\n",
      "----------\n",
      "train Loss: 0.6678 Acc: 0.8813\n",
      "val Loss: 0.6677 Acc: 0.8680\n",
      "test Loss: 0.6678 Acc: 0.8840\n",
      "Epoch 926/1499\n",
      "----------\n",
      "train Loss: 0.6691 Acc: 0.8802\n",
      "val Loss: 0.6698 Acc: 0.8840\n",
      "test Loss: 0.6691 Acc: 0.8800\n",
      "Epoch 927/1499\n",
      "----------\n",
      "train Loss: 0.6687 Acc: 0.8804\n",
      "val Loss: 0.6723 Acc: 0.8640\n",
      "test Loss: 0.6671 Acc: 0.8800\n",
      "Epoch 928/1499\n",
      "----------\n",
      "train Loss: 0.6679 Acc: 0.8813\n",
      "val Loss: 0.6738 Acc: 0.8680\n",
      "test Loss: 0.6626 Acc: 0.9000\n",
      "Epoch 929/1499\n",
      "----------\n",
      "train Loss: 0.6679 Acc: 0.8802\n",
      "val Loss: 0.6706 Acc: 0.8720\n",
      "test Loss: 0.6635 Acc: 0.8920\n",
      "Epoch 930/1499\n",
      "----------\n",
      "train Loss: 0.6683 Acc: 0.8804\n",
      "val Loss: 0.6705 Acc: 0.8760\n",
      "test Loss: 0.6615 Acc: 0.8920\n",
      "Epoch 931/1499\n",
      "----------\n",
      "train Loss: 0.6683 Acc: 0.8816\n",
      "val Loss: 0.6685 Acc: 0.8800\n",
      "test Loss: 0.6626 Acc: 0.8960\n",
      "Epoch 932/1499\n",
      "----------\n",
      "train Loss: 0.6677 Acc: 0.8824\n",
      "val Loss: 0.6692 Acc: 0.8800\n",
      "test Loss: 0.6655 Acc: 0.8840\n",
      "Epoch 933/1499\n",
      "----------\n",
      "train Loss: 0.6656 Acc: 0.8833\n",
      "val Loss: 0.6703 Acc: 0.8800\n",
      "test Loss: 0.6655 Acc: 0.8880\n",
      "Epoch 934/1499\n",
      "----------\n",
      "train Loss: 0.6676 Acc: 0.8804\n",
      "val Loss: 0.6678 Acc: 0.8720\n",
      "test Loss: 0.6651 Acc: 0.8920\n",
      "Epoch 935/1499\n",
      "----------\n",
      "train Loss: 0.6653 Acc: 0.8840\n",
      "val Loss: 0.6700 Acc: 0.8720\n",
      "test Loss: 0.6659 Acc: 0.8880\n",
      "Epoch 936/1499\n",
      "----------\n",
      "train Loss: 0.6681 Acc: 0.8809\n",
      "val Loss: 0.6680 Acc: 0.8720\n",
      "test Loss: 0.6585 Acc: 0.8920\n",
      "Epoch 937/1499\n",
      "----------\n",
      "train Loss: 0.6674 Acc: 0.8818\n",
      "val Loss: 0.6679 Acc: 0.8760\n",
      "test Loss: 0.6628 Acc: 0.8920\n",
      "Epoch 938/1499\n",
      "----------\n",
      "train Loss: 0.6672 Acc: 0.8807\n",
      "val Loss: 0.6714 Acc: 0.8680\n",
      "test Loss: 0.6617 Acc: 0.8880\n",
      "Epoch 939/1499\n",
      "----------\n",
      "train Loss: 0.6684 Acc: 0.8811\n",
      "val Loss: 0.6707 Acc: 0.8720\n",
      "test Loss: 0.6661 Acc: 0.8880\n",
      "Epoch 940/1499\n",
      "----------\n",
      "train Loss: 0.6673 Acc: 0.8798\n",
      "val Loss: 0.6739 Acc: 0.8720\n",
      "test Loss: 0.6620 Acc: 0.8920\n",
      "Epoch 941/1499\n",
      "----------\n",
      "train Loss: 0.6650 Acc: 0.8853\n",
      "val Loss: 0.6830 Acc: 0.8560\n",
      "test Loss: 0.6685 Acc: 0.8840\n",
      "Epoch 942/1499\n",
      "----------\n",
      "train Loss: 0.6665 Acc: 0.8816\n",
      "val Loss: 0.6641 Acc: 0.8840\n",
      "test Loss: 0.6663 Acc: 0.8880\n",
      "Epoch 943/1499\n",
      "----------\n",
      "train Loss: 0.6665 Acc: 0.8816\n",
      "val Loss: 0.6825 Acc: 0.8640\n",
      "test Loss: 0.6710 Acc: 0.8800\n",
      "Epoch 944/1499\n",
      "----------\n",
      "train Loss: 0.6678 Acc: 0.8816\n",
      "val Loss: 0.6642 Acc: 0.8960\n",
      "test Loss: 0.6640 Acc: 0.8920\n",
      "Epoch 945/1499\n",
      "----------\n",
      "train Loss: 0.6669 Acc: 0.8836\n",
      "val Loss: 0.6711 Acc: 0.8720\n",
      "test Loss: 0.6732 Acc: 0.8800\n",
      "Epoch 946/1499\n",
      "----------\n",
      "train Loss: 0.6702 Acc: 0.8787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.6729 Acc: 0.8760\n",
      "test Loss: 0.6698 Acc: 0.8840\n",
      "Epoch 947/1499\n",
      "----------\n",
      "train Loss: 0.6667 Acc: 0.8813\n",
      "val Loss: 0.6765 Acc: 0.8600\n",
      "test Loss: 0.6569 Acc: 0.9000\n",
      "Epoch 948/1499\n",
      "----------\n",
      "train Loss: 0.6652 Acc: 0.8824\n",
      "val Loss: 0.6630 Acc: 0.8880\n",
      "test Loss: 0.6723 Acc: 0.8800\n",
      "Epoch 949/1499\n",
      "----------\n",
      "train Loss: 0.6644 Acc: 0.8840\n",
      "val Loss: 0.6705 Acc: 0.8760\n",
      "test Loss: 0.6648 Acc: 0.8880\n",
      "Epoch 950/1499\n",
      "----------\n",
      "train Loss: 0.6639 Acc: 0.8853\n",
      "val Loss: 0.6713 Acc: 0.8720\n",
      "test Loss: 0.6640 Acc: 0.8920\n",
      "Epoch 951/1499\n",
      "----------\n",
      "train Loss: 0.6675 Acc: 0.8796\n",
      "val Loss: 0.6766 Acc: 0.8720\n",
      "test Loss: 0.6687 Acc: 0.8880\n",
      "Epoch 952/1499\n",
      "----------\n",
      "train Loss: 0.6653 Acc: 0.8818\n",
      "val Loss: 0.6688 Acc: 0.8760\n",
      "test Loss: 0.6607 Acc: 0.8920\n",
      "Epoch 953/1499\n",
      "----------\n",
      "train Loss: 0.6641 Acc: 0.8853\n",
      "val Loss: 0.6745 Acc: 0.8680\n",
      "test Loss: 0.6643 Acc: 0.8920\n",
      "Epoch 954/1499\n",
      "----------\n",
      "train Loss: 0.6673 Acc: 0.8804\n",
      "val Loss: 0.6743 Acc: 0.8640\n",
      "test Loss: 0.6688 Acc: 0.8720\n",
      "Epoch 955/1499\n",
      "----------\n",
      "train Loss: 0.6668 Acc: 0.8811\n",
      "val Loss: 0.6738 Acc: 0.8720\n",
      "test Loss: 0.6590 Acc: 0.9040\n",
      "Epoch 956/1499\n",
      "----------\n",
      "train Loss: 0.6677 Acc: 0.8811\n",
      "val Loss: 0.6676 Acc: 0.8800\n",
      "test Loss: 0.6650 Acc: 0.8960\n",
      "Epoch 957/1499\n",
      "----------\n",
      "train Loss: 0.6666 Acc: 0.8800\n",
      "val Loss: 0.6801 Acc: 0.8600\n",
      "test Loss: 0.6707 Acc: 0.8800\n",
      "Epoch 958/1499\n",
      "----------\n",
      "train Loss: 0.6644 Acc: 0.8829\n",
      "val Loss: 0.6711 Acc: 0.8680\n",
      "test Loss: 0.6614 Acc: 0.8920\n",
      "Epoch 959/1499\n",
      "----------\n",
      "train Loss: 0.6663 Acc: 0.8809\n",
      "val Loss: 0.6735 Acc: 0.8720\n",
      "test Loss: 0.6566 Acc: 0.8920\n",
      "Epoch 960/1499\n",
      "----------\n",
      "train Loss: 0.6650 Acc: 0.8829\n",
      "val Loss: 0.6723 Acc: 0.8720\n",
      "test Loss: 0.6607 Acc: 0.8960\n",
      "Epoch 961/1499\n",
      "----------\n",
      "train Loss: 0.6683 Acc: 0.8802\n",
      "val Loss: 0.6642 Acc: 0.8920\n",
      "test Loss: 0.6646 Acc: 0.8920\n",
      "Epoch 962/1499\n",
      "----------\n",
      "train Loss: 0.6652 Acc: 0.8827\n",
      "val Loss: 0.6734 Acc: 0.8720\n",
      "test Loss: 0.6646 Acc: 0.8920\n",
      "Epoch 963/1499\n",
      "----------\n",
      "train Loss: 0.6671 Acc: 0.8811\n",
      "val Loss: 0.6734 Acc: 0.8680\n",
      "test Loss: 0.6733 Acc: 0.8840\n",
      "Epoch 964/1499\n",
      "----------\n",
      "train Loss: 0.6655 Acc: 0.8831\n",
      "val Loss: 0.6662 Acc: 0.8760\n",
      "test Loss: 0.6675 Acc: 0.8800\n",
      "Epoch 965/1499\n",
      "----------\n",
      "train Loss: 0.6665 Acc: 0.8822\n",
      "val Loss: 0.6679 Acc: 0.8720\n",
      "test Loss: 0.6693 Acc: 0.8840\n",
      "Epoch 966/1499\n",
      "----------\n",
      "train Loss: 0.6650 Acc: 0.8822\n",
      "val Loss: 0.6804 Acc: 0.8600\n",
      "test Loss: 0.6681 Acc: 0.8800\n",
      "Epoch 967/1499\n",
      "----------\n",
      "train Loss: 0.6672 Acc: 0.8811\n",
      "val Loss: 0.6673 Acc: 0.8760\n",
      "test Loss: 0.6671 Acc: 0.8800\n",
      "Epoch 968/1499\n",
      "----------\n",
      "train Loss: 0.6671 Acc: 0.8818\n",
      "val Loss: 0.6545 Acc: 0.8960\n",
      "test Loss: 0.6594 Acc: 0.8960\n",
      "Epoch 969/1499\n",
      "----------\n",
      "train Loss: 0.6654 Acc: 0.8824\n",
      "val Loss: 0.6770 Acc: 0.8680\n",
      "test Loss: 0.6624 Acc: 0.8880\n",
      "Epoch 970/1499\n",
      "----------\n",
      "train Loss: 0.6648 Acc: 0.8833\n",
      "val Loss: 0.6663 Acc: 0.8720\n",
      "test Loss: 0.6643 Acc: 0.8920\n",
      "Epoch 971/1499\n",
      "----------\n",
      "train Loss: 0.6653 Acc: 0.8827\n",
      "val Loss: 0.6693 Acc: 0.8720\n",
      "test Loss: 0.6654 Acc: 0.8760\n",
      "Epoch 972/1499\n",
      "----------\n",
      "train Loss: 0.6674 Acc: 0.8800\n",
      "val Loss: 0.6780 Acc: 0.8680\n",
      "test Loss: 0.6646 Acc: 0.8880\n",
      "Epoch 973/1499\n",
      "----------\n",
      "train Loss: 0.6670 Acc: 0.8793\n",
      "val Loss: 0.6715 Acc: 0.8680\n",
      "test Loss: 0.6603 Acc: 0.8960\n",
      "Epoch 974/1499\n",
      "----------\n",
      "train Loss: 0.6669 Acc: 0.8816\n",
      "val Loss: 0.6678 Acc: 0.8800\n",
      "test Loss: 0.6634 Acc: 0.8960\n",
      "Epoch 975/1499\n",
      "----------\n",
      "train Loss: 0.6668 Acc: 0.8798\n",
      "val Loss: 0.6694 Acc: 0.8800\n",
      "test Loss: 0.6618 Acc: 0.8960\n",
      "Epoch 976/1499\n",
      "----------\n",
      "train Loss: 0.6655 Acc: 0.8816\n",
      "val Loss: 0.6724 Acc: 0.8640\n",
      "test Loss: 0.6650 Acc: 0.8880\n",
      "Epoch 977/1499\n",
      "----------\n",
      "train Loss: 0.6658 Acc: 0.8820\n",
      "val Loss: 0.6674 Acc: 0.8720\n",
      "test Loss: 0.6591 Acc: 0.9000\n",
      "Epoch 978/1499\n",
      "----------\n",
      "train Loss: 0.6673 Acc: 0.8829\n",
      "val Loss: 0.6673 Acc: 0.8720\n",
      "test Loss: 0.6607 Acc: 0.8880\n",
      "Epoch 979/1499\n",
      "----------\n",
      "train Loss: 0.6670 Acc: 0.8813\n",
      "val Loss: 0.6719 Acc: 0.8680\n",
      "test Loss: 0.6667 Acc: 0.8840\n",
      "Epoch 980/1499\n",
      "----------\n",
      "train Loss: 0.6647 Acc: 0.8829\n",
      "val Loss: 0.6679 Acc: 0.8880\n",
      "test Loss: 0.6676 Acc: 0.8920\n",
      "Epoch 981/1499\n",
      "----------\n",
      "train Loss: 0.6661 Acc: 0.8798\n",
      "val Loss: 0.6666 Acc: 0.8760\n",
      "test Loss: 0.6719 Acc: 0.8720\n",
      "Epoch 982/1499\n",
      "----------\n",
      "train Loss: 0.6660 Acc: 0.8813\n",
      "val Loss: 0.6682 Acc: 0.8800\n",
      "test Loss: 0.6536 Acc: 0.9080\n",
      "Epoch 983/1499\n",
      "----------\n",
      "train Loss: 0.6661 Acc: 0.8840\n",
      "val Loss: 0.6679 Acc: 0.8840\n",
      "test Loss: 0.6713 Acc: 0.8720\n",
      "Epoch 984/1499\n",
      "----------\n",
      "train Loss: 0.6685 Acc: 0.8807\n",
      "val Loss: 0.6626 Acc: 0.8800\n",
      "test Loss: 0.6664 Acc: 0.8920\n",
      "Epoch 985/1499\n",
      "----------\n",
      "train Loss: 0.6655 Acc: 0.8816\n",
      "val Loss: 0.6670 Acc: 0.8760\n",
      "test Loss: 0.6601 Acc: 0.8920\n",
      "Epoch 986/1499\n",
      "----------\n",
      "train Loss: 0.6656 Acc: 0.8824\n",
      "val Loss: 0.6654 Acc: 0.8840\n",
      "test Loss: 0.6532 Acc: 0.8960\n",
      "Epoch 987/1499\n",
      "----------\n",
      "train Loss: 0.6678 Acc: 0.8807\n",
      "val Loss: 0.6756 Acc: 0.8720\n",
      "test Loss: 0.6637 Acc: 0.8920\n",
      "Epoch 988/1499\n",
      "----------\n",
      "train Loss: 0.6662 Acc: 0.8809\n",
      "val Loss: 0.6808 Acc: 0.8560\n",
      "test Loss: 0.6626 Acc: 0.8960\n",
      "Epoch 989/1499\n",
      "----------\n",
      "train Loss: 0.6658 Acc: 0.8807\n",
      "val Loss: 0.6655 Acc: 0.8920\n",
      "test Loss: 0.6593 Acc: 0.8960\n",
      "Epoch 990/1499\n",
      "----------\n",
      "train Loss: 0.6684 Acc: 0.8804\n",
      "val Loss: 0.6685 Acc: 0.8720\n",
      "test Loss: 0.6609 Acc: 0.8920\n",
      "Epoch 991/1499\n",
      "----------\n",
      "train Loss: 0.6659 Acc: 0.8831\n",
      "val Loss: 0.6795 Acc: 0.8680\n",
      "test Loss: 0.6584 Acc: 0.9000\n",
      "Epoch 992/1499\n",
      "----------\n",
      "train Loss: 0.6660 Acc: 0.8829\n",
      "val Loss: 0.6672 Acc: 0.8760\n",
      "test Loss: 0.6634 Acc: 0.8960\n",
      "Epoch 993/1499\n",
      "----------\n",
      "train Loss: 0.6661 Acc: 0.8822\n",
      "val Loss: 0.6694 Acc: 0.8720\n",
      "test Loss: 0.6607 Acc: 0.9040\n",
      "Epoch 994/1499\n",
      "----------\n",
      "train Loss: 0.6664 Acc: 0.8827\n",
      "val Loss: 0.6733 Acc: 0.8640\n",
      "test Loss: 0.6634 Acc: 0.8880\n",
      "Epoch 995/1499\n",
      "----------\n",
      "train Loss: 0.6676 Acc: 0.8809\n",
      "val Loss: 0.6740 Acc: 0.8640\n",
      "test Loss: 0.6682 Acc: 0.8920\n",
      "Epoch 996/1499\n",
      "----------\n",
      "train Loss: 0.6660 Acc: 0.8822\n",
      "val Loss: 0.6714 Acc: 0.8680\n",
      "test Loss: 0.6677 Acc: 0.8880\n",
      "Epoch 997/1499\n",
      "----------\n",
      "train Loss: 0.6662 Acc: 0.8816\n",
      "val Loss: 0.6743 Acc: 0.8720\n",
      "test Loss: 0.6604 Acc: 0.8920\n",
      "Epoch 998/1499\n",
      "----------\n",
      "train Loss: 0.6644 Acc: 0.8816\n",
      "val Loss: 0.6753 Acc: 0.8720\n",
      "test Loss: 0.6622 Acc: 0.9000\n",
      "Epoch 999/1499\n",
      "----------\n",
      "train Loss: 0.6661 Acc: 0.8816\n",
      "val Loss: 0.6740 Acc: 0.8760\n",
      "test Loss: 0.6627 Acc: 0.8920\n",
      "Epoch 1000/1499\n",
      "----------\n",
      "train Loss: 0.6648 Acc: 0.8842\n",
      "val Loss: 0.6759 Acc: 0.8760\n",
      "test Loss: 0.6700 Acc: 0.8880\n",
      "Epoch 1001/1499\n",
      "----------\n",
      "train Loss: 0.6651 Acc: 0.8824\n",
      "val Loss: 0.6634 Acc: 0.8840\n",
      "test Loss: 0.6584 Acc: 0.9000\n",
      "Epoch 1002/1499\n",
      "----------\n",
      "train Loss: 0.6653 Acc: 0.8842\n",
      "val Loss: 0.6720 Acc: 0.8680\n",
      "test Loss: 0.6714 Acc: 0.8840\n",
      "Epoch 1003/1499\n",
      "----------\n",
      "train Loss: 0.6664 Acc: 0.8818\n",
      "val Loss: 0.6696 Acc: 0.8760\n",
      "test Loss: 0.6662 Acc: 0.8920\n",
      "Epoch 1004/1499\n",
      "----------\n",
      "train Loss: 0.6638 Acc: 0.8849\n",
      "val Loss: 0.6701 Acc: 0.8760\n",
      "test Loss: 0.6638 Acc: 0.8880\n",
      "Epoch 1005/1499\n",
      "----------\n",
      "train Loss: 0.6660 Acc: 0.8842\n",
      "val Loss: 0.6698 Acc: 0.8760\n",
      "test Loss: 0.6701 Acc: 0.8760\n",
      "Epoch 1006/1499\n",
      "----------\n",
      "train Loss: 0.6640 Acc: 0.8842\n",
      "val Loss: 0.6704 Acc: 0.8680\n",
      "test Loss: 0.6603 Acc: 0.8960\n",
      "Epoch 1007/1499\n",
      "----------\n",
      "train Loss: 0.6659 Acc: 0.8811\n",
      "val Loss: 0.6701 Acc: 0.8680\n",
      "test Loss: 0.6635 Acc: 0.8840\n",
      "Epoch 1008/1499\n",
      "----------\n",
      "train Loss: 0.6664 Acc: 0.8833\n",
      "val Loss: 0.6733 Acc: 0.8800\n",
      "test Loss: 0.6596 Acc: 0.8960\n",
      "Epoch 1009/1499\n",
      "----------\n",
      "train Loss: 0.6659 Acc: 0.8818\n",
      "val Loss: 0.6715 Acc: 0.8720\n",
      "test Loss: 0.6634 Acc: 0.8920\n",
      "Epoch 1010/1499\n",
      "----------\n",
      "train Loss: 0.6656 Acc: 0.8818\n",
      "val Loss: 0.6605 Acc: 0.8880\n",
      "test Loss: 0.6649 Acc: 0.8960\n",
      "Epoch 1011/1499\n",
      "----------\n",
      "train Loss: 0.6647 Acc: 0.8820\n",
      "val Loss: 0.6730 Acc: 0.8640\n",
      "test Loss: 0.6678 Acc: 0.8840\n",
      "Epoch 1012/1499\n",
      "----------\n",
      "train Loss: 0.6652 Acc: 0.8844\n",
      "val Loss: 0.6684 Acc: 0.8800\n",
      "test Loss: 0.6619 Acc: 0.8920\n",
      "Epoch 1013/1499\n",
      "----------\n",
      "train Loss: 0.6654 Acc: 0.8829\n",
      "val Loss: 0.6676 Acc: 0.8800\n",
      "test Loss: 0.6615 Acc: 0.8960\n",
      "Epoch 1014/1499\n",
      "----------\n",
      "train Loss: 0.6640 Acc: 0.8849\n",
      "val Loss: 0.6702 Acc: 0.8720\n",
      "test Loss: 0.6602 Acc: 0.8920\n",
      "Epoch 1015/1499\n",
      "----------\n",
      "train Loss: 0.6654 Acc: 0.8809\n",
      "val Loss: 0.6717 Acc: 0.8800\n",
      "test Loss: 0.6603 Acc: 0.8960\n",
      "Epoch 1016/1499\n",
      "----------\n",
      "train Loss: 0.6631 Acc: 0.8831\n",
      "val Loss: 0.6586 Acc: 0.8920\n",
      "test Loss: 0.6664 Acc: 0.8880\n",
      "Epoch 1017/1499\n",
      "----------\n",
      "train Loss: 0.6646 Acc: 0.8840\n",
      "val Loss: 0.6724 Acc: 0.8760\n",
      "test Loss: 0.6567 Acc: 0.8920\n",
      "Epoch 1018/1499\n",
      "----------\n",
      "train Loss: 0.6674 Acc: 0.8807\n",
      "val Loss: 0.6750 Acc: 0.8680\n",
      "test Loss: 0.6644 Acc: 0.8960\n",
      "Epoch 1019/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6656 Acc: 0.8816\n",
      "val Loss: 0.6751 Acc: 0.8640\n",
      "test Loss: 0.6646 Acc: 0.8920\n",
      "Epoch 1020/1499\n",
      "----------\n",
      "train Loss: 0.6663 Acc: 0.8811\n",
      "val Loss: 0.6707 Acc: 0.8720\n",
      "test Loss: 0.6564 Acc: 0.9000\n",
      "Epoch 1021/1499\n",
      "----------\n",
      "train Loss: 0.6653 Acc: 0.8851\n",
      "val Loss: 0.6767 Acc: 0.8800\n",
      "test Loss: 0.6641 Acc: 0.8920\n",
      "Epoch 1022/1499\n",
      "----------\n",
      "train Loss: 0.6663 Acc: 0.8804\n",
      "val Loss: 0.6796 Acc: 0.8600\n",
      "test Loss: 0.6583 Acc: 0.8960\n",
      "Epoch 1023/1499\n",
      "----------\n",
      "train Loss: 0.6640 Acc: 0.8849\n",
      "val Loss: 0.6723 Acc: 0.8720\n",
      "test Loss: 0.6605 Acc: 0.8920\n",
      "Epoch 1024/1499\n",
      "----------\n",
      "train Loss: 0.6615 Acc: 0.8869\n",
      "val Loss: 0.6722 Acc: 0.8800\n",
      "test Loss: 0.6665 Acc: 0.8880\n",
      "Epoch 1025/1499\n",
      "----------\n",
      "train Loss: 0.6643 Acc: 0.8844\n",
      "val Loss: 0.6787 Acc: 0.8640\n",
      "test Loss: 0.6633 Acc: 0.8920\n",
      "Epoch 1026/1499\n",
      "----------\n",
      "train Loss: 0.6666 Acc: 0.8793\n",
      "val Loss: 0.6666 Acc: 0.8760\n",
      "test Loss: 0.6637 Acc: 0.8920\n",
      "Epoch 1027/1499\n",
      "----------\n",
      "train Loss: 0.6641 Acc: 0.8842\n",
      "val Loss: 0.6650 Acc: 0.8760\n",
      "test Loss: 0.6578 Acc: 0.8960\n",
      "Epoch 1028/1499\n",
      "----------\n",
      "train Loss: 0.6657 Acc: 0.8811\n",
      "val Loss: 0.6644 Acc: 0.8760\n",
      "test Loss: 0.6678 Acc: 0.8840\n",
      "Epoch 1029/1499\n",
      "----------\n",
      "train Loss: 0.6645 Acc: 0.8827\n",
      "val Loss: 0.6713 Acc: 0.8680\n",
      "test Loss: 0.6648 Acc: 0.8880\n",
      "Epoch 1030/1499\n",
      "----------\n",
      "train Loss: 0.6639 Acc: 0.8844\n",
      "val Loss: 0.6673 Acc: 0.8760\n",
      "test Loss: 0.6613 Acc: 0.8920\n",
      "Epoch 1031/1499\n",
      "----------\n",
      "train Loss: 0.6647 Acc: 0.8829\n",
      "val Loss: 0.6690 Acc: 0.8840\n",
      "test Loss: 0.6614 Acc: 0.8920\n",
      "Epoch 1032/1499\n",
      "----------\n",
      "train Loss: 0.6647 Acc: 0.8829\n",
      "val Loss: 0.6660 Acc: 0.8760\n",
      "test Loss: 0.6601 Acc: 0.8920\n",
      "Epoch 1033/1499\n",
      "----------\n",
      "train Loss: 0.6654 Acc: 0.8818\n",
      "val Loss: 0.6667 Acc: 0.8680\n",
      "test Loss: 0.6642 Acc: 0.8880\n",
      "Epoch 1034/1499\n",
      "----------\n",
      "train Loss: 0.6626 Acc: 0.8878\n",
      "val Loss: 0.6647 Acc: 0.8760\n",
      "test Loss: 0.6668 Acc: 0.8880\n",
      "Epoch 1035/1499\n",
      "----------\n",
      "train Loss: 0.6658 Acc: 0.8813\n",
      "val Loss: 0.6666 Acc: 0.8760\n",
      "test Loss: 0.6636 Acc: 0.8920\n",
      "Epoch 1036/1499\n",
      "----------\n",
      "train Loss: 0.6655 Acc: 0.8827\n",
      "val Loss: 0.6742 Acc: 0.8720\n",
      "test Loss: 0.6593 Acc: 0.9000\n",
      "Epoch 1037/1499\n",
      "----------\n",
      "train Loss: 0.6641 Acc: 0.8851\n",
      "val Loss: 0.6716 Acc: 0.8680\n",
      "test Loss: 0.6616 Acc: 0.8920\n",
      "Epoch 1038/1499\n",
      "----------\n",
      "train Loss: 0.6634 Acc: 0.8849\n",
      "val Loss: 0.6776 Acc: 0.8680\n",
      "test Loss: 0.6701 Acc: 0.8840\n",
      "Epoch 1039/1499\n",
      "----------\n",
      "train Loss: 0.6616 Acc: 0.8856\n",
      "val Loss: 0.6668 Acc: 0.8800\n",
      "test Loss: 0.6614 Acc: 0.8920\n",
      "Epoch 1040/1499\n",
      "----------\n",
      "train Loss: 0.6640 Acc: 0.8856\n",
      "val Loss: 0.6664 Acc: 0.8800\n",
      "test Loss: 0.6674 Acc: 0.8880\n",
      "Epoch 1041/1499\n",
      "----------\n",
      "train Loss: 0.6641 Acc: 0.8827\n",
      "val Loss: 0.6668 Acc: 0.8760\n",
      "test Loss: 0.6584 Acc: 0.9000\n",
      "Epoch 1042/1499\n",
      "----------\n",
      "train Loss: 0.6642 Acc: 0.8829\n",
      "val Loss: 0.6713 Acc: 0.8720\n",
      "test Loss: 0.6616 Acc: 0.8920\n",
      "Epoch 1043/1499\n",
      "----------\n",
      "train Loss: 0.6646 Acc: 0.8827\n",
      "val Loss: 0.6665 Acc: 0.8800\n",
      "test Loss: 0.6617 Acc: 0.8920\n",
      "Epoch 1044/1499\n",
      "----------\n",
      "train Loss: 0.6618 Acc: 0.8869\n",
      "val Loss: 0.6648 Acc: 0.8800\n",
      "test Loss: 0.6605 Acc: 0.9000\n",
      "Epoch 1045/1499\n",
      "----------\n",
      "train Loss: 0.6616 Acc: 0.8867\n",
      "val Loss: 0.6777 Acc: 0.8760\n",
      "test Loss: 0.6584 Acc: 0.8960\n",
      "Epoch 1046/1499\n",
      "----------\n",
      "train Loss: 0.6630 Acc: 0.8838\n",
      "val Loss: 0.6711 Acc: 0.8720\n",
      "test Loss: 0.6619 Acc: 0.8960\n",
      "Epoch 1047/1499\n",
      "----------\n",
      "train Loss: 0.6625 Acc: 0.8849\n",
      "val Loss: 0.6701 Acc: 0.8640\n",
      "test Loss: 0.6564 Acc: 0.8960\n",
      "Epoch 1048/1499\n",
      "----------\n",
      "train Loss: 0.6637 Acc: 0.8831\n",
      "val Loss: 0.6666 Acc: 0.8680\n",
      "test Loss: 0.6734 Acc: 0.8840\n",
      "Epoch 1049/1499\n",
      "----------\n",
      "train Loss: 0.6633 Acc: 0.8831\n",
      "val Loss: 0.6674 Acc: 0.8760\n",
      "test Loss: 0.6609 Acc: 0.8880\n",
      "Epoch 1050/1499\n",
      "----------\n",
      "train Loss: 0.6627 Acc: 0.8833\n",
      "val Loss: 0.6641 Acc: 0.8760\n",
      "test Loss: 0.6621 Acc: 0.8960\n",
      "Epoch 1051/1499\n",
      "----------\n",
      "train Loss: 0.6633 Acc: 0.8844\n",
      "val Loss: 0.6740 Acc: 0.8760\n",
      "test Loss: 0.6627 Acc: 0.8920\n",
      "Epoch 1052/1499\n",
      "----------\n",
      "train Loss: 0.6651 Acc: 0.8809\n",
      "val Loss: 0.6709 Acc: 0.8680\n",
      "test Loss: 0.6548 Acc: 0.8920\n",
      "Epoch 1053/1499\n",
      "----------\n",
      "train Loss: 0.6635 Acc: 0.8836\n",
      "val Loss: 0.6662 Acc: 0.8720\n",
      "test Loss: 0.6645 Acc: 0.8880\n",
      "Epoch 1054/1499\n",
      "----------\n",
      "train Loss: 0.6643 Acc: 0.8844\n",
      "val Loss: 0.6607 Acc: 0.8960\n",
      "test Loss: 0.6613 Acc: 0.8920\n",
      "Epoch 1055/1499\n",
      "----------\n",
      "train Loss: 0.6627 Acc: 0.8849\n",
      "val Loss: 0.6679 Acc: 0.8720\n",
      "test Loss: 0.6650 Acc: 0.9000\n",
      "Epoch 1056/1499\n",
      "----------\n",
      "train Loss: 0.6641 Acc: 0.8831\n",
      "val Loss: 0.6635 Acc: 0.8760\n",
      "test Loss: 0.6638 Acc: 0.8920\n",
      "Epoch 1057/1499\n",
      "----------\n",
      "train Loss: 0.6625 Acc: 0.8873\n",
      "val Loss: 0.6704 Acc: 0.8680\n",
      "test Loss: 0.6670 Acc: 0.8880\n",
      "Epoch 1058/1499\n",
      "----------\n",
      "train Loss: 0.6654 Acc: 0.8796\n",
      "val Loss: 0.6722 Acc: 0.8760\n",
      "test Loss: 0.6614 Acc: 0.8920\n",
      "Epoch 1059/1499\n",
      "----------\n",
      "train Loss: 0.6643 Acc: 0.8840\n",
      "val Loss: 0.6740 Acc: 0.8600\n",
      "test Loss: 0.6618 Acc: 0.9000\n",
      "Epoch 1060/1499\n",
      "----------\n",
      "train Loss: 0.6647 Acc: 0.8836\n",
      "val Loss: 0.6652 Acc: 0.8840\n",
      "test Loss: 0.6584 Acc: 0.8960\n",
      "Epoch 1061/1499\n",
      "----------\n",
      "train Loss: 0.6653 Acc: 0.8831\n",
      "val Loss: 0.6665 Acc: 0.8920\n",
      "test Loss: 0.6649 Acc: 0.9000\n",
      "Epoch 1062/1499\n",
      "----------\n",
      "train Loss: 0.6633 Acc: 0.8820\n",
      "val Loss: 0.6623 Acc: 0.8880\n",
      "test Loss: 0.6579 Acc: 0.8960\n",
      "Epoch 1063/1499\n",
      "----------\n",
      "train Loss: 0.6630 Acc: 0.8838\n",
      "val Loss: 0.6660 Acc: 0.8720\n",
      "test Loss: 0.6646 Acc: 0.8920\n",
      "Epoch 1064/1499\n",
      "----------\n",
      "train Loss: 0.6631 Acc: 0.8849\n",
      "val Loss: 0.6671 Acc: 0.8840\n",
      "test Loss: 0.6665 Acc: 0.8880\n",
      "Epoch 1065/1499\n",
      "----------\n",
      "train Loss: 0.6630 Acc: 0.8853\n",
      "val Loss: 0.6643 Acc: 0.8840\n",
      "test Loss: 0.6614 Acc: 0.8960\n",
      "Epoch 1066/1499\n",
      "----------\n",
      "train Loss: 0.6646 Acc: 0.8833\n",
      "val Loss: 0.6683 Acc: 0.8760\n",
      "test Loss: 0.6670 Acc: 0.8920\n",
      "Epoch 1067/1499\n",
      "----------\n",
      "train Loss: 0.6633 Acc: 0.8853\n",
      "val Loss: 0.6707 Acc: 0.8760\n",
      "test Loss: 0.6588 Acc: 0.8960\n",
      "Epoch 1068/1499\n",
      "----------\n",
      "train Loss: 0.6637 Acc: 0.8822\n",
      "val Loss: 0.6716 Acc: 0.8760\n",
      "test Loss: 0.6568 Acc: 0.8960\n",
      "Epoch 1069/1499\n",
      "----------\n",
      "train Loss: 0.6628 Acc: 0.8847\n",
      "val Loss: 0.6671 Acc: 0.8760\n",
      "test Loss: 0.6676 Acc: 0.8840\n",
      "Epoch 1070/1499\n",
      "----------\n",
      "train Loss: 0.6627 Acc: 0.8856\n",
      "val Loss: 0.6731 Acc: 0.8760\n",
      "test Loss: 0.6565 Acc: 0.8960\n",
      "Epoch 1071/1499\n",
      "----------\n",
      "train Loss: 0.6628 Acc: 0.8829\n",
      "val Loss: 0.6697 Acc: 0.8760\n",
      "test Loss: 0.6666 Acc: 0.8800\n",
      "Epoch 1072/1499\n",
      "----------\n",
      "train Loss: 0.6629 Acc: 0.8842\n",
      "val Loss: 0.6730 Acc: 0.8720\n",
      "test Loss: 0.6636 Acc: 0.8880\n",
      "Epoch 1073/1499\n",
      "----------\n",
      "train Loss: 0.6639 Acc: 0.8824\n",
      "val Loss: 0.6680 Acc: 0.8800\n",
      "test Loss: 0.6636 Acc: 0.8920\n",
      "Epoch 1074/1499\n",
      "----------\n",
      "train Loss: 0.6618 Acc: 0.8853\n",
      "val Loss: 0.6621 Acc: 0.8800\n",
      "test Loss: 0.6574 Acc: 0.9000\n",
      "Epoch 1075/1499\n",
      "----------\n",
      "train Loss: 0.6653 Acc: 0.8820\n",
      "val Loss: 0.6740 Acc: 0.8640\n",
      "test Loss: 0.6526 Acc: 0.8960\n",
      "Epoch 1076/1499\n",
      "----------\n",
      "train Loss: 0.6627 Acc: 0.8829\n",
      "val Loss: 0.6668 Acc: 0.8800\n",
      "test Loss: 0.6599 Acc: 0.8960\n",
      "Epoch 1077/1499\n",
      "----------\n",
      "train Loss: 0.6625 Acc: 0.8862\n",
      "val Loss: 0.6756 Acc: 0.8600\n",
      "test Loss: 0.6679 Acc: 0.8920\n",
      "Epoch 1078/1499\n",
      "----------\n",
      "train Loss: 0.6624 Acc: 0.8853\n",
      "val Loss: 0.6706 Acc: 0.8760\n",
      "test Loss: 0.6601 Acc: 0.8960\n",
      "Epoch 1079/1499\n",
      "----------\n",
      "train Loss: 0.6632 Acc: 0.8842\n",
      "val Loss: 0.6636 Acc: 0.8760\n",
      "test Loss: 0.6571 Acc: 0.8920\n",
      "Epoch 1080/1499\n",
      "----------\n",
      "train Loss: 0.6618 Acc: 0.8844\n",
      "val Loss: 0.6601 Acc: 0.8880\n",
      "test Loss: 0.6587 Acc: 0.8920\n",
      "Epoch 1081/1499\n",
      "----------\n",
      "train Loss: 0.6629 Acc: 0.8847\n",
      "val Loss: 0.6660 Acc: 0.8800\n",
      "test Loss: 0.6594 Acc: 0.9000\n",
      "Epoch 1082/1499\n",
      "----------\n",
      "train Loss: 0.6623 Acc: 0.8869\n",
      "val Loss: 0.6675 Acc: 0.8720\n",
      "test Loss: 0.6577 Acc: 0.9000\n",
      "Epoch 1083/1499\n",
      "----------\n",
      "train Loss: 0.6617 Acc: 0.8840\n",
      "val Loss: 0.6644 Acc: 0.8880\n",
      "test Loss: 0.6580 Acc: 0.9040\n",
      "Epoch 1084/1499\n",
      "----------\n",
      "train Loss: 0.6616 Acc: 0.8856\n",
      "val Loss: 0.6697 Acc: 0.8800\n",
      "test Loss: 0.6690 Acc: 0.8840\n",
      "Epoch 1085/1499\n",
      "----------\n",
      "train Loss: 0.6619 Acc: 0.8844\n",
      "val Loss: 0.6653 Acc: 0.8800\n",
      "test Loss: 0.6612 Acc: 0.8920\n",
      "Epoch 1086/1499\n",
      "----------\n",
      "train Loss: 0.6602 Acc: 0.8884\n",
      "val Loss: 0.6620 Acc: 0.8800\n",
      "test Loss: 0.6637 Acc: 0.8920\n",
      "Epoch 1087/1499\n",
      "----------\n",
      "train Loss: 0.6615 Acc: 0.8853\n",
      "val Loss: 0.6657 Acc: 0.8800\n",
      "test Loss: 0.6631 Acc: 0.8960\n",
      "Epoch 1088/1499\n",
      "----------\n",
      "train Loss: 0.6610 Acc: 0.8851\n",
      "val Loss: 0.6620 Acc: 0.8840\n",
      "test Loss: 0.6592 Acc: 0.9000\n",
      "Epoch 1089/1499\n",
      "----------\n",
      "train Loss: 0.6647 Acc: 0.8818\n",
      "val Loss: 0.6667 Acc: 0.8800\n",
      "test Loss: 0.6654 Acc: 0.8880\n",
      "Epoch 1090/1499\n",
      "----------\n",
      "train Loss: 0.6622 Acc: 0.8869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.6670 Acc: 0.8840\n",
      "test Loss: 0.6651 Acc: 0.8920\n",
      "Epoch 1091/1499\n",
      "----------\n",
      "train Loss: 0.6613 Acc: 0.8871\n",
      "val Loss: 0.6777 Acc: 0.8680\n",
      "test Loss: 0.6575 Acc: 0.9000\n",
      "Epoch 1092/1499\n",
      "----------\n",
      "train Loss: 0.6628 Acc: 0.8858\n",
      "val Loss: 0.6668 Acc: 0.8800\n",
      "test Loss: 0.6639 Acc: 0.8960\n",
      "Epoch 1093/1499\n",
      "----------\n",
      "train Loss: 0.6625 Acc: 0.8871\n",
      "val Loss: 0.6699 Acc: 0.8800\n",
      "test Loss: 0.6737 Acc: 0.8840\n",
      "Epoch 1094/1499\n",
      "----------\n",
      "train Loss: 0.6626 Acc: 0.8853\n",
      "val Loss: 0.6656 Acc: 0.8840\n",
      "test Loss: 0.6596 Acc: 0.8920\n",
      "Epoch 1095/1499\n",
      "----------\n",
      "train Loss: 0.6599 Acc: 0.8889\n",
      "val Loss: 0.6562 Acc: 0.8840\n",
      "test Loss: 0.6659 Acc: 0.8920\n",
      "Epoch 1096/1499\n",
      "----------\n",
      "train Loss: 0.6637 Acc: 0.8824\n",
      "val Loss: 0.6634 Acc: 0.8800\n",
      "test Loss: 0.6610 Acc: 0.8960\n",
      "Epoch 1097/1499\n",
      "----------\n",
      "train Loss: 0.6636 Acc: 0.8838\n",
      "val Loss: 0.6693 Acc: 0.8760\n",
      "test Loss: 0.6551 Acc: 0.8960\n",
      "Epoch 1098/1499\n",
      "----------\n",
      "train Loss: 0.6611 Acc: 0.8873\n",
      "val Loss: 0.6676 Acc: 0.8760\n",
      "test Loss: 0.6555 Acc: 0.9000\n",
      "Epoch 1099/1499\n",
      "----------\n",
      "train Loss: 0.6616 Acc: 0.8869\n",
      "val Loss: 0.6698 Acc: 0.8800\n",
      "test Loss: 0.6631 Acc: 0.8880\n",
      "Epoch 1100/1499\n",
      "----------\n",
      "train Loss: 0.6594 Acc: 0.8860\n",
      "val Loss: 0.6620 Acc: 0.8760\n",
      "test Loss: 0.6657 Acc: 0.8880\n",
      "Epoch 1101/1499\n",
      "----------\n",
      "train Loss: 0.6620 Acc: 0.8856\n",
      "val Loss: 0.6674 Acc: 0.8720\n",
      "test Loss: 0.6589 Acc: 0.8960\n",
      "Epoch 1102/1499\n",
      "----------\n",
      "train Loss: 0.6643 Acc: 0.8849\n",
      "val Loss: 0.6691 Acc: 0.8720\n",
      "test Loss: 0.6648 Acc: 0.8920\n",
      "Epoch 1103/1499\n",
      "----------\n",
      "train Loss: 0.6629 Acc: 0.8847\n",
      "val Loss: 0.6609 Acc: 0.8920\n",
      "test Loss: 0.6627 Acc: 0.8960\n",
      "Epoch 1104/1499\n",
      "----------\n",
      "train Loss: 0.6621 Acc: 0.8856\n",
      "val Loss: 0.6705 Acc: 0.8800\n",
      "test Loss: 0.6586 Acc: 0.8920\n",
      "Epoch 1105/1499\n",
      "----------\n",
      "train Loss: 0.6627 Acc: 0.8849\n",
      "val Loss: 0.6620 Acc: 0.8800\n",
      "test Loss: 0.6593 Acc: 0.9040\n",
      "Epoch 1106/1499\n",
      "----------\n",
      "train Loss: 0.6616 Acc: 0.8878\n",
      "val Loss: 0.6734 Acc: 0.8680\n",
      "test Loss: 0.6618 Acc: 0.8920\n",
      "Epoch 1107/1499\n",
      "----------\n",
      "train Loss: 0.6629 Acc: 0.8849\n",
      "val Loss: 0.6634 Acc: 0.8680\n",
      "test Loss: 0.6618 Acc: 0.8960\n",
      "Epoch 1108/1499\n",
      "----------\n",
      "train Loss: 0.6615 Acc: 0.8858\n",
      "val Loss: 0.6750 Acc: 0.8720\n",
      "test Loss: 0.6609 Acc: 0.8960\n",
      "Epoch 1109/1499\n",
      "----------\n",
      "train Loss: 0.6633 Acc: 0.8849\n",
      "val Loss: 0.6704 Acc: 0.8720\n",
      "test Loss: 0.6579 Acc: 0.8920\n",
      "Epoch 1110/1499\n",
      "----------\n",
      "train Loss: 0.6624 Acc: 0.8851\n",
      "val Loss: 0.6674 Acc: 0.8720\n",
      "test Loss: 0.6565 Acc: 0.9040\n",
      "Epoch 1111/1499\n",
      "----------\n",
      "train Loss: 0.6604 Acc: 0.8860\n",
      "val Loss: 0.6632 Acc: 0.8760\n",
      "test Loss: 0.6621 Acc: 0.8880\n",
      "Epoch 1112/1499\n",
      "----------\n",
      "train Loss: 0.6621 Acc: 0.8867\n",
      "val Loss: 0.6611 Acc: 0.8840\n",
      "test Loss: 0.6621 Acc: 0.8880\n",
      "Epoch 1113/1499\n",
      "----------\n",
      "train Loss: 0.6625 Acc: 0.8851\n",
      "val Loss: 0.6653 Acc: 0.8720\n",
      "test Loss: 0.6665 Acc: 0.8920\n",
      "Epoch 1114/1499\n",
      "----------\n",
      "train Loss: 0.6620 Acc: 0.8836\n",
      "val Loss: 0.6665 Acc: 0.8720\n",
      "test Loss: 0.6574 Acc: 0.9000\n",
      "Epoch 1115/1499\n",
      "----------\n",
      "train Loss: 0.6624 Acc: 0.8849\n",
      "val Loss: 0.6679 Acc: 0.8680\n",
      "test Loss: 0.6575 Acc: 0.8960\n",
      "Epoch 1116/1499\n",
      "----------\n",
      "train Loss: 0.6636 Acc: 0.8851\n",
      "val Loss: 0.6638 Acc: 0.8760\n",
      "test Loss: 0.6627 Acc: 0.8920\n",
      "Epoch 1117/1499\n",
      "----------\n",
      "train Loss: 0.6637 Acc: 0.8811\n",
      "val Loss: 0.6610 Acc: 0.8880\n",
      "test Loss: 0.6577 Acc: 0.9000\n",
      "Epoch 1118/1499\n",
      "----------\n",
      "train Loss: 0.6602 Acc: 0.8858\n",
      "val Loss: 0.6658 Acc: 0.8680\n",
      "test Loss: 0.6590 Acc: 0.8960\n",
      "Epoch 1119/1499\n",
      "----------\n",
      "train Loss: 0.6609 Acc: 0.8896\n",
      "val Loss: 0.6636 Acc: 0.8840\n",
      "test Loss: 0.6717 Acc: 0.8840\n",
      "Epoch 1120/1499\n",
      "----------\n",
      "train Loss: 0.6622 Acc: 0.8847\n",
      "val Loss: 0.6709 Acc: 0.8640\n",
      "test Loss: 0.6626 Acc: 0.8960\n",
      "Epoch 1121/1499\n",
      "----------\n",
      "train Loss: 0.6613 Acc: 0.8876\n",
      "val Loss: 0.6693 Acc: 0.8720\n",
      "test Loss: 0.6631 Acc: 0.8920\n",
      "Epoch 1122/1499\n",
      "----------\n",
      "train Loss: 0.6619 Acc: 0.8864\n",
      "val Loss: 0.6695 Acc: 0.8640\n",
      "test Loss: 0.6548 Acc: 0.8960\n",
      "Epoch 1123/1499\n",
      "----------\n",
      "train Loss: 0.6612 Acc: 0.8873\n",
      "val Loss: 0.6567 Acc: 0.8840\n",
      "test Loss: 0.6625 Acc: 0.8920\n",
      "Epoch 1124/1499\n",
      "----------\n",
      "train Loss: 0.6606 Acc: 0.8887\n",
      "val Loss: 0.6669 Acc: 0.8760\n",
      "test Loss: 0.6583 Acc: 0.9080\n",
      "Epoch 1125/1499\n",
      "----------\n",
      "train Loss: 0.6612 Acc: 0.8876\n",
      "val Loss: 0.6676 Acc: 0.8720\n",
      "test Loss: 0.6662 Acc: 0.8800\n",
      "Epoch 1126/1499\n",
      "----------\n",
      "train Loss: 0.6621 Acc: 0.8869\n",
      "val Loss: 0.6720 Acc: 0.8720\n",
      "test Loss: 0.6621 Acc: 0.8920\n",
      "Epoch 1127/1499\n",
      "----------\n",
      "train Loss: 0.6634 Acc: 0.8851\n",
      "val Loss: 0.6590 Acc: 0.8840\n",
      "test Loss: 0.6633 Acc: 0.8840\n",
      "Epoch 1128/1499\n",
      "----------\n",
      "train Loss: 0.6610 Acc: 0.8884\n",
      "val Loss: 0.6634 Acc: 0.8800\n",
      "test Loss: 0.6562 Acc: 0.8960\n",
      "Epoch 1129/1499\n",
      "----------\n",
      "train Loss: 0.6602 Acc: 0.8887\n",
      "val Loss: 0.6643 Acc: 0.8720\n",
      "test Loss: 0.6697 Acc: 0.8880\n",
      "Epoch 1130/1499\n",
      "----------\n",
      "train Loss: 0.6594 Acc: 0.8898\n",
      "val Loss: 0.6691 Acc: 0.8720\n",
      "test Loss: 0.6625 Acc: 0.8880\n",
      "Epoch 1131/1499\n",
      "----------\n",
      "train Loss: 0.6619 Acc: 0.8860\n",
      "val Loss: 0.6682 Acc: 0.8760\n",
      "test Loss: 0.6594 Acc: 0.9040\n",
      "Epoch 1132/1499\n",
      "----------\n",
      "train Loss: 0.6611 Acc: 0.8864\n",
      "val Loss: 0.6648 Acc: 0.8840\n",
      "test Loss: 0.6568 Acc: 0.8920\n",
      "Epoch 1133/1499\n",
      "----------\n",
      "train Loss: 0.6631 Acc: 0.8804\n",
      "val Loss: 0.6681 Acc: 0.8760\n",
      "test Loss: 0.6531 Acc: 0.9040\n",
      "Epoch 1134/1499\n",
      "----------\n",
      "train Loss: 0.6612 Acc: 0.8871\n",
      "val Loss: 0.6648 Acc: 0.8720\n",
      "test Loss: 0.6612 Acc: 0.8920\n",
      "Epoch 1135/1499\n",
      "----------\n",
      "train Loss: 0.6618 Acc: 0.8849\n",
      "val Loss: 0.6571 Acc: 0.8840\n",
      "test Loss: 0.6540 Acc: 0.9000\n",
      "Epoch 1136/1499\n",
      "----------\n",
      "train Loss: 0.6616 Acc: 0.8893\n",
      "val Loss: 0.6651 Acc: 0.8720\n",
      "test Loss: 0.6566 Acc: 0.9000\n",
      "Epoch 1137/1499\n",
      "----------\n",
      "train Loss: 0.6610 Acc: 0.8867\n",
      "val Loss: 0.6630 Acc: 0.8760\n",
      "test Loss: 0.6613 Acc: 0.9000\n",
      "Epoch 1138/1499\n",
      "----------\n",
      "train Loss: 0.6604 Acc: 0.8876\n",
      "val Loss: 0.6761 Acc: 0.8720\n",
      "test Loss: 0.6569 Acc: 0.9080\n",
      "Epoch 1139/1499\n",
      "----------\n",
      "train Loss: 0.6613 Acc: 0.8864\n",
      "val Loss: 0.6681 Acc: 0.8840\n",
      "test Loss: 0.6559 Acc: 0.9080\n",
      "Epoch 1140/1499\n",
      "----------\n",
      "train Loss: 0.6613 Acc: 0.8873\n",
      "val Loss: 0.6657 Acc: 0.8760\n",
      "test Loss: 0.6621 Acc: 0.8920\n",
      "Epoch 1141/1499\n",
      "----------\n",
      "train Loss: 0.6611 Acc: 0.8862\n",
      "val Loss: 0.6640 Acc: 0.8760\n",
      "test Loss: 0.6646 Acc: 0.8920\n",
      "Epoch 1142/1499\n",
      "----------\n",
      "train Loss: 0.6611 Acc: 0.8867\n",
      "val Loss: 0.6590 Acc: 0.8960\n",
      "test Loss: 0.6615 Acc: 0.8960\n",
      "Epoch 1143/1499\n",
      "----------\n",
      "train Loss: 0.6613 Acc: 0.8851\n",
      "val Loss: 0.6710 Acc: 0.8720\n",
      "test Loss: 0.6593 Acc: 0.8960\n",
      "Epoch 1144/1499\n",
      "----------\n",
      "train Loss: 0.6601 Acc: 0.8902\n",
      "val Loss: 0.6670 Acc: 0.8760\n",
      "test Loss: 0.6598 Acc: 0.8920\n",
      "Epoch 1145/1499\n",
      "----------\n",
      "train Loss: 0.6607 Acc: 0.8882\n",
      "val Loss: 0.6628 Acc: 0.8840\n",
      "test Loss: 0.6609 Acc: 0.8880\n",
      "Epoch 1146/1499\n",
      "----------\n",
      "train Loss: 0.6619 Acc: 0.8873\n",
      "val Loss: 0.6607 Acc: 0.8840\n",
      "test Loss: 0.6555 Acc: 0.9000\n",
      "Epoch 1147/1499\n",
      "----------\n",
      "train Loss: 0.6602 Acc: 0.8873\n",
      "val Loss: 0.6561 Acc: 0.8920\n",
      "test Loss: 0.6652 Acc: 0.8920\n",
      "Epoch 1148/1499\n",
      "----------\n",
      "train Loss: 0.6622 Acc: 0.8878\n",
      "val Loss: 0.6584 Acc: 0.8920\n",
      "test Loss: 0.6592 Acc: 0.8960\n",
      "Epoch 1149/1499\n",
      "----------\n",
      "train Loss: 0.6605 Acc: 0.8891\n",
      "val Loss: 0.6611 Acc: 0.8880\n",
      "test Loss: 0.6641 Acc: 0.8920\n",
      "Epoch 1150/1499\n",
      "----------\n",
      "train Loss: 0.6611 Acc: 0.8867\n",
      "val Loss: 0.6576 Acc: 0.8920\n",
      "test Loss: 0.6586 Acc: 0.8960\n",
      "Epoch 1151/1499\n",
      "----------\n",
      "train Loss: 0.6599 Acc: 0.8862\n",
      "val Loss: 0.6556 Acc: 0.9000\n",
      "test Loss: 0.6648 Acc: 0.8880\n",
      "Epoch 1152/1499\n",
      "----------\n",
      "train Loss: 0.6606 Acc: 0.8862\n",
      "val Loss: 0.6740 Acc: 0.8760\n",
      "test Loss: 0.6584 Acc: 0.8960\n",
      "Epoch 1153/1499\n",
      "----------\n",
      "train Loss: 0.6612 Acc: 0.8853\n",
      "val Loss: 0.6663 Acc: 0.8800\n",
      "test Loss: 0.6604 Acc: 0.8920\n",
      "Epoch 1154/1499\n",
      "----------\n",
      "train Loss: 0.6607 Acc: 0.8860\n",
      "val Loss: 0.6726 Acc: 0.8640\n",
      "test Loss: 0.6598 Acc: 0.8960\n",
      "Epoch 1155/1499\n",
      "----------\n",
      "train Loss: 0.6602 Acc: 0.8867\n",
      "val Loss: 0.6617 Acc: 0.8840\n",
      "test Loss: 0.6543 Acc: 0.8960\n",
      "Epoch 1156/1499\n",
      "----------\n",
      "train Loss: 0.6599 Acc: 0.8871\n",
      "val Loss: 0.6625 Acc: 0.8840\n",
      "test Loss: 0.6620 Acc: 0.8840\n",
      "Epoch 1157/1499\n",
      "----------\n",
      "train Loss: 0.6620 Acc: 0.8842\n",
      "val Loss: 0.6620 Acc: 0.8760\n",
      "test Loss: 0.6561 Acc: 0.9000\n",
      "Epoch 1158/1499\n",
      "----------\n",
      "train Loss: 0.6611 Acc: 0.8878\n",
      "val Loss: 0.6674 Acc: 0.8760\n",
      "test Loss: 0.6659 Acc: 0.8920\n",
      "Epoch 1159/1499\n",
      "----------\n",
      "train Loss: 0.6607 Acc: 0.8867\n",
      "val Loss: 0.6595 Acc: 0.8800\n",
      "test Loss: 0.6604 Acc: 0.8920\n",
      "Epoch 1160/1499\n",
      "----------\n",
      "train Loss: 0.6611 Acc: 0.8867\n",
      "val Loss: 0.6642 Acc: 0.8720\n",
      "test Loss: 0.6575 Acc: 0.8960\n",
      "Epoch 1161/1499\n",
      "----------\n",
      "train Loss: 0.6612 Acc: 0.8876\n",
      "val Loss: 0.6667 Acc: 0.8800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6653 Acc: 0.8880\n",
      "Epoch 1162/1499\n",
      "----------\n",
      "train Loss: 0.6596 Acc: 0.8871\n",
      "val Loss: 0.6614 Acc: 0.8760\n",
      "test Loss: 0.6546 Acc: 0.9040\n",
      "Epoch 1163/1499\n",
      "----------\n",
      "train Loss: 0.6625 Acc: 0.8858\n",
      "val Loss: 0.6687 Acc: 0.8680\n",
      "test Loss: 0.6589 Acc: 0.9000\n",
      "Epoch 1164/1499\n",
      "----------\n",
      "train Loss: 0.6610 Acc: 0.8891\n",
      "val Loss: 0.6783 Acc: 0.8600\n",
      "test Loss: 0.6651 Acc: 0.8920\n",
      "Epoch 1165/1499\n",
      "----------\n",
      "train Loss: 0.6594 Acc: 0.8889\n",
      "val Loss: 0.6610 Acc: 0.8840\n",
      "test Loss: 0.6626 Acc: 0.8880\n",
      "Epoch 1166/1499\n",
      "----------\n",
      "train Loss: 0.6615 Acc: 0.8864\n",
      "val Loss: 0.6650 Acc: 0.8800\n",
      "test Loss: 0.6629 Acc: 0.8920\n",
      "Epoch 1167/1499\n",
      "----------\n",
      "train Loss: 0.6612 Acc: 0.8898\n",
      "val Loss: 0.6576 Acc: 0.8920\n",
      "test Loss: 0.6584 Acc: 0.9000\n",
      "Epoch 1168/1499\n",
      "----------\n",
      "train Loss: 0.6593 Acc: 0.8882\n",
      "val Loss: 0.6653 Acc: 0.8840\n",
      "test Loss: 0.6525 Acc: 0.9040\n",
      "Epoch 1169/1499\n",
      "----------\n",
      "train Loss: 0.6594 Acc: 0.8896\n",
      "val Loss: 0.6654 Acc: 0.8760\n",
      "test Loss: 0.6698 Acc: 0.8800\n",
      "Epoch 1170/1499\n",
      "----------\n",
      "train Loss: 0.6601 Acc: 0.8880\n",
      "val Loss: 0.6608 Acc: 0.8760\n",
      "test Loss: 0.6568 Acc: 0.8960\n",
      "Epoch 1171/1499\n",
      "----------\n",
      "train Loss: 0.6607 Acc: 0.8853\n",
      "val Loss: 0.6579 Acc: 0.8840\n",
      "test Loss: 0.6567 Acc: 0.8960\n",
      "Epoch 1172/1499\n",
      "----------\n",
      "train Loss: 0.6617 Acc: 0.8836\n",
      "val Loss: 0.6620 Acc: 0.8760\n",
      "test Loss: 0.6645 Acc: 0.8880\n",
      "Epoch 1173/1499\n",
      "----------\n",
      "train Loss: 0.6580 Acc: 0.8898\n",
      "val Loss: 0.6676 Acc: 0.8760\n",
      "test Loss: 0.6550 Acc: 0.9000\n",
      "Epoch 1174/1499\n",
      "----------\n",
      "train Loss: 0.6580 Acc: 0.8913\n",
      "val Loss: 0.6580 Acc: 0.8880\n",
      "test Loss: 0.6567 Acc: 0.8960\n",
      "Epoch 1175/1499\n",
      "----------\n",
      "train Loss: 0.6598 Acc: 0.8887\n",
      "val Loss: 0.6631 Acc: 0.8840\n",
      "test Loss: 0.6557 Acc: 0.8960\n",
      "Epoch 1176/1499\n",
      "----------\n",
      "train Loss: 0.6603 Acc: 0.8862\n",
      "val Loss: 0.6642 Acc: 0.8800\n",
      "test Loss: 0.6571 Acc: 0.8920\n",
      "Epoch 1177/1499\n",
      "----------\n",
      "train Loss: 0.6598 Acc: 0.8880\n",
      "val Loss: 0.6659 Acc: 0.8880\n",
      "test Loss: 0.6586 Acc: 0.9000\n",
      "Epoch 1178/1499\n",
      "----------\n",
      "train Loss: 0.6591 Acc: 0.8891\n",
      "val Loss: 0.6638 Acc: 0.9000\n",
      "test Loss: 0.6519 Acc: 0.9040\n",
      "Epoch 1179/1499\n",
      "----------\n",
      "train Loss: 0.6607 Acc: 0.8878\n",
      "val Loss: 0.6613 Acc: 0.8920\n",
      "test Loss: 0.6571 Acc: 0.9040\n",
      "Epoch 1180/1499\n",
      "----------\n",
      "train Loss: 0.6580 Acc: 0.8911\n",
      "val Loss: 0.6680 Acc: 0.8800\n",
      "test Loss: 0.6586 Acc: 0.8920\n",
      "Epoch 1181/1499\n",
      "----------\n",
      "train Loss: 0.6593 Acc: 0.8889\n",
      "val Loss: 0.6842 Acc: 0.8560\n",
      "test Loss: 0.6672 Acc: 0.8840\n",
      "Epoch 1182/1499\n",
      "----------\n",
      "train Loss: 0.6586 Acc: 0.8896\n",
      "val Loss: 0.6679 Acc: 0.8680\n",
      "test Loss: 0.6617 Acc: 0.9000\n",
      "Epoch 1183/1499\n",
      "----------\n",
      "train Loss: 0.6587 Acc: 0.8904\n",
      "val Loss: 0.6673 Acc: 0.8840\n",
      "test Loss: 0.6594 Acc: 0.8960\n",
      "Epoch 1184/1499\n",
      "----------\n",
      "train Loss: 0.6584 Acc: 0.8918\n",
      "val Loss: 0.6778 Acc: 0.8720\n",
      "test Loss: 0.6660 Acc: 0.8840\n",
      "Epoch 1185/1499\n",
      "----------\n",
      "train Loss: 0.6604 Acc: 0.8873\n",
      "val Loss: 0.6656 Acc: 0.8720\n",
      "test Loss: 0.6632 Acc: 0.8920\n",
      "Epoch 1186/1499\n",
      "----------\n",
      "train Loss: 0.6609 Acc: 0.8862\n",
      "val Loss: 0.6689 Acc: 0.8800\n",
      "test Loss: 0.6599 Acc: 0.9000\n",
      "Epoch 1187/1499\n",
      "----------\n",
      "train Loss: 0.6584 Acc: 0.8920\n",
      "val Loss: 0.6590 Acc: 0.8960\n",
      "test Loss: 0.6572 Acc: 0.9000\n",
      "Epoch 1188/1499\n",
      "----------\n",
      "train Loss: 0.6590 Acc: 0.8900\n",
      "val Loss: 0.6621 Acc: 0.8760\n",
      "test Loss: 0.6558 Acc: 0.9000\n",
      "Epoch 1189/1499\n",
      "----------\n",
      "train Loss: 0.6596 Acc: 0.8889\n",
      "val Loss: 0.6709 Acc: 0.8720\n",
      "test Loss: 0.6631 Acc: 0.8920\n",
      "Epoch 1190/1499\n",
      "----------\n",
      "train Loss: 0.6604 Acc: 0.8860\n",
      "val Loss: 0.6609 Acc: 0.8880\n",
      "test Loss: 0.6675 Acc: 0.8840\n",
      "Epoch 1191/1499\n",
      "----------\n",
      "train Loss: 0.6619 Acc: 0.8858\n",
      "val Loss: 0.6599 Acc: 0.8920\n",
      "test Loss: 0.6611 Acc: 0.8960\n",
      "Epoch 1192/1499\n",
      "----------\n",
      "train Loss: 0.6609 Acc: 0.8887\n",
      "val Loss: 0.6666 Acc: 0.8720\n",
      "test Loss: 0.6586 Acc: 0.8960\n",
      "Epoch 1193/1499\n",
      "----------\n",
      "train Loss: 0.6599 Acc: 0.8878\n",
      "val Loss: 0.6638 Acc: 0.8880\n",
      "test Loss: 0.6577 Acc: 0.9000\n",
      "Epoch 1194/1499\n",
      "----------\n",
      "train Loss: 0.6571 Acc: 0.8904\n",
      "val Loss: 0.6701 Acc: 0.8760\n",
      "test Loss: 0.6686 Acc: 0.8880\n",
      "Epoch 1195/1499\n",
      "----------\n",
      "train Loss: 0.6601 Acc: 0.8878\n",
      "val Loss: 0.6632 Acc: 0.8800\n",
      "test Loss: 0.6580 Acc: 0.8960\n",
      "Epoch 1196/1499\n",
      "----------\n",
      "train Loss: 0.6589 Acc: 0.8880\n",
      "val Loss: 0.6635 Acc: 0.8880\n",
      "test Loss: 0.6595 Acc: 0.9000\n",
      "Epoch 1197/1499\n",
      "----------\n",
      "train Loss: 0.6593 Acc: 0.8887\n",
      "val Loss: 0.6639 Acc: 0.8800\n",
      "test Loss: 0.6662 Acc: 0.8840\n",
      "Epoch 1198/1499\n",
      "----------\n",
      "train Loss: 0.6609 Acc: 0.8853\n",
      "val Loss: 0.6680 Acc: 0.8760\n",
      "test Loss: 0.6570 Acc: 0.8960\n",
      "Epoch 1199/1499\n",
      "----------\n",
      "train Loss: 0.6608 Acc: 0.8869\n",
      "val Loss: 0.6626 Acc: 0.8760\n",
      "test Loss: 0.6564 Acc: 0.8920\n",
      "Epoch 1200/1499\n",
      "----------\n",
      "train Loss: 0.6595 Acc: 0.8856\n",
      "val Loss: 0.6593 Acc: 0.8880\n",
      "test Loss: 0.6571 Acc: 0.8960\n",
      "Epoch 1201/1499\n",
      "----------\n",
      "train Loss: 0.6600 Acc: 0.8887\n",
      "val Loss: 0.6678 Acc: 0.8800\n",
      "test Loss: 0.6566 Acc: 0.8960\n",
      "Epoch 1202/1499\n",
      "----------\n",
      "train Loss: 0.6609 Acc: 0.8882\n",
      "val Loss: 0.6607 Acc: 0.8680\n",
      "test Loss: 0.6558 Acc: 0.8960\n",
      "Epoch 1203/1499\n",
      "----------\n",
      "train Loss: 0.6611 Acc: 0.8860\n",
      "val Loss: 0.6642 Acc: 0.8880\n",
      "test Loss: 0.6597 Acc: 0.9000\n",
      "Epoch 1204/1499\n",
      "----------\n",
      "train Loss: 0.6603 Acc: 0.8871\n",
      "val Loss: 0.6674 Acc: 0.8760\n",
      "test Loss: 0.6578 Acc: 0.9000\n",
      "Epoch 1205/1499\n",
      "----------\n",
      "train Loss: 0.6613 Acc: 0.8869\n",
      "val Loss: 0.6689 Acc: 0.8640\n",
      "test Loss: 0.6531 Acc: 0.9000\n",
      "Epoch 1206/1499\n",
      "----------\n",
      "train Loss: 0.6603 Acc: 0.8867\n",
      "val Loss: 0.6634 Acc: 0.8760\n",
      "test Loss: 0.6553 Acc: 0.9000\n",
      "Epoch 1207/1499\n",
      "----------\n",
      "train Loss: 0.6611 Acc: 0.8856\n",
      "val Loss: 0.6618 Acc: 0.8800\n",
      "test Loss: 0.6594 Acc: 0.9000\n",
      "Epoch 1208/1499\n",
      "----------\n",
      "train Loss: 0.6587 Acc: 0.8907\n",
      "val Loss: 0.6566 Acc: 0.9000\n",
      "test Loss: 0.6625 Acc: 0.8960\n",
      "Epoch 1209/1499\n",
      "----------\n",
      "train Loss: 0.6611 Acc: 0.8876\n",
      "val Loss: 0.6601 Acc: 0.8800\n",
      "test Loss: 0.6556 Acc: 0.8960\n",
      "Epoch 1210/1499\n",
      "----------\n",
      "train Loss: 0.6581 Acc: 0.8893\n",
      "val Loss: 0.6637 Acc: 0.8800\n",
      "test Loss: 0.6599 Acc: 0.8960\n",
      "Epoch 1211/1499\n",
      "----------\n",
      "train Loss: 0.6581 Acc: 0.8887\n",
      "val Loss: 0.6594 Acc: 0.8800\n",
      "test Loss: 0.6648 Acc: 0.9000\n",
      "Epoch 1212/1499\n",
      "----------\n",
      "train Loss: 0.6580 Acc: 0.8911\n",
      "val Loss: 0.6576 Acc: 0.8880\n",
      "test Loss: 0.6610 Acc: 0.8960\n",
      "Epoch 1213/1499\n",
      "----------\n",
      "train Loss: 0.6573 Acc: 0.8922\n",
      "val Loss: 0.6661 Acc: 0.8800\n",
      "test Loss: 0.6616 Acc: 0.8880\n",
      "Epoch 1214/1499\n",
      "----------\n",
      "train Loss: 0.6588 Acc: 0.8891\n",
      "val Loss: 0.6636 Acc: 0.8800\n",
      "test Loss: 0.6564 Acc: 0.8880\n",
      "Epoch 1215/1499\n",
      "----------\n",
      "train Loss: 0.6601 Acc: 0.8849\n",
      "val Loss: 0.6637 Acc: 0.8880\n",
      "test Loss: 0.6658 Acc: 0.8880\n",
      "Epoch 1216/1499\n",
      "----------\n",
      "train Loss: 0.6588 Acc: 0.8891\n",
      "val Loss: 0.6613 Acc: 0.8800\n",
      "test Loss: 0.6618 Acc: 0.8960\n",
      "Epoch 1217/1499\n",
      "----------\n",
      "train Loss: 0.6597 Acc: 0.8878\n",
      "val Loss: 0.6676 Acc: 0.8760\n",
      "test Loss: 0.6652 Acc: 0.8840\n",
      "Epoch 1218/1499\n",
      "----------\n",
      "train Loss: 0.6583 Acc: 0.8900\n",
      "val Loss: 0.6665 Acc: 0.8720\n",
      "test Loss: 0.6572 Acc: 0.8960\n",
      "Epoch 1219/1499\n",
      "----------\n",
      "train Loss: 0.6612 Acc: 0.8873\n",
      "val Loss: 0.6640 Acc: 0.8760\n",
      "test Loss: 0.6558 Acc: 0.9000\n",
      "Epoch 1220/1499\n",
      "----------\n",
      "train Loss: 0.6591 Acc: 0.8891\n",
      "val Loss: 0.6588 Acc: 0.8840\n",
      "test Loss: 0.6597 Acc: 0.8960\n",
      "Epoch 1221/1499\n",
      "----------\n",
      "train Loss: 0.6584 Acc: 0.8893\n",
      "val Loss: 0.6586 Acc: 0.8960\n",
      "test Loss: 0.6565 Acc: 0.9000\n",
      "Epoch 1222/1499\n",
      "----------\n",
      "train Loss: 0.6577 Acc: 0.8902\n",
      "val Loss: 0.6567 Acc: 0.8800\n",
      "test Loss: 0.6595 Acc: 0.8960\n",
      "Epoch 1223/1499\n",
      "----------\n",
      "train Loss: 0.6588 Acc: 0.8891\n",
      "val Loss: 0.6571 Acc: 0.8840\n",
      "test Loss: 0.6638 Acc: 0.8920\n",
      "Epoch 1224/1499\n",
      "----------\n",
      "train Loss: 0.6587 Acc: 0.8884\n",
      "val Loss: 0.6593 Acc: 0.8880\n",
      "test Loss: 0.6636 Acc: 0.8880\n",
      "Epoch 1225/1499\n",
      "----------\n",
      "train Loss: 0.6598 Acc: 0.8853\n",
      "val Loss: 0.6659 Acc: 0.8800\n",
      "test Loss: 0.6573 Acc: 0.8920\n",
      "Epoch 1226/1499\n",
      "----------\n",
      "train Loss: 0.6592 Acc: 0.8884\n",
      "val Loss: 0.6633 Acc: 0.8800\n",
      "test Loss: 0.6547 Acc: 0.8920\n",
      "Epoch 1227/1499\n",
      "----------\n",
      "train Loss: 0.6584 Acc: 0.8867\n",
      "val Loss: 0.6581 Acc: 0.8920\n",
      "test Loss: 0.6612 Acc: 0.8960\n",
      "Epoch 1228/1499\n",
      "----------\n",
      "train Loss: 0.6580 Acc: 0.8907\n",
      "val Loss: 0.6670 Acc: 0.8720\n",
      "test Loss: 0.6574 Acc: 0.8920\n",
      "Epoch 1229/1499\n",
      "----------\n",
      "train Loss: 0.6571 Acc: 0.8893\n",
      "val Loss: 0.6608 Acc: 0.8800\n",
      "test Loss: 0.6561 Acc: 0.9040\n",
      "Epoch 1230/1499\n",
      "----------\n",
      "train Loss: 0.6600 Acc: 0.8882\n",
      "val Loss: 0.6632 Acc: 0.8960\n",
      "test Loss: 0.6516 Acc: 0.9000\n",
      "Epoch 1231/1499\n",
      "----------\n",
      "train Loss: 0.6579 Acc: 0.8889\n",
      "val Loss: 0.6538 Acc: 0.8920\n",
      "test Loss: 0.6684 Acc: 0.8800\n",
      "Epoch 1232/1499\n",
      "----------\n",
      "train Loss: 0.6575 Acc: 0.8891\n",
      "val Loss: 0.6558 Acc: 0.8960\n",
      "test Loss: 0.6600 Acc: 0.8960\n",
      "Epoch 1233/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6571 Acc: 0.8896\n",
      "val Loss: 0.6744 Acc: 0.8640\n",
      "test Loss: 0.6572 Acc: 0.8920\n",
      "Epoch 1234/1499\n",
      "----------\n",
      "train Loss: 0.6596 Acc: 0.8847\n",
      "val Loss: 0.6671 Acc: 0.8800\n",
      "test Loss: 0.6567 Acc: 0.8960\n",
      "Epoch 1235/1499\n",
      "----------\n",
      "train Loss: 0.6600 Acc: 0.8869\n",
      "val Loss: 0.6615 Acc: 0.8880\n",
      "test Loss: 0.6598 Acc: 0.8880\n",
      "Epoch 1236/1499\n",
      "----------\n",
      "train Loss: 0.6594 Acc: 0.8873\n",
      "val Loss: 0.6599 Acc: 0.8840\n",
      "test Loss: 0.6544 Acc: 0.8960\n",
      "Epoch 1237/1499\n",
      "----------\n",
      "train Loss: 0.6598 Acc: 0.8878\n",
      "val Loss: 0.6565 Acc: 0.8920\n",
      "test Loss: 0.6532 Acc: 0.8920\n",
      "Epoch 1238/1499\n",
      "----------\n",
      "train Loss: 0.6582 Acc: 0.8893\n",
      "val Loss: 0.6705 Acc: 0.8760\n",
      "test Loss: 0.6553 Acc: 0.9040\n",
      "Epoch 1239/1499\n",
      "----------\n",
      "train Loss: 0.6601 Acc: 0.8871\n",
      "val Loss: 0.6674 Acc: 0.8840\n",
      "test Loss: 0.6654 Acc: 0.8880\n",
      "Epoch 1240/1499\n",
      "----------\n",
      "train Loss: 0.6581 Acc: 0.8904\n",
      "val Loss: 0.6633 Acc: 0.8760\n",
      "test Loss: 0.6563 Acc: 0.8920\n",
      "Epoch 1241/1499\n",
      "----------\n",
      "train Loss: 0.6588 Acc: 0.8884\n",
      "val Loss: 0.6604 Acc: 0.8840\n",
      "test Loss: 0.6578 Acc: 0.9000\n",
      "Epoch 1242/1499\n",
      "----------\n",
      "train Loss: 0.6580 Acc: 0.8907\n",
      "val Loss: 0.6552 Acc: 0.8840\n",
      "test Loss: 0.6594 Acc: 0.8920\n",
      "Epoch 1243/1499\n",
      "----------\n",
      "train Loss: 0.6582 Acc: 0.8896\n",
      "val Loss: 0.6545 Acc: 0.8960\n",
      "test Loss: 0.6565 Acc: 0.8960\n",
      "Epoch 1244/1499\n",
      "----------\n",
      "train Loss: 0.6597 Acc: 0.8867\n",
      "val Loss: 0.6655 Acc: 0.8920\n",
      "test Loss: 0.6513 Acc: 0.9040\n",
      "Epoch 1245/1499\n",
      "----------\n",
      "train Loss: 0.6589 Acc: 0.8889\n",
      "val Loss: 0.6561 Acc: 0.8920\n",
      "test Loss: 0.6619 Acc: 0.8880\n",
      "Epoch 1246/1499\n",
      "----------\n",
      "train Loss: 0.6598 Acc: 0.8884\n",
      "val Loss: 0.6637 Acc: 0.8800\n",
      "test Loss: 0.6542 Acc: 0.9000\n",
      "Epoch 1247/1499\n",
      "----------\n",
      "train Loss: 0.6583 Acc: 0.8887\n",
      "val Loss: 0.6646 Acc: 0.8840\n",
      "test Loss: 0.6574 Acc: 0.8880\n",
      "Epoch 1248/1499\n",
      "----------\n",
      "train Loss: 0.6589 Acc: 0.8889\n",
      "val Loss: 0.6598 Acc: 0.8920\n",
      "test Loss: 0.6552 Acc: 0.9000\n",
      "Epoch 1249/1499\n",
      "----------\n",
      "train Loss: 0.6581 Acc: 0.8900\n",
      "val Loss: 0.6597 Acc: 0.8760\n",
      "test Loss: 0.6595 Acc: 0.8960\n",
      "Epoch 1250/1499\n",
      "----------\n",
      "train Loss: 0.6583 Acc: 0.8904\n",
      "val Loss: 0.6636 Acc: 0.8840\n",
      "test Loss: 0.6637 Acc: 0.8960\n",
      "Epoch 1251/1499\n",
      "----------\n",
      "train Loss: 0.6594 Acc: 0.8909\n",
      "val Loss: 0.6693 Acc: 0.8680\n",
      "test Loss: 0.6525 Acc: 0.9000\n",
      "Epoch 1252/1499\n",
      "----------\n",
      "train Loss: 0.6615 Acc: 0.8871\n",
      "val Loss: 0.6584 Acc: 0.8920\n",
      "test Loss: 0.6638 Acc: 0.8920\n",
      "Epoch 1253/1499\n",
      "----------\n",
      "train Loss: 0.6570 Acc: 0.8893\n",
      "val Loss: 0.6545 Acc: 0.8920\n",
      "test Loss: 0.6552 Acc: 0.9000\n",
      "Epoch 1254/1499\n",
      "----------\n",
      "train Loss: 0.6561 Acc: 0.8918\n",
      "val Loss: 0.6683 Acc: 0.8800\n",
      "test Loss: 0.6613 Acc: 0.8920\n",
      "Epoch 1255/1499\n",
      "----------\n",
      "train Loss: 0.6572 Acc: 0.8909\n",
      "val Loss: 0.6560 Acc: 0.8960\n",
      "test Loss: 0.6589 Acc: 0.8880\n",
      "Epoch 1256/1499\n",
      "----------\n",
      "train Loss: 0.6575 Acc: 0.8891\n",
      "val Loss: 0.6620 Acc: 0.8880\n",
      "test Loss: 0.6647 Acc: 0.8880\n",
      "Epoch 1257/1499\n",
      "----------\n",
      "train Loss: 0.6576 Acc: 0.8902\n",
      "val Loss: 0.6653 Acc: 0.8800\n",
      "test Loss: 0.6665 Acc: 0.8840\n",
      "Epoch 1258/1499\n",
      "----------\n",
      "train Loss: 0.6569 Acc: 0.8922\n",
      "val Loss: 0.6603 Acc: 0.8800\n",
      "test Loss: 0.6612 Acc: 0.8960\n",
      "Epoch 1259/1499\n",
      "----------\n",
      "train Loss: 0.6574 Acc: 0.8896\n",
      "val Loss: 0.6622 Acc: 0.8920\n",
      "test Loss: 0.6530 Acc: 0.8960\n",
      "Epoch 1260/1499\n",
      "----------\n",
      "train Loss: 0.6588 Acc: 0.8889\n",
      "val Loss: 0.6611 Acc: 0.8800\n",
      "test Loss: 0.6536 Acc: 0.8920\n",
      "Epoch 1261/1499\n",
      "----------\n",
      "train Loss: 0.6572 Acc: 0.8907\n",
      "val Loss: 0.6635 Acc: 0.8760\n",
      "test Loss: 0.6631 Acc: 0.8840\n",
      "Epoch 1262/1499\n",
      "----------\n",
      "train Loss: 0.6563 Acc: 0.8927\n",
      "val Loss: 0.6721 Acc: 0.8680\n",
      "test Loss: 0.6630 Acc: 0.8800\n",
      "Epoch 1263/1499\n",
      "----------\n",
      "train Loss: 0.6580 Acc: 0.8900\n",
      "val Loss: 0.6505 Acc: 0.9040\n",
      "test Loss: 0.6630 Acc: 0.8920\n",
      "Epoch 1264/1499\n",
      "----------\n",
      "train Loss: 0.6575 Acc: 0.8902\n",
      "val Loss: 0.6655 Acc: 0.8800\n",
      "test Loss: 0.6586 Acc: 0.8920\n",
      "Epoch 1265/1499\n",
      "----------\n",
      "train Loss: 0.6590 Acc: 0.8891\n",
      "val Loss: 0.6687 Acc: 0.8760\n",
      "test Loss: 0.6510 Acc: 0.9040\n",
      "Epoch 1266/1499\n",
      "----------\n",
      "train Loss: 0.6580 Acc: 0.8858\n",
      "val Loss: 0.6595 Acc: 0.8880\n",
      "test Loss: 0.6698 Acc: 0.8880\n",
      "Epoch 1267/1499\n",
      "----------\n",
      "train Loss: 0.6568 Acc: 0.8911\n",
      "val Loss: 0.6535 Acc: 0.8960\n",
      "test Loss: 0.6597 Acc: 0.8920\n",
      "Epoch 1268/1499\n",
      "----------\n",
      "train Loss: 0.6581 Acc: 0.8924\n",
      "val Loss: 0.6662 Acc: 0.8800\n",
      "test Loss: 0.6651 Acc: 0.8800\n",
      "Epoch 1269/1499\n",
      "----------\n",
      "train Loss: 0.6595 Acc: 0.8887\n",
      "val Loss: 0.6647 Acc: 0.8840\n",
      "test Loss: 0.6573 Acc: 0.9000\n",
      "Epoch 1270/1499\n",
      "----------\n",
      "train Loss: 0.6582 Acc: 0.8896\n",
      "val Loss: 0.6618 Acc: 0.8880\n",
      "test Loss: 0.6595 Acc: 0.8960\n",
      "Epoch 1271/1499\n",
      "----------\n",
      "train Loss: 0.6600 Acc: 0.8882\n",
      "val Loss: 0.6648 Acc: 0.8760\n",
      "test Loss: 0.6546 Acc: 0.8960\n",
      "Epoch 1272/1499\n",
      "----------\n",
      "train Loss: 0.6555 Acc: 0.8931\n",
      "val Loss: 0.6596 Acc: 0.8920\n",
      "test Loss: 0.6631 Acc: 0.8920\n",
      "Epoch 1273/1499\n",
      "----------\n",
      "train Loss: 0.6571 Acc: 0.8929\n",
      "val Loss: 0.6583 Acc: 0.8880\n",
      "test Loss: 0.6577 Acc: 0.8920\n",
      "Epoch 1274/1499\n",
      "----------\n",
      "train Loss: 0.6578 Acc: 0.8907\n",
      "val Loss: 0.6555 Acc: 0.8920\n",
      "test Loss: 0.6622 Acc: 0.9040\n",
      "Epoch 1275/1499\n",
      "----------\n",
      "train Loss: 0.6568 Acc: 0.8942\n",
      "val Loss: 0.6581 Acc: 0.8880\n",
      "test Loss: 0.6527 Acc: 0.9000\n",
      "Epoch 1276/1499\n",
      "----------\n",
      "train Loss: 0.6608 Acc: 0.8878\n",
      "val Loss: 0.6595 Acc: 0.8920\n",
      "test Loss: 0.6508 Acc: 0.9040\n",
      "Epoch 1277/1499\n",
      "----------\n",
      "train Loss: 0.6574 Acc: 0.8911\n",
      "val Loss: 0.6642 Acc: 0.8800\n",
      "test Loss: 0.6627 Acc: 0.8880\n",
      "Epoch 1278/1499\n",
      "----------\n",
      "train Loss: 0.6566 Acc: 0.8927\n",
      "val Loss: 0.6648 Acc: 0.8840\n",
      "test Loss: 0.6532 Acc: 0.9000\n",
      "Epoch 1279/1499\n",
      "----------\n",
      "train Loss: 0.6587 Acc: 0.8896\n",
      "val Loss: 0.6678 Acc: 0.8720\n",
      "test Loss: 0.6593 Acc: 0.8920\n",
      "Epoch 1280/1499\n",
      "----------\n",
      "train Loss: 0.6577 Acc: 0.8893\n",
      "val Loss: 0.6689 Acc: 0.8920\n",
      "test Loss: 0.6555 Acc: 0.8960\n",
      "Epoch 1281/1499\n",
      "----------\n",
      "train Loss: 0.6565 Acc: 0.8909\n",
      "val Loss: 0.6648 Acc: 0.8840\n",
      "test Loss: 0.6562 Acc: 0.9000\n",
      "Epoch 1282/1499\n",
      "----------\n",
      "train Loss: 0.6572 Acc: 0.8918\n",
      "val Loss: 0.6602 Acc: 0.8880\n",
      "test Loss: 0.6607 Acc: 0.8920\n",
      "Epoch 1283/1499\n",
      "----------\n",
      "train Loss: 0.6556 Acc: 0.8936\n",
      "val Loss: 0.6618 Acc: 0.8840\n",
      "test Loss: 0.6656 Acc: 0.8880\n",
      "Epoch 1284/1499\n",
      "----------\n",
      "train Loss: 0.6569 Acc: 0.8933\n",
      "val Loss: 0.6646 Acc: 0.8720\n",
      "test Loss: 0.6671 Acc: 0.8920\n",
      "Epoch 1285/1499\n",
      "----------\n",
      "train Loss: 0.6582 Acc: 0.8902\n",
      "val Loss: 0.6604 Acc: 0.8840\n",
      "test Loss: 0.6577 Acc: 0.9000\n",
      "Epoch 1286/1499\n",
      "----------\n",
      "train Loss: 0.6600 Acc: 0.8876\n",
      "val Loss: 0.6632 Acc: 0.8800\n",
      "test Loss: 0.6603 Acc: 0.8880\n",
      "Epoch 1287/1499\n",
      "----------\n",
      "train Loss: 0.6582 Acc: 0.8916\n",
      "val Loss: 0.6554 Acc: 0.8840\n",
      "test Loss: 0.6610 Acc: 0.8880\n",
      "Epoch 1288/1499\n",
      "----------\n",
      "train Loss: 0.6569 Acc: 0.8911\n",
      "val Loss: 0.6612 Acc: 0.8800\n",
      "test Loss: 0.6612 Acc: 0.8880\n",
      "Epoch 1289/1499\n",
      "----------\n",
      "train Loss: 0.6573 Acc: 0.8907\n",
      "val Loss: 0.6626 Acc: 0.8840\n",
      "test Loss: 0.6548 Acc: 0.9000\n",
      "Epoch 1290/1499\n",
      "----------\n",
      "train Loss: 0.6580 Acc: 0.8898\n",
      "val Loss: 0.6614 Acc: 0.8800\n",
      "test Loss: 0.6580 Acc: 0.8960\n",
      "Epoch 1291/1499\n",
      "----------\n",
      "train Loss: 0.6558 Acc: 0.8909\n",
      "val Loss: 0.6620 Acc: 0.8800\n",
      "test Loss: 0.6563 Acc: 0.8960\n",
      "Epoch 1292/1499\n",
      "----------\n",
      "train Loss: 0.6584 Acc: 0.8911\n",
      "val Loss: 0.6518 Acc: 0.8920\n",
      "test Loss: 0.6571 Acc: 0.8960\n",
      "Epoch 1293/1499\n",
      "----------\n",
      "train Loss: 0.6584 Acc: 0.8896\n",
      "val Loss: 0.6648 Acc: 0.8800\n",
      "test Loss: 0.6593 Acc: 0.8920\n",
      "Epoch 1294/1499\n",
      "----------\n",
      "train Loss: 0.6583 Acc: 0.8891\n",
      "val Loss: 0.6597 Acc: 0.8960\n",
      "test Loss: 0.6503 Acc: 0.9040\n",
      "Epoch 1295/1499\n",
      "----------\n",
      "train Loss: 0.6574 Acc: 0.8916\n",
      "val Loss: 0.6686 Acc: 0.8720\n",
      "test Loss: 0.6616 Acc: 0.9000\n",
      "Epoch 1296/1499\n",
      "----------\n",
      "train Loss: 0.6567 Acc: 0.8916\n",
      "val Loss: 0.6639 Acc: 0.8880\n",
      "test Loss: 0.6508 Acc: 0.9040\n",
      "Epoch 1297/1499\n",
      "----------\n",
      "train Loss: 0.6565 Acc: 0.8913\n",
      "val Loss: 0.6599 Acc: 0.8840\n",
      "test Loss: 0.6656 Acc: 0.8880\n",
      "Epoch 1298/1499\n",
      "----------\n",
      "train Loss: 0.6555 Acc: 0.8922\n",
      "val Loss: 0.6658 Acc: 0.8800\n",
      "test Loss: 0.6595 Acc: 0.8960\n",
      "Epoch 1299/1499\n",
      "----------\n",
      "train Loss: 0.6572 Acc: 0.8893\n",
      "val Loss: 0.6578 Acc: 0.8800\n",
      "test Loss: 0.6560 Acc: 0.8960\n",
      "Epoch 1300/1499\n",
      "----------\n",
      "train Loss: 0.6582 Acc: 0.8913\n",
      "val Loss: 0.6578 Acc: 0.8960\n",
      "test Loss: 0.6623 Acc: 0.8920\n",
      "Epoch 1301/1499\n",
      "----------\n",
      "train Loss: 0.6564 Acc: 0.8913\n",
      "val Loss: 0.6603 Acc: 0.8920\n",
      "test Loss: 0.6583 Acc: 0.9000\n",
      "Epoch 1302/1499\n",
      "----------\n",
      "train Loss: 0.6572 Acc: 0.8920\n",
      "val Loss: 0.6511 Acc: 0.9000\n",
      "test Loss: 0.6548 Acc: 0.8960\n",
      "Epoch 1303/1499\n",
      "----------\n",
      "train Loss: 0.6562 Acc: 0.8891\n",
      "val Loss: 0.6629 Acc: 0.8840\n",
      "test Loss: 0.6558 Acc: 0.8960\n",
      "Epoch 1304/1499\n",
      "----------\n",
      "train Loss: 0.6558 Acc: 0.8909\n",
      "val Loss: 0.6564 Acc: 0.8920\n",
      "test Loss: 0.6587 Acc: 0.8920\n",
      "Epoch 1305/1499\n",
      "----------\n",
      "train Loss: 0.6577 Acc: 0.8893\n",
      "val Loss: 0.6641 Acc: 0.8800\n",
      "test Loss: 0.6626 Acc: 0.8880\n",
      "Epoch 1306/1499\n",
      "----------\n",
      "train Loss: 0.6572 Acc: 0.8922\n",
      "val Loss: 0.6572 Acc: 0.8880\n",
      "test Loss: 0.6537 Acc: 0.8960\n",
      "Epoch 1307/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6568 Acc: 0.8922\n",
      "val Loss: 0.6572 Acc: 0.8920\n",
      "test Loss: 0.6606 Acc: 0.8960\n",
      "Epoch 1308/1499\n",
      "----------\n",
      "train Loss: 0.6586 Acc: 0.8876\n",
      "val Loss: 0.6599 Acc: 0.8880\n",
      "test Loss: 0.6585 Acc: 0.8920\n",
      "Epoch 1309/1499\n",
      "----------\n",
      "train Loss: 0.6576 Acc: 0.8904\n",
      "val Loss: 0.6639 Acc: 0.8840\n",
      "test Loss: 0.6587 Acc: 0.8880\n",
      "Epoch 1310/1499\n",
      "----------\n",
      "train Loss: 0.6563 Acc: 0.8898\n",
      "val Loss: 0.6608 Acc: 0.8880\n",
      "test Loss: 0.6548 Acc: 0.9000\n",
      "Epoch 1311/1499\n",
      "----------\n",
      "train Loss: 0.6563 Acc: 0.8938\n",
      "val Loss: 0.6641 Acc: 0.8760\n",
      "test Loss: 0.6592 Acc: 0.8960\n",
      "Epoch 1312/1499\n",
      "----------\n",
      "train Loss: 0.6555 Acc: 0.8916\n",
      "val Loss: 0.6604 Acc: 0.8840\n",
      "test Loss: 0.6580 Acc: 0.8960\n",
      "Epoch 1313/1499\n",
      "----------\n",
      "train Loss: 0.6565 Acc: 0.8913\n",
      "val Loss: 0.6620 Acc: 0.8800\n",
      "test Loss: 0.6554 Acc: 0.9000\n",
      "Epoch 1314/1499\n",
      "----------\n",
      "train Loss: 0.6548 Acc: 0.8938\n",
      "val Loss: 0.6607 Acc: 0.8880\n",
      "test Loss: 0.6555 Acc: 0.8920\n",
      "Epoch 1315/1499\n",
      "----------\n",
      "train Loss: 0.6551 Acc: 0.8929\n",
      "val Loss: 0.6587 Acc: 0.8920\n",
      "test Loss: 0.6576 Acc: 0.8920\n",
      "Epoch 1316/1499\n",
      "----------\n",
      "train Loss: 0.6553 Acc: 0.8911\n",
      "val Loss: 0.6604 Acc: 0.8880\n",
      "test Loss: 0.6628 Acc: 0.8920\n",
      "Epoch 1317/1499\n",
      "----------\n",
      "train Loss: 0.6583 Acc: 0.8896\n",
      "val Loss: 0.6773 Acc: 0.8720\n",
      "test Loss: 0.6629 Acc: 0.8880\n",
      "Epoch 1318/1499\n",
      "----------\n",
      "train Loss: 0.6570 Acc: 0.8902\n",
      "val Loss: 0.6560 Acc: 0.8960\n",
      "test Loss: 0.6602 Acc: 0.8960\n",
      "Epoch 1319/1499\n",
      "----------\n",
      "train Loss: 0.6573 Acc: 0.8918\n",
      "val Loss: 0.6616 Acc: 0.8760\n",
      "test Loss: 0.6650 Acc: 0.8920\n",
      "Epoch 1320/1499\n",
      "----------\n",
      "train Loss: 0.6552 Acc: 0.8922\n",
      "val Loss: 0.6570 Acc: 0.8920\n",
      "test Loss: 0.6546 Acc: 0.8920\n",
      "Epoch 1321/1499\n",
      "----------\n",
      "train Loss: 0.6562 Acc: 0.8907\n",
      "val Loss: 0.6621 Acc: 0.8840\n",
      "test Loss: 0.6589 Acc: 0.8920\n",
      "Epoch 1322/1499\n",
      "----------\n",
      "train Loss: 0.6555 Acc: 0.8918\n",
      "val Loss: 0.6590 Acc: 0.8880\n",
      "test Loss: 0.6595 Acc: 0.8920\n",
      "Epoch 1323/1499\n",
      "----------\n",
      "train Loss: 0.6570 Acc: 0.8924\n",
      "val Loss: 0.6614 Acc: 0.8840\n",
      "test Loss: 0.6560 Acc: 0.9040\n",
      "Epoch 1324/1499\n",
      "----------\n",
      "train Loss: 0.6584 Acc: 0.8882\n",
      "val Loss: 0.6583 Acc: 0.8880\n",
      "test Loss: 0.6589 Acc: 0.8920\n",
      "Epoch 1325/1499\n",
      "----------\n",
      "train Loss: 0.6566 Acc: 0.8889\n",
      "val Loss: 0.6688 Acc: 0.8640\n",
      "test Loss: 0.6515 Acc: 0.9000\n",
      "Epoch 1326/1499\n",
      "----------\n",
      "train Loss: 0.6570 Acc: 0.8902\n",
      "val Loss: 0.6550 Acc: 0.9040\n",
      "test Loss: 0.6578 Acc: 0.8960\n",
      "Epoch 1327/1499\n",
      "----------\n",
      "train Loss: 0.6558 Acc: 0.8920\n",
      "val Loss: 0.6606 Acc: 0.8840\n",
      "test Loss: 0.6584 Acc: 0.8960\n",
      "Epoch 1328/1499\n",
      "----------\n",
      "train Loss: 0.6550 Acc: 0.8924\n",
      "val Loss: 0.6655 Acc: 0.8760\n",
      "test Loss: 0.6554 Acc: 0.8960\n",
      "Epoch 1329/1499\n",
      "----------\n",
      "train Loss: 0.6553 Acc: 0.8893\n",
      "val Loss: 0.6602 Acc: 0.8880\n",
      "test Loss: 0.6627 Acc: 0.8920\n",
      "Epoch 1330/1499\n",
      "----------\n",
      "train Loss: 0.6574 Acc: 0.8891\n",
      "val Loss: 0.6649 Acc: 0.8840\n",
      "test Loss: 0.6539 Acc: 0.9000\n",
      "Epoch 1331/1499\n",
      "----------\n",
      "train Loss: 0.6552 Acc: 0.8913\n",
      "val Loss: 0.6612 Acc: 0.8800\n",
      "test Loss: 0.6495 Acc: 0.9040\n",
      "Epoch 1332/1499\n",
      "----------\n",
      "train Loss: 0.6550 Acc: 0.8918\n",
      "val Loss: 0.6560 Acc: 0.8960\n",
      "test Loss: 0.6545 Acc: 0.9000\n",
      "Epoch 1333/1499\n",
      "----------\n",
      "train Loss: 0.6568 Acc: 0.8900\n",
      "val Loss: 0.6580 Acc: 0.8760\n",
      "test Loss: 0.6513 Acc: 0.9000\n",
      "Epoch 1334/1499\n",
      "----------\n",
      "train Loss: 0.6553 Acc: 0.8929\n",
      "val Loss: 0.6567 Acc: 0.8920\n",
      "test Loss: 0.6520 Acc: 0.9000\n",
      "Epoch 1335/1499\n",
      "----------\n",
      "train Loss: 0.6549 Acc: 0.8929\n",
      "val Loss: 0.6597 Acc: 0.8800\n",
      "test Loss: 0.6546 Acc: 0.8960\n",
      "Epoch 1336/1499\n",
      "----------\n",
      "train Loss: 0.6556 Acc: 0.8909\n",
      "val Loss: 0.6565 Acc: 0.8920\n",
      "test Loss: 0.6576 Acc: 0.9000\n",
      "Epoch 1337/1499\n",
      "----------\n",
      "train Loss: 0.6549 Acc: 0.8944\n",
      "val Loss: 0.6583 Acc: 0.8880\n",
      "test Loss: 0.6494 Acc: 0.9000\n",
      "Epoch 1338/1499\n",
      "----------\n",
      "train Loss: 0.6559 Acc: 0.8896\n",
      "val Loss: 0.6668 Acc: 0.8720\n",
      "test Loss: 0.6613 Acc: 0.8960\n",
      "Epoch 1339/1499\n",
      "----------\n",
      "train Loss: 0.6557 Acc: 0.8902\n",
      "val Loss: 0.6587 Acc: 0.8800\n",
      "test Loss: 0.6597 Acc: 0.8920\n",
      "Epoch 1340/1499\n",
      "----------\n",
      "train Loss: 0.6552 Acc: 0.8924\n",
      "val Loss: 0.6625 Acc: 0.8760\n",
      "test Loss: 0.6633 Acc: 0.8920\n",
      "Epoch 1341/1499\n",
      "----------\n",
      "train Loss: 0.6571 Acc: 0.8907\n",
      "val Loss: 0.6597 Acc: 0.8880\n",
      "test Loss: 0.6586 Acc: 0.8920\n",
      "Epoch 1342/1499\n",
      "----------\n",
      "train Loss: 0.6556 Acc: 0.8924\n",
      "val Loss: 0.6536 Acc: 0.8920\n",
      "test Loss: 0.6599 Acc: 0.8920\n",
      "Epoch 1343/1499\n",
      "----------\n",
      "train Loss: 0.6548 Acc: 0.8936\n",
      "val Loss: 0.6601 Acc: 0.8880\n",
      "test Loss: 0.6554 Acc: 0.8920\n",
      "Epoch 1344/1499\n",
      "----------\n",
      "train Loss: 0.6551 Acc: 0.8918\n",
      "val Loss: 0.6617 Acc: 0.8800\n",
      "test Loss: 0.6535 Acc: 0.9080\n",
      "Epoch 1345/1499\n",
      "----------\n",
      "train Loss: 0.6574 Acc: 0.8927\n",
      "val Loss: 0.6633 Acc: 0.8800\n",
      "test Loss: 0.6556 Acc: 0.9000\n",
      "Epoch 1346/1499\n",
      "----------\n",
      "train Loss: 0.6553 Acc: 0.8940\n",
      "val Loss: 0.6569 Acc: 0.8960\n",
      "test Loss: 0.6595 Acc: 0.8880\n",
      "Epoch 1347/1499\n",
      "----------\n",
      "train Loss: 0.6557 Acc: 0.8938\n",
      "val Loss: 0.6606 Acc: 0.8760\n",
      "test Loss: 0.6579 Acc: 0.8920\n",
      "Epoch 1348/1499\n",
      "----------\n",
      "train Loss: 0.6543 Acc: 0.8924\n",
      "val Loss: 0.6577 Acc: 0.9040\n",
      "test Loss: 0.6510 Acc: 0.9000\n",
      "Epoch 1349/1499\n",
      "----------\n",
      "train Loss: 0.6547 Acc: 0.8944\n",
      "val Loss: 0.6541 Acc: 0.8840\n",
      "test Loss: 0.6613 Acc: 0.8880\n",
      "Epoch 1350/1499\n",
      "----------\n",
      "train Loss: 0.6553 Acc: 0.8931\n",
      "val Loss: 0.6589 Acc: 0.8920\n",
      "test Loss: 0.6502 Acc: 0.9080\n",
      "Epoch 1351/1499\n",
      "----------\n",
      "train Loss: 0.6544 Acc: 0.8951\n",
      "val Loss: 0.6553 Acc: 0.8920\n",
      "test Loss: 0.6665 Acc: 0.8840\n",
      "Epoch 1352/1499\n",
      "----------\n",
      "train Loss: 0.6587 Acc: 0.8882\n",
      "val Loss: 0.6544 Acc: 0.8920\n",
      "test Loss: 0.6611 Acc: 0.8880\n",
      "Epoch 1353/1499\n",
      "----------\n",
      "train Loss: 0.6539 Acc: 0.8951\n",
      "val Loss: 0.6580 Acc: 0.8840\n",
      "test Loss: 0.6637 Acc: 0.8880\n",
      "Epoch 1354/1499\n",
      "----------\n",
      "train Loss: 0.6556 Acc: 0.8920\n",
      "val Loss: 0.6585 Acc: 0.8880\n",
      "test Loss: 0.6546 Acc: 0.8960\n",
      "Epoch 1355/1499\n",
      "----------\n",
      "train Loss: 0.6555 Acc: 0.8918\n",
      "val Loss: 0.6578 Acc: 0.8920\n",
      "test Loss: 0.6534 Acc: 0.8960\n",
      "Epoch 1356/1499\n",
      "----------\n",
      "train Loss: 0.6535 Acc: 0.8947\n",
      "val Loss: 0.6652 Acc: 0.8840\n",
      "test Loss: 0.6529 Acc: 0.8960\n",
      "Epoch 1357/1499\n",
      "----------\n",
      "train Loss: 0.6559 Acc: 0.8909\n",
      "val Loss: 0.6684 Acc: 0.8760\n",
      "test Loss: 0.6494 Acc: 0.9040\n",
      "Epoch 1358/1499\n",
      "----------\n",
      "train Loss: 0.6549 Acc: 0.8940\n",
      "val Loss: 0.6620 Acc: 0.8880\n",
      "test Loss: 0.6670 Acc: 0.8800\n",
      "Epoch 1359/1499\n",
      "----------\n",
      "train Loss: 0.6565 Acc: 0.8931\n",
      "val Loss: 0.6610 Acc: 0.8880\n",
      "test Loss: 0.6520 Acc: 0.9000\n",
      "Epoch 1360/1499\n",
      "----------\n",
      "train Loss: 0.6549 Acc: 0.8953\n",
      "val Loss: 0.6703 Acc: 0.8800\n",
      "test Loss: 0.6490 Acc: 0.9000\n",
      "Epoch 1361/1499\n",
      "----------\n",
      "train Loss: 0.6541 Acc: 0.8953\n",
      "val Loss: 0.6618 Acc: 0.8840\n",
      "test Loss: 0.6588 Acc: 0.8920\n",
      "Epoch 1362/1499\n",
      "----------\n",
      "train Loss: 0.6555 Acc: 0.8913\n",
      "val Loss: 0.6564 Acc: 0.8880\n",
      "test Loss: 0.6674 Acc: 0.8800\n",
      "Epoch 1363/1499\n",
      "----------\n",
      "train Loss: 0.6550 Acc: 0.8916\n",
      "val Loss: 0.6605 Acc: 0.8840\n",
      "test Loss: 0.6574 Acc: 0.8920\n",
      "Epoch 1364/1499\n",
      "----------\n",
      "train Loss: 0.6555 Acc: 0.8904\n",
      "val Loss: 0.6633 Acc: 0.8800\n",
      "test Loss: 0.6526 Acc: 0.8960\n",
      "Epoch 1365/1499\n",
      "----------\n",
      "train Loss: 0.6559 Acc: 0.8927\n",
      "val Loss: 0.6554 Acc: 0.8880\n",
      "test Loss: 0.6550 Acc: 0.9040\n",
      "Epoch 1366/1499\n",
      "----------\n",
      "train Loss: 0.6542 Acc: 0.8947\n",
      "val Loss: 0.6582 Acc: 0.8840\n",
      "test Loss: 0.6566 Acc: 0.8960\n",
      "Epoch 1367/1499\n",
      "----------\n",
      "train Loss: 0.6562 Acc: 0.8924\n",
      "val Loss: 0.6675 Acc: 0.8760\n",
      "test Loss: 0.6533 Acc: 0.8960\n",
      "Epoch 1368/1499\n",
      "----------\n",
      "train Loss: 0.6566 Acc: 0.8920\n",
      "val Loss: 0.6609 Acc: 0.8840\n",
      "test Loss: 0.6533 Acc: 0.8960\n",
      "Epoch 1369/1499\n",
      "----------\n",
      "train Loss: 0.6548 Acc: 0.8947\n",
      "val Loss: 0.6592 Acc: 0.8840\n",
      "test Loss: 0.6617 Acc: 0.8880\n",
      "Epoch 1370/1499\n",
      "----------\n",
      "train Loss: 0.6559 Acc: 0.8929\n",
      "val Loss: 0.6639 Acc: 0.8840\n",
      "test Loss: 0.6588 Acc: 0.8960\n",
      "Epoch 1371/1499\n",
      "----------\n",
      "train Loss: 0.6568 Acc: 0.8936\n",
      "val Loss: 0.6603 Acc: 0.8760\n",
      "test Loss: 0.6531 Acc: 0.9000\n",
      "Epoch 1372/1499\n",
      "----------\n",
      "train Loss: 0.6573 Acc: 0.8873\n",
      "val Loss: 0.6611 Acc: 0.8840\n",
      "test Loss: 0.6558 Acc: 0.8960\n",
      "Epoch 1373/1499\n",
      "----------\n",
      "train Loss: 0.6556 Acc: 0.8916\n",
      "val Loss: 0.6639 Acc: 0.8840\n",
      "test Loss: 0.6536 Acc: 0.9000\n",
      "Epoch 1374/1499\n",
      "----------\n",
      "train Loss: 0.6558 Acc: 0.8931\n",
      "val Loss: 0.6582 Acc: 0.8920\n",
      "test Loss: 0.6619 Acc: 0.8880\n",
      "Epoch 1375/1499\n",
      "----------\n",
      "train Loss: 0.6550 Acc: 0.8907\n",
      "val Loss: 0.6700 Acc: 0.8760\n",
      "test Loss: 0.6519 Acc: 0.9000\n",
      "Epoch 1376/1499\n",
      "----------\n",
      "train Loss: 0.6541 Acc: 0.8942\n",
      "val Loss: 0.6589 Acc: 0.8840\n",
      "test Loss: 0.6643 Acc: 0.9000\n",
      "Epoch 1377/1499\n",
      "----------\n",
      "train Loss: 0.6574 Acc: 0.8927\n",
      "val Loss: 0.6604 Acc: 0.8920\n",
      "test Loss: 0.6568 Acc: 0.9000\n",
      "Epoch 1378/1499\n",
      "----------\n",
      "train Loss: 0.6539 Acc: 0.8960\n",
      "val Loss: 0.6570 Acc: 0.8920\n",
      "test Loss: 0.6595 Acc: 0.8880\n",
      "Epoch 1379/1499\n",
      "----------\n",
      "train Loss: 0.6542 Acc: 0.8936\n",
      "val Loss: 0.6629 Acc: 0.8760\n",
      "test Loss: 0.6541 Acc: 0.9040\n",
      "Epoch 1380/1499\n",
      "----------\n",
      "train Loss: 0.6557 Acc: 0.8931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.6614 Acc: 0.8840\n",
      "test Loss: 0.6638 Acc: 0.8840\n",
      "Epoch 1381/1499\n",
      "----------\n",
      "train Loss: 0.6556 Acc: 0.8916\n",
      "val Loss: 0.6621 Acc: 0.8840\n",
      "test Loss: 0.6480 Acc: 0.9080\n",
      "Epoch 1382/1499\n",
      "----------\n",
      "train Loss: 0.6567 Acc: 0.8896\n",
      "val Loss: 0.6617 Acc: 0.8840\n",
      "test Loss: 0.6572 Acc: 0.8960\n",
      "Epoch 1383/1499\n",
      "----------\n",
      "train Loss: 0.6544 Acc: 0.8918\n",
      "val Loss: 0.6649 Acc: 0.8760\n",
      "test Loss: 0.6586 Acc: 0.8960\n",
      "Epoch 1384/1499\n",
      "----------\n",
      "train Loss: 0.6556 Acc: 0.8922\n",
      "val Loss: 0.6550 Acc: 0.8920\n",
      "test Loss: 0.6629 Acc: 0.8920\n",
      "Epoch 1385/1499\n",
      "----------\n",
      "train Loss: 0.6536 Acc: 0.8933\n",
      "val Loss: 0.6552 Acc: 0.8920\n",
      "test Loss: 0.6527 Acc: 0.8960\n",
      "Epoch 1386/1499\n",
      "----------\n",
      "train Loss: 0.6551 Acc: 0.8938\n",
      "val Loss: 0.6647 Acc: 0.8800\n",
      "test Loss: 0.6645 Acc: 0.8840\n",
      "Epoch 1387/1499\n",
      "----------\n",
      "train Loss: 0.6545 Acc: 0.8913\n",
      "val Loss: 0.6621 Acc: 0.8720\n",
      "test Loss: 0.6613 Acc: 0.8920\n",
      "Epoch 1388/1499\n",
      "----------\n",
      "train Loss: 0.6557 Acc: 0.8913\n",
      "val Loss: 0.6616 Acc: 0.8920\n",
      "test Loss: 0.6620 Acc: 0.8960\n",
      "Epoch 1389/1499\n",
      "----------\n",
      "train Loss: 0.6555 Acc: 0.8931\n",
      "val Loss: 0.6556 Acc: 0.8880\n",
      "test Loss: 0.6568 Acc: 0.9040\n",
      "Epoch 1390/1499\n",
      "----------\n",
      "train Loss: 0.6545 Acc: 0.8933\n",
      "val Loss: 0.6618 Acc: 0.8760\n",
      "test Loss: 0.6538 Acc: 0.9040\n",
      "Epoch 1391/1499\n",
      "----------\n",
      "train Loss: 0.6557 Acc: 0.8916\n",
      "val Loss: 0.6545 Acc: 0.8920\n",
      "test Loss: 0.6538 Acc: 0.9000\n",
      "Epoch 1392/1499\n",
      "----------\n",
      "train Loss: 0.6556 Acc: 0.8920\n",
      "val Loss: 0.6625 Acc: 0.8800\n",
      "test Loss: 0.6585 Acc: 0.8960\n",
      "Epoch 1393/1499\n",
      "----------\n",
      "train Loss: 0.6577 Acc: 0.8916\n",
      "val Loss: 0.6667 Acc: 0.8840\n",
      "test Loss: 0.6564 Acc: 0.8920\n",
      "Epoch 1394/1499\n",
      "----------\n",
      "train Loss: 0.6537 Acc: 0.8940\n",
      "val Loss: 0.6594 Acc: 0.8760\n",
      "test Loss: 0.6645 Acc: 0.8840\n",
      "Epoch 1395/1499\n",
      "----------\n",
      "train Loss: 0.6557 Acc: 0.8900\n",
      "val Loss: 0.6548 Acc: 0.8840\n",
      "test Loss: 0.6641 Acc: 0.8840\n",
      "Epoch 1396/1499\n",
      "----------\n",
      "train Loss: 0.6554 Acc: 0.8938\n",
      "val Loss: 0.6565 Acc: 0.8880\n",
      "test Loss: 0.6612 Acc: 0.8960\n",
      "Epoch 1397/1499\n",
      "----------\n",
      "train Loss: 0.6551 Acc: 0.8922\n",
      "val Loss: 0.6724 Acc: 0.8600\n",
      "test Loss: 0.6510 Acc: 0.8960\n",
      "Epoch 1398/1499\n",
      "----------\n",
      "train Loss: 0.6554 Acc: 0.8931\n",
      "val Loss: 0.6584 Acc: 0.8920\n",
      "test Loss: 0.6607 Acc: 0.8920\n",
      "Epoch 1399/1499\n",
      "----------\n",
      "train Loss: 0.6570 Acc: 0.8900\n",
      "val Loss: 0.6625 Acc: 0.8840\n",
      "test Loss: 0.6575 Acc: 0.8920\n",
      "Epoch 1400/1499\n",
      "----------\n",
      "train Loss: 0.6551 Acc: 0.8922\n",
      "val Loss: 0.6526 Acc: 0.8920\n",
      "test Loss: 0.6577 Acc: 0.8920\n",
      "Epoch 1401/1499\n",
      "----------\n",
      "train Loss: 0.6532 Acc: 0.8947\n",
      "val Loss: 0.6661 Acc: 0.8840\n",
      "test Loss: 0.6503 Acc: 0.9040\n",
      "Epoch 1402/1499\n",
      "----------\n",
      "train Loss: 0.6539 Acc: 0.8931\n",
      "val Loss: 0.6528 Acc: 0.8960\n",
      "test Loss: 0.6644 Acc: 0.8840\n",
      "Epoch 1403/1499\n",
      "----------\n",
      "train Loss: 0.6550 Acc: 0.8927\n",
      "val Loss: 0.6586 Acc: 0.8920\n",
      "test Loss: 0.6648 Acc: 0.8840\n",
      "Epoch 1404/1499\n",
      "----------\n",
      "train Loss: 0.6545 Acc: 0.8936\n",
      "val Loss: 0.6626 Acc: 0.8880\n",
      "test Loss: 0.6527 Acc: 0.9040\n",
      "Epoch 1405/1499\n",
      "----------\n",
      "train Loss: 0.6537 Acc: 0.8924\n",
      "val Loss: 0.6646 Acc: 0.8880\n",
      "test Loss: 0.6537 Acc: 0.8960\n",
      "Epoch 1406/1499\n",
      "----------\n",
      "train Loss: 0.6521 Acc: 0.8949\n",
      "val Loss: 0.6602 Acc: 0.8840\n",
      "test Loss: 0.6618 Acc: 0.8880\n",
      "Epoch 1407/1499\n",
      "----------\n",
      "train Loss: 0.6542 Acc: 0.8924\n",
      "val Loss: 0.6547 Acc: 0.8960\n",
      "test Loss: 0.6547 Acc: 0.8960\n",
      "Epoch 1408/1499\n",
      "----------\n",
      "train Loss: 0.6541 Acc: 0.8942\n",
      "val Loss: 0.6596 Acc: 0.8800\n",
      "test Loss: 0.6542 Acc: 0.8960\n",
      "Epoch 1409/1499\n",
      "----------\n",
      "train Loss: 0.6551 Acc: 0.8936\n",
      "val Loss: 0.6559 Acc: 0.8920\n",
      "test Loss: 0.6571 Acc: 0.8920\n",
      "Epoch 1410/1499\n",
      "----------\n",
      "train Loss: 0.6553 Acc: 0.8942\n",
      "val Loss: 0.6598 Acc: 0.8800\n",
      "test Loss: 0.6531 Acc: 0.9040\n",
      "Epoch 1411/1499\n",
      "----------\n",
      "train Loss: 0.6568 Acc: 0.8931\n",
      "val Loss: 0.6541 Acc: 0.8960\n",
      "test Loss: 0.6564 Acc: 0.8960\n",
      "Epoch 1412/1499\n",
      "----------\n",
      "train Loss: 0.6532 Acc: 0.8953\n",
      "val Loss: 0.6630 Acc: 0.8880\n",
      "test Loss: 0.6658 Acc: 0.8880\n",
      "Epoch 1413/1499\n",
      "----------\n",
      "train Loss: 0.6556 Acc: 0.8920\n",
      "val Loss: 0.6647 Acc: 0.8840\n",
      "test Loss: 0.6572 Acc: 0.8920\n",
      "Epoch 1414/1499\n",
      "----------\n",
      "train Loss: 0.6549 Acc: 0.8956\n",
      "val Loss: 0.6655 Acc: 0.8840\n",
      "test Loss: 0.6619 Acc: 0.8880\n",
      "Epoch 1415/1499\n",
      "----------\n",
      "train Loss: 0.6538 Acc: 0.8953\n",
      "val Loss: 0.6636 Acc: 0.8840\n",
      "test Loss: 0.6532 Acc: 0.9080\n",
      "Epoch 1416/1499\n",
      "----------\n",
      "train Loss: 0.6552 Acc: 0.8949\n",
      "val Loss: 0.6616 Acc: 0.8880\n",
      "test Loss: 0.6590 Acc: 0.8920\n",
      "Epoch 1417/1499\n",
      "----------\n",
      "train Loss: 0.6555 Acc: 0.8893\n",
      "val Loss: 0.6650 Acc: 0.8840\n",
      "test Loss: 0.6550 Acc: 0.8960\n",
      "Epoch 1418/1499\n",
      "----------\n",
      "train Loss: 0.6533 Acc: 0.8927\n",
      "val Loss: 0.6607 Acc: 0.8840\n",
      "test Loss: 0.6569 Acc: 0.8920\n",
      "Epoch 1419/1499\n",
      "----------\n",
      "train Loss: 0.6555 Acc: 0.8953\n",
      "val Loss: 0.6536 Acc: 0.8920\n",
      "test Loss: 0.6517 Acc: 0.9000\n",
      "Epoch 1420/1499\n",
      "----------\n",
      "train Loss: 0.6541 Acc: 0.8951\n",
      "val Loss: 0.6592 Acc: 0.8840\n",
      "test Loss: 0.6611 Acc: 0.8920\n",
      "Epoch 1421/1499\n",
      "----------\n",
      "train Loss: 0.6538 Acc: 0.8936\n",
      "val Loss: 0.6621 Acc: 0.8920\n",
      "test Loss: 0.6574 Acc: 0.8960\n",
      "Epoch 1422/1499\n",
      "----------\n",
      "train Loss: 0.6554 Acc: 0.8938\n",
      "val Loss: 0.6674 Acc: 0.8760\n",
      "test Loss: 0.6632 Acc: 0.8840\n",
      "Epoch 1423/1499\n",
      "----------\n",
      "train Loss: 0.6545 Acc: 0.8924\n",
      "val Loss: 0.6597 Acc: 0.8880\n",
      "test Loss: 0.6581 Acc: 0.8960\n",
      "Epoch 1424/1499\n",
      "----------\n",
      "train Loss: 0.6538 Acc: 0.8949\n",
      "val Loss: 0.6663 Acc: 0.8840\n",
      "test Loss: 0.6539 Acc: 0.8960\n",
      "Epoch 1425/1499\n",
      "----------\n",
      "train Loss: 0.6530 Acc: 0.8936\n",
      "val Loss: 0.6482 Acc: 0.9000\n",
      "test Loss: 0.6564 Acc: 0.8960\n",
      "Epoch 1426/1499\n",
      "----------\n",
      "train Loss: 0.6542 Acc: 0.8936\n",
      "val Loss: 0.6608 Acc: 0.8880\n",
      "test Loss: 0.6660 Acc: 0.8920\n",
      "Epoch 1427/1499\n",
      "----------\n",
      "train Loss: 0.6549 Acc: 0.8947\n",
      "val Loss: 0.6621 Acc: 0.8760\n",
      "test Loss: 0.6512 Acc: 0.9040\n",
      "Epoch 1428/1499\n",
      "----------\n",
      "train Loss: 0.6532 Acc: 0.8962\n",
      "val Loss: 0.6590 Acc: 0.8920\n",
      "test Loss: 0.6598 Acc: 0.8880\n",
      "Epoch 1429/1499\n",
      "----------\n",
      "train Loss: 0.6540 Acc: 0.8942\n",
      "val Loss: 0.6535 Acc: 0.8960\n",
      "test Loss: 0.6609 Acc: 0.8880\n",
      "Epoch 1430/1499\n",
      "----------\n",
      "train Loss: 0.6556 Acc: 0.8916\n",
      "val Loss: 0.6531 Acc: 0.8920\n",
      "test Loss: 0.6532 Acc: 0.9000\n",
      "Epoch 1431/1499\n",
      "----------\n",
      "train Loss: 0.6563 Acc: 0.8911\n",
      "val Loss: 0.6691 Acc: 0.8760\n",
      "test Loss: 0.6525 Acc: 0.9000\n",
      "Epoch 1432/1499\n",
      "----------\n",
      "train Loss: 0.6543 Acc: 0.8960\n",
      "val Loss: 0.6617 Acc: 0.8800\n",
      "test Loss: 0.6588 Acc: 0.8920\n",
      "Epoch 1433/1499\n",
      "----------\n",
      "train Loss: 0.6555 Acc: 0.8918\n",
      "val Loss: 0.6506 Acc: 0.8960\n",
      "test Loss: 0.6557 Acc: 0.9000\n",
      "Epoch 1434/1499\n",
      "----------\n",
      "train Loss: 0.6548 Acc: 0.8933\n",
      "val Loss: 0.6561 Acc: 0.8840\n",
      "test Loss: 0.6581 Acc: 0.9000\n",
      "Epoch 1435/1499\n",
      "----------\n",
      "train Loss: 0.6534 Acc: 0.8962\n",
      "val Loss: 0.6657 Acc: 0.8800\n",
      "test Loss: 0.6601 Acc: 0.8920\n",
      "Epoch 1436/1499\n",
      "----------\n",
      "train Loss: 0.6547 Acc: 0.8940\n",
      "val Loss: 0.6549 Acc: 0.8960\n",
      "test Loss: 0.6542 Acc: 0.9000\n",
      "Epoch 1437/1499\n",
      "----------\n",
      "train Loss: 0.6531 Acc: 0.8951\n",
      "val Loss: 0.6653 Acc: 0.8840\n",
      "test Loss: 0.6564 Acc: 0.8960\n",
      "Epoch 1438/1499\n",
      "----------\n",
      "train Loss: 0.6530 Acc: 0.8960\n",
      "val Loss: 0.6629 Acc: 0.8760\n",
      "test Loss: 0.6615 Acc: 0.8800\n",
      "Epoch 1439/1499\n",
      "----------\n",
      "train Loss: 0.6537 Acc: 0.8958\n",
      "val Loss: 0.6546 Acc: 0.8880\n",
      "test Loss: 0.6613 Acc: 0.8880\n",
      "Epoch 1440/1499\n",
      "----------\n",
      "train Loss: 0.6544 Acc: 0.8938\n",
      "val Loss: 0.6535 Acc: 0.8920\n",
      "test Loss: 0.6533 Acc: 0.8920\n",
      "Epoch 1441/1499\n",
      "----------\n",
      "train Loss: 0.6535 Acc: 0.8967\n",
      "val Loss: 0.6643 Acc: 0.8680\n",
      "test Loss: 0.6522 Acc: 0.9000\n",
      "Epoch 1442/1499\n",
      "----------\n",
      "train Loss: 0.6535 Acc: 0.8960\n",
      "val Loss: 0.6548 Acc: 0.8920\n",
      "test Loss: 0.6520 Acc: 0.9000\n",
      "Epoch 1443/1499\n",
      "----------\n",
      "train Loss: 0.6556 Acc: 0.8916\n",
      "val Loss: 0.6528 Acc: 0.8960\n",
      "test Loss: 0.6623 Acc: 0.8920\n",
      "Epoch 1444/1499\n",
      "----------\n",
      "train Loss: 0.6541 Acc: 0.8931\n",
      "val Loss: 0.6558 Acc: 0.9000\n",
      "test Loss: 0.6582 Acc: 0.8920\n",
      "Epoch 1445/1499\n",
      "----------\n",
      "train Loss: 0.6560 Acc: 0.8922\n",
      "val Loss: 0.6521 Acc: 0.8920\n",
      "test Loss: 0.6550 Acc: 0.8960\n",
      "Epoch 1446/1499\n",
      "----------\n",
      "train Loss: 0.6553 Acc: 0.8916\n",
      "val Loss: 0.6550 Acc: 0.8920\n",
      "test Loss: 0.6628 Acc: 0.8920\n",
      "Epoch 1447/1499\n",
      "----------\n",
      "train Loss: 0.6538 Acc: 0.8964\n",
      "val Loss: 0.6556 Acc: 0.8920\n",
      "test Loss: 0.6545 Acc: 0.8960\n",
      "Epoch 1448/1499\n",
      "----------\n",
      "train Loss: 0.6532 Acc: 0.8953\n",
      "val Loss: 0.6490 Acc: 0.8920\n",
      "test Loss: 0.6603 Acc: 0.8920\n",
      "Epoch 1449/1499\n",
      "----------\n",
      "train Loss: 0.6538 Acc: 0.8940\n",
      "val Loss: 0.6551 Acc: 0.8960\n",
      "test Loss: 0.6529 Acc: 0.9000\n",
      "Epoch 1450/1499\n",
      "----------\n",
      "train Loss: 0.6529 Acc: 0.8947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.6602 Acc: 0.8840\n",
      "test Loss: 0.6578 Acc: 0.8920\n",
      "Epoch 1451/1499\n",
      "----------\n",
      "train Loss: 0.6526 Acc: 0.8933\n",
      "val Loss: 0.6598 Acc: 0.8880\n",
      "test Loss: 0.6552 Acc: 0.8960\n",
      "Epoch 1452/1499\n",
      "----------\n",
      "train Loss: 0.6534 Acc: 0.8929\n",
      "val Loss: 0.6673 Acc: 0.8840\n",
      "test Loss: 0.6554 Acc: 0.9080\n",
      "Epoch 1453/1499\n",
      "----------\n",
      "train Loss: 0.6546 Acc: 0.8911\n",
      "val Loss: 0.6573 Acc: 0.8920\n",
      "test Loss: 0.6593 Acc: 0.8920\n",
      "Epoch 1454/1499\n",
      "----------\n",
      "train Loss: 0.6546 Acc: 0.8924\n",
      "val Loss: 0.6599 Acc: 0.8760\n",
      "test Loss: 0.6600 Acc: 0.8920\n",
      "Epoch 1455/1499\n",
      "----------\n",
      "train Loss: 0.6536 Acc: 0.8927\n",
      "val Loss: 0.6556 Acc: 0.8880\n",
      "test Loss: 0.6598 Acc: 0.8920\n",
      "Epoch 1456/1499\n",
      "----------\n",
      "train Loss: 0.6527 Acc: 0.8942\n",
      "val Loss: 0.6530 Acc: 0.8960\n",
      "test Loss: 0.6670 Acc: 0.8880\n",
      "Epoch 1457/1499\n",
      "----------\n",
      "train Loss: 0.6526 Acc: 0.8936\n",
      "val Loss: 0.6535 Acc: 0.8960\n",
      "test Loss: 0.6562 Acc: 0.8920\n",
      "Epoch 1458/1499\n",
      "----------\n",
      "train Loss: 0.6538 Acc: 0.8949\n",
      "val Loss: 0.6575 Acc: 0.8840\n",
      "test Loss: 0.6551 Acc: 0.8920\n",
      "Epoch 1459/1499\n",
      "----------\n",
      "train Loss: 0.6545 Acc: 0.8927\n",
      "val Loss: 0.6557 Acc: 0.8920\n",
      "test Loss: 0.6609 Acc: 0.8920\n",
      "Epoch 1460/1499\n",
      "----------\n",
      "train Loss: 0.6539 Acc: 0.8942\n",
      "val Loss: 0.6627 Acc: 0.8720\n",
      "test Loss: 0.6588 Acc: 0.8960\n",
      "Epoch 1461/1499\n",
      "----------\n",
      "train Loss: 0.6543 Acc: 0.8958\n",
      "val Loss: 0.6514 Acc: 0.8880\n",
      "test Loss: 0.6616 Acc: 0.8920\n",
      "Epoch 1462/1499\n",
      "----------\n",
      "train Loss: 0.6525 Acc: 0.8944\n",
      "val Loss: 0.6529 Acc: 0.8920\n",
      "test Loss: 0.6540 Acc: 0.8960\n",
      "Epoch 1463/1499\n",
      "----------\n",
      "train Loss: 0.6546 Acc: 0.8929\n",
      "val Loss: 0.6520 Acc: 0.8920\n",
      "test Loss: 0.6523 Acc: 0.9000\n",
      "Epoch 1464/1499\n",
      "----------\n",
      "train Loss: 0.6545 Acc: 0.8920\n",
      "val Loss: 0.6599 Acc: 0.8840\n",
      "test Loss: 0.6542 Acc: 0.9000\n",
      "Epoch 1465/1499\n",
      "----------\n",
      "train Loss: 0.6550 Acc: 0.8922\n",
      "val Loss: 0.6569 Acc: 0.8880\n",
      "test Loss: 0.6565 Acc: 0.9000\n",
      "Epoch 1466/1499\n",
      "----------\n",
      "train Loss: 0.6534 Acc: 0.8927\n",
      "val Loss: 0.6529 Acc: 0.8960\n",
      "test Loss: 0.6553 Acc: 0.8920\n",
      "Epoch 1467/1499\n",
      "----------\n",
      "train Loss: 0.6549 Acc: 0.8918\n",
      "val Loss: 0.6619 Acc: 0.8840\n",
      "test Loss: 0.6585 Acc: 0.8920\n",
      "Epoch 1468/1499\n",
      "----------\n",
      "train Loss: 0.6534 Acc: 0.8940\n",
      "val Loss: 0.6541 Acc: 0.8960\n",
      "test Loss: 0.6527 Acc: 0.8960\n",
      "Epoch 1469/1499\n",
      "----------\n",
      "train Loss: 0.6530 Acc: 0.8942\n",
      "val Loss: 0.6610 Acc: 0.8960\n",
      "test Loss: 0.6541 Acc: 0.9000\n",
      "Epoch 1470/1499\n",
      "----------\n",
      "train Loss: 0.6538 Acc: 0.8940\n",
      "val Loss: 0.6569 Acc: 0.8920\n",
      "test Loss: 0.6495 Acc: 0.9040\n",
      "Epoch 1471/1499\n",
      "----------\n",
      "train Loss: 0.6548 Acc: 0.8929\n",
      "val Loss: 0.6563 Acc: 0.9000\n",
      "test Loss: 0.6641 Acc: 0.8880\n",
      "Epoch 1472/1499\n",
      "----------\n",
      "train Loss: 0.6549 Acc: 0.8940\n",
      "val Loss: 0.6574 Acc: 0.8840\n",
      "test Loss: 0.6602 Acc: 0.8880\n",
      "Epoch 1473/1499\n",
      "----------\n",
      "train Loss: 0.6525 Acc: 0.8940\n",
      "val Loss: 0.6596 Acc: 0.8800\n",
      "test Loss: 0.6579 Acc: 0.8920\n",
      "Epoch 1474/1499\n",
      "----------\n",
      "train Loss: 0.6531 Acc: 0.8978\n",
      "val Loss: 0.6501 Acc: 0.8920\n",
      "test Loss: 0.6527 Acc: 0.8960\n",
      "Epoch 1475/1499\n",
      "----------\n",
      "train Loss: 0.6531 Acc: 0.8933\n",
      "val Loss: 0.6567 Acc: 0.8840\n",
      "test Loss: 0.6586 Acc: 0.9000\n",
      "Epoch 1476/1499\n",
      "----------\n",
      "train Loss: 0.6555 Acc: 0.8922\n",
      "val Loss: 0.6540 Acc: 0.8920\n",
      "test Loss: 0.6538 Acc: 0.9000\n",
      "Epoch 1477/1499\n",
      "----------\n",
      "train Loss: 0.6549 Acc: 0.8922\n",
      "val Loss: 0.6554 Acc: 0.8800\n",
      "test Loss: 0.6562 Acc: 0.8960\n",
      "Epoch 1478/1499\n",
      "----------\n",
      "train Loss: 0.6545 Acc: 0.8933\n",
      "val Loss: 0.6584 Acc: 0.8800\n",
      "test Loss: 0.6512 Acc: 0.9040\n",
      "Epoch 1479/1499\n",
      "----------\n",
      "train Loss: 0.6527 Acc: 0.8940\n",
      "val Loss: 0.6579 Acc: 0.8800\n",
      "test Loss: 0.6576 Acc: 0.8920\n",
      "Epoch 1480/1499\n",
      "----------\n",
      "train Loss: 0.6533 Acc: 0.8936\n",
      "val Loss: 0.6527 Acc: 0.8920\n",
      "test Loss: 0.6517 Acc: 0.9040\n",
      "Epoch 1481/1499\n",
      "----------\n",
      "train Loss: 0.6532 Acc: 0.8951\n",
      "val Loss: 0.6542 Acc: 0.9000\n",
      "test Loss: 0.6484 Acc: 0.9000\n",
      "Epoch 1482/1499\n",
      "----------\n",
      "train Loss: 0.6523 Acc: 0.8927\n",
      "val Loss: 0.6579 Acc: 0.8880\n",
      "test Loss: 0.6561 Acc: 0.8880\n",
      "Epoch 1483/1499\n",
      "----------\n",
      "train Loss: 0.6540 Acc: 0.8927\n",
      "val Loss: 0.6634 Acc: 0.8760\n",
      "test Loss: 0.6565 Acc: 0.8960\n",
      "Epoch 1484/1499\n",
      "----------\n",
      "train Loss: 0.6532 Acc: 0.8924\n",
      "val Loss: 0.6584 Acc: 0.8880\n",
      "test Loss: 0.6529 Acc: 0.9000\n",
      "Epoch 1485/1499\n",
      "----------\n",
      "train Loss: 0.6545 Acc: 0.8911\n",
      "val Loss: 0.6573 Acc: 0.9000\n",
      "test Loss: 0.6526 Acc: 0.9000\n",
      "Epoch 1486/1499\n",
      "----------\n",
      "train Loss: 0.6525 Acc: 0.8976\n",
      "val Loss: 0.6529 Acc: 0.8920\n",
      "test Loss: 0.6484 Acc: 0.9000\n",
      "Epoch 1487/1499\n",
      "----------\n",
      "train Loss: 0.6544 Acc: 0.8916\n",
      "val Loss: 0.6584 Acc: 0.8840\n",
      "test Loss: 0.6614 Acc: 0.8880\n",
      "Epoch 1488/1499\n",
      "----------\n",
      "train Loss: 0.6521 Acc: 0.8969\n",
      "val Loss: 0.6583 Acc: 0.8760\n",
      "test Loss: 0.6594 Acc: 0.8920\n",
      "Epoch 1489/1499\n",
      "----------\n",
      "train Loss: 0.6533 Acc: 0.8938\n",
      "val Loss: 0.6550 Acc: 0.8960\n",
      "test Loss: 0.6620 Acc: 0.8960\n",
      "Epoch 1490/1499\n",
      "----------\n",
      "train Loss: 0.6525 Acc: 0.8962\n",
      "val Loss: 0.6569 Acc: 0.8920\n",
      "test Loss: 0.6566 Acc: 0.8960\n",
      "Epoch 1491/1499\n",
      "----------\n",
      "train Loss: 0.6530 Acc: 0.8933\n",
      "val Loss: 0.6578 Acc: 0.8840\n",
      "test Loss: 0.6569 Acc: 0.8960\n",
      "Epoch 1492/1499\n",
      "----------\n",
      "train Loss: 0.6514 Acc: 0.8924\n",
      "val Loss: 0.6646 Acc: 0.8800\n",
      "test Loss: 0.6572 Acc: 0.9000\n",
      "Epoch 1493/1499\n",
      "----------\n",
      "train Loss: 0.6547 Acc: 0.8896\n",
      "val Loss: 0.6558 Acc: 0.8960\n",
      "test Loss: 0.6566 Acc: 0.8960\n",
      "Epoch 1494/1499\n",
      "----------\n",
      "train Loss: 0.6537 Acc: 0.8911\n",
      "val Loss: 0.6558 Acc: 0.8880\n",
      "test Loss: 0.6578 Acc: 0.9000\n",
      "Epoch 1495/1499\n",
      "----------\n",
      "train Loss: 0.6544 Acc: 0.8940\n",
      "val Loss: 0.6642 Acc: 0.8800\n",
      "test Loss: 0.6445 Acc: 0.9040\n",
      "Epoch 1496/1499\n",
      "----------\n",
      "train Loss: 0.6527 Acc: 0.8962\n",
      "val Loss: 0.6539 Acc: 0.9000\n",
      "test Loss: 0.6542 Acc: 0.8920\n",
      "Epoch 1497/1499\n",
      "----------\n",
      "train Loss: 0.6522 Acc: 0.8942\n",
      "val Loss: 0.6597 Acc: 0.8920\n",
      "test Loss: 0.6558 Acc: 0.8920\n",
      "Epoch 1498/1499\n",
      "----------\n",
      "train Loss: 0.6524 Acc: 0.8956\n",
      "val Loss: 0.6593 Acc: 0.8960\n",
      "test Loss: 0.6511 Acc: 0.9000\n",
      "Epoch 1499/1499\n",
      "----------\n",
      "train Loss: 0.6542 Acc: 0.8922\n",
      "val Loss: 0.6565 Acc: 0.9000\n",
      "test Loss: 0.6591 Acc: 0.8880\n",
      "Training complete in 1m 23s\n",
      "Best test Acc: 0.908000\n",
      "Epoch 0/1499\n",
      "----------\n",
      "train Loss: 1.0872 Acc: 0.3287\n",
      "val Loss: 1.0930 Acc: 0.3120\n",
      "test Loss: 1.0837 Acc: 0.3440\n",
      "Epoch 1/1499\n",
      "----------\n",
      "train Loss: 1.0855 Acc: 0.3407\n",
      "val Loss: 1.0927 Acc: 0.3200\n",
      "test Loss: 1.0821 Acc: 0.3400\n",
      "Epoch 2/1499\n",
      "----------\n",
      "train Loss: 1.0855 Acc: 0.3329\n",
      "val Loss: 1.0931 Acc: 0.3360\n",
      "test Loss: 1.0823 Acc: 0.3360\n",
      "Epoch 3/1499\n",
      "----------\n",
      "train Loss: 1.0848 Acc: 0.3344\n",
      "val Loss: 1.0889 Acc: 0.3200\n",
      "test Loss: 1.0823 Acc: 0.3360\n",
      "Epoch 4/1499\n",
      "----------\n",
      "train Loss: 1.0834 Acc: 0.3424\n",
      "val Loss: 1.0929 Acc: 0.3160\n",
      "test Loss: 1.0808 Acc: 0.3240\n",
      "Epoch 5/1499\n",
      "----------\n",
      "train Loss: 1.0831 Acc: 0.3398\n",
      "val Loss: 1.0921 Acc: 0.3280\n",
      "test Loss: 1.0797 Acc: 0.3280\n",
      "Epoch 6/1499\n",
      "----------\n",
      "train Loss: 1.0813 Acc: 0.3411\n",
      "val Loss: 1.0909 Acc: 0.3320\n",
      "test Loss: 1.0792 Acc: 0.3360\n",
      "Epoch 7/1499\n",
      "----------\n",
      "train Loss: 1.0805 Acc: 0.3431\n",
      "val Loss: 1.0890 Acc: 0.3320\n",
      "test Loss: 1.0783 Acc: 0.3440\n",
      "Epoch 8/1499\n",
      "----------\n",
      "train Loss: 1.0796 Acc: 0.3438\n",
      "val Loss: 1.0885 Acc: 0.3400\n",
      "test Loss: 1.0765 Acc: 0.3480\n",
      "Epoch 9/1499\n",
      "----------\n",
      "train Loss: 1.0785 Acc: 0.3447\n",
      "val Loss: 1.0907 Acc: 0.3240\n",
      "test Loss: 1.0770 Acc: 0.3600\n",
      "Epoch 10/1499\n",
      "----------\n",
      "train Loss: 1.0775 Acc: 0.3511\n",
      "val Loss: 1.0866 Acc: 0.3280\n",
      "test Loss: 1.0747 Acc: 0.3520\n",
      "Epoch 11/1499\n",
      "----------\n",
      "train Loss: 1.0773 Acc: 0.3524\n",
      "val Loss: 1.0849 Acc: 0.3360\n",
      "test Loss: 1.0725 Acc: 0.3640\n",
      "Epoch 12/1499\n",
      "----------\n",
      "train Loss: 1.0764 Acc: 0.3527\n",
      "val Loss: 1.0857 Acc: 0.3080\n",
      "test Loss: 1.0720 Acc: 0.3520\n",
      "Epoch 13/1499\n",
      "----------\n",
      "train Loss: 1.0752 Acc: 0.3564\n",
      "val Loss: 1.0857 Acc: 0.3160\n",
      "test Loss: 1.0752 Acc: 0.3480\n",
      "Epoch 14/1499\n",
      "----------\n",
      "train Loss: 1.0745 Acc: 0.3560\n",
      "val Loss: 1.0835 Acc: 0.3360\n",
      "test Loss: 1.0694 Acc: 0.3760\n",
      "Epoch 15/1499\n",
      "----------\n",
      "train Loss: 1.0741 Acc: 0.3533\n",
      "val Loss: 1.0829 Acc: 0.3240\n",
      "test Loss: 1.0697 Acc: 0.3680\n",
      "Epoch 16/1499\n",
      "----------\n",
      "train Loss: 1.0737 Acc: 0.3533\n",
      "val Loss: 1.0818 Acc: 0.3520\n",
      "test Loss: 1.0695 Acc: 0.3760\n",
      "Epoch 17/1499\n",
      "----------\n",
      "train Loss: 1.0720 Acc: 0.3647\n",
      "val Loss: 1.0797 Acc: 0.3160\n",
      "test Loss: 1.0663 Acc: 0.3720\n",
      "Epoch 18/1499\n",
      "----------\n",
      "train Loss: 1.0712 Acc: 0.3613\n",
      "val Loss: 1.0765 Acc: 0.3200\n",
      "test Loss: 1.0677 Acc: 0.3720\n",
      "Epoch 19/1499\n",
      "----------\n",
      "train Loss: 1.0703 Acc: 0.3613\n",
      "val Loss: 1.0808 Acc: 0.3320\n",
      "test Loss: 1.0681 Acc: 0.3320\n",
      "Epoch 20/1499\n",
      "----------\n",
      "train Loss: 1.0689 Acc: 0.3678\n",
      "val Loss: 1.0735 Acc: 0.3440\n",
      "test Loss: 1.0667 Acc: 0.3400\n",
      "Epoch 21/1499\n",
      "----------\n",
      "train Loss: 1.0686 Acc: 0.3658\n",
      "val Loss: 1.0764 Acc: 0.3240\n",
      "test Loss: 1.0639 Acc: 0.3800\n",
      "Epoch 22/1499\n",
      "----------\n",
      "train Loss: 1.0678 Acc: 0.3673\n",
      "val Loss: 1.0764 Acc: 0.3280\n",
      "test Loss: 1.0671 Acc: 0.3640\n",
      "Epoch 23/1499\n",
      "----------\n",
      "train Loss: 1.0672 Acc: 0.3709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0732 Acc: 0.3400\n",
      "test Loss: 1.0661 Acc: 0.3680\n",
      "Epoch 24/1499\n",
      "----------\n",
      "train Loss: 1.0659 Acc: 0.3693\n",
      "val Loss: 1.0713 Acc: 0.3400\n",
      "test Loss: 1.0613 Acc: 0.3720\n",
      "Epoch 25/1499\n",
      "----------\n",
      "train Loss: 1.0654 Acc: 0.3640\n",
      "val Loss: 1.0738 Acc: 0.3280\n",
      "test Loss: 1.0629 Acc: 0.3800\n",
      "Epoch 26/1499\n",
      "----------\n",
      "train Loss: 1.0653 Acc: 0.3678\n",
      "val Loss: 1.0723 Acc: 0.3360\n",
      "test Loss: 1.0576 Acc: 0.3880\n",
      "Epoch 27/1499\n",
      "----------\n",
      "train Loss: 1.0637 Acc: 0.3751\n",
      "val Loss: 1.0744 Acc: 0.3440\n",
      "test Loss: 1.0628 Acc: 0.3560\n",
      "Epoch 28/1499\n",
      "----------\n",
      "train Loss: 1.0630 Acc: 0.3787\n",
      "val Loss: 1.0696 Acc: 0.3520\n",
      "test Loss: 1.0570 Acc: 0.3920\n",
      "Epoch 29/1499\n",
      "----------\n",
      "train Loss: 1.0624 Acc: 0.3751\n",
      "val Loss: 1.0682 Acc: 0.3480\n",
      "test Loss: 1.0590 Acc: 0.3720\n",
      "Epoch 30/1499\n",
      "----------\n",
      "train Loss: 1.0607 Acc: 0.3787\n",
      "val Loss: 1.0670 Acc: 0.3600\n",
      "test Loss: 1.0616 Acc: 0.3760\n",
      "Epoch 31/1499\n",
      "----------\n",
      "train Loss: 1.0607 Acc: 0.3831\n",
      "val Loss: 1.0689 Acc: 0.3680\n",
      "test Loss: 1.0554 Acc: 0.3920\n",
      "Epoch 32/1499\n",
      "----------\n",
      "train Loss: 1.0598 Acc: 0.3847\n",
      "val Loss: 1.0657 Acc: 0.3400\n",
      "test Loss: 1.0547 Acc: 0.3960\n",
      "Epoch 33/1499\n",
      "----------\n",
      "train Loss: 1.0581 Acc: 0.3820\n",
      "val Loss: 1.0641 Acc: 0.3600\n",
      "test Loss: 1.0562 Acc: 0.4000\n",
      "Epoch 34/1499\n",
      "----------\n",
      "train Loss: 1.0584 Acc: 0.3840\n",
      "val Loss: 1.0676 Acc: 0.3360\n",
      "test Loss: 1.0553 Acc: 0.4000\n",
      "Epoch 35/1499\n",
      "----------\n",
      "train Loss: 1.0569 Acc: 0.3884\n",
      "val Loss: 1.0667 Acc: 0.3440\n",
      "test Loss: 1.0556 Acc: 0.4040\n",
      "Epoch 36/1499\n",
      "----------\n",
      "train Loss: 1.0567 Acc: 0.3909\n",
      "val Loss: 1.0644 Acc: 0.3600\n",
      "test Loss: 1.0525 Acc: 0.3840\n",
      "Epoch 37/1499\n",
      "----------\n",
      "train Loss: 1.0549 Acc: 0.3993\n",
      "val Loss: 1.0685 Acc: 0.3520\n",
      "test Loss: 1.0534 Acc: 0.4000\n",
      "Epoch 38/1499\n",
      "----------\n",
      "train Loss: 1.0542 Acc: 0.3967\n",
      "val Loss: 1.0644 Acc: 0.3560\n",
      "test Loss: 1.0530 Acc: 0.3920\n",
      "Epoch 39/1499\n",
      "----------\n",
      "train Loss: 1.0543 Acc: 0.3944\n",
      "val Loss: 1.0600 Acc: 0.3680\n",
      "test Loss: 1.0521 Acc: 0.3760\n",
      "Epoch 40/1499\n",
      "----------\n",
      "train Loss: 1.0531 Acc: 0.3933\n",
      "val Loss: 1.0666 Acc: 0.3440\n",
      "test Loss: 1.0501 Acc: 0.3840\n",
      "Epoch 41/1499\n",
      "----------\n",
      "train Loss: 1.0527 Acc: 0.3996\n",
      "val Loss: 1.0623 Acc: 0.3600\n",
      "test Loss: 1.0476 Acc: 0.4080\n",
      "Epoch 42/1499\n",
      "----------\n",
      "train Loss: 1.0512 Acc: 0.3991\n",
      "val Loss: 1.0628 Acc: 0.3720\n",
      "test Loss: 1.0470 Acc: 0.4240\n",
      "Epoch 43/1499\n",
      "----------\n",
      "train Loss: 1.0499 Acc: 0.4053\n",
      "val Loss: 1.0596 Acc: 0.3600\n",
      "test Loss: 1.0459 Acc: 0.4240\n",
      "Epoch 44/1499\n",
      "----------\n",
      "train Loss: 1.0511 Acc: 0.3969\n",
      "val Loss: 1.0607 Acc: 0.3680\n",
      "test Loss: 1.0465 Acc: 0.4120\n",
      "Epoch 45/1499\n",
      "----------\n",
      "train Loss: 1.0493 Acc: 0.4078\n",
      "val Loss: 1.0592 Acc: 0.3720\n",
      "test Loss: 1.0443 Acc: 0.4320\n",
      "Epoch 46/1499\n",
      "----------\n",
      "train Loss: 1.0488 Acc: 0.4049\n",
      "val Loss: 1.0605 Acc: 0.3720\n",
      "test Loss: 1.0460 Acc: 0.4120\n",
      "Epoch 47/1499\n",
      "----------\n",
      "train Loss: 1.0482 Acc: 0.4040\n",
      "val Loss: 1.0545 Acc: 0.3800\n",
      "test Loss: 1.0432 Acc: 0.4320\n",
      "Epoch 48/1499\n",
      "----------\n",
      "train Loss: 1.0480 Acc: 0.4102\n",
      "val Loss: 1.0572 Acc: 0.4040\n",
      "test Loss: 1.0494 Acc: 0.4080\n",
      "Epoch 49/1499\n",
      "----------\n",
      "train Loss: 1.0468 Acc: 0.4142\n",
      "val Loss: 1.0531 Acc: 0.3920\n",
      "test Loss: 1.0431 Acc: 0.4360\n",
      "Epoch 50/1499\n",
      "----------\n",
      "train Loss: 1.0457 Acc: 0.4302\n",
      "val Loss: 1.0539 Acc: 0.4040\n",
      "test Loss: 1.0447 Acc: 0.4480\n",
      "Epoch 51/1499\n",
      "----------\n",
      "train Loss: 1.0446 Acc: 0.4298\n",
      "val Loss: 1.0537 Acc: 0.4040\n",
      "test Loss: 1.0412 Acc: 0.4640\n",
      "Epoch 52/1499\n",
      "----------\n",
      "train Loss: 1.0441 Acc: 0.4349\n",
      "val Loss: 1.0533 Acc: 0.4120\n",
      "test Loss: 1.0426 Acc: 0.4440\n",
      "Epoch 53/1499\n",
      "----------\n",
      "train Loss: 1.0429 Acc: 0.4471\n",
      "val Loss: 1.0538 Acc: 0.3960\n",
      "test Loss: 1.0419 Acc: 0.4680\n",
      "Epoch 54/1499\n",
      "----------\n",
      "train Loss: 1.0415 Acc: 0.4522\n",
      "val Loss: 1.0496 Acc: 0.4240\n",
      "test Loss: 1.0399 Acc: 0.4640\n",
      "Epoch 55/1499\n",
      "----------\n",
      "train Loss: 1.0425 Acc: 0.4531\n",
      "val Loss: 1.0499 Acc: 0.4400\n",
      "test Loss: 1.0397 Acc: 0.4640\n",
      "Epoch 56/1499\n",
      "----------\n",
      "train Loss: 1.0408 Acc: 0.4733\n",
      "val Loss: 1.0499 Acc: 0.4240\n",
      "test Loss: 1.0366 Acc: 0.4880\n",
      "Epoch 57/1499\n",
      "----------\n",
      "train Loss: 1.0395 Acc: 0.4773\n",
      "val Loss: 1.0484 Acc: 0.4480\n",
      "test Loss: 1.0385 Acc: 0.4960\n",
      "Epoch 58/1499\n",
      "----------\n",
      "train Loss: 1.0387 Acc: 0.4847\n",
      "val Loss: 1.0494 Acc: 0.4480\n",
      "test Loss: 1.0380 Acc: 0.5000\n",
      "Epoch 59/1499\n",
      "----------\n",
      "train Loss: 1.0387 Acc: 0.4880\n",
      "val Loss: 1.0439 Acc: 0.4560\n",
      "test Loss: 1.0343 Acc: 0.5320\n",
      "Epoch 60/1499\n",
      "----------\n",
      "train Loss: 1.0380 Acc: 0.4951\n",
      "val Loss: 1.0500 Acc: 0.4440\n",
      "test Loss: 1.0335 Acc: 0.5160\n",
      "Epoch 61/1499\n",
      "----------\n",
      "train Loss: 1.0368 Acc: 0.5038\n",
      "val Loss: 1.0490 Acc: 0.4360\n",
      "test Loss: 1.0335 Acc: 0.5160\n",
      "Epoch 62/1499\n",
      "----------\n",
      "train Loss: 1.0357 Acc: 0.5127\n",
      "val Loss: 1.0468 Acc: 0.4680\n",
      "test Loss: 1.0345 Acc: 0.5080\n",
      "Epoch 63/1499\n",
      "----------\n",
      "train Loss: 1.0351 Acc: 0.5140\n",
      "val Loss: 1.0472 Acc: 0.4880\n",
      "test Loss: 1.0289 Acc: 0.5560\n",
      "Epoch 64/1499\n",
      "----------\n",
      "train Loss: 1.0347 Acc: 0.5189\n",
      "val Loss: 1.0412 Acc: 0.5000\n",
      "test Loss: 1.0362 Acc: 0.5040\n",
      "Epoch 65/1499\n",
      "----------\n",
      "train Loss: 1.0330 Acc: 0.5251\n",
      "val Loss: 1.0449 Acc: 0.4720\n",
      "test Loss: 1.0322 Acc: 0.5400\n",
      "Epoch 66/1499\n",
      "----------\n",
      "train Loss: 1.0330 Acc: 0.5287\n",
      "val Loss: 1.0456 Acc: 0.4720\n",
      "test Loss: 1.0289 Acc: 0.5320\n",
      "Epoch 67/1499\n",
      "----------\n",
      "train Loss: 1.0329 Acc: 0.5289\n",
      "val Loss: 1.0398 Acc: 0.4880\n",
      "test Loss: 1.0278 Acc: 0.5600\n",
      "Epoch 68/1499\n",
      "----------\n",
      "train Loss: 1.0316 Acc: 0.5442\n",
      "val Loss: 1.0374 Acc: 0.5240\n",
      "test Loss: 1.0260 Acc: 0.5440\n",
      "Epoch 69/1499\n",
      "----------\n",
      "train Loss: 1.0308 Acc: 0.5418\n",
      "val Loss: 1.0419 Acc: 0.5080\n",
      "test Loss: 1.0300 Acc: 0.5320\n",
      "Epoch 70/1499\n",
      "----------\n",
      "train Loss: 1.0297 Acc: 0.5442\n",
      "val Loss: 1.0398 Acc: 0.5240\n",
      "test Loss: 1.0311 Acc: 0.5160\n",
      "Epoch 71/1499\n",
      "----------\n",
      "train Loss: 1.0289 Acc: 0.5547\n",
      "val Loss: 1.0397 Acc: 0.5400\n",
      "test Loss: 1.0272 Acc: 0.5320\n",
      "Epoch 72/1499\n",
      "----------\n",
      "train Loss: 1.0286 Acc: 0.5551\n",
      "val Loss: 1.0347 Acc: 0.5680\n",
      "test Loss: 1.0241 Acc: 0.5840\n",
      "Epoch 73/1499\n",
      "----------\n",
      "train Loss: 1.0288 Acc: 0.5640\n",
      "val Loss: 1.0365 Acc: 0.5520\n",
      "test Loss: 1.0251 Acc: 0.5400\n",
      "Epoch 74/1499\n",
      "----------\n",
      "train Loss: 1.0272 Acc: 0.5633\n",
      "val Loss: 1.0395 Acc: 0.5600\n",
      "test Loss: 1.0210 Acc: 0.5800\n",
      "Epoch 75/1499\n",
      "----------\n",
      "train Loss: 1.0258 Acc: 0.5787\n",
      "val Loss: 1.0331 Acc: 0.5560\n",
      "test Loss: 1.0239 Acc: 0.5760\n",
      "Epoch 76/1499\n",
      "----------\n",
      "train Loss: 1.0256 Acc: 0.5880\n",
      "val Loss: 1.0316 Acc: 0.5760\n",
      "test Loss: 1.0222 Acc: 0.5640\n",
      "Epoch 77/1499\n",
      "----------\n",
      "train Loss: 1.0236 Acc: 0.5967\n",
      "val Loss: 1.0308 Acc: 0.5960\n",
      "test Loss: 1.0247 Acc: 0.5720\n",
      "Epoch 78/1499\n",
      "----------\n",
      "train Loss: 1.0238 Acc: 0.5913\n",
      "val Loss: 1.0337 Acc: 0.5440\n",
      "test Loss: 1.0216 Acc: 0.5880\n",
      "Epoch 79/1499\n",
      "----------\n",
      "train Loss: 1.0234 Acc: 0.5951\n",
      "val Loss: 1.0335 Acc: 0.5880\n",
      "test Loss: 1.0185 Acc: 0.5840\n",
      "Epoch 80/1499\n",
      "----------\n",
      "train Loss: 1.0233 Acc: 0.5964\n",
      "val Loss: 1.0297 Acc: 0.6040\n",
      "test Loss: 1.0185 Acc: 0.6080\n",
      "Epoch 81/1499\n",
      "----------\n",
      "train Loss: 1.0213 Acc: 0.6104\n",
      "val Loss: 1.0304 Acc: 0.6120\n",
      "test Loss: 1.0180 Acc: 0.5840\n",
      "Epoch 82/1499\n",
      "----------\n",
      "train Loss: 1.0208 Acc: 0.6096\n",
      "val Loss: 1.0333 Acc: 0.5880\n",
      "test Loss: 1.0163 Acc: 0.6080\n",
      "Epoch 83/1499\n",
      "----------\n",
      "train Loss: 1.0201 Acc: 0.6067\n",
      "val Loss: 1.0271 Acc: 0.6040\n",
      "test Loss: 1.0164 Acc: 0.5840\n",
      "Epoch 84/1499\n",
      "----------\n",
      "train Loss: 1.0199 Acc: 0.6100\n",
      "val Loss: 1.0327 Acc: 0.5760\n",
      "test Loss: 1.0153 Acc: 0.6120\n",
      "Epoch 85/1499\n",
      "----------\n",
      "train Loss: 1.0192 Acc: 0.6127\n",
      "val Loss: 1.0323 Acc: 0.5800\n",
      "test Loss: 1.0153 Acc: 0.6360\n",
      "Epoch 86/1499\n",
      "----------\n",
      "train Loss: 1.0177 Acc: 0.6207\n",
      "val Loss: 1.0282 Acc: 0.5840\n",
      "test Loss: 1.0136 Acc: 0.6120\n",
      "Epoch 87/1499\n",
      "----------\n",
      "train Loss: 1.0169 Acc: 0.6251\n",
      "val Loss: 1.0249 Acc: 0.6360\n",
      "test Loss: 1.0142 Acc: 0.6120\n",
      "Epoch 88/1499\n",
      "----------\n",
      "train Loss: 1.0170 Acc: 0.6236\n",
      "val Loss: 1.0299 Acc: 0.5760\n",
      "test Loss: 1.0128 Acc: 0.6360\n",
      "Epoch 89/1499\n",
      "----------\n",
      "train Loss: 1.0154 Acc: 0.6284\n",
      "val Loss: 1.0251 Acc: 0.5920\n",
      "test Loss: 1.0155 Acc: 0.6080\n",
      "Epoch 90/1499\n",
      "----------\n",
      "train Loss: 1.0141 Acc: 0.6256\n",
      "val Loss: 1.0240 Acc: 0.6240\n",
      "test Loss: 1.0087 Acc: 0.6240\n",
      "Epoch 91/1499\n",
      "----------\n",
      "train Loss: 1.0132 Acc: 0.6278\n",
      "val Loss: 1.0255 Acc: 0.5920\n",
      "test Loss: 1.0112 Acc: 0.5920\n",
      "Epoch 92/1499\n",
      "----------\n",
      "train Loss: 1.0132 Acc: 0.6307\n",
      "val Loss: 1.0175 Acc: 0.6200\n",
      "test Loss: 1.0101 Acc: 0.6040\n",
      "Epoch 93/1499\n",
      "----------\n",
      "train Loss: 1.0113 Acc: 0.6353\n",
      "val Loss: 1.0220 Acc: 0.6200\n",
      "test Loss: 1.0079 Acc: 0.6480\n",
      "Epoch 94/1499\n",
      "----------\n",
      "train Loss: 1.0117 Acc: 0.6362\n",
      "val Loss: 1.0185 Acc: 0.6000\n",
      "test Loss: 1.0020 Acc: 0.6480\n",
      "Epoch 95/1499\n",
      "----------\n",
      "train Loss: 1.0108 Acc: 0.6376\n",
      "val Loss: 1.0211 Acc: 0.6120\n",
      "test Loss: 1.0055 Acc: 0.6440\n",
      "Epoch 96/1499\n",
      "----------\n",
      "train Loss: 1.0108 Acc: 0.6389\n",
      "val Loss: 1.0195 Acc: 0.6200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.0053 Acc: 0.6280\n",
      "Epoch 97/1499\n",
      "----------\n",
      "train Loss: 1.0083 Acc: 0.6427\n",
      "val Loss: 1.0201 Acc: 0.6200\n",
      "test Loss: 1.0048 Acc: 0.6400\n",
      "Epoch 98/1499\n",
      "----------\n",
      "train Loss: 1.0085 Acc: 0.6438\n",
      "val Loss: 1.0188 Acc: 0.6080\n",
      "test Loss: 1.0030 Acc: 0.6360\n",
      "Epoch 99/1499\n",
      "----------\n",
      "train Loss: 1.0072 Acc: 0.6533\n",
      "val Loss: 1.0177 Acc: 0.6280\n",
      "test Loss: 1.0036 Acc: 0.6480\n",
      "Epoch 100/1499\n",
      "----------\n",
      "train Loss: 1.0061 Acc: 0.6511\n",
      "val Loss: 1.0209 Acc: 0.6080\n",
      "test Loss: 1.0008 Acc: 0.6480\n",
      "Epoch 101/1499\n",
      "----------\n",
      "train Loss: 1.0058 Acc: 0.6531\n",
      "val Loss: 1.0156 Acc: 0.6360\n",
      "test Loss: 1.0027 Acc: 0.6520\n",
      "Epoch 102/1499\n",
      "----------\n",
      "train Loss: 1.0047 Acc: 0.6553\n",
      "val Loss: 1.0153 Acc: 0.6320\n",
      "test Loss: 0.9988 Acc: 0.6600\n",
      "Epoch 103/1499\n",
      "----------\n",
      "train Loss: 1.0048 Acc: 0.6562\n",
      "val Loss: 1.0151 Acc: 0.6040\n",
      "test Loss: 0.9979 Acc: 0.6600\n",
      "Epoch 104/1499\n",
      "----------\n",
      "train Loss: 1.0041 Acc: 0.6536\n",
      "val Loss: 1.0150 Acc: 0.6000\n",
      "test Loss: 1.0033 Acc: 0.6360\n",
      "Epoch 105/1499\n",
      "----------\n",
      "train Loss: 1.0018 Acc: 0.6620\n",
      "val Loss: 1.0159 Acc: 0.6240\n",
      "test Loss: 0.9973 Acc: 0.6680\n",
      "Epoch 106/1499\n",
      "----------\n",
      "train Loss: 1.0024 Acc: 0.6536\n",
      "val Loss: 1.0105 Acc: 0.6400\n",
      "test Loss: 0.9960 Acc: 0.6600\n",
      "Epoch 107/1499\n",
      "----------\n",
      "train Loss: 1.0001 Acc: 0.6609\n",
      "val Loss: 1.0093 Acc: 0.6320\n",
      "test Loss: 0.9948 Acc: 0.6640\n",
      "Epoch 108/1499\n",
      "----------\n",
      "train Loss: 1.0005 Acc: 0.6596\n",
      "val Loss: 1.0138 Acc: 0.6360\n",
      "test Loss: 0.9986 Acc: 0.6680\n",
      "Epoch 109/1499\n",
      "----------\n",
      "train Loss: 0.9998 Acc: 0.6624\n",
      "val Loss: 1.0115 Acc: 0.6160\n",
      "test Loss: 1.0001 Acc: 0.6440\n",
      "Epoch 110/1499\n",
      "----------\n",
      "train Loss: 0.9973 Acc: 0.6711\n",
      "val Loss: 1.0121 Acc: 0.6040\n",
      "test Loss: 0.9962 Acc: 0.6720\n",
      "Epoch 111/1499\n",
      "----------\n",
      "train Loss: 0.9977 Acc: 0.6653\n",
      "val Loss: 1.0085 Acc: 0.6280\n",
      "test Loss: 0.9937 Acc: 0.6600\n",
      "Epoch 112/1499\n",
      "----------\n",
      "train Loss: 0.9978 Acc: 0.6624\n",
      "val Loss: 1.0082 Acc: 0.6240\n",
      "test Loss: 0.9916 Acc: 0.6720\n",
      "Epoch 113/1499\n",
      "----------\n",
      "train Loss: 0.9965 Acc: 0.6718\n",
      "val Loss: 1.0076 Acc: 0.6360\n",
      "test Loss: 0.9917 Acc: 0.6880\n",
      "Epoch 114/1499\n",
      "----------\n",
      "train Loss: 0.9949 Acc: 0.6713\n",
      "val Loss: 1.0069 Acc: 0.6160\n",
      "test Loss: 0.9916 Acc: 0.6680\n",
      "Epoch 115/1499\n",
      "----------\n",
      "train Loss: 0.9953 Acc: 0.6689\n",
      "val Loss: 1.0036 Acc: 0.6440\n",
      "test Loss: 0.9926 Acc: 0.6720\n",
      "Epoch 116/1499\n",
      "----------\n",
      "train Loss: 0.9943 Acc: 0.6733\n",
      "val Loss: 1.0016 Acc: 0.6400\n",
      "test Loss: 0.9923 Acc: 0.6560\n",
      "Epoch 117/1499\n",
      "----------\n",
      "train Loss: 0.9932 Acc: 0.6727\n",
      "val Loss: 1.0066 Acc: 0.6360\n",
      "test Loss: 0.9916 Acc: 0.6680\n",
      "Epoch 118/1499\n",
      "----------\n",
      "train Loss: 0.9922 Acc: 0.6776\n",
      "val Loss: 1.0023 Acc: 0.6560\n",
      "test Loss: 0.9896 Acc: 0.6720\n",
      "Epoch 119/1499\n",
      "----------\n",
      "train Loss: 0.9924 Acc: 0.6700\n",
      "val Loss: 1.0050 Acc: 0.6400\n",
      "test Loss: 0.9891 Acc: 0.6640\n",
      "Epoch 120/1499\n",
      "----------\n",
      "train Loss: 0.9905 Acc: 0.6736\n",
      "val Loss: 1.0000 Acc: 0.6520\n",
      "test Loss: 0.9874 Acc: 0.6640\n",
      "Epoch 121/1499\n",
      "----------\n",
      "train Loss: 0.9914 Acc: 0.6669\n",
      "val Loss: 0.9923 Acc: 0.6480\n",
      "test Loss: 0.9841 Acc: 0.6720\n",
      "Epoch 122/1499\n",
      "----------\n",
      "train Loss: 0.9902 Acc: 0.6733\n",
      "val Loss: 0.9964 Acc: 0.6480\n",
      "test Loss: 0.9882 Acc: 0.6480\n",
      "Epoch 123/1499\n",
      "----------\n",
      "train Loss: 0.9872 Acc: 0.6820\n",
      "val Loss: 1.0032 Acc: 0.6280\n",
      "test Loss: 0.9862 Acc: 0.6720\n",
      "Epoch 124/1499\n",
      "----------\n",
      "train Loss: 0.9879 Acc: 0.6833\n",
      "val Loss: 0.9969 Acc: 0.6360\n",
      "test Loss: 0.9842 Acc: 0.6800\n",
      "Epoch 125/1499\n",
      "----------\n",
      "train Loss: 0.9877 Acc: 0.6767\n",
      "val Loss: 1.0004 Acc: 0.6160\n",
      "test Loss: 0.9819 Acc: 0.6720\n",
      "Epoch 126/1499\n",
      "----------\n",
      "train Loss: 0.9864 Acc: 0.6793\n",
      "val Loss: 0.9956 Acc: 0.6520\n",
      "test Loss: 0.9829 Acc: 0.6720\n",
      "Epoch 127/1499\n",
      "----------\n",
      "train Loss: 0.9844 Acc: 0.6873\n",
      "val Loss: 0.9989 Acc: 0.6480\n",
      "test Loss: 0.9836 Acc: 0.6920\n",
      "Epoch 128/1499\n",
      "----------\n",
      "train Loss: 0.9829 Acc: 0.6936\n",
      "val Loss: 0.9920 Acc: 0.6800\n",
      "test Loss: 0.9795 Acc: 0.6960\n",
      "Epoch 129/1499\n",
      "----------\n",
      "train Loss: 0.9845 Acc: 0.6856\n",
      "val Loss: 0.9928 Acc: 0.6600\n",
      "test Loss: 0.9803 Acc: 0.6600\n",
      "Epoch 130/1499\n",
      "----------\n",
      "train Loss: 0.9830 Acc: 0.6918\n",
      "val Loss: 0.9927 Acc: 0.6560\n",
      "test Loss: 0.9837 Acc: 0.6760\n",
      "Epoch 131/1499\n",
      "----------\n",
      "train Loss: 0.9827 Acc: 0.6840\n",
      "val Loss: 0.9954 Acc: 0.6400\n",
      "test Loss: 0.9721 Acc: 0.7000\n",
      "Epoch 132/1499\n",
      "----------\n",
      "train Loss: 0.9823 Acc: 0.6827\n",
      "val Loss: 0.9953 Acc: 0.6440\n",
      "test Loss: 0.9770 Acc: 0.6800\n",
      "Epoch 133/1499\n",
      "----------\n",
      "train Loss: 0.9805 Acc: 0.6947\n",
      "val Loss: 0.9894 Acc: 0.6600\n",
      "test Loss: 0.9730 Acc: 0.7000\n",
      "Epoch 134/1499\n",
      "----------\n",
      "train Loss: 0.9806 Acc: 0.6869\n",
      "val Loss: 0.9879 Acc: 0.6640\n",
      "test Loss: 0.9759 Acc: 0.6880\n",
      "Epoch 135/1499\n",
      "----------\n",
      "train Loss: 0.9783 Acc: 0.6940\n",
      "val Loss: 0.9904 Acc: 0.6520\n",
      "test Loss: 0.9745 Acc: 0.6840\n",
      "Epoch 136/1499\n",
      "----------\n",
      "train Loss: 0.9785 Acc: 0.6916\n",
      "val Loss: 0.9887 Acc: 0.6440\n",
      "test Loss: 0.9719 Acc: 0.6800\n",
      "Epoch 137/1499\n",
      "----------\n",
      "train Loss: 0.9772 Acc: 0.7018\n",
      "val Loss: 0.9891 Acc: 0.6720\n",
      "test Loss: 0.9744 Acc: 0.7040\n",
      "Epoch 138/1499\n",
      "----------\n",
      "train Loss: 0.9771 Acc: 0.6909\n",
      "val Loss: 0.9839 Acc: 0.6720\n",
      "test Loss: 0.9752 Acc: 0.6880\n",
      "Epoch 139/1499\n",
      "----------\n",
      "train Loss: 0.9763 Acc: 0.6962\n",
      "val Loss: 0.9843 Acc: 0.6480\n",
      "test Loss: 0.9727 Acc: 0.6920\n",
      "Epoch 140/1499\n",
      "----------\n",
      "train Loss: 0.9753 Acc: 0.6989\n",
      "val Loss: 0.9853 Acc: 0.6440\n",
      "test Loss: 0.9724 Acc: 0.6920\n",
      "Epoch 141/1499\n",
      "----------\n",
      "train Loss: 0.9739 Acc: 0.6942\n",
      "val Loss: 0.9882 Acc: 0.6520\n",
      "test Loss: 0.9740 Acc: 0.6840\n",
      "Epoch 142/1499\n",
      "----------\n",
      "train Loss: 0.9739 Acc: 0.7044\n",
      "val Loss: 0.9863 Acc: 0.6600\n",
      "test Loss: 0.9751 Acc: 0.6680\n",
      "Epoch 143/1499\n",
      "----------\n",
      "train Loss: 0.9742 Acc: 0.6996\n",
      "val Loss: 0.9826 Acc: 0.6600\n",
      "test Loss: 0.9672 Acc: 0.6880\n",
      "Epoch 144/1499\n",
      "----------\n",
      "train Loss: 0.9722 Acc: 0.7004\n",
      "val Loss: 0.9843 Acc: 0.6440\n",
      "test Loss: 0.9719 Acc: 0.6760\n",
      "Epoch 145/1499\n",
      "----------\n",
      "train Loss: 0.9702 Acc: 0.7020\n",
      "val Loss: 0.9822 Acc: 0.6800\n",
      "test Loss: 0.9769 Acc: 0.7000\n",
      "Epoch 146/1499\n",
      "----------\n",
      "train Loss: 0.9713 Acc: 0.7009\n",
      "val Loss: 0.9858 Acc: 0.6760\n",
      "test Loss: 0.9665 Acc: 0.7000\n",
      "Epoch 147/1499\n",
      "----------\n",
      "train Loss: 0.9708 Acc: 0.6984\n",
      "val Loss: 0.9871 Acc: 0.6360\n",
      "test Loss: 0.9660 Acc: 0.6960\n",
      "Epoch 148/1499\n",
      "----------\n",
      "train Loss: 0.9677 Acc: 0.6998\n",
      "val Loss: 0.9789 Acc: 0.6600\n",
      "test Loss: 0.9704 Acc: 0.6800\n",
      "Epoch 149/1499\n",
      "----------\n",
      "train Loss: 0.9691 Acc: 0.7004\n",
      "val Loss: 0.9814 Acc: 0.6920\n",
      "test Loss: 0.9625 Acc: 0.6880\n",
      "Epoch 150/1499\n",
      "----------\n",
      "train Loss: 0.9664 Acc: 0.7018\n",
      "val Loss: 0.9738 Acc: 0.7000\n",
      "test Loss: 0.9647 Acc: 0.7040\n",
      "Epoch 151/1499\n",
      "----------\n",
      "train Loss: 0.9662 Acc: 0.7047\n",
      "val Loss: 0.9758 Acc: 0.6480\n",
      "test Loss: 0.9648 Acc: 0.7200\n",
      "Epoch 152/1499\n",
      "----------\n",
      "train Loss: 0.9652 Acc: 0.7069\n",
      "val Loss: 0.9777 Acc: 0.6680\n",
      "test Loss: 0.9617 Acc: 0.6880\n",
      "Epoch 153/1499\n",
      "----------\n",
      "train Loss: 0.9661 Acc: 0.6989\n",
      "val Loss: 0.9767 Acc: 0.6840\n",
      "test Loss: 0.9556 Acc: 0.7080\n",
      "Epoch 154/1499\n",
      "----------\n",
      "train Loss: 0.9633 Acc: 0.7069\n",
      "val Loss: 0.9809 Acc: 0.6600\n",
      "test Loss: 0.9631 Acc: 0.7080\n",
      "Epoch 155/1499\n",
      "----------\n",
      "train Loss: 0.9636 Acc: 0.7024\n",
      "val Loss: 0.9688 Acc: 0.6960\n",
      "test Loss: 0.9606 Acc: 0.7200\n",
      "Epoch 156/1499\n",
      "----------\n",
      "train Loss: 0.9622 Acc: 0.7073\n",
      "val Loss: 0.9782 Acc: 0.6680\n",
      "test Loss: 0.9590 Acc: 0.7040\n",
      "Epoch 157/1499\n",
      "----------\n",
      "train Loss: 0.9607 Acc: 0.7098\n",
      "val Loss: 0.9725 Acc: 0.6840\n",
      "test Loss: 0.9566 Acc: 0.7080\n",
      "Epoch 158/1499\n",
      "----------\n",
      "train Loss: 0.9613 Acc: 0.7064\n",
      "val Loss: 0.9745 Acc: 0.6440\n",
      "test Loss: 0.9598 Acc: 0.6920\n",
      "Epoch 159/1499\n",
      "----------\n",
      "train Loss: 0.9592 Acc: 0.7098\n",
      "val Loss: 0.9720 Acc: 0.6720\n",
      "test Loss: 0.9571 Acc: 0.7000\n",
      "Epoch 160/1499\n",
      "----------\n",
      "train Loss: 0.9595 Acc: 0.7111\n",
      "val Loss: 0.9691 Acc: 0.6760\n",
      "test Loss: 0.9517 Acc: 0.7000\n",
      "Epoch 161/1499\n",
      "----------\n",
      "train Loss: 0.9597 Acc: 0.7064\n",
      "val Loss: 0.9765 Acc: 0.6560\n",
      "test Loss: 0.9564 Acc: 0.7200\n",
      "Epoch 162/1499\n",
      "----------\n",
      "train Loss: 0.9577 Acc: 0.7113\n",
      "val Loss: 0.9709 Acc: 0.6840\n",
      "test Loss: 0.9559 Acc: 0.7080\n",
      "Epoch 163/1499\n",
      "----------\n",
      "train Loss: 0.9568 Acc: 0.7047\n",
      "val Loss: 0.9721 Acc: 0.6760\n",
      "test Loss: 0.9530 Acc: 0.6960\n",
      "Epoch 164/1499\n",
      "----------\n",
      "train Loss: 0.9577 Acc: 0.7129\n",
      "val Loss: 0.9673 Acc: 0.7000\n",
      "test Loss: 0.9511 Acc: 0.7040\n",
      "Epoch 165/1499\n",
      "----------\n",
      "train Loss: 0.9557 Acc: 0.7107\n",
      "val Loss: 0.9652 Acc: 0.6760\n",
      "test Loss: 0.9458 Acc: 0.7240\n",
      "Epoch 166/1499\n",
      "----------\n",
      "train Loss: 0.9562 Acc: 0.7093\n",
      "val Loss: 0.9620 Acc: 0.6880\n",
      "test Loss: 0.9534 Acc: 0.6800\n",
      "Epoch 167/1499\n",
      "----------\n",
      "train Loss: 0.9537 Acc: 0.7180\n",
      "val Loss: 0.9637 Acc: 0.6920\n",
      "test Loss: 0.9514 Acc: 0.7000\n",
      "Epoch 168/1499\n",
      "----------\n",
      "train Loss: 0.9545 Acc: 0.7122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.9645 Acc: 0.6640\n",
      "test Loss: 0.9486 Acc: 0.6960\n",
      "Epoch 169/1499\n",
      "----------\n",
      "train Loss: 0.9534 Acc: 0.7127\n",
      "val Loss: 0.9652 Acc: 0.6720\n",
      "test Loss: 0.9487 Acc: 0.7040\n",
      "Epoch 170/1499\n",
      "----------\n",
      "train Loss: 0.9521 Acc: 0.7158\n",
      "val Loss: 0.9611 Acc: 0.6800\n",
      "test Loss: 0.9519 Acc: 0.7120\n",
      "Epoch 171/1499\n",
      "----------\n",
      "train Loss: 0.9516 Acc: 0.7124\n",
      "val Loss: 0.9612 Acc: 0.7040\n",
      "test Loss: 0.9376 Acc: 0.7200\n",
      "Epoch 172/1499\n",
      "----------\n",
      "train Loss: 0.9500 Acc: 0.7180\n",
      "val Loss: 0.9610 Acc: 0.6920\n",
      "test Loss: 0.9478 Acc: 0.7040\n",
      "Epoch 173/1499\n",
      "----------\n",
      "train Loss: 0.9496 Acc: 0.7136\n",
      "val Loss: 0.9629 Acc: 0.6960\n",
      "test Loss: 0.9454 Acc: 0.7360\n",
      "Epoch 174/1499\n",
      "----------\n",
      "train Loss: 0.9475 Acc: 0.7207\n",
      "val Loss: 0.9630 Acc: 0.6720\n",
      "test Loss: 0.9433 Acc: 0.7040\n",
      "Epoch 175/1499\n",
      "----------\n",
      "train Loss: 0.9474 Acc: 0.7180\n",
      "val Loss: 0.9554 Acc: 0.7040\n",
      "test Loss: 0.9425 Acc: 0.6960\n",
      "Epoch 176/1499\n",
      "----------\n",
      "train Loss: 0.9485 Acc: 0.7140\n",
      "val Loss: 0.9618 Acc: 0.6800\n",
      "test Loss: 0.9482 Acc: 0.7080\n",
      "Epoch 177/1499\n",
      "----------\n",
      "train Loss: 0.9457 Acc: 0.7220\n",
      "val Loss: 0.9540 Acc: 0.7000\n",
      "test Loss: 0.9501 Acc: 0.6960\n",
      "Epoch 178/1499\n",
      "----------\n",
      "train Loss: 0.9461 Acc: 0.7251\n",
      "val Loss: 0.9584 Acc: 0.6800\n",
      "test Loss: 0.9406 Acc: 0.7200\n",
      "Epoch 179/1499\n",
      "----------\n",
      "train Loss: 0.9458 Acc: 0.7202\n",
      "val Loss: 0.9622 Acc: 0.6800\n",
      "test Loss: 0.9450 Acc: 0.7080\n",
      "Epoch 180/1499\n",
      "----------\n",
      "train Loss: 0.9455 Acc: 0.7180\n",
      "val Loss: 0.9597 Acc: 0.6960\n",
      "test Loss: 0.9401 Acc: 0.6920\n",
      "Epoch 181/1499\n",
      "----------\n",
      "train Loss: 0.9434 Acc: 0.7180\n",
      "val Loss: 0.9522 Acc: 0.6840\n",
      "test Loss: 0.9328 Acc: 0.7400\n",
      "Epoch 182/1499\n",
      "----------\n",
      "train Loss: 0.9412 Acc: 0.7238\n",
      "val Loss: 0.9557 Acc: 0.7080\n",
      "test Loss: 0.9429 Acc: 0.7200\n",
      "Epoch 183/1499\n",
      "----------\n",
      "train Loss: 0.9420 Acc: 0.7220\n",
      "val Loss: 0.9511 Acc: 0.7000\n",
      "test Loss: 0.9322 Acc: 0.7320\n",
      "Epoch 184/1499\n",
      "----------\n",
      "train Loss: 0.9416 Acc: 0.7216\n",
      "val Loss: 0.9502 Acc: 0.6840\n",
      "test Loss: 0.9375 Acc: 0.7200\n",
      "Epoch 185/1499\n",
      "----------\n",
      "train Loss: 0.9398 Acc: 0.7264\n",
      "val Loss: 0.9524 Acc: 0.6920\n",
      "test Loss: 0.9320 Acc: 0.7280\n",
      "Epoch 186/1499\n",
      "----------\n",
      "train Loss: 0.9386 Acc: 0.7264\n",
      "val Loss: 0.9546 Acc: 0.7040\n",
      "test Loss: 0.9407 Acc: 0.7320\n",
      "Epoch 187/1499\n",
      "----------\n",
      "train Loss: 0.9379 Acc: 0.7271\n",
      "val Loss: 0.9569 Acc: 0.6640\n",
      "test Loss: 0.9371 Acc: 0.7160\n",
      "Epoch 188/1499\n",
      "----------\n",
      "train Loss: 0.9376 Acc: 0.7231\n",
      "val Loss: 0.9493 Acc: 0.7000\n",
      "test Loss: 0.9414 Acc: 0.6920\n",
      "Epoch 189/1499\n",
      "----------\n",
      "train Loss: 0.9376 Acc: 0.7233\n",
      "val Loss: 0.9524 Acc: 0.6760\n",
      "test Loss: 0.9308 Acc: 0.7440\n",
      "Epoch 190/1499\n",
      "----------\n",
      "train Loss: 0.9369 Acc: 0.7211\n",
      "val Loss: 0.9429 Acc: 0.6960\n",
      "test Loss: 0.9358 Acc: 0.7160\n",
      "Epoch 191/1499\n",
      "----------\n",
      "train Loss: 0.9362 Acc: 0.7273\n",
      "val Loss: 0.9498 Acc: 0.6920\n",
      "test Loss: 0.9302 Acc: 0.7320\n",
      "Epoch 192/1499\n",
      "----------\n",
      "train Loss: 0.9344 Acc: 0.7240\n",
      "val Loss: 0.9485 Acc: 0.6760\n",
      "test Loss: 0.9314 Acc: 0.7240\n",
      "Epoch 193/1499\n",
      "----------\n",
      "train Loss: 0.9343 Acc: 0.7298\n",
      "val Loss: 0.9475 Acc: 0.6760\n",
      "test Loss: 0.9289 Acc: 0.7120\n",
      "Epoch 194/1499\n",
      "----------\n",
      "train Loss: 0.9345 Acc: 0.7244\n",
      "val Loss: 0.9418 Acc: 0.6960\n",
      "test Loss: 0.9262 Acc: 0.7160\n",
      "Epoch 195/1499\n",
      "----------\n",
      "train Loss: 0.9334 Acc: 0.7311\n",
      "val Loss: 0.9405 Acc: 0.6920\n",
      "test Loss: 0.9334 Acc: 0.7000\n",
      "Epoch 196/1499\n",
      "----------\n",
      "train Loss: 0.9335 Acc: 0.7271\n",
      "val Loss: 0.9433 Acc: 0.7000\n",
      "test Loss: 0.9307 Acc: 0.7200\n",
      "Epoch 197/1499\n",
      "----------\n",
      "train Loss: 0.9308 Acc: 0.7316\n",
      "val Loss: 0.9397 Acc: 0.7080\n",
      "test Loss: 0.9226 Acc: 0.7200\n",
      "Epoch 198/1499\n",
      "----------\n",
      "train Loss: 0.9315 Acc: 0.7256\n",
      "val Loss: 0.9412 Acc: 0.6960\n",
      "test Loss: 0.9317 Acc: 0.7240\n",
      "Epoch 199/1499\n",
      "----------\n",
      "train Loss: 0.9301 Acc: 0.7311\n",
      "val Loss: 0.9424 Acc: 0.7040\n",
      "test Loss: 0.9333 Acc: 0.6960\n",
      "Epoch 200/1499\n",
      "----------\n",
      "train Loss: 0.9311 Acc: 0.7240\n",
      "val Loss: 0.9420 Acc: 0.6920\n",
      "test Loss: 0.9223 Acc: 0.7400\n",
      "Epoch 201/1499\n",
      "----------\n",
      "train Loss: 0.9272 Acc: 0.7307\n",
      "val Loss: 0.9390 Acc: 0.7080\n",
      "test Loss: 0.9244 Acc: 0.7400\n",
      "Epoch 202/1499\n",
      "----------\n",
      "train Loss: 0.9271 Acc: 0.7313\n",
      "val Loss: 0.9382 Acc: 0.6920\n",
      "test Loss: 0.9246 Acc: 0.7360\n",
      "Epoch 203/1499\n",
      "----------\n",
      "train Loss: 0.9272 Acc: 0.7300\n",
      "val Loss: 0.9452 Acc: 0.6880\n",
      "test Loss: 0.9208 Acc: 0.7400\n",
      "Epoch 204/1499\n",
      "----------\n",
      "train Loss: 0.9261 Acc: 0.7307\n",
      "val Loss: 0.9423 Acc: 0.6960\n",
      "test Loss: 0.9205 Acc: 0.7160\n",
      "Epoch 205/1499\n",
      "----------\n",
      "train Loss: 0.9261 Acc: 0.7309\n",
      "val Loss: 0.9383 Acc: 0.6960\n",
      "test Loss: 0.9218 Acc: 0.7160\n",
      "Epoch 206/1499\n",
      "----------\n",
      "train Loss: 0.9258 Acc: 0.7302\n",
      "val Loss: 0.9383 Acc: 0.7040\n",
      "test Loss: 0.9240 Acc: 0.7440\n",
      "Epoch 207/1499\n",
      "----------\n",
      "train Loss: 0.9251 Acc: 0.7293\n",
      "val Loss: 0.9386 Acc: 0.6880\n",
      "test Loss: 0.9200 Acc: 0.7280\n",
      "Epoch 208/1499\n",
      "----------\n",
      "train Loss: 0.9227 Acc: 0.7307\n",
      "val Loss: 0.9372 Acc: 0.6760\n",
      "test Loss: 0.9174 Acc: 0.7440\n",
      "Epoch 209/1499\n",
      "----------\n",
      "train Loss: 0.9221 Acc: 0.7258\n",
      "val Loss: 0.9347 Acc: 0.7200\n",
      "test Loss: 0.9190 Acc: 0.7200\n",
      "Epoch 210/1499\n",
      "----------\n",
      "train Loss: 0.9224 Acc: 0.7267\n",
      "val Loss: 0.9349 Acc: 0.6920\n",
      "test Loss: 0.9173 Acc: 0.7080\n",
      "Epoch 211/1499\n",
      "----------\n",
      "train Loss: 0.9213 Acc: 0.7322\n",
      "val Loss: 0.9308 Acc: 0.7040\n",
      "test Loss: 0.9235 Acc: 0.7080\n",
      "Epoch 212/1499\n",
      "----------\n",
      "train Loss: 0.9197 Acc: 0.7313\n",
      "val Loss: 0.9365 Acc: 0.7040\n",
      "test Loss: 0.9128 Acc: 0.7120\n",
      "Epoch 213/1499\n",
      "----------\n",
      "train Loss: 0.9209 Acc: 0.7331\n",
      "val Loss: 0.9288 Acc: 0.7000\n",
      "test Loss: 0.9103 Acc: 0.7600\n",
      "Epoch 214/1499\n",
      "----------\n",
      "train Loss: 0.9209 Acc: 0.7309\n",
      "val Loss: 0.9343 Acc: 0.6880\n",
      "test Loss: 0.9102 Acc: 0.7320\n",
      "Epoch 215/1499\n",
      "----------\n",
      "train Loss: 0.9182 Acc: 0.7324\n",
      "val Loss: 0.9355 Acc: 0.6800\n",
      "test Loss: 0.9132 Acc: 0.7480\n",
      "Epoch 216/1499\n",
      "----------\n",
      "train Loss: 0.9169 Acc: 0.7376\n",
      "val Loss: 0.9339 Acc: 0.6880\n",
      "test Loss: 0.9148 Acc: 0.7360\n",
      "Epoch 217/1499\n",
      "----------\n",
      "train Loss: 0.9170 Acc: 0.7371\n",
      "val Loss: 0.9308 Acc: 0.6920\n",
      "test Loss: 0.9171 Acc: 0.7360\n",
      "Epoch 218/1499\n",
      "----------\n",
      "train Loss: 0.9158 Acc: 0.7411\n",
      "val Loss: 0.9290 Acc: 0.7040\n",
      "test Loss: 0.9136 Acc: 0.7360\n",
      "Epoch 219/1499\n",
      "----------\n",
      "train Loss: 0.9145 Acc: 0.7422\n",
      "val Loss: 0.9341 Acc: 0.7000\n",
      "test Loss: 0.9060 Acc: 0.7280\n",
      "Epoch 220/1499\n",
      "----------\n",
      "train Loss: 0.9161 Acc: 0.7367\n",
      "val Loss: 0.9305 Acc: 0.6800\n",
      "test Loss: 0.9152 Acc: 0.7160\n",
      "Epoch 221/1499\n",
      "----------\n",
      "train Loss: 0.9144 Acc: 0.7407\n",
      "val Loss: 0.9283 Acc: 0.6680\n",
      "test Loss: 0.9056 Acc: 0.7640\n",
      "Epoch 222/1499\n",
      "----------\n",
      "train Loss: 0.9135 Acc: 0.7407\n",
      "val Loss: 0.9268 Acc: 0.7000\n",
      "test Loss: 0.9050 Acc: 0.7360\n",
      "Epoch 223/1499\n",
      "----------\n",
      "train Loss: 0.9128 Acc: 0.7393\n",
      "val Loss: 0.9320 Acc: 0.7040\n",
      "test Loss: 0.9123 Acc: 0.7240\n",
      "Epoch 224/1499\n",
      "----------\n",
      "train Loss: 0.9114 Acc: 0.7453\n",
      "val Loss: 0.9266 Acc: 0.6760\n",
      "test Loss: 0.9085 Acc: 0.7040\n",
      "Epoch 225/1499\n",
      "----------\n",
      "train Loss: 0.9107 Acc: 0.7416\n",
      "val Loss: 0.9227 Acc: 0.7320\n",
      "test Loss: 0.9039 Acc: 0.7400\n",
      "Epoch 226/1499\n",
      "----------\n",
      "train Loss: 0.9114 Acc: 0.7393\n",
      "val Loss: 0.9210 Acc: 0.7320\n",
      "test Loss: 0.9086 Acc: 0.7400\n",
      "Epoch 227/1499\n",
      "----------\n",
      "train Loss: 0.9119 Acc: 0.7384\n",
      "val Loss: 0.9245 Acc: 0.7280\n",
      "test Loss: 0.9066 Acc: 0.7600\n",
      "Epoch 228/1499\n",
      "----------\n",
      "train Loss: 0.9107 Acc: 0.7427\n",
      "val Loss: 0.9253 Acc: 0.7080\n",
      "test Loss: 0.9005 Acc: 0.7600\n",
      "Epoch 229/1499\n",
      "----------\n",
      "train Loss: 0.9103 Acc: 0.7369\n",
      "val Loss: 0.9205 Acc: 0.7160\n",
      "test Loss: 0.9026 Acc: 0.7320\n",
      "Epoch 230/1499\n",
      "----------\n",
      "train Loss: 0.9075 Acc: 0.7411\n",
      "val Loss: 0.9270 Acc: 0.7000\n",
      "test Loss: 0.9056 Acc: 0.7200\n",
      "Epoch 231/1499\n",
      "----------\n",
      "train Loss: 0.9067 Acc: 0.7436\n",
      "val Loss: 0.9218 Acc: 0.7120\n",
      "test Loss: 0.9056 Acc: 0.7200\n",
      "Epoch 232/1499\n",
      "----------\n",
      "train Loss: 0.9061 Acc: 0.7440\n",
      "val Loss: 0.9257 Acc: 0.7000\n",
      "test Loss: 0.9068 Acc: 0.7360\n",
      "Epoch 233/1499\n",
      "----------\n",
      "train Loss: 0.9061 Acc: 0.7427\n",
      "val Loss: 0.9231 Acc: 0.7200\n",
      "test Loss: 0.9029 Acc: 0.7360\n",
      "Epoch 234/1499\n",
      "----------\n",
      "train Loss: 0.9062 Acc: 0.7391\n",
      "val Loss: 0.9201 Acc: 0.7080\n",
      "test Loss: 0.8971 Acc: 0.7560\n",
      "Epoch 235/1499\n",
      "----------\n",
      "train Loss: 0.9063 Acc: 0.7380\n",
      "val Loss: 0.9157 Acc: 0.7120\n",
      "test Loss: 0.8982 Acc: 0.7800\n",
      "Epoch 236/1499\n",
      "----------\n",
      "train Loss: 0.9036 Acc: 0.7456\n",
      "val Loss: 0.9178 Acc: 0.7160\n",
      "test Loss: 0.9021 Acc: 0.7440\n",
      "Epoch 237/1499\n",
      "----------\n",
      "train Loss: 0.9035 Acc: 0.7458\n",
      "val Loss: 0.9135 Acc: 0.7400\n",
      "test Loss: 0.8954 Acc: 0.7440\n",
      "Epoch 238/1499\n",
      "----------\n",
      "train Loss: 0.9023 Acc: 0.7447\n",
      "val Loss: 0.9105 Acc: 0.7000\n",
      "test Loss: 0.8951 Acc: 0.7560\n",
      "Epoch 239/1499\n",
      "----------\n",
      "train Loss: 0.9020 Acc: 0.7471\n",
      "val Loss: 0.9202 Acc: 0.7000\n",
      "test Loss: 0.8944 Acc: 0.7440\n",
      "Epoch 240/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.9027 Acc: 0.7400\n",
      "val Loss: 0.9147 Acc: 0.7200\n",
      "test Loss: 0.8997 Acc: 0.7360\n",
      "Epoch 241/1499\n",
      "----------\n",
      "train Loss: 0.9005 Acc: 0.7529\n",
      "val Loss: 0.9166 Acc: 0.7000\n",
      "test Loss: 0.8983 Acc: 0.7120\n",
      "Epoch 242/1499\n",
      "----------\n",
      "train Loss: 0.9017 Acc: 0.7416\n",
      "val Loss: 0.9139 Acc: 0.7080\n",
      "test Loss: 0.8950 Acc: 0.7360\n",
      "Epoch 243/1499\n",
      "----------\n",
      "train Loss: 0.8985 Acc: 0.7442\n",
      "val Loss: 0.9133 Acc: 0.7080\n",
      "test Loss: 0.8978 Acc: 0.7240\n",
      "Epoch 244/1499\n",
      "----------\n",
      "train Loss: 0.8995 Acc: 0.7429\n",
      "val Loss: 0.9140 Acc: 0.7200\n",
      "test Loss: 0.8912 Acc: 0.7280\n",
      "Epoch 245/1499\n",
      "----------\n",
      "train Loss: 0.8984 Acc: 0.7469\n",
      "val Loss: 0.9162 Acc: 0.7320\n",
      "test Loss: 0.8932 Acc: 0.7520\n",
      "Epoch 246/1499\n",
      "----------\n",
      "train Loss: 0.8980 Acc: 0.7447\n",
      "val Loss: 0.9124 Acc: 0.7120\n",
      "test Loss: 0.8888 Acc: 0.7680\n",
      "Epoch 247/1499\n",
      "----------\n",
      "train Loss: 0.8962 Acc: 0.7436\n",
      "val Loss: 0.9161 Acc: 0.7080\n",
      "test Loss: 0.8861 Acc: 0.7520\n",
      "Epoch 248/1499\n",
      "----------\n",
      "train Loss: 0.8950 Acc: 0.7462\n",
      "val Loss: 0.9132 Acc: 0.7000\n",
      "test Loss: 0.8916 Acc: 0.7520\n",
      "Epoch 249/1499\n",
      "----------\n",
      "train Loss: 0.8956 Acc: 0.7511\n",
      "val Loss: 0.9097 Acc: 0.7200\n",
      "test Loss: 0.8951 Acc: 0.7560\n",
      "Epoch 250/1499\n",
      "----------\n",
      "train Loss: 0.8945 Acc: 0.7500\n",
      "val Loss: 0.9178 Acc: 0.7000\n",
      "test Loss: 0.8909 Acc: 0.7400\n",
      "Epoch 251/1499\n",
      "----------\n",
      "train Loss: 0.8938 Acc: 0.7462\n",
      "val Loss: 0.9038 Acc: 0.7200\n",
      "test Loss: 0.8872 Acc: 0.7560\n",
      "Epoch 252/1499\n",
      "----------\n",
      "train Loss: 0.8938 Acc: 0.7453\n",
      "val Loss: 0.8986 Acc: 0.7440\n",
      "test Loss: 0.8892 Acc: 0.7600\n",
      "Epoch 253/1499\n",
      "----------\n",
      "train Loss: 0.8958 Acc: 0.7453\n",
      "val Loss: 0.9125 Acc: 0.7200\n",
      "test Loss: 0.8965 Acc: 0.7520\n",
      "Epoch 254/1499\n",
      "----------\n",
      "train Loss: 0.8942 Acc: 0.7431\n",
      "val Loss: 0.9048 Acc: 0.7160\n",
      "test Loss: 0.8837 Acc: 0.7640\n",
      "Epoch 255/1499\n",
      "----------\n",
      "train Loss: 0.8923 Acc: 0.7442\n",
      "val Loss: 0.9119 Acc: 0.6800\n",
      "test Loss: 0.8879 Acc: 0.7520\n",
      "Epoch 256/1499\n",
      "----------\n",
      "train Loss: 0.8912 Acc: 0.7507\n",
      "val Loss: 0.9057 Acc: 0.7120\n",
      "test Loss: 0.8832 Acc: 0.7640\n",
      "Epoch 257/1499\n",
      "----------\n",
      "train Loss: 0.8902 Acc: 0.7509\n",
      "val Loss: 0.9133 Acc: 0.7080\n",
      "test Loss: 0.8897 Acc: 0.7560\n",
      "Epoch 258/1499\n",
      "----------\n",
      "train Loss: 0.8897 Acc: 0.7516\n",
      "val Loss: 0.9094 Acc: 0.6840\n",
      "test Loss: 0.8835 Acc: 0.7600\n",
      "Epoch 259/1499\n",
      "----------\n",
      "train Loss: 0.8900 Acc: 0.7558\n",
      "val Loss: 0.9087 Acc: 0.6880\n",
      "test Loss: 0.8833 Acc: 0.7560\n",
      "Epoch 260/1499\n",
      "----------\n",
      "train Loss: 0.8894 Acc: 0.7473\n",
      "val Loss: 0.9151 Acc: 0.7000\n",
      "test Loss: 0.8865 Acc: 0.7360\n",
      "Epoch 261/1499\n",
      "----------\n",
      "train Loss: 0.8890 Acc: 0.7509\n",
      "val Loss: 0.9034 Acc: 0.7200\n",
      "test Loss: 0.8794 Acc: 0.7800\n",
      "Epoch 262/1499\n",
      "----------\n",
      "train Loss: 0.8877 Acc: 0.7509\n",
      "val Loss: 0.9034 Acc: 0.7200\n",
      "test Loss: 0.8817 Acc: 0.7600\n",
      "Epoch 263/1499\n",
      "----------\n",
      "train Loss: 0.8891 Acc: 0.7489\n",
      "val Loss: 0.9036 Acc: 0.7080\n",
      "test Loss: 0.8845 Acc: 0.7520\n",
      "Epoch 264/1499\n",
      "----------\n",
      "train Loss: 0.8861 Acc: 0.7556\n",
      "val Loss: 0.8964 Acc: 0.7200\n",
      "test Loss: 0.8829 Acc: 0.7520\n",
      "Epoch 265/1499\n",
      "----------\n",
      "train Loss: 0.8864 Acc: 0.7549\n",
      "val Loss: 0.9013 Acc: 0.7120\n",
      "test Loss: 0.8812 Acc: 0.7480\n",
      "Epoch 266/1499\n",
      "----------\n",
      "train Loss: 0.8865 Acc: 0.7498\n",
      "val Loss: 0.9070 Acc: 0.7200\n",
      "test Loss: 0.8772 Acc: 0.7600\n",
      "Epoch 267/1499\n",
      "----------\n",
      "train Loss: 0.8863 Acc: 0.7482\n",
      "val Loss: 0.9030 Acc: 0.7000\n",
      "test Loss: 0.8750 Acc: 0.7600\n",
      "Epoch 268/1499\n",
      "----------\n",
      "train Loss: 0.8836 Acc: 0.7551\n",
      "val Loss: 0.8959 Acc: 0.7240\n",
      "test Loss: 0.8749 Acc: 0.7440\n",
      "Epoch 269/1499\n",
      "----------\n",
      "train Loss: 0.8825 Acc: 0.7558\n",
      "val Loss: 0.8995 Acc: 0.7080\n",
      "test Loss: 0.8775 Acc: 0.7720\n",
      "Epoch 270/1499\n",
      "----------\n",
      "train Loss: 0.8834 Acc: 0.7567\n",
      "val Loss: 0.8929 Acc: 0.7320\n",
      "test Loss: 0.8820 Acc: 0.7600\n",
      "Epoch 271/1499\n",
      "----------\n",
      "train Loss: 0.8810 Acc: 0.7596\n",
      "val Loss: 0.8931 Acc: 0.7200\n",
      "test Loss: 0.8825 Acc: 0.7480\n",
      "Epoch 272/1499\n",
      "----------\n",
      "train Loss: 0.8824 Acc: 0.7604\n",
      "val Loss: 0.8963 Acc: 0.7240\n",
      "test Loss: 0.8744 Acc: 0.7720\n",
      "Epoch 273/1499\n",
      "----------\n",
      "train Loss: 0.8811 Acc: 0.7604\n",
      "val Loss: 0.8992 Acc: 0.7120\n",
      "test Loss: 0.8754 Acc: 0.7520\n",
      "Epoch 274/1499\n",
      "----------\n",
      "train Loss: 0.8797 Acc: 0.7567\n",
      "val Loss: 0.8979 Acc: 0.7080\n",
      "test Loss: 0.8720 Acc: 0.7640\n",
      "Epoch 275/1499\n",
      "----------\n",
      "train Loss: 0.8793 Acc: 0.7576\n",
      "val Loss: 0.8899 Acc: 0.7240\n",
      "test Loss: 0.8702 Acc: 0.7680\n",
      "Epoch 276/1499\n",
      "----------\n",
      "train Loss: 0.8797 Acc: 0.7569\n",
      "val Loss: 0.8947 Acc: 0.7280\n",
      "test Loss: 0.8724 Acc: 0.7600\n",
      "Epoch 277/1499\n",
      "----------\n",
      "train Loss: 0.8779 Acc: 0.7587\n",
      "val Loss: 0.8927 Acc: 0.7000\n",
      "test Loss: 0.8695 Acc: 0.7560\n",
      "Epoch 278/1499\n",
      "----------\n",
      "train Loss: 0.8785 Acc: 0.7607\n",
      "val Loss: 0.8972 Acc: 0.7040\n",
      "test Loss: 0.8738 Acc: 0.7640\n",
      "Epoch 279/1499\n",
      "----------\n",
      "train Loss: 0.8791 Acc: 0.7584\n",
      "val Loss: 0.8890 Acc: 0.7360\n",
      "test Loss: 0.8701 Acc: 0.7680\n",
      "Epoch 280/1499\n",
      "----------\n",
      "train Loss: 0.8772 Acc: 0.7598\n",
      "val Loss: 0.8870 Acc: 0.7240\n",
      "test Loss: 0.8753 Acc: 0.7640\n",
      "Epoch 281/1499\n",
      "----------\n",
      "train Loss: 0.8760 Acc: 0.7629\n",
      "val Loss: 0.8925 Acc: 0.7080\n",
      "test Loss: 0.8654 Acc: 0.7880\n",
      "Epoch 282/1499\n",
      "----------\n",
      "train Loss: 0.8742 Acc: 0.7636\n",
      "val Loss: 0.8826 Acc: 0.7240\n",
      "test Loss: 0.8738 Acc: 0.7720\n",
      "Epoch 283/1499\n",
      "----------\n",
      "train Loss: 0.8740 Acc: 0.7684\n",
      "val Loss: 0.8909 Acc: 0.7160\n",
      "test Loss: 0.8680 Acc: 0.7800\n",
      "Epoch 284/1499\n",
      "----------\n",
      "train Loss: 0.8730 Acc: 0.7664\n",
      "val Loss: 0.8919 Acc: 0.7200\n",
      "test Loss: 0.8662 Acc: 0.7640\n",
      "Epoch 285/1499\n",
      "----------\n",
      "train Loss: 0.8748 Acc: 0.7607\n",
      "val Loss: 0.8861 Acc: 0.7120\n",
      "test Loss: 0.8711 Acc: 0.7560\n",
      "Epoch 286/1499\n",
      "----------\n",
      "train Loss: 0.8736 Acc: 0.7618\n",
      "val Loss: 0.8876 Acc: 0.7080\n",
      "test Loss: 0.8724 Acc: 0.7520\n",
      "Epoch 287/1499\n",
      "----------\n",
      "train Loss: 0.8718 Acc: 0.7636\n",
      "val Loss: 0.8831 Acc: 0.7080\n",
      "test Loss: 0.8652 Acc: 0.7600\n",
      "Epoch 288/1499\n",
      "----------\n",
      "train Loss: 0.8713 Acc: 0.7676\n",
      "val Loss: 0.8910 Acc: 0.7120\n",
      "test Loss: 0.8622 Acc: 0.7840\n",
      "Epoch 289/1499\n",
      "----------\n",
      "train Loss: 0.8714 Acc: 0.7640\n",
      "val Loss: 0.8938 Acc: 0.7040\n",
      "test Loss: 0.8620 Acc: 0.7680\n",
      "Epoch 290/1499\n",
      "----------\n",
      "train Loss: 0.8708 Acc: 0.7627\n",
      "val Loss: 0.8917 Acc: 0.7120\n",
      "test Loss: 0.8607 Acc: 0.7680\n",
      "Epoch 291/1499\n",
      "----------\n",
      "train Loss: 0.8719 Acc: 0.7618\n",
      "val Loss: 0.8880 Acc: 0.7360\n",
      "test Loss: 0.8637 Acc: 0.7640\n",
      "Epoch 292/1499\n",
      "----------\n",
      "train Loss: 0.8694 Acc: 0.7644\n",
      "val Loss: 0.8887 Acc: 0.7080\n",
      "test Loss: 0.8529 Acc: 0.7760\n",
      "Epoch 293/1499\n",
      "----------\n",
      "train Loss: 0.8678 Acc: 0.7627\n",
      "val Loss: 0.8864 Acc: 0.7200\n",
      "test Loss: 0.8617 Acc: 0.7840\n",
      "Epoch 294/1499\n",
      "----------\n",
      "train Loss: 0.8676 Acc: 0.7636\n",
      "val Loss: 0.8817 Acc: 0.7320\n",
      "test Loss: 0.8548 Acc: 0.8080\n",
      "Epoch 295/1499\n",
      "----------\n",
      "train Loss: 0.8684 Acc: 0.7658\n",
      "val Loss: 0.8821 Acc: 0.7320\n",
      "test Loss: 0.8622 Acc: 0.7680\n",
      "Epoch 296/1499\n",
      "----------\n",
      "train Loss: 0.8680 Acc: 0.7642\n",
      "val Loss: 0.8796 Acc: 0.7200\n",
      "test Loss: 0.8601 Acc: 0.7920\n",
      "Epoch 297/1499\n",
      "----------\n",
      "train Loss: 0.8679 Acc: 0.7609\n",
      "val Loss: 0.8929 Acc: 0.7000\n",
      "test Loss: 0.8612 Acc: 0.7880\n",
      "Epoch 298/1499\n",
      "----------\n",
      "train Loss: 0.8655 Acc: 0.7658\n",
      "val Loss: 0.8883 Acc: 0.7080\n",
      "test Loss: 0.8603 Acc: 0.7840\n",
      "Epoch 299/1499\n",
      "----------\n",
      "train Loss: 0.8678 Acc: 0.7631\n",
      "val Loss: 0.8741 Acc: 0.7240\n",
      "test Loss: 0.8573 Acc: 0.7920\n",
      "Epoch 300/1499\n",
      "----------\n",
      "train Loss: 0.8642 Acc: 0.7660\n",
      "val Loss: 0.8833 Acc: 0.7280\n",
      "test Loss: 0.8565 Acc: 0.7880\n",
      "Epoch 301/1499\n",
      "----------\n",
      "train Loss: 0.8641 Acc: 0.7736\n",
      "val Loss: 0.8744 Acc: 0.7200\n",
      "test Loss: 0.8541 Acc: 0.7760\n",
      "Epoch 302/1499\n",
      "----------\n",
      "train Loss: 0.8641 Acc: 0.7680\n",
      "val Loss: 0.8770 Acc: 0.7320\n",
      "test Loss: 0.8591 Acc: 0.7640\n",
      "Epoch 303/1499\n",
      "----------\n",
      "train Loss: 0.8644 Acc: 0.7616\n",
      "val Loss: 0.8862 Acc: 0.6960\n",
      "test Loss: 0.8585 Acc: 0.7800\n",
      "Epoch 304/1499\n",
      "----------\n",
      "train Loss: 0.8626 Acc: 0.7693\n",
      "val Loss: 0.8829 Acc: 0.7000\n",
      "test Loss: 0.8617 Acc: 0.7960\n",
      "Epoch 305/1499\n",
      "----------\n",
      "train Loss: 0.8649 Acc: 0.7656\n",
      "val Loss: 0.8877 Acc: 0.7320\n",
      "test Loss: 0.8568 Acc: 0.7760\n",
      "Epoch 306/1499\n",
      "----------\n",
      "train Loss: 0.8650 Acc: 0.7613\n",
      "val Loss: 0.8821 Acc: 0.7200\n",
      "test Loss: 0.8536 Acc: 0.7840\n",
      "Epoch 307/1499\n",
      "----------\n",
      "train Loss: 0.8629 Acc: 0.7629\n",
      "val Loss: 0.8823 Acc: 0.6960\n",
      "test Loss: 0.8596 Acc: 0.7920\n",
      "Epoch 308/1499\n",
      "----------\n",
      "train Loss: 0.8616 Acc: 0.7709\n",
      "val Loss: 0.8739 Acc: 0.7080\n",
      "test Loss: 0.8517 Acc: 0.7920\n",
      "Epoch 309/1499\n",
      "----------\n",
      "train Loss: 0.8605 Acc: 0.7700\n",
      "val Loss: 0.8743 Acc: 0.7120\n",
      "test Loss: 0.8538 Acc: 0.7760\n",
      "Epoch 310/1499\n",
      "----------\n",
      "train Loss: 0.8608 Acc: 0.7720\n",
      "val Loss: 0.8723 Acc: 0.7200\n",
      "test Loss: 0.8516 Acc: 0.7840\n",
      "Epoch 311/1499\n",
      "----------\n",
      "train Loss: 0.8601 Acc: 0.7724\n",
      "val Loss: 0.8782 Acc: 0.7200\n",
      "test Loss: 0.8502 Acc: 0.7880\n",
      "Epoch 312/1499\n",
      "----------\n",
      "train Loss: 0.8590 Acc: 0.7749\n",
      "val Loss: 0.8844 Acc: 0.7200\n",
      "test Loss: 0.8518 Acc: 0.7720\n",
      "Epoch 313/1499\n",
      "----------\n",
      "train Loss: 0.8588 Acc: 0.7762\n",
      "val Loss: 0.8818 Acc: 0.6960\n",
      "test Loss: 0.8566 Acc: 0.7600\n",
      "Epoch 314/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.8599 Acc: 0.7744\n",
      "val Loss: 0.8732 Acc: 0.7360\n",
      "test Loss: 0.8491 Acc: 0.7920\n",
      "Epoch 315/1499\n",
      "----------\n",
      "train Loss: 0.8573 Acc: 0.7716\n",
      "val Loss: 0.8758 Acc: 0.7040\n",
      "test Loss: 0.8501 Acc: 0.7760\n",
      "Epoch 316/1499\n",
      "----------\n",
      "train Loss: 0.8573 Acc: 0.7687\n",
      "val Loss: 0.8705 Acc: 0.7200\n",
      "test Loss: 0.8471 Acc: 0.8120\n",
      "Epoch 317/1499\n",
      "----------\n",
      "train Loss: 0.8575 Acc: 0.7693\n",
      "val Loss: 0.8808 Acc: 0.6960\n",
      "test Loss: 0.8574 Acc: 0.7760\n",
      "Epoch 318/1499\n",
      "----------\n",
      "train Loss: 0.8560 Acc: 0.7753\n",
      "val Loss: 0.8662 Acc: 0.7320\n",
      "test Loss: 0.8502 Acc: 0.7960\n",
      "Epoch 319/1499\n",
      "----------\n",
      "train Loss: 0.8551 Acc: 0.7760\n",
      "val Loss: 0.8676 Acc: 0.7400\n",
      "test Loss: 0.8513 Acc: 0.7920\n",
      "Epoch 320/1499\n",
      "----------\n",
      "train Loss: 0.8540 Acc: 0.7787\n",
      "val Loss: 0.8699 Acc: 0.7280\n",
      "test Loss: 0.8490 Acc: 0.7880\n",
      "Epoch 321/1499\n",
      "----------\n",
      "train Loss: 0.8543 Acc: 0.7747\n",
      "val Loss: 0.8774 Acc: 0.6840\n",
      "test Loss: 0.8528 Acc: 0.7800\n",
      "Epoch 322/1499\n",
      "----------\n",
      "train Loss: 0.8532 Acc: 0.7760\n",
      "val Loss: 0.8737 Acc: 0.7080\n",
      "test Loss: 0.8389 Acc: 0.8080\n",
      "Epoch 323/1499\n",
      "----------\n",
      "train Loss: 0.8535 Acc: 0.7787\n",
      "val Loss: 0.8701 Acc: 0.7360\n",
      "test Loss: 0.8449 Acc: 0.7800\n",
      "Epoch 324/1499\n",
      "----------\n",
      "train Loss: 0.8533 Acc: 0.7767\n",
      "val Loss: 0.8715 Acc: 0.7200\n",
      "test Loss: 0.8428 Acc: 0.7840\n",
      "Epoch 325/1499\n",
      "----------\n",
      "train Loss: 0.8524 Acc: 0.7762\n",
      "val Loss: 0.8764 Acc: 0.7160\n",
      "test Loss: 0.8392 Acc: 0.7920\n",
      "Epoch 326/1499\n",
      "----------\n",
      "train Loss: 0.8511 Acc: 0.7800\n",
      "val Loss: 0.8679 Acc: 0.7000\n",
      "test Loss: 0.8380 Acc: 0.7960\n",
      "Epoch 327/1499\n",
      "----------\n",
      "train Loss: 0.8535 Acc: 0.7782\n",
      "val Loss: 0.8716 Acc: 0.7280\n",
      "test Loss: 0.8439 Acc: 0.7920\n",
      "Epoch 328/1499\n",
      "----------\n",
      "train Loss: 0.8511 Acc: 0.7784\n",
      "val Loss: 0.8619 Acc: 0.7400\n",
      "test Loss: 0.8439 Acc: 0.8080\n",
      "Epoch 329/1499\n",
      "----------\n",
      "train Loss: 0.8505 Acc: 0.7782\n",
      "val Loss: 0.8674 Acc: 0.7200\n",
      "test Loss: 0.8445 Acc: 0.8080\n",
      "Epoch 330/1499\n",
      "----------\n",
      "train Loss: 0.8492 Acc: 0.7811\n",
      "val Loss: 0.8738 Acc: 0.6800\n",
      "test Loss: 0.8481 Acc: 0.7960\n",
      "Epoch 331/1499\n",
      "----------\n",
      "train Loss: 0.8499 Acc: 0.7798\n",
      "val Loss: 0.8697 Acc: 0.7360\n",
      "test Loss: 0.8445 Acc: 0.8040\n",
      "Epoch 332/1499\n",
      "----------\n",
      "train Loss: 0.8511 Acc: 0.7693\n",
      "val Loss: 0.8750 Acc: 0.7080\n",
      "test Loss: 0.8370 Acc: 0.8080\n",
      "Epoch 333/1499\n",
      "----------\n",
      "train Loss: 0.8471 Acc: 0.7782\n",
      "val Loss: 0.8670 Acc: 0.7320\n",
      "test Loss: 0.8478 Acc: 0.7840\n",
      "Epoch 334/1499\n",
      "----------\n",
      "train Loss: 0.8476 Acc: 0.7771\n",
      "val Loss: 0.8660 Acc: 0.7320\n",
      "test Loss: 0.8418 Acc: 0.7920\n",
      "Epoch 335/1499\n",
      "----------\n",
      "train Loss: 0.8506 Acc: 0.7758\n",
      "val Loss: 0.8695 Acc: 0.7360\n",
      "test Loss: 0.8398 Acc: 0.7840\n",
      "Epoch 336/1499\n",
      "----------\n",
      "train Loss: 0.8467 Acc: 0.7778\n",
      "val Loss: 0.8628 Acc: 0.7240\n",
      "test Loss: 0.8467 Acc: 0.7760\n",
      "Epoch 337/1499\n",
      "----------\n",
      "train Loss: 0.8472 Acc: 0.7789\n",
      "val Loss: 0.8593 Acc: 0.7280\n",
      "test Loss: 0.8318 Acc: 0.8040\n",
      "Epoch 338/1499\n",
      "----------\n",
      "train Loss: 0.8473 Acc: 0.7753\n",
      "val Loss: 0.8645 Acc: 0.7320\n",
      "test Loss: 0.8429 Acc: 0.7920\n",
      "Epoch 339/1499\n",
      "----------\n",
      "train Loss: 0.8480 Acc: 0.7813\n",
      "val Loss: 0.8633 Acc: 0.7320\n",
      "test Loss: 0.8340 Acc: 0.7960\n",
      "Epoch 340/1499\n",
      "----------\n",
      "train Loss: 0.8445 Acc: 0.7758\n",
      "val Loss: 0.8700 Acc: 0.7240\n",
      "test Loss: 0.8346 Acc: 0.8000\n",
      "Epoch 341/1499\n",
      "----------\n",
      "train Loss: 0.8458 Acc: 0.7800\n",
      "val Loss: 0.8636 Acc: 0.7400\n",
      "test Loss: 0.8345 Acc: 0.8240\n",
      "Epoch 342/1499\n",
      "----------\n",
      "train Loss: 0.8470 Acc: 0.7824\n",
      "val Loss: 0.8575 Acc: 0.7560\n",
      "test Loss: 0.8403 Acc: 0.7960\n",
      "Epoch 343/1499\n",
      "----------\n",
      "train Loss: 0.8438 Acc: 0.7836\n",
      "val Loss: 0.8577 Acc: 0.7320\n",
      "test Loss: 0.8367 Acc: 0.8080\n",
      "Epoch 344/1499\n",
      "----------\n",
      "train Loss: 0.8429 Acc: 0.7818\n",
      "val Loss: 0.8571 Acc: 0.7480\n",
      "test Loss: 0.8500 Acc: 0.7840\n",
      "Epoch 345/1499\n",
      "----------\n",
      "train Loss: 0.8435 Acc: 0.7816\n",
      "val Loss: 0.8594 Acc: 0.7400\n",
      "test Loss: 0.8369 Acc: 0.7760\n",
      "Epoch 346/1499\n",
      "----------\n",
      "train Loss: 0.8414 Acc: 0.7844\n",
      "val Loss: 0.8554 Acc: 0.7480\n",
      "test Loss: 0.8311 Acc: 0.8280\n",
      "Epoch 347/1499\n",
      "----------\n",
      "train Loss: 0.8413 Acc: 0.7798\n",
      "val Loss: 0.8630 Acc: 0.7240\n",
      "test Loss: 0.8420 Acc: 0.7880\n",
      "Epoch 348/1499\n",
      "----------\n",
      "train Loss: 0.8415 Acc: 0.7824\n",
      "val Loss: 0.8662 Acc: 0.7400\n",
      "test Loss: 0.8288 Acc: 0.8000\n",
      "Epoch 349/1499\n",
      "----------\n",
      "train Loss: 0.8441 Acc: 0.7764\n",
      "val Loss: 0.8524 Acc: 0.7480\n",
      "test Loss: 0.8341 Acc: 0.7960\n",
      "Epoch 350/1499\n",
      "----------\n",
      "train Loss: 0.8420 Acc: 0.7840\n",
      "val Loss: 0.8530 Acc: 0.7680\n",
      "test Loss: 0.8267 Acc: 0.8200\n",
      "Epoch 351/1499\n",
      "----------\n",
      "train Loss: 0.8403 Acc: 0.7816\n",
      "val Loss: 0.8570 Acc: 0.7480\n",
      "test Loss: 0.8246 Acc: 0.8200\n",
      "Epoch 352/1499\n",
      "----------\n",
      "train Loss: 0.8415 Acc: 0.7762\n",
      "val Loss: 0.8561 Acc: 0.7760\n",
      "test Loss: 0.8374 Acc: 0.8000\n",
      "Epoch 353/1499\n",
      "----------\n",
      "train Loss: 0.8390 Acc: 0.7816\n",
      "val Loss: 0.8622 Acc: 0.7360\n",
      "test Loss: 0.8301 Acc: 0.8200\n",
      "Epoch 354/1499\n",
      "----------\n",
      "train Loss: 0.8400 Acc: 0.7827\n",
      "val Loss: 0.8542 Acc: 0.7600\n",
      "test Loss: 0.8274 Acc: 0.7960\n",
      "Epoch 355/1499\n",
      "----------\n",
      "train Loss: 0.8396 Acc: 0.7769\n",
      "val Loss: 0.8581 Acc: 0.7480\n",
      "test Loss: 0.8210 Acc: 0.8080\n",
      "Epoch 356/1499\n",
      "----------\n",
      "train Loss: 0.8380 Acc: 0.7802\n",
      "val Loss: 0.8592 Acc: 0.7400\n",
      "test Loss: 0.8259 Acc: 0.8120\n",
      "Epoch 357/1499\n",
      "----------\n",
      "train Loss: 0.8376 Acc: 0.7824\n",
      "val Loss: 0.8601 Acc: 0.7320\n",
      "test Loss: 0.8291 Acc: 0.8040\n",
      "Epoch 358/1499\n",
      "----------\n",
      "train Loss: 0.8381 Acc: 0.7802\n",
      "val Loss: 0.8518 Acc: 0.7560\n",
      "test Loss: 0.8358 Acc: 0.8000\n",
      "Epoch 359/1499\n",
      "----------\n",
      "train Loss: 0.8366 Acc: 0.7813\n",
      "val Loss: 0.8488 Acc: 0.7600\n",
      "test Loss: 0.8293 Acc: 0.8040\n",
      "Epoch 360/1499\n",
      "----------\n",
      "train Loss: 0.8395 Acc: 0.7822\n",
      "val Loss: 0.8495 Acc: 0.7520\n",
      "test Loss: 0.8340 Acc: 0.7920\n",
      "Epoch 361/1499\n",
      "----------\n",
      "train Loss: 0.8364 Acc: 0.7873\n",
      "val Loss: 0.8537 Acc: 0.7440\n",
      "test Loss: 0.8254 Acc: 0.8200\n",
      "Epoch 362/1499\n",
      "----------\n",
      "train Loss: 0.8375 Acc: 0.7811\n",
      "val Loss: 0.8595 Acc: 0.7400\n",
      "test Loss: 0.8229 Acc: 0.8040\n",
      "Epoch 363/1499\n",
      "----------\n",
      "train Loss: 0.8361 Acc: 0.7896\n",
      "val Loss: 0.8546 Acc: 0.7600\n",
      "test Loss: 0.8228 Acc: 0.8160\n",
      "Epoch 364/1499\n",
      "----------\n",
      "train Loss: 0.8346 Acc: 0.7869\n",
      "val Loss: 0.8507 Acc: 0.7520\n",
      "test Loss: 0.8192 Acc: 0.8120\n",
      "Epoch 365/1499\n",
      "----------\n",
      "train Loss: 0.8351 Acc: 0.7822\n",
      "val Loss: 0.8484 Acc: 0.7480\n",
      "test Loss: 0.8276 Acc: 0.7840\n",
      "Epoch 366/1499\n",
      "----------\n",
      "train Loss: 0.8346 Acc: 0.7849\n",
      "val Loss: 0.8476 Acc: 0.7640\n",
      "test Loss: 0.8216 Acc: 0.8200\n",
      "Epoch 367/1499\n",
      "----------\n",
      "train Loss: 0.8366 Acc: 0.7844\n",
      "val Loss: 0.8379 Acc: 0.7800\n",
      "test Loss: 0.8233 Acc: 0.8200\n",
      "Epoch 368/1499\n",
      "----------\n",
      "train Loss: 0.8344 Acc: 0.7853\n",
      "val Loss: 0.8459 Acc: 0.7640\n",
      "test Loss: 0.8270 Acc: 0.8040\n",
      "Epoch 369/1499\n",
      "----------\n",
      "train Loss: 0.8356 Acc: 0.7798\n",
      "val Loss: 0.8531 Acc: 0.7520\n",
      "test Loss: 0.8350 Acc: 0.7920\n",
      "Epoch 370/1499\n",
      "----------\n",
      "train Loss: 0.8344 Acc: 0.7813\n",
      "val Loss: 0.8552 Acc: 0.7680\n",
      "test Loss: 0.8241 Acc: 0.8120\n",
      "Epoch 371/1499\n",
      "----------\n",
      "train Loss: 0.8343 Acc: 0.7858\n",
      "val Loss: 0.8467 Acc: 0.7720\n",
      "test Loss: 0.8235 Acc: 0.8040\n",
      "Epoch 372/1499\n",
      "----------\n",
      "train Loss: 0.8338 Acc: 0.7811\n",
      "val Loss: 0.8468 Acc: 0.7600\n",
      "test Loss: 0.8239 Acc: 0.8200\n",
      "Epoch 373/1499\n",
      "----------\n",
      "train Loss: 0.8317 Acc: 0.7911\n",
      "val Loss: 0.8501 Acc: 0.7520\n",
      "test Loss: 0.8252 Acc: 0.8040\n",
      "Epoch 374/1499\n",
      "----------\n",
      "train Loss: 0.8318 Acc: 0.7856\n",
      "val Loss: 0.8525 Acc: 0.7440\n",
      "test Loss: 0.8258 Acc: 0.8080\n",
      "Epoch 375/1499\n",
      "----------\n",
      "train Loss: 0.8327 Acc: 0.7822\n",
      "val Loss: 0.8520 Acc: 0.7760\n",
      "test Loss: 0.8145 Acc: 0.8040\n",
      "Epoch 376/1499\n",
      "----------\n",
      "train Loss: 0.8299 Acc: 0.7873\n",
      "val Loss: 0.8500 Acc: 0.7320\n",
      "test Loss: 0.8300 Acc: 0.7920\n",
      "Epoch 377/1499\n",
      "----------\n",
      "train Loss: 0.8301 Acc: 0.7876\n",
      "val Loss: 0.8450 Acc: 0.7480\n",
      "test Loss: 0.8197 Acc: 0.8120\n",
      "Epoch 378/1499\n",
      "----------\n",
      "train Loss: 0.8297 Acc: 0.7864\n",
      "val Loss: 0.8431 Acc: 0.7800\n",
      "test Loss: 0.8182 Acc: 0.7920\n",
      "Epoch 379/1499\n",
      "----------\n",
      "train Loss: 0.8307 Acc: 0.7896\n",
      "val Loss: 0.8401 Acc: 0.7640\n",
      "test Loss: 0.8204 Acc: 0.8040\n",
      "Epoch 380/1499\n",
      "----------\n",
      "train Loss: 0.8296 Acc: 0.7831\n",
      "val Loss: 0.8516 Acc: 0.7600\n",
      "test Loss: 0.8184 Acc: 0.8120\n",
      "Epoch 381/1499\n",
      "----------\n",
      "train Loss: 0.8316 Acc: 0.7820\n",
      "val Loss: 0.8487 Acc: 0.7600\n",
      "test Loss: 0.8171 Acc: 0.8120\n",
      "Epoch 382/1499\n",
      "----------\n",
      "train Loss: 0.8298 Acc: 0.7820\n",
      "val Loss: 0.8497 Acc: 0.7680\n",
      "test Loss: 0.8255 Acc: 0.7960\n",
      "Epoch 383/1499\n",
      "----------\n",
      "train Loss: 0.8291 Acc: 0.7844\n",
      "val Loss: 0.8402 Acc: 0.7600\n",
      "test Loss: 0.8171 Acc: 0.8120\n",
      "Epoch 384/1499\n",
      "----------\n",
      "train Loss: 0.8284 Acc: 0.7869\n",
      "val Loss: 0.8457 Acc: 0.7520\n",
      "test Loss: 0.8190 Acc: 0.8120\n",
      "Epoch 385/1499\n",
      "----------\n",
      "train Loss: 0.8292 Acc: 0.7820\n",
      "val Loss: 0.8414 Acc: 0.7560\n",
      "test Loss: 0.8196 Acc: 0.8200\n",
      "Epoch 386/1499\n",
      "----------\n",
      "train Loss: 0.8287 Acc: 0.7793\n",
      "val Loss: 0.8455 Acc: 0.7480\n",
      "test Loss: 0.8102 Acc: 0.8160\n",
      "Epoch 387/1499\n",
      "----------\n",
      "train Loss: 0.8262 Acc: 0.7836\n",
      "val Loss: 0.8421 Acc: 0.7640\n",
      "test Loss: 0.8155 Acc: 0.8160\n",
      "Epoch 388/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.8289 Acc: 0.7836\n",
      "val Loss: 0.8381 Acc: 0.7800\n",
      "test Loss: 0.8198 Acc: 0.8040\n",
      "Epoch 389/1499\n",
      "----------\n",
      "train Loss: 0.8274 Acc: 0.7887\n",
      "val Loss: 0.8342 Acc: 0.7720\n",
      "test Loss: 0.8172 Acc: 0.8280\n",
      "Epoch 390/1499\n",
      "----------\n",
      "train Loss: 0.8259 Acc: 0.7851\n",
      "val Loss: 0.8429 Acc: 0.7600\n",
      "test Loss: 0.8136 Acc: 0.8000\n",
      "Epoch 391/1499\n",
      "----------\n",
      "train Loss: 0.8251 Acc: 0.7891\n",
      "val Loss: 0.8496 Acc: 0.7440\n",
      "test Loss: 0.8191 Acc: 0.8040\n",
      "Epoch 392/1499\n",
      "----------\n",
      "train Loss: 0.8264 Acc: 0.7862\n",
      "val Loss: 0.8436 Acc: 0.7440\n",
      "test Loss: 0.8098 Acc: 0.8080\n",
      "Epoch 393/1499\n",
      "----------\n",
      "train Loss: 0.8252 Acc: 0.7862\n",
      "val Loss: 0.8388 Acc: 0.7600\n",
      "test Loss: 0.8218 Acc: 0.8080\n",
      "Epoch 394/1499\n",
      "----------\n",
      "train Loss: 0.8229 Acc: 0.7918\n",
      "val Loss: 0.8417 Acc: 0.7720\n",
      "test Loss: 0.8183 Acc: 0.8120\n",
      "Epoch 395/1499\n",
      "----------\n",
      "train Loss: 0.8247 Acc: 0.7907\n",
      "val Loss: 0.8489 Acc: 0.7600\n",
      "test Loss: 0.8126 Acc: 0.8160\n",
      "Epoch 396/1499\n",
      "----------\n",
      "train Loss: 0.8230 Acc: 0.7880\n",
      "val Loss: 0.8476 Acc: 0.7600\n",
      "test Loss: 0.8184 Acc: 0.7920\n",
      "Epoch 397/1499\n",
      "----------\n",
      "train Loss: 0.8235 Acc: 0.7853\n",
      "val Loss: 0.8427 Acc: 0.7600\n",
      "test Loss: 0.8118 Acc: 0.8160\n",
      "Epoch 398/1499\n",
      "----------\n",
      "train Loss: 0.8253 Acc: 0.7871\n",
      "val Loss: 0.8382 Acc: 0.7720\n",
      "test Loss: 0.8089 Acc: 0.8280\n",
      "Epoch 399/1499\n",
      "----------\n",
      "train Loss: 0.8219 Acc: 0.7902\n",
      "val Loss: 0.8338 Acc: 0.7800\n",
      "test Loss: 0.8235 Acc: 0.8000\n",
      "Epoch 400/1499\n",
      "----------\n",
      "train Loss: 0.8234 Acc: 0.7864\n",
      "val Loss: 0.8436 Acc: 0.7600\n",
      "test Loss: 0.8140 Acc: 0.8000\n",
      "Epoch 401/1499\n",
      "----------\n",
      "train Loss: 0.8226 Acc: 0.7869\n",
      "val Loss: 0.8439 Acc: 0.7560\n",
      "test Loss: 0.8121 Acc: 0.8160\n",
      "Epoch 402/1499\n",
      "----------\n",
      "train Loss: 0.8220 Acc: 0.7867\n",
      "val Loss: 0.8421 Acc: 0.7680\n",
      "test Loss: 0.8043 Acc: 0.8240\n",
      "Epoch 403/1499\n",
      "----------\n",
      "train Loss: 0.8211 Acc: 0.7911\n",
      "val Loss: 0.8400 Acc: 0.7520\n",
      "test Loss: 0.8168 Acc: 0.8000\n",
      "Epoch 404/1499\n",
      "----------\n",
      "train Loss: 0.8208 Acc: 0.7916\n",
      "val Loss: 0.8462 Acc: 0.7480\n",
      "test Loss: 0.8103 Acc: 0.8160\n",
      "Epoch 405/1499\n",
      "----------\n",
      "train Loss: 0.8206 Acc: 0.7880\n",
      "val Loss: 0.8435 Acc: 0.7560\n",
      "test Loss: 0.8086 Acc: 0.8160\n",
      "Epoch 406/1499\n",
      "----------\n",
      "train Loss: 0.8216 Acc: 0.7891\n",
      "val Loss: 0.8336 Acc: 0.7520\n",
      "test Loss: 0.8109 Acc: 0.8160\n",
      "Epoch 407/1499\n",
      "----------\n",
      "train Loss: 0.8201 Acc: 0.7893\n",
      "val Loss: 0.8427 Acc: 0.7720\n",
      "test Loss: 0.8074 Acc: 0.8120\n",
      "Epoch 408/1499\n",
      "----------\n",
      "train Loss: 0.8217 Acc: 0.7862\n",
      "val Loss: 0.8402 Acc: 0.7600\n",
      "test Loss: 0.8092 Acc: 0.8080\n",
      "Epoch 409/1499\n",
      "----------\n",
      "train Loss: 0.8211 Acc: 0.7862\n",
      "val Loss: 0.8327 Acc: 0.7560\n",
      "test Loss: 0.8117 Acc: 0.8040\n",
      "Epoch 410/1499\n",
      "----------\n",
      "train Loss: 0.8194 Acc: 0.7838\n",
      "val Loss: 0.8408 Acc: 0.7480\n",
      "test Loss: 0.8166 Acc: 0.7880\n",
      "Epoch 411/1499\n",
      "----------\n",
      "train Loss: 0.8186 Acc: 0.7893\n",
      "val Loss: 0.8351 Acc: 0.7760\n",
      "test Loss: 0.8014 Acc: 0.8200\n",
      "Epoch 412/1499\n",
      "----------\n",
      "train Loss: 0.8174 Acc: 0.7929\n",
      "val Loss: 0.8316 Acc: 0.7680\n",
      "test Loss: 0.8186 Acc: 0.8000\n",
      "Epoch 413/1499\n",
      "----------\n",
      "train Loss: 0.8172 Acc: 0.7960\n",
      "val Loss: 0.8290 Acc: 0.7720\n",
      "test Loss: 0.8128 Acc: 0.8120\n",
      "Epoch 414/1499\n",
      "----------\n",
      "train Loss: 0.8179 Acc: 0.7902\n",
      "val Loss: 0.8305 Acc: 0.7840\n",
      "test Loss: 0.8012 Acc: 0.8200\n",
      "Epoch 415/1499\n",
      "----------\n",
      "train Loss: 0.8179 Acc: 0.7920\n",
      "val Loss: 0.8455 Acc: 0.7400\n",
      "test Loss: 0.8162 Acc: 0.7960\n",
      "Epoch 416/1499\n",
      "----------\n",
      "train Loss: 0.8164 Acc: 0.7931\n",
      "val Loss: 0.8288 Acc: 0.7720\n",
      "test Loss: 0.8143 Acc: 0.8040\n",
      "Epoch 417/1499\n",
      "----------\n",
      "train Loss: 0.8178 Acc: 0.7880\n",
      "val Loss: 0.8380 Acc: 0.7480\n",
      "test Loss: 0.8007 Acc: 0.8080\n",
      "Epoch 418/1499\n",
      "----------\n",
      "train Loss: 0.8179 Acc: 0.7889\n",
      "val Loss: 0.8353 Acc: 0.7720\n",
      "test Loss: 0.8084 Acc: 0.8080\n",
      "Epoch 419/1499\n",
      "----------\n",
      "train Loss: 0.8177 Acc: 0.7851\n",
      "val Loss: 0.8289 Acc: 0.7720\n",
      "test Loss: 0.8098 Acc: 0.7840\n",
      "Epoch 420/1499\n",
      "----------\n",
      "train Loss: 0.8148 Acc: 0.7929\n",
      "val Loss: 0.8337 Acc: 0.7480\n",
      "test Loss: 0.8013 Acc: 0.8240\n",
      "Epoch 421/1499\n",
      "----------\n",
      "train Loss: 0.8138 Acc: 0.7911\n",
      "val Loss: 0.8362 Acc: 0.7600\n",
      "test Loss: 0.7953 Acc: 0.8400\n",
      "Epoch 422/1499\n",
      "----------\n",
      "train Loss: 0.8142 Acc: 0.7896\n",
      "val Loss: 0.8328 Acc: 0.7720\n",
      "test Loss: 0.8112 Acc: 0.8040\n",
      "Epoch 423/1499\n",
      "----------\n",
      "train Loss: 0.8152 Acc: 0.7931\n",
      "val Loss: 0.8392 Acc: 0.7680\n",
      "test Loss: 0.7983 Acc: 0.8160\n",
      "Epoch 424/1499\n",
      "----------\n",
      "train Loss: 0.8146 Acc: 0.7911\n",
      "val Loss: 0.8258 Acc: 0.7680\n",
      "test Loss: 0.8055 Acc: 0.8040\n",
      "Epoch 425/1499\n",
      "----------\n",
      "train Loss: 0.8146 Acc: 0.7891\n",
      "val Loss: 0.8275 Acc: 0.7680\n",
      "test Loss: 0.8042 Acc: 0.8280\n",
      "Epoch 426/1499\n",
      "----------\n",
      "train Loss: 0.8138 Acc: 0.7922\n",
      "val Loss: 0.8282 Acc: 0.7840\n",
      "test Loss: 0.8115 Acc: 0.7960\n",
      "Epoch 427/1499\n",
      "----------\n",
      "train Loss: 0.8115 Acc: 0.7927\n",
      "val Loss: 0.8319 Acc: 0.7560\n",
      "test Loss: 0.7940 Acc: 0.8360\n",
      "Epoch 428/1499\n",
      "----------\n",
      "train Loss: 0.8151 Acc: 0.7876\n",
      "val Loss: 0.8264 Acc: 0.7440\n",
      "test Loss: 0.8050 Acc: 0.8160\n",
      "Epoch 429/1499\n",
      "----------\n",
      "train Loss: 0.8144 Acc: 0.7880\n",
      "val Loss: 0.8306 Acc: 0.7640\n",
      "test Loss: 0.8018 Acc: 0.8160\n",
      "Epoch 430/1499\n",
      "----------\n",
      "train Loss: 0.8127 Acc: 0.7891\n",
      "val Loss: 0.8262 Acc: 0.7720\n",
      "test Loss: 0.8011 Acc: 0.8120\n",
      "Epoch 431/1499\n",
      "----------\n",
      "train Loss: 0.8114 Acc: 0.7931\n",
      "val Loss: 0.8208 Acc: 0.7920\n",
      "test Loss: 0.8014 Acc: 0.8320\n",
      "Epoch 432/1499\n",
      "----------\n",
      "train Loss: 0.8112 Acc: 0.7924\n",
      "val Loss: 0.8265 Acc: 0.7600\n",
      "test Loss: 0.8067 Acc: 0.7920\n",
      "Epoch 433/1499\n",
      "----------\n",
      "train Loss: 0.8123 Acc: 0.7896\n",
      "val Loss: 0.8306 Acc: 0.7800\n",
      "test Loss: 0.7947 Acc: 0.8360\n",
      "Epoch 434/1499\n",
      "----------\n",
      "train Loss: 0.8104 Acc: 0.7920\n",
      "val Loss: 0.8279 Acc: 0.7760\n",
      "test Loss: 0.7991 Acc: 0.8320\n",
      "Epoch 435/1499\n",
      "----------\n",
      "train Loss: 0.8113 Acc: 0.7931\n",
      "val Loss: 0.8303 Acc: 0.7720\n",
      "test Loss: 0.7990 Acc: 0.8320\n",
      "Epoch 436/1499\n",
      "----------\n",
      "train Loss: 0.8132 Acc: 0.7907\n",
      "val Loss: 0.8327 Acc: 0.7600\n",
      "test Loss: 0.7985 Acc: 0.8280\n",
      "Epoch 437/1499\n",
      "----------\n",
      "train Loss: 0.8106 Acc: 0.7951\n",
      "val Loss: 0.8300 Acc: 0.7760\n",
      "test Loss: 0.8013 Acc: 0.8160\n",
      "Epoch 438/1499\n",
      "----------\n",
      "train Loss: 0.8099 Acc: 0.7902\n",
      "val Loss: 0.8249 Acc: 0.7760\n",
      "test Loss: 0.7986 Acc: 0.8160\n",
      "Epoch 439/1499\n",
      "----------\n",
      "train Loss: 0.8095 Acc: 0.7929\n",
      "val Loss: 0.8265 Acc: 0.7680\n",
      "test Loss: 0.7990 Acc: 0.8160\n",
      "Epoch 440/1499\n",
      "----------\n",
      "train Loss: 0.8111 Acc: 0.7898\n",
      "val Loss: 0.8323 Acc: 0.7680\n",
      "test Loss: 0.7994 Acc: 0.8160\n",
      "Epoch 441/1499\n",
      "----------\n",
      "train Loss: 0.8101 Acc: 0.7942\n",
      "val Loss: 0.8297 Acc: 0.7560\n",
      "test Loss: 0.7961 Acc: 0.8080\n",
      "Epoch 442/1499\n",
      "----------\n",
      "train Loss: 0.8104 Acc: 0.7947\n",
      "val Loss: 0.8225 Acc: 0.7760\n",
      "test Loss: 0.7902 Acc: 0.8360\n",
      "Epoch 443/1499\n",
      "----------\n",
      "train Loss: 0.8105 Acc: 0.7933\n",
      "val Loss: 0.8269 Acc: 0.7680\n",
      "test Loss: 0.7967 Acc: 0.8320\n",
      "Epoch 444/1499\n",
      "----------\n",
      "train Loss: 0.8099 Acc: 0.7938\n",
      "val Loss: 0.8246 Acc: 0.7600\n",
      "test Loss: 0.7953 Acc: 0.8200\n",
      "Epoch 445/1499\n",
      "----------\n",
      "train Loss: 0.8091 Acc: 0.7924\n",
      "val Loss: 0.8256 Acc: 0.7640\n",
      "test Loss: 0.7932 Acc: 0.8400\n",
      "Epoch 446/1499\n",
      "----------\n",
      "train Loss: 0.8073 Acc: 0.7951\n",
      "val Loss: 0.8203 Acc: 0.7720\n",
      "test Loss: 0.7980 Acc: 0.8200\n",
      "Epoch 447/1499\n",
      "----------\n",
      "train Loss: 0.8075 Acc: 0.7956\n",
      "val Loss: 0.8261 Acc: 0.7680\n",
      "test Loss: 0.7964 Acc: 0.8160\n",
      "Epoch 448/1499\n",
      "----------\n",
      "train Loss: 0.8084 Acc: 0.7967\n",
      "val Loss: 0.8234 Acc: 0.7680\n",
      "test Loss: 0.7994 Acc: 0.8200\n",
      "Epoch 449/1499\n",
      "----------\n",
      "train Loss: 0.8073 Acc: 0.7909\n",
      "val Loss: 0.8235 Acc: 0.7800\n",
      "test Loss: 0.7904 Acc: 0.8240\n",
      "Epoch 450/1499\n",
      "----------\n",
      "train Loss: 0.8082 Acc: 0.7913\n",
      "val Loss: 0.8285 Acc: 0.7520\n",
      "test Loss: 0.7961 Acc: 0.8400\n",
      "Epoch 451/1499\n",
      "----------\n",
      "train Loss: 0.8054 Acc: 0.7984\n",
      "val Loss: 0.8294 Acc: 0.7600\n",
      "test Loss: 0.7862 Acc: 0.8440\n",
      "Epoch 452/1499\n",
      "----------\n",
      "train Loss: 0.8076 Acc: 0.7933\n",
      "val Loss: 0.8198 Acc: 0.7800\n",
      "test Loss: 0.7934 Acc: 0.8280\n",
      "Epoch 453/1499\n",
      "----------\n",
      "train Loss: 0.8080 Acc: 0.7918\n",
      "val Loss: 0.8190 Acc: 0.8000\n",
      "test Loss: 0.7906 Acc: 0.8160\n",
      "Epoch 454/1499\n",
      "----------\n",
      "train Loss: 0.8052 Acc: 0.7931\n",
      "val Loss: 0.8281 Acc: 0.7760\n",
      "test Loss: 0.7917 Acc: 0.8400\n",
      "Epoch 455/1499\n",
      "----------\n",
      "train Loss: 0.8064 Acc: 0.7893\n",
      "val Loss: 0.8183 Acc: 0.7920\n",
      "test Loss: 0.8002 Acc: 0.8120\n",
      "Epoch 456/1499\n",
      "----------\n",
      "train Loss: 0.8060 Acc: 0.7953\n",
      "val Loss: 0.8174 Acc: 0.7760\n",
      "test Loss: 0.7924 Acc: 0.8360\n",
      "Epoch 457/1499\n",
      "----------\n",
      "train Loss: 0.8068 Acc: 0.7889\n",
      "val Loss: 0.8243 Acc: 0.7760\n",
      "test Loss: 0.7900 Acc: 0.8200\n",
      "Epoch 458/1499\n",
      "----------\n",
      "train Loss: 0.8049 Acc: 0.7929\n",
      "val Loss: 0.8211 Acc: 0.7720\n",
      "test Loss: 0.7872 Acc: 0.8360\n",
      "Epoch 459/1499\n",
      "----------\n",
      "train Loss: 0.8044 Acc: 0.7953\n",
      "val Loss: 0.8246 Acc: 0.7520\n",
      "test Loss: 0.7953 Acc: 0.8120\n",
      "Epoch 460/1499\n",
      "----------\n",
      "train Loss: 0.8056 Acc: 0.7960\n",
      "val Loss: 0.8255 Acc: 0.7560\n",
      "test Loss: 0.7895 Acc: 0.7960\n",
      "Epoch 461/1499\n",
      "----------\n",
      "train Loss: 0.8050 Acc: 0.7949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.8226 Acc: 0.7640\n",
      "test Loss: 0.7977 Acc: 0.8280\n",
      "Epoch 462/1499\n",
      "----------\n",
      "train Loss: 0.8033 Acc: 0.7967\n",
      "val Loss: 0.8303 Acc: 0.7440\n",
      "test Loss: 0.7983 Acc: 0.8000\n",
      "Epoch 463/1499\n",
      "----------\n",
      "train Loss: 0.8050 Acc: 0.7971\n",
      "val Loss: 0.8248 Acc: 0.7800\n",
      "test Loss: 0.7980 Acc: 0.8320\n",
      "Epoch 464/1499\n",
      "----------\n",
      "train Loss: 0.8028 Acc: 0.7967\n",
      "val Loss: 0.8137 Acc: 0.7720\n",
      "test Loss: 0.7941 Acc: 0.8040\n",
      "Epoch 465/1499\n",
      "----------\n",
      "train Loss: 0.8036 Acc: 0.8011\n",
      "val Loss: 0.8239 Acc: 0.7600\n",
      "test Loss: 0.7981 Acc: 0.7960\n",
      "Epoch 466/1499\n",
      "----------\n",
      "train Loss: 0.8027 Acc: 0.7949\n",
      "val Loss: 0.8318 Acc: 0.7400\n",
      "test Loss: 0.7921 Acc: 0.8120\n",
      "Epoch 467/1499\n",
      "----------\n",
      "train Loss: 0.8026 Acc: 0.7909\n",
      "val Loss: 0.8133 Acc: 0.7680\n",
      "test Loss: 0.8032 Acc: 0.8240\n",
      "Epoch 468/1499\n",
      "----------\n",
      "train Loss: 0.8008 Acc: 0.7944\n",
      "val Loss: 0.8218 Acc: 0.7560\n",
      "test Loss: 0.7927 Acc: 0.8200\n",
      "Epoch 469/1499\n",
      "----------\n",
      "train Loss: 0.8023 Acc: 0.7964\n",
      "val Loss: 0.8116 Acc: 0.7920\n",
      "test Loss: 0.7869 Acc: 0.8200\n",
      "Epoch 470/1499\n",
      "----------\n",
      "train Loss: 0.8013 Acc: 0.7958\n",
      "val Loss: 0.8250 Acc: 0.7680\n",
      "test Loss: 0.7846 Acc: 0.8280\n",
      "Epoch 471/1499\n",
      "----------\n",
      "train Loss: 0.8015 Acc: 0.7964\n",
      "val Loss: 0.8192 Acc: 0.7760\n",
      "test Loss: 0.7881 Acc: 0.8240\n",
      "Epoch 472/1499\n",
      "----------\n",
      "train Loss: 0.8017 Acc: 0.7956\n",
      "val Loss: 0.8194 Acc: 0.7440\n",
      "test Loss: 0.7901 Acc: 0.8280\n",
      "Epoch 473/1499\n",
      "----------\n",
      "train Loss: 0.8026 Acc: 0.7938\n",
      "val Loss: 0.8157 Acc: 0.7720\n",
      "test Loss: 0.7909 Acc: 0.8240\n",
      "Epoch 474/1499\n",
      "----------\n",
      "train Loss: 0.8013 Acc: 0.7976\n",
      "val Loss: 0.8154 Acc: 0.7800\n",
      "test Loss: 0.7824 Acc: 0.8240\n",
      "Epoch 475/1499\n",
      "----------\n",
      "train Loss: 0.8010 Acc: 0.7942\n",
      "val Loss: 0.8111 Acc: 0.7880\n",
      "test Loss: 0.7877 Acc: 0.8400\n",
      "Epoch 476/1499\n",
      "----------\n",
      "train Loss: 0.8001 Acc: 0.8002\n",
      "val Loss: 0.8191 Acc: 0.7720\n",
      "test Loss: 0.7880 Acc: 0.8240\n",
      "Epoch 477/1499\n",
      "----------\n",
      "train Loss: 0.8013 Acc: 0.7969\n",
      "val Loss: 0.8199 Acc: 0.7680\n",
      "test Loss: 0.7806 Acc: 0.8440\n",
      "Epoch 478/1499\n",
      "----------\n",
      "train Loss: 0.7982 Acc: 0.8020\n",
      "val Loss: 0.8141 Acc: 0.7720\n",
      "test Loss: 0.7865 Acc: 0.8280\n",
      "Epoch 479/1499\n",
      "----------\n",
      "train Loss: 0.8024 Acc: 0.7931\n",
      "val Loss: 0.8232 Acc: 0.7600\n",
      "test Loss: 0.7891 Acc: 0.8320\n",
      "Epoch 480/1499\n",
      "----------\n",
      "train Loss: 0.7990 Acc: 0.8009\n",
      "val Loss: 0.8198 Acc: 0.7640\n",
      "test Loss: 0.7835 Acc: 0.8280\n",
      "Epoch 481/1499\n",
      "----------\n",
      "train Loss: 0.7984 Acc: 0.8004\n",
      "val Loss: 0.8164 Acc: 0.7720\n",
      "test Loss: 0.7894 Acc: 0.8160\n",
      "Epoch 482/1499\n",
      "----------\n",
      "train Loss: 0.7989 Acc: 0.8000\n",
      "val Loss: 0.8129 Acc: 0.7840\n",
      "test Loss: 0.7880 Acc: 0.8200\n",
      "Epoch 483/1499\n",
      "----------\n",
      "train Loss: 0.7975 Acc: 0.8020\n",
      "val Loss: 0.8148 Acc: 0.7800\n",
      "test Loss: 0.7852 Acc: 0.8080\n",
      "Epoch 484/1499\n",
      "----------\n",
      "train Loss: 0.7990 Acc: 0.7978\n",
      "val Loss: 0.8139 Acc: 0.7760\n",
      "test Loss: 0.7877 Acc: 0.8160\n",
      "Epoch 485/1499\n",
      "----------\n",
      "train Loss: 0.7982 Acc: 0.7978\n",
      "val Loss: 0.8165 Acc: 0.7760\n",
      "test Loss: 0.7838 Acc: 0.8280\n",
      "Epoch 486/1499\n",
      "----------\n",
      "train Loss: 0.7954 Acc: 0.8036\n",
      "val Loss: 0.8144 Acc: 0.7840\n",
      "test Loss: 0.7898 Acc: 0.8200\n",
      "Epoch 487/1499\n",
      "----------\n",
      "train Loss: 0.7983 Acc: 0.7953\n",
      "val Loss: 0.8183 Acc: 0.7680\n",
      "test Loss: 0.7956 Acc: 0.8160\n",
      "Epoch 488/1499\n",
      "----------\n",
      "train Loss: 0.7987 Acc: 0.7947\n",
      "val Loss: 0.8119 Acc: 0.7880\n",
      "test Loss: 0.7827 Acc: 0.8400\n",
      "Epoch 489/1499\n",
      "----------\n",
      "train Loss: 0.7982 Acc: 0.7953\n",
      "val Loss: 0.8076 Acc: 0.7920\n",
      "test Loss: 0.7887 Acc: 0.8320\n",
      "Epoch 490/1499\n",
      "----------\n",
      "train Loss: 0.7977 Acc: 0.7976\n",
      "val Loss: 0.8085 Acc: 0.7840\n",
      "test Loss: 0.7899 Acc: 0.8160\n",
      "Epoch 491/1499\n",
      "----------\n",
      "train Loss: 0.7964 Acc: 0.7967\n",
      "val Loss: 0.8104 Acc: 0.7720\n",
      "test Loss: 0.7872 Acc: 0.8160\n",
      "Epoch 492/1499\n",
      "----------\n",
      "train Loss: 0.7992 Acc: 0.7927\n",
      "val Loss: 0.8177 Acc: 0.7680\n",
      "test Loss: 0.7767 Acc: 0.8480\n",
      "Epoch 493/1499\n",
      "----------\n",
      "train Loss: 0.7961 Acc: 0.7953\n",
      "val Loss: 0.8139 Acc: 0.7720\n",
      "test Loss: 0.7873 Acc: 0.8400\n",
      "Epoch 494/1499\n",
      "----------\n",
      "train Loss: 0.7964 Acc: 0.7989\n",
      "val Loss: 0.8125 Acc: 0.7640\n",
      "test Loss: 0.7841 Acc: 0.8240\n",
      "Epoch 495/1499\n",
      "----------\n",
      "train Loss: 0.7948 Acc: 0.8004\n",
      "val Loss: 0.8205 Acc: 0.7560\n",
      "test Loss: 0.7798 Acc: 0.8280\n",
      "Epoch 496/1499\n",
      "----------\n",
      "train Loss: 0.7964 Acc: 0.7936\n",
      "val Loss: 0.8078 Acc: 0.7840\n",
      "test Loss: 0.7854 Acc: 0.8200\n",
      "Epoch 497/1499\n",
      "----------\n",
      "train Loss: 0.7961 Acc: 0.7933\n",
      "val Loss: 0.8069 Acc: 0.7680\n",
      "test Loss: 0.7825 Acc: 0.8360\n",
      "Epoch 498/1499\n",
      "----------\n",
      "train Loss: 0.7952 Acc: 0.7982\n",
      "val Loss: 0.8084 Acc: 0.7760\n",
      "test Loss: 0.7905 Acc: 0.8200\n",
      "Epoch 499/1499\n",
      "----------\n",
      "train Loss: 0.7952 Acc: 0.7987\n",
      "val Loss: 0.8080 Acc: 0.7840\n",
      "test Loss: 0.7927 Acc: 0.8080\n",
      "Epoch 500/1499\n",
      "----------\n",
      "train Loss: 0.7943 Acc: 0.7982\n",
      "val Loss: 0.8153 Acc: 0.7560\n",
      "test Loss: 0.7951 Acc: 0.8040\n",
      "Epoch 501/1499\n",
      "----------\n",
      "train Loss: 0.7935 Acc: 0.7978\n",
      "val Loss: 0.8168 Acc: 0.7720\n",
      "test Loss: 0.7909 Acc: 0.8040\n",
      "Epoch 502/1499\n",
      "----------\n",
      "train Loss: 0.7936 Acc: 0.7980\n",
      "val Loss: 0.8128 Acc: 0.7800\n",
      "test Loss: 0.7933 Acc: 0.8160\n",
      "Epoch 503/1499\n",
      "----------\n",
      "train Loss: 0.7942 Acc: 0.7951\n",
      "val Loss: 0.8111 Acc: 0.7600\n",
      "test Loss: 0.7786 Acc: 0.8360\n",
      "Epoch 504/1499\n",
      "----------\n",
      "train Loss: 0.7922 Acc: 0.7964\n",
      "val Loss: 0.8133 Acc: 0.7800\n",
      "test Loss: 0.7810 Acc: 0.8360\n",
      "Epoch 505/1499\n",
      "----------\n",
      "train Loss: 0.7942 Acc: 0.7956\n",
      "val Loss: 0.8017 Acc: 0.7840\n",
      "test Loss: 0.7863 Acc: 0.8200\n",
      "Epoch 506/1499\n",
      "----------\n",
      "train Loss: 0.7938 Acc: 0.7980\n",
      "val Loss: 0.8054 Acc: 0.7680\n",
      "test Loss: 0.7876 Acc: 0.8120\n",
      "Epoch 507/1499\n",
      "----------\n",
      "train Loss: 0.7906 Acc: 0.8013\n",
      "val Loss: 0.8025 Acc: 0.7680\n",
      "test Loss: 0.7831 Acc: 0.8120\n",
      "Epoch 508/1499\n",
      "----------\n",
      "train Loss: 0.7946 Acc: 0.8000\n",
      "val Loss: 0.8098 Acc: 0.7800\n",
      "test Loss: 0.7758 Acc: 0.8400\n",
      "Epoch 509/1499\n",
      "----------\n",
      "train Loss: 0.7942 Acc: 0.7947\n",
      "val Loss: 0.8008 Acc: 0.7760\n",
      "test Loss: 0.7813 Acc: 0.8120\n",
      "Epoch 510/1499\n",
      "----------\n",
      "train Loss: 0.7938 Acc: 0.7938\n",
      "val Loss: 0.8068 Acc: 0.7840\n",
      "test Loss: 0.7753 Acc: 0.8240\n",
      "Epoch 511/1499\n",
      "----------\n",
      "train Loss: 0.7914 Acc: 0.7982\n",
      "val Loss: 0.8074 Acc: 0.7800\n",
      "test Loss: 0.7765 Acc: 0.8320\n",
      "Epoch 512/1499\n",
      "----------\n",
      "train Loss: 0.7930 Acc: 0.7987\n",
      "val Loss: 0.8161 Acc: 0.7600\n",
      "test Loss: 0.7726 Acc: 0.8280\n",
      "Epoch 513/1499\n",
      "----------\n",
      "train Loss: 0.7944 Acc: 0.7942\n",
      "val Loss: 0.8014 Acc: 0.7840\n",
      "test Loss: 0.7822 Acc: 0.8240\n",
      "Epoch 514/1499\n",
      "----------\n",
      "train Loss: 0.7930 Acc: 0.8029\n",
      "val Loss: 0.8095 Acc: 0.7800\n",
      "test Loss: 0.7668 Acc: 0.8240\n",
      "Epoch 515/1499\n",
      "----------\n",
      "train Loss: 0.7917 Acc: 0.7964\n",
      "val Loss: 0.8041 Acc: 0.7760\n",
      "test Loss: 0.7805 Acc: 0.8240\n",
      "Epoch 516/1499\n",
      "----------\n",
      "train Loss: 0.7918 Acc: 0.7998\n",
      "val Loss: 0.8035 Acc: 0.7800\n",
      "test Loss: 0.7827 Acc: 0.8080\n",
      "Epoch 517/1499\n",
      "----------\n",
      "train Loss: 0.7921 Acc: 0.7987\n",
      "val Loss: 0.8041 Acc: 0.7960\n",
      "test Loss: 0.7841 Acc: 0.8240\n",
      "Epoch 518/1499\n",
      "----------\n",
      "train Loss: 0.7905 Acc: 0.7993\n",
      "val Loss: 0.8160 Acc: 0.7480\n",
      "test Loss: 0.7756 Acc: 0.8280\n",
      "Epoch 519/1499\n",
      "----------\n",
      "train Loss: 0.7925 Acc: 0.7958\n",
      "val Loss: 0.8040 Acc: 0.7840\n",
      "test Loss: 0.7763 Acc: 0.8200\n",
      "Epoch 520/1499\n",
      "----------\n",
      "train Loss: 0.7887 Acc: 0.8002\n",
      "val Loss: 0.8089 Acc: 0.7800\n",
      "test Loss: 0.7769 Acc: 0.8280\n",
      "Epoch 521/1499\n",
      "----------\n",
      "train Loss: 0.7914 Acc: 0.7984\n",
      "val Loss: 0.8034 Acc: 0.7720\n",
      "test Loss: 0.7789 Acc: 0.8160\n",
      "Epoch 522/1499\n",
      "----------\n",
      "train Loss: 0.7891 Acc: 0.8007\n",
      "val Loss: 0.8152 Acc: 0.7600\n",
      "test Loss: 0.7758 Acc: 0.8280\n",
      "Epoch 523/1499\n",
      "----------\n",
      "train Loss: 0.7890 Acc: 0.8009\n",
      "val Loss: 0.8127 Acc: 0.7560\n",
      "test Loss: 0.7853 Acc: 0.8080\n",
      "Epoch 524/1499\n",
      "----------\n",
      "train Loss: 0.7885 Acc: 0.8044\n",
      "val Loss: 0.8123 Acc: 0.7680\n",
      "test Loss: 0.7734 Acc: 0.8200\n",
      "Epoch 525/1499\n",
      "----------\n",
      "train Loss: 0.7893 Acc: 0.7996\n",
      "val Loss: 0.7926 Acc: 0.8040\n",
      "test Loss: 0.7702 Acc: 0.8240\n",
      "Epoch 526/1499\n",
      "----------\n",
      "train Loss: 0.7890 Acc: 0.7998\n",
      "val Loss: 0.8044 Acc: 0.7760\n",
      "test Loss: 0.7778 Acc: 0.8440\n",
      "Epoch 527/1499\n",
      "----------\n",
      "train Loss: 0.7884 Acc: 0.8027\n",
      "val Loss: 0.8055 Acc: 0.7800\n",
      "test Loss: 0.7780 Acc: 0.8320\n",
      "Epoch 528/1499\n",
      "----------\n",
      "train Loss: 0.7894 Acc: 0.7973\n",
      "val Loss: 0.8156 Acc: 0.7480\n",
      "test Loss: 0.7691 Acc: 0.8320\n",
      "Epoch 529/1499\n",
      "----------\n",
      "train Loss: 0.7901 Acc: 0.7967\n",
      "val Loss: 0.8037 Acc: 0.7640\n",
      "test Loss: 0.7753 Acc: 0.8520\n",
      "Epoch 530/1499\n",
      "----------\n",
      "train Loss: 0.7896 Acc: 0.7998\n",
      "val Loss: 0.8056 Acc: 0.7600\n",
      "test Loss: 0.7744 Acc: 0.8240\n",
      "Epoch 531/1499\n",
      "----------\n",
      "train Loss: 0.7888 Acc: 0.7944\n",
      "val Loss: 0.8059 Acc: 0.7720\n",
      "test Loss: 0.7719 Acc: 0.8280\n",
      "Epoch 532/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.7876 Acc: 0.8020\n",
      "val Loss: 0.7948 Acc: 0.7840\n",
      "test Loss: 0.7703 Acc: 0.8360\n",
      "Epoch 533/1499\n",
      "----------\n",
      "train Loss: 0.7891 Acc: 0.8044\n",
      "val Loss: 0.8018 Acc: 0.7920\n",
      "test Loss: 0.7734 Acc: 0.8320\n",
      "Epoch 534/1499\n",
      "----------\n",
      "train Loss: 0.7885 Acc: 0.7976\n",
      "val Loss: 0.8087 Acc: 0.7720\n",
      "test Loss: 0.7824 Acc: 0.8080\n",
      "Epoch 535/1499\n",
      "----------\n",
      "train Loss: 0.7866 Acc: 0.8040\n",
      "val Loss: 0.7957 Acc: 0.7880\n",
      "test Loss: 0.7671 Acc: 0.8400\n",
      "Epoch 536/1499\n",
      "----------\n",
      "train Loss: 0.7881 Acc: 0.8013\n",
      "val Loss: 0.7992 Acc: 0.7680\n",
      "test Loss: 0.7795 Acc: 0.8240\n",
      "Epoch 537/1499\n",
      "----------\n",
      "train Loss: 0.7853 Acc: 0.8051\n",
      "val Loss: 0.8009 Acc: 0.7640\n",
      "test Loss: 0.7693 Acc: 0.8320\n",
      "Epoch 538/1499\n",
      "----------\n",
      "train Loss: 0.7875 Acc: 0.8007\n",
      "val Loss: 0.8096 Acc: 0.7600\n",
      "test Loss: 0.7725 Acc: 0.8280\n",
      "Epoch 539/1499\n",
      "----------\n",
      "train Loss: 0.7881 Acc: 0.8007\n",
      "val Loss: 0.8008 Acc: 0.7880\n",
      "test Loss: 0.7750 Acc: 0.8280\n",
      "Epoch 540/1499\n",
      "----------\n",
      "train Loss: 0.7892 Acc: 0.7973\n",
      "val Loss: 0.8057 Acc: 0.7680\n",
      "test Loss: 0.7752 Acc: 0.8240\n",
      "Epoch 541/1499\n",
      "----------\n",
      "train Loss: 0.7865 Acc: 0.8009\n",
      "val Loss: 0.8077 Acc: 0.7600\n",
      "test Loss: 0.7751 Acc: 0.8160\n",
      "Epoch 542/1499\n",
      "----------\n",
      "train Loss: 0.7861 Acc: 0.8007\n",
      "val Loss: 0.7989 Acc: 0.7640\n",
      "test Loss: 0.7792 Acc: 0.8080\n",
      "Epoch 543/1499\n",
      "----------\n",
      "train Loss: 0.7866 Acc: 0.7964\n",
      "val Loss: 0.8059 Acc: 0.7480\n",
      "test Loss: 0.7718 Acc: 0.8160\n",
      "Epoch 544/1499\n",
      "----------\n",
      "train Loss: 0.7871 Acc: 0.7991\n",
      "val Loss: 0.7937 Acc: 0.8000\n",
      "test Loss: 0.7731 Acc: 0.8280\n",
      "Epoch 545/1499\n",
      "----------\n",
      "train Loss: 0.7876 Acc: 0.7962\n",
      "val Loss: 0.7989 Acc: 0.7720\n",
      "test Loss: 0.7651 Acc: 0.8280\n",
      "Epoch 546/1499\n",
      "----------\n",
      "train Loss: 0.7846 Acc: 0.8011\n",
      "val Loss: 0.8012 Acc: 0.7760\n",
      "test Loss: 0.7831 Acc: 0.8000\n",
      "Epoch 547/1499\n",
      "----------\n",
      "train Loss: 0.7831 Acc: 0.8042\n",
      "val Loss: 0.7967 Acc: 0.7960\n",
      "test Loss: 0.7796 Acc: 0.8200\n",
      "Epoch 548/1499\n",
      "----------\n",
      "train Loss: 0.7872 Acc: 0.7944\n",
      "val Loss: 0.8008 Acc: 0.7880\n",
      "test Loss: 0.7763 Acc: 0.8080\n",
      "Epoch 549/1499\n",
      "----------\n",
      "train Loss: 0.7852 Acc: 0.7998\n",
      "val Loss: 0.8022 Acc: 0.7960\n",
      "test Loss: 0.7771 Acc: 0.8160\n",
      "Epoch 550/1499\n",
      "----------\n",
      "train Loss: 0.7833 Acc: 0.8022\n",
      "val Loss: 0.7953 Acc: 0.7720\n",
      "test Loss: 0.7716 Acc: 0.8280\n",
      "Epoch 551/1499\n",
      "----------\n",
      "train Loss: 0.7846 Acc: 0.7976\n",
      "val Loss: 0.8021 Acc: 0.7560\n",
      "test Loss: 0.7690 Acc: 0.8360\n",
      "Epoch 552/1499\n",
      "----------\n",
      "train Loss: 0.7848 Acc: 0.7956\n",
      "val Loss: 0.8045 Acc: 0.7760\n",
      "test Loss: 0.7792 Acc: 0.8200\n",
      "Epoch 553/1499\n",
      "----------\n",
      "train Loss: 0.7830 Acc: 0.8040\n",
      "val Loss: 0.8029 Acc: 0.7600\n",
      "test Loss: 0.7703 Acc: 0.8240\n",
      "Epoch 554/1499\n",
      "----------\n",
      "train Loss: 0.7860 Acc: 0.7978\n",
      "val Loss: 0.8056 Acc: 0.7640\n",
      "test Loss: 0.7765 Acc: 0.8280\n",
      "Epoch 555/1499\n",
      "----------\n",
      "train Loss: 0.7850 Acc: 0.7993\n",
      "val Loss: 0.7975 Acc: 0.7920\n",
      "test Loss: 0.7728 Acc: 0.8360\n",
      "Epoch 556/1499\n",
      "----------\n",
      "train Loss: 0.7847 Acc: 0.7998\n",
      "val Loss: 0.8094 Acc: 0.7600\n",
      "test Loss: 0.7681 Acc: 0.8320\n",
      "Epoch 557/1499\n",
      "----------\n",
      "train Loss: 0.7855 Acc: 0.8002\n",
      "val Loss: 0.8020 Acc: 0.7840\n",
      "test Loss: 0.7669 Acc: 0.8240\n",
      "Epoch 558/1499\n",
      "----------\n",
      "train Loss: 0.7837 Acc: 0.7982\n",
      "val Loss: 0.7992 Acc: 0.7800\n",
      "test Loss: 0.7679 Acc: 0.8160\n",
      "Epoch 559/1499\n",
      "----------\n",
      "train Loss: 0.7841 Acc: 0.7953\n",
      "val Loss: 0.7978 Acc: 0.7840\n",
      "test Loss: 0.7743 Acc: 0.8400\n",
      "Epoch 560/1499\n",
      "----------\n",
      "train Loss: 0.7845 Acc: 0.7980\n",
      "val Loss: 0.7998 Acc: 0.7720\n",
      "test Loss: 0.7839 Acc: 0.8120\n",
      "Epoch 561/1499\n",
      "----------\n",
      "train Loss: 0.7844 Acc: 0.7989\n",
      "val Loss: 0.8000 Acc: 0.7680\n",
      "test Loss: 0.7669 Acc: 0.8240\n",
      "Epoch 562/1499\n",
      "----------\n",
      "train Loss: 0.7829 Acc: 0.7991\n",
      "val Loss: 0.8006 Acc: 0.7680\n",
      "test Loss: 0.7807 Acc: 0.8040\n",
      "Epoch 563/1499\n",
      "----------\n",
      "train Loss: 0.7830 Acc: 0.8004\n",
      "val Loss: 0.8047 Acc: 0.7800\n",
      "test Loss: 0.7699 Acc: 0.8280\n",
      "Epoch 564/1499\n",
      "----------\n",
      "train Loss: 0.7812 Acc: 0.8036\n",
      "val Loss: 0.8023 Acc: 0.7720\n",
      "test Loss: 0.7747 Acc: 0.8000\n",
      "Epoch 565/1499\n",
      "----------\n",
      "train Loss: 0.7853 Acc: 0.7962\n",
      "val Loss: 0.8054 Acc: 0.7680\n",
      "test Loss: 0.7747 Acc: 0.8160\n",
      "Epoch 566/1499\n",
      "----------\n",
      "train Loss: 0.7834 Acc: 0.7998\n",
      "val Loss: 0.7989 Acc: 0.7720\n",
      "test Loss: 0.7794 Acc: 0.8200\n",
      "Epoch 567/1499\n",
      "----------\n",
      "train Loss: 0.7834 Acc: 0.7987\n",
      "val Loss: 0.7877 Acc: 0.7920\n",
      "test Loss: 0.7621 Acc: 0.8240\n",
      "Epoch 568/1499\n",
      "----------\n",
      "train Loss: 0.7813 Acc: 0.8018\n",
      "val Loss: 0.8084 Acc: 0.7480\n",
      "test Loss: 0.7671 Acc: 0.8200\n",
      "Epoch 569/1499\n",
      "----------\n",
      "train Loss: 0.7814 Acc: 0.8013\n",
      "val Loss: 0.8026 Acc: 0.7640\n",
      "test Loss: 0.7678 Acc: 0.8320\n",
      "Epoch 570/1499\n",
      "----------\n",
      "train Loss: 0.7820 Acc: 0.8013\n",
      "val Loss: 0.7975 Acc: 0.7840\n",
      "test Loss: 0.7750 Acc: 0.8160\n",
      "Epoch 571/1499\n",
      "----------\n",
      "train Loss: 0.7804 Acc: 0.8029\n",
      "val Loss: 0.7930 Acc: 0.7880\n",
      "test Loss: 0.7691 Acc: 0.8240\n",
      "Epoch 572/1499\n",
      "----------\n",
      "train Loss: 0.7827 Acc: 0.8009\n",
      "val Loss: 0.7945 Acc: 0.7720\n",
      "test Loss: 0.7751 Acc: 0.8160\n",
      "Epoch 573/1499\n",
      "----------\n",
      "train Loss: 0.7822 Acc: 0.7967\n",
      "val Loss: 0.7984 Acc: 0.7800\n",
      "test Loss: 0.7720 Acc: 0.8040\n",
      "Epoch 574/1499\n",
      "----------\n",
      "train Loss: 0.7815 Acc: 0.7978\n",
      "val Loss: 0.7855 Acc: 0.8000\n",
      "test Loss: 0.7679 Acc: 0.8360\n",
      "Epoch 575/1499\n",
      "----------\n",
      "train Loss: 0.7828 Acc: 0.7947\n",
      "val Loss: 0.7882 Acc: 0.7840\n",
      "test Loss: 0.7810 Acc: 0.8080\n",
      "Epoch 576/1499\n",
      "----------\n",
      "train Loss: 0.7816 Acc: 0.8018\n",
      "val Loss: 0.7999 Acc: 0.7800\n",
      "test Loss: 0.7647 Acc: 0.8400\n",
      "Epoch 577/1499\n",
      "----------\n",
      "train Loss: 0.7809 Acc: 0.8002\n",
      "val Loss: 0.7915 Acc: 0.7920\n",
      "test Loss: 0.7714 Acc: 0.8080\n",
      "Epoch 578/1499\n",
      "----------\n",
      "train Loss: 0.7797 Acc: 0.8024\n",
      "val Loss: 0.7967 Acc: 0.7760\n",
      "test Loss: 0.7665 Acc: 0.8240\n",
      "Epoch 579/1499\n",
      "----------\n",
      "train Loss: 0.7818 Acc: 0.8011\n",
      "val Loss: 0.7995 Acc: 0.7800\n",
      "test Loss: 0.7726 Acc: 0.8200\n",
      "Epoch 580/1499\n",
      "----------\n",
      "train Loss: 0.7819 Acc: 0.7951\n",
      "val Loss: 0.7936 Acc: 0.7760\n",
      "test Loss: 0.7810 Acc: 0.8160\n",
      "Epoch 581/1499\n",
      "----------\n",
      "train Loss: 0.7788 Acc: 0.8047\n",
      "val Loss: 0.7932 Acc: 0.7920\n",
      "test Loss: 0.7693 Acc: 0.8000\n",
      "Epoch 582/1499\n",
      "----------\n",
      "train Loss: 0.7802 Acc: 0.7989\n",
      "val Loss: 0.8045 Acc: 0.7600\n",
      "test Loss: 0.7640 Acc: 0.8320\n",
      "Epoch 583/1499\n",
      "----------\n",
      "train Loss: 0.7809 Acc: 0.7980\n",
      "val Loss: 0.8037 Acc: 0.7640\n",
      "test Loss: 0.7601 Acc: 0.8320\n",
      "Epoch 584/1499\n",
      "----------\n",
      "train Loss: 0.7780 Acc: 0.8000\n",
      "val Loss: 0.7861 Acc: 0.7880\n",
      "test Loss: 0.7603 Acc: 0.8280\n",
      "Epoch 585/1499\n",
      "----------\n",
      "train Loss: 0.7824 Acc: 0.7947\n",
      "val Loss: 0.7967 Acc: 0.7840\n",
      "test Loss: 0.7622 Acc: 0.8360\n",
      "Epoch 586/1499\n",
      "----------\n",
      "train Loss: 0.7789 Acc: 0.8011\n",
      "val Loss: 0.7932 Acc: 0.7960\n",
      "test Loss: 0.7645 Acc: 0.8240\n",
      "Epoch 587/1499\n",
      "----------\n",
      "train Loss: 0.7790 Acc: 0.8027\n",
      "val Loss: 0.7899 Acc: 0.7920\n",
      "test Loss: 0.7711 Acc: 0.8160\n",
      "Epoch 588/1499\n",
      "----------\n",
      "train Loss: 0.7798 Acc: 0.8000\n",
      "val Loss: 0.7990 Acc: 0.7800\n",
      "test Loss: 0.7743 Acc: 0.8080\n",
      "Epoch 589/1499\n",
      "----------\n",
      "train Loss: 0.7781 Acc: 0.8018\n",
      "val Loss: 0.7856 Acc: 0.7880\n",
      "test Loss: 0.7617 Acc: 0.8400\n",
      "Epoch 590/1499\n",
      "----------\n",
      "train Loss: 0.7786 Acc: 0.8016\n",
      "val Loss: 0.7936 Acc: 0.7920\n",
      "test Loss: 0.7703 Acc: 0.8240\n",
      "Epoch 591/1499\n",
      "----------\n",
      "train Loss: 0.7761 Acc: 0.8053\n",
      "val Loss: 0.7950 Acc: 0.7760\n",
      "test Loss: 0.7610 Acc: 0.8240\n",
      "Epoch 592/1499\n",
      "----------\n",
      "train Loss: 0.7774 Acc: 0.8036\n",
      "val Loss: 0.8079 Acc: 0.7520\n",
      "test Loss: 0.7679 Acc: 0.8160\n",
      "Epoch 593/1499\n",
      "----------\n",
      "train Loss: 0.7773 Acc: 0.8084\n",
      "val Loss: 0.7963 Acc: 0.7760\n",
      "test Loss: 0.7714 Acc: 0.8200\n",
      "Epoch 594/1499\n",
      "----------\n",
      "train Loss: 0.7778 Acc: 0.8004\n",
      "val Loss: 0.7995 Acc: 0.7560\n",
      "test Loss: 0.7557 Acc: 0.8280\n",
      "Epoch 595/1499\n",
      "----------\n",
      "train Loss: 0.7763 Acc: 0.8067\n",
      "val Loss: 0.7983 Acc: 0.7640\n",
      "test Loss: 0.7626 Acc: 0.8240\n",
      "Epoch 596/1499\n",
      "----------\n",
      "train Loss: 0.7802 Acc: 0.7967\n",
      "val Loss: 0.8016 Acc: 0.7760\n",
      "test Loss: 0.7688 Acc: 0.8160\n",
      "Epoch 597/1499\n",
      "----------\n",
      "train Loss: 0.7786 Acc: 0.7989\n",
      "val Loss: 0.7968 Acc: 0.7880\n",
      "test Loss: 0.7664 Acc: 0.8000\n",
      "Epoch 598/1499\n",
      "----------\n",
      "train Loss: 0.7785 Acc: 0.7993\n",
      "val Loss: 0.7895 Acc: 0.7920\n",
      "test Loss: 0.7528 Acc: 0.8320\n",
      "Epoch 599/1499\n",
      "----------\n",
      "train Loss: 0.7779 Acc: 0.7996\n",
      "val Loss: 0.7919 Acc: 0.7840\n",
      "test Loss: 0.7621 Acc: 0.8320\n",
      "Epoch 600/1499\n",
      "----------\n",
      "train Loss: 0.7770 Acc: 0.8047\n",
      "val Loss: 0.8026 Acc: 0.7560\n",
      "test Loss: 0.7609 Acc: 0.8360\n",
      "Epoch 601/1499\n",
      "----------\n",
      "train Loss: 0.7777 Acc: 0.8013\n",
      "val Loss: 0.7891 Acc: 0.7800\n",
      "test Loss: 0.7787 Acc: 0.8120\n",
      "Epoch 602/1499\n",
      "----------\n",
      "train Loss: 0.7772 Acc: 0.8040\n",
      "val Loss: 0.8020 Acc: 0.7600\n",
      "test Loss: 0.7639 Acc: 0.8160\n",
      "Epoch 603/1499\n",
      "----------\n",
      "train Loss: 0.7798 Acc: 0.7980\n",
      "val Loss: 0.7918 Acc: 0.7920\n",
      "test Loss: 0.7661 Acc: 0.8160\n",
      "Epoch 604/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.7758 Acc: 0.8009\n",
      "val Loss: 0.7853 Acc: 0.7760\n",
      "test Loss: 0.7602 Acc: 0.8160\n",
      "Epoch 605/1499\n",
      "----------\n",
      "train Loss: 0.7748 Acc: 0.8024\n",
      "val Loss: 0.7869 Acc: 0.7880\n",
      "test Loss: 0.7652 Acc: 0.8320\n",
      "Epoch 606/1499\n",
      "----------\n",
      "train Loss: 0.7771 Acc: 0.8009\n",
      "val Loss: 0.7930 Acc: 0.7640\n",
      "test Loss: 0.7637 Acc: 0.8480\n",
      "Epoch 607/1499\n",
      "----------\n",
      "train Loss: 0.7778 Acc: 0.8000\n",
      "val Loss: 0.7935 Acc: 0.7800\n",
      "test Loss: 0.7689 Acc: 0.8120\n",
      "Epoch 608/1499\n",
      "----------\n",
      "train Loss: 0.7765 Acc: 0.7998\n",
      "val Loss: 0.7869 Acc: 0.7960\n",
      "test Loss: 0.7579 Acc: 0.8360\n",
      "Epoch 609/1499\n",
      "----------\n",
      "train Loss: 0.7753 Acc: 0.8040\n",
      "val Loss: 0.7923 Acc: 0.7640\n",
      "test Loss: 0.7628 Acc: 0.8480\n",
      "Epoch 610/1499\n",
      "----------\n",
      "train Loss: 0.7769 Acc: 0.8029\n",
      "val Loss: 0.7771 Acc: 0.8000\n",
      "test Loss: 0.7595 Acc: 0.8160\n",
      "Epoch 611/1499\n",
      "----------\n",
      "train Loss: 0.7765 Acc: 0.8029\n",
      "val Loss: 0.7866 Acc: 0.7840\n",
      "test Loss: 0.7549 Acc: 0.8400\n",
      "Epoch 612/1499\n",
      "----------\n",
      "train Loss: 0.7755 Acc: 0.8018\n",
      "val Loss: 0.7860 Acc: 0.7680\n",
      "test Loss: 0.7613 Acc: 0.8400\n",
      "Epoch 613/1499\n",
      "----------\n",
      "train Loss: 0.7773 Acc: 0.7962\n",
      "val Loss: 0.7898 Acc: 0.7760\n",
      "test Loss: 0.7577 Acc: 0.8280\n",
      "Epoch 614/1499\n",
      "----------\n",
      "train Loss: 0.7743 Acc: 0.8007\n",
      "val Loss: 0.7965 Acc: 0.7680\n",
      "test Loss: 0.7614 Acc: 0.8360\n",
      "Epoch 615/1499\n",
      "----------\n",
      "train Loss: 0.7761 Acc: 0.8002\n",
      "val Loss: 0.7985 Acc: 0.7680\n",
      "test Loss: 0.7722 Acc: 0.8040\n",
      "Epoch 616/1499\n",
      "----------\n",
      "train Loss: 0.7763 Acc: 0.7996\n",
      "val Loss: 0.7898 Acc: 0.7960\n",
      "test Loss: 0.7554 Acc: 0.8280\n",
      "Epoch 617/1499\n",
      "----------\n",
      "train Loss: 0.7760 Acc: 0.8009\n",
      "val Loss: 0.7998 Acc: 0.7560\n",
      "test Loss: 0.7600 Acc: 0.8400\n",
      "Epoch 618/1499\n",
      "----------\n",
      "train Loss: 0.7762 Acc: 0.7993\n",
      "val Loss: 0.7962 Acc: 0.7720\n",
      "test Loss: 0.7613 Acc: 0.8200\n",
      "Epoch 619/1499\n",
      "----------\n",
      "train Loss: 0.7742 Acc: 0.8060\n",
      "val Loss: 0.7911 Acc: 0.7640\n",
      "test Loss: 0.7593 Acc: 0.8320\n",
      "Epoch 620/1499\n",
      "----------\n",
      "train Loss: 0.7750 Acc: 0.8018\n",
      "val Loss: 0.8042 Acc: 0.7560\n",
      "test Loss: 0.7590 Acc: 0.8400\n",
      "Epoch 621/1499\n",
      "----------\n",
      "train Loss: 0.7715 Acc: 0.8080\n",
      "val Loss: 0.7887 Acc: 0.7840\n",
      "test Loss: 0.7516 Acc: 0.8400\n",
      "Epoch 622/1499\n",
      "----------\n",
      "train Loss: 0.7750 Acc: 0.8004\n",
      "val Loss: 0.7859 Acc: 0.7920\n",
      "test Loss: 0.7569 Acc: 0.8280\n",
      "Epoch 623/1499\n",
      "----------\n",
      "train Loss: 0.7746 Acc: 0.8013\n",
      "val Loss: 0.7977 Acc: 0.7560\n",
      "test Loss: 0.7565 Acc: 0.8400\n",
      "Epoch 624/1499\n",
      "----------\n",
      "train Loss: 0.7749 Acc: 0.7993\n",
      "val Loss: 0.7835 Acc: 0.7880\n",
      "test Loss: 0.7496 Acc: 0.8480\n",
      "Epoch 625/1499\n",
      "----------\n",
      "train Loss: 0.7748 Acc: 0.8011\n",
      "val Loss: 0.7841 Acc: 0.7840\n",
      "test Loss: 0.7503 Acc: 0.8400\n",
      "Epoch 626/1499\n",
      "----------\n",
      "train Loss: 0.7742 Acc: 0.8016\n",
      "val Loss: 0.7922 Acc: 0.7720\n",
      "test Loss: 0.7590 Acc: 0.8320\n",
      "Epoch 627/1499\n",
      "----------\n",
      "train Loss: 0.7740 Acc: 0.8022\n",
      "val Loss: 0.7875 Acc: 0.7800\n",
      "test Loss: 0.7642 Acc: 0.8200\n",
      "Epoch 628/1499\n",
      "----------\n",
      "train Loss: 0.7735 Acc: 0.8033\n",
      "val Loss: 0.7923 Acc: 0.7840\n",
      "test Loss: 0.7619 Acc: 0.8160\n",
      "Epoch 629/1499\n",
      "----------\n",
      "train Loss: 0.7748 Acc: 0.8009\n",
      "val Loss: 0.7929 Acc: 0.7760\n",
      "test Loss: 0.7586 Acc: 0.8160\n",
      "Epoch 630/1499\n",
      "----------\n",
      "train Loss: 0.7728 Acc: 0.8062\n",
      "val Loss: 0.7834 Acc: 0.7840\n",
      "test Loss: 0.7576 Acc: 0.8360\n",
      "Epoch 631/1499\n",
      "----------\n",
      "train Loss: 0.7733 Acc: 0.8044\n",
      "val Loss: 0.7918 Acc: 0.7560\n",
      "test Loss: 0.7585 Acc: 0.8400\n",
      "Epoch 632/1499\n",
      "----------\n",
      "train Loss: 0.7725 Acc: 0.8007\n",
      "val Loss: 0.7968 Acc: 0.7760\n",
      "test Loss: 0.7631 Acc: 0.8320\n",
      "Epoch 633/1499\n",
      "----------\n",
      "train Loss: 0.7751 Acc: 0.8029\n",
      "val Loss: 0.7904 Acc: 0.7840\n",
      "test Loss: 0.7571 Acc: 0.8320\n",
      "Epoch 634/1499\n",
      "----------\n",
      "train Loss: 0.7739 Acc: 0.8033\n",
      "val Loss: 0.7858 Acc: 0.7840\n",
      "test Loss: 0.7562 Acc: 0.8440\n",
      "Epoch 635/1499\n",
      "----------\n",
      "train Loss: 0.7704 Acc: 0.8067\n",
      "val Loss: 0.7872 Acc: 0.7640\n",
      "test Loss: 0.7586 Acc: 0.8360\n",
      "Epoch 636/1499\n",
      "----------\n",
      "train Loss: 0.7746 Acc: 0.8029\n",
      "val Loss: 0.7855 Acc: 0.7960\n",
      "test Loss: 0.7544 Acc: 0.8320\n",
      "Epoch 637/1499\n",
      "----------\n",
      "train Loss: 0.7721 Acc: 0.8029\n",
      "val Loss: 0.7873 Acc: 0.7880\n",
      "test Loss: 0.7615 Acc: 0.8280\n",
      "Epoch 638/1499\n",
      "----------\n",
      "train Loss: 0.7712 Acc: 0.8011\n",
      "val Loss: 0.7917 Acc: 0.7720\n",
      "test Loss: 0.7547 Acc: 0.8320\n",
      "Epoch 639/1499\n",
      "----------\n",
      "train Loss: 0.7705 Acc: 0.8051\n",
      "val Loss: 0.7858 Acc: 0.7840\n",
      "test Loss: 0.7530 Acc: 0.8280\n",
      "Epoch 640/1499\n",
      "----------\n",
      "train Loss: 0.7734 Acc: 0.8024\n",
      "val Loss: 0.8065 Acc: 0.7480\n",
      "test Loss: 0.7585 Acc: 0.8320\n",
      "Epoch 641/1499\n",
      "----------\n",
      "train Loss: 0.7733 Acc: 0.8002\n",
      "val Loss: 0.7885 Acc: 0.7840\n",
      "test Loss: 0.7517 Acc: 0.8480\n",
      "Epoch 642/1499\n",
      "----------\n",
      "train Loss: 0.7690 Acc: 0.8089\n",
      "val Loss: 0.7894 Acc: 0.7760\n",
      "test Loss: 0.7590 Acc: 0.8400\n",
      "Epoch 643/1499\n",
      "----------\n",
      "train Loss: 0.7705 Acc: 0.7984\n",
      "val Loss: 0.7898 Acc: 0.7880\n",
      "test Loss: 0.7544 Acc: 0.8400\n",
      "Epoch 644/1499\n",
      "----------\n",
      "train Loss: 0.7727 Acc: 0.8011\n",
      "val Loss: 0.7880 Acc: 0.7800\n",
      "test Loss: 0.7611 Acc: 0.8160\n",
      "Epoch 645/1499\n",
      "----------\n",
      "train Loss: 0.7716 Acc: 0.8056\n",
      "val Loss: 0.7990 Acc: 0.7600\n",
      "test Loss: 0.7668 Acc: 0.8160\n",
      "Epoch 646/1499\n",
      "----------\n",
      "train Loss: 0.7712 Acc: 0.8031\n",
      "val Loss: 0.7812 Acc: 0.7960\n",
      "test Loss: 0.7655 Acc: 0.8160\n",
      "Epoch 647/1499\n",
      "----------\n",
      "train Loss: 0.7700 Acc: 0.8076\n",
      "val Loss: 0.7952 Acc: 0.7640\n",
      "test Loss: 0.7624 Acc: 0.8280\n",
      "Epoch 648/1499\n",
      "----------\n",
      "train Loss: 0.7680 Acc: 0.8069\n",
      "val Loss: 0.7932 Acc: 0.7640\n",
      "test Loss: 0.7523 Acc: 0.8400\n",
      "Epoch 649/1499\n",
      "----------\n",
      "train Loss: 0.7720 Acc: 0.8038\n",
      "val Loss: 0.7855 Acc: 0.8000\n",
      "test Loss: 0.7512 Acc: 0.8200\n",
      "Epoch 650/1499\n",
      "----------\n",
      "train Loss: 0.7701 Acc: 0.8013\n",
      "val Loss: 0.8005 Acc: 0.7680\n",
      "test Loss: 0.7497 Acc: 0.8360\n",
      "Epoch 651/1499\n",
      "----------\n",
      "train Loss: 0.7698 Acc: 0.8053\n",
      "val Loss: 0.7826 Acc: 0.7880\n",
      "test Loss: 0.7615 Acc: 0.8200\n",
      "Epoch 652/1499\n",
      "----------\n",
      "train Loss: 0.7701 Acc: 0.8038\n",
      "val Loss: 0.7917 Acc: 0.7800\n",
      "test Loss: 0.7678 Acc: 0.8240\n",
      "Epoch 653/1499\n",
      "----------\n",
      "train Loss: 0.7694 Acc: 0.8020\n",
      "val Loss: 0.7801 Acc: 0.7920\n",
      "test Loss: 0.7556 Acc: 0.8320\n",
      "Epoch 654/1499\n",
      "----------\n",
      "train Loss: 0.7721 Acc: 0.8038\n",
      "val Loss: 0.7813 Acc: 0.7800\n",
      "test Loss: 0.7560 Acc: 0.8280\n",
      "Epoch 655/1499\n",
      "----------\n",
      "train Loss: 0.7687 Acc: 0.8062\n",
      "val Loss: 0.7794 Acc: 0.7880\n",
      "test Loss: 0.7625 Acc: 0.8200\n",
      "Epoch 656/1499\n",
      "----------\n",
      "train Loss: 0.7697 Acc: 0.8062\n",
      "val Loss: 0.7877 Acc: 0.7760\n",
      "test Loss: 0.7628 Acc: 0.8160\n",
      "Epoch 657/1499\n",
      "----------\n",
      "train Loss: 0.7682 Acc: 0.8060\n",
      "val Loss: 0.7968 Acc: 0.7720\n",
      "test Loss: 0.7604 Acc: 0.8320\n",
      "Epoch 658/1499\n",
      "----------\n",
      "train Loss: 0.7707 Acc: 0.7989\n",
      "val Loss: 0.7837 Acc: 0.7760\n",
      "test Loss: 0.7528 Acc: 0.8320\n",
      "Epoch 659/1499\n",
      "----------\n",
      "train Loss: 0.7684 Acc: 0.8022\n",
      "val Loss: 0.7804 Acc: 0.7840\n",
      "test Loss: 0.7475 Acc: 0.8440\n",
      "Epoch 660/1499\n",
      "----------\n",
      "train Loss: 0.7719 Acc: 0.8011\n",
      "val Loss: 0.7859 Acc: 0.7760\n",
      "test Loss: 0.7549 Acc: 0.8320\n",
      "Epoch 661/1499\n",
      "----------\n",
      "train Loss: 0.7694 Acc: 0.8056\n",
      "val Loss: 0.7895 Acc: 0.7680\n",
      "test Loss: 0.7634 Acc: 0.8120\n",
      "Epoch 662/1499\n",
      "----------\n",
      "train Loss: 0.7707 Acc: 0.8018\n",
      "val Loss: 0.7772 Acc: 0.7840\n",
      "test Loss: 0.7513 Acc: 0.8280\n",
      "Epoch 663/1499\n",
      "----------\n",
      "train Loss: 0.7676 Acc: 0.8044\n",
      "val Loss: 0.7803 Acc: 0.7920\n",
      "test Loss: 0.7633 Acc: 0.8200\n",
      "Epoch 664/1499\n",
      "----------\n",
      "train Loss: 0.7691 Acc: 0.8062\n",
      "val Loss: 0.7916 Acc: 0.7720\n",
      "test Loss: 0.7541 Acc: 0.8400\n",
      "Epoch 665/1499\n",
      "----------\n",
      "train Loss: 0.7714 Acc: 0.8007\n",
      "val Loss: 0.7874 Acc: 0.7680\n",
      "test Loss: 0.7577 Acc: 0.8360\n",
      "Epoch 666/1499\n",
      "----------\n",
      "train Loss: 0.7687 Acc: 0.8047\n",
      "val Loss: 0.7815 Acc: 0.7760\n",
      "test Loss: 0.7550 Acc: 0.8400\n",
      "Epoch 667/1499\n",
      "----------\n",
      "train Loss: 0.7686 Acc: 0.8044\n",
      "val Loss: 0.7897 Acc: 0.7880\n",
      "test Loss: 0.7489 Acc: 0.8560\n",
      "Epoch 668/1499\n",
      "----------\n",
      "train Loss: 0.7685 Acc: 0.7982\n",
      "val Loss: 0.7843 Acc: 0.7840\n",
      "test Loss: 0.7582 Acc: 0.8440\n",
      "Epoch 669/1499\n",
      "----------\n",
      "train Loss: 0.7703 Acc: 0.7978\n",
      "val Loss: 0.7879 Acc: 0.7720\n",
      "test Loss: 0.7590 Acc: 0.8240\n",
      "Epoch 670/1499\n",
      "----------\n",
      "train Loss: 0.7685 Acc: 0.8058\n",
      "val Loss: 0.7908 Acc: 0.7760\n",
      "test Loss: 0.7528 Acc: 0.8400\n",
      "Epoch 671/1499\n",
      "----------\n",
      "train Loss: 0.7665 Acc: 0.8098\n",
      "val Loss: 0.7808 Acc: 0.7920\n",
      "test Loss: 0.7506 Acc: 0.8360\n",
      "Epoch 672/1499\n",
      "----------\n",
      "train Loss: 0.7667 Acc: 0.8073\n",
      "val Loss: 0.7841 Acc: 0.7840\n",
      "test Loss: 0.7651 Acc: 0.8120\n",
      "Epoch 673/1499\n",
      "----------\n",
      "train Loss: 0.7686 Acc: 0.8007\n",
      "val Loss: 0.7920 Acc: 0.7680\n",
      "test Loss: 0.7461 Acc: 0.8480\n",
      "Epoch 674/1499\n",
      "----------\n",
      "train Loss: 0.7678 Acc: 0.8078\n",
      "val Loss: 0.7899 Acc: 0.7520\n",
      "test Loss: 0.7518 Acc: 0.8240\n",
      "Epoch 675/1499\n",
      "----------\n",
      "train Loss: 0.7692 Acc: 0.8013\n",
      "val Loss: 0.7796 Acc: 0.7960\n",
      "test Loss: 0.7553 Acc: 0.8400\n",
      "Epoch 676/1499\n",
      "----------\n",
      "train Loss: 0.7669 Acc: 0.8069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.7763 Acc: 0.7960\n",
      "test Loss: 0.7509 Acc: 0.8480\n",
      "Epoch 677/1499\n",
      "----------\n",
      "train Loss: 0.7704 Acc: 0.7998\n",
      "val Loss: 0.7773 Acc: 0.8000\n",
      "test Loss: 0.7572 Acc: 0.8320\n",
      "Epoch 678/1499\n",
      "----------\n",
      "train Loss: 0.7667 Acc: 0.8047\n",
      "val Loss: 0.7786 Acc: 0.7960\n",
      "test Loss: 0.7534 Acc: 0.8440\n",
      "Epoch 679/1499\n",
      "----------\n",
      "train Loss: 0.7691 Acc: 0.8051\n",
      "val Loss: 0.7863 Acc: 0.7760\n",
      "test Loss: 0.7495 Acc: 0.8360\n",
      "Epoch 680/1499\n",
      "----------\n",
      "train Loss: 0.7676 Acc: 0.8027\n",
      "val Loss: 0.7828 Acc: 0.7840\n",
      "test Loss: 0.7521 Acc: 0.8400\n",
      "Epoch 681/1499\n",
      "----------\n",
      "train Loss: 0.7664 Acc: 0.8060\n",
      "val Loss: 0.7797 Acc: 0.7880\n",
      "test Loss: 0.7593 Acc: 0.8280\n",
      "Epoch 682/1499\n",
      "----------\n",
      "train Loss: 0.7662 Acc: 0.8069\n",
      "val Loss: 0.7849 Acc: 0.7760\n",
      "test Loss: 0.7595 Acc: 0.8320\n",
      "Epoch 683/1499\n",
      "----------\n",
      "train Loss: 0.7663 Acc: 0.8080\n",
      "val Loss: 0.7954 Acc: 0.7800\n",
      "test Loss: 0.7495 Acc: 0.8320\n",
      "Epoch 684/1499\n",
      "----------\n",
      "train Loss: 0.7678 Acc: 0.8024\n",
      "val Loss: 0.7861 Acc: 0.7920\n",
      "test Loss: 0.7607 Acc: 0.8200\n",
      "Epoch 685/1499\n",
      "----------\n",
      "train Loss: 0.7683 Acc: 0.8002\n",
      "val Loss: 0.7892 Acc: 0.7680\n",
      "test Loss: 0.7527 Acc: 0.8280\n",
      "Epoch 686/1499\n",
      "----------\n",
      "train Loss: 0.7673 Acc: 0.8064\n",
      "val Loss: 0.7866 Acc: 0.7840\n",
      "test Loss: 0.7499 Acc: 0.8400\n",
      "Epoch 687/1499\n",
      "----------\n",
      "train Loss: 0.7668 Acc: 0.8056\n",
      "val Loss: 0.7838 Acc: 0.7760\n",
      "test Loss: 0.7552 Acc: 0.8400\n",
      "Epoch 688/1499\n",
      "----------\n",
      "train Loss: 0.7666 Acc: 0.8013\n",
      "val Loss: 0.7724 Acc: 0.8080\n",
      "test Loss: 0.7583 Acc: 0.8200\n",
      "Epoch 689/1499\n",
      "----------\n",
      "train Loss: 0.7661 Acc: 0.8029\n",
      "val Loss: 0.7741 Acc: 0.7760\n",
      "test Loss: 0.7574 Acc: 0.8240\n",
      "Epoch 690/1499\n",
      "----------\n",
      "train Loss: 0.7638 Acc: 0.8033\n",
      "val Loss: 0.7810 Acc: 0.7960\n",
      "test Loss: 0.7556 Acc: 0.8320\n",
      "Epoch 691/1499\n",
      "----------\n",
      "train Loss: 0.7684 Acc: 0.8018\n",
      "val Loss: 0.7806 Acc: 0.7920\n",
      "test Loss: 0.7580 Acc: 0.8120\n",
      "Epoch 692/1499\n",
      "----------\n",
      "train Loss: 0.7657 Acc: 0.8076\n",
      "val Loss: 0.7760 Acc: 0.7960\n",
      "test Loss: 0.7507 Acc: 0.8280\n",
      "Epoch 693/1499\n",
      "----------\n",
      "train Loss: 0.7657 Acc: 0.8024\n",
      "val Loss: 0.7812 Acc: 0.7760\n",
      "test Loss: 0.7624 Acc: 0.8120\n",
      "Epoch 694/1499\n",
      "----------\n",
      "train Loss: 0.7637 Acc: 0.8073\n",
      "val Loss: 0.7778 Acc: 0.7920\n",
      "test Loss: 0.7502 Acc: 0.8320\n",
      "Epoch 695/1499\n",
      "----------\n",
      "train Loss: 0.7637 Acc: 0.8078\n",
      "val Loss: 0.7835 Acc: 0.7840\n",
      "test Loss: 0.7513 Acc: 0.8240\n",
      "Epoch 696/1499\n",
      "----------\n",
      "train Loss: 0.7649 Acc: 0.8058\n",
      "val Loss: 0.7809 Acc: 0.7840\n",
      "test Loss: 0.7576 Acc: 0.8200\n",
      "Epoch 697/1499\n",
      "----------\n",
      "train Loss: 0.7676 Acc: 0.8016\n",
      "val Loss: 0.7807 Acc: 0.7840\n",
      "test Loss: 0.7463 Acc: 0.8480\n",
      "Epoch 698/1499\n",
      "----------\n",
      "train Loss: 0.7659 Acc: 0.8004\n",
      "val Loss: 0.7861 Acc: 0.7960\n",
      "test Loss: 0.7461 Acc: 0.8440\n",
      "Epoch 699/1499\n",
      "----------\n",
      "train Loss: 0.7666 Acc: 0.8016\n",
      "val Loss: 0.7890 Acc: 0.7720\n",
      "test Loss: 0.7587 Acc: 0.8320\n",
      "Epoch 700/1499\n",
      "----------\n",
      "train Loss: 0.7662 Acc: 0.8024\n",
      "val Loss: 0.7731 Acc: 0.8000\n",
      "test Loss: 0.7530 Acc: 0.8320\n",
      "Epoch 701/1499\n",
      "----------\n",
      "train Loss: 0.7655 Acc: 0.8016\n",
      "val Loss: 0.7864 Acc: 0.7760\n",
      "test Loss: 0.7541 Acc: 0.8280\n",
      "Epoch 702/1499\n",
      "----------\n",
      "train Loss: 0.7657 Acc: 0.7998\n",
      "val Loss: 0.7749 Acc: 0.7840\n",
      "test Loss: 0.7529 Acc: 0.8320\n",
      "Epoch 703/1499\n",
      "----------\n",
      "train Loss: 0.7651 Acc: 0.8036\n",
      "val Loss: 0.7792 Acc: 0.7800\n",
      "test Loss: 0.7519 Acc: 0.8280\n",
      "Epoch 704/1499\n",
      "----------\n",
      "train Loss: 0.7660 Acc: 0.7958\n",
      "val Loss: 0.7823 Acc: 0.7840\n",
      "test Loss: 0.7512 Acc: 0.8360\n",
      "Epoch 705/1499\n",
      "----------\n",
      "train Loss: 0.7633 Acc: 0.8069\n",
      "val Loss: 0.7884 Acc: 0.7600\n",
      "test Loss: 0.7465 Acc: 0.8360\n",
      "Epoch 706/1499\n",
      "----------\n",
      "train Loss: 0.7644 Acc: 0.8036\n",
      "val Loss: 0.7735 Acc: 0.7800\n",
      "test Loss: 0.7426 Acc: 0.8480\n",
      "Epoch 707/1499\n",
      "----------\n",
      "train Loss: 0.7647 Acc: 0.8029\n",
      "val Loss: 0.7791 Acc: 0.7880\n",
      "test Loss: 0.7553 Acc: 0.8280\n",
      "Epoch 708/1499\n",
      "----------\n",
      "train Loss: 0.7650 Acc: 0.8022\n",
      "val Loss: 0.7703 Acc: 0.7840\n",
      "test Loss: 0.7476 Acc: 0.8320\n",
      "Epoch 709/1499\n",
      "----------\n",
      "train Loss: 0.7630 Acc: 0.8064\n",
      "val Loss: 0.7669 Acc: 0.8000\n",
      "test Loss: 0.7450 Acc: 0.8360\n",
      "Epoch 710/1499\n",
      "----------\n",
      "train Loss: 0.7652 Acc: 0.8033\n",
      "val Loss: 0.7740 Acc: 0.7720\n",
      "test Loss: 0.7453 Acc: 0.8400\n",
      "Epoch 711/1499\n",
      "----------\n",
      "train Loss: 0.7639 Acc: 0.8022\n",
      "val Loss: 0.7858 Acc: 0.7680\n",
      "test Loss: 0.7566 Acc: 0.8200\n",
      "Epoch 712/1499\n",
      "----------\n",
      "train Loss: 0.7651 Acc: 0.8047\n",
      "val Loss: 0.7798 Acc: 0.7640\n",
      "test Loss: 0.7504 Acc: 0.8280\n",
      "Epoch 713/1499\n",
      "----------\n",
      "train Loss: 0.7642 Acc: 0.7993\n",
      "val Loss: 0.7855 Acc: 0.7720\n",
      "test Loss: 0.7442 Acc: 0.8480\n",
      "Epoch 714/1499\n",
      "----------\n",
      "train Loss: 0.7623 Acc: 0.8089\n",
      "val Loss: 0.7771 Acc: 0.7760\n",
      "test Loss: 0.7539 Acc: 0.8440\n",
      "Epoch 715/1499\n",
      "----------\n",
      "train Loss: 0.7637 Acc: 0.8033\n",
      "val Loss: 0.7788 Acc: 0.7840\n",
      "test Loss: 0.7453 Acc: 0.8320\n",
      "Epoch 716/1499\n",
      "----------\n",
      "train Loss: 0.7651 Acc: 0.8047\n",
      "val Loss: 0.7743 Acc: 0.7960\n",
      "test Loss: 0.7456 Acc: 0.8320\n",
      "Epoch 717/1499\n",
      "----------\n",
      "train Loss: 0.7632 Acc: 0.8051\n",
      "val Loss: 0.7831 Acc: 0.7880\n",
      "test Loss: 0.7514 Acc: 0.8360\n",
      "Epoch 718/1499\n",
      "----------\n",
      "train Loss: 0.7631 Acc: 0.8036\n",
      "val Loss: 0.7813 Acc: 0.8040\n",
      "test Loss: 0.7535 Acc: 0.8200\n",
      "Epoch 719/1499\n",
      "----------\n",
      "train Loss: 0.7656 Acc: 0.8013\n",
      "val Loss: 0.7801 Acc: 0.7680\n",
      "test Loss: 0.7480 Acc: 0.8320\n",
      "Epoch 720/1499\n",
      "----------\n",
      "train Loss: 0.7615 Acc: 0.8062\n",
      "val Loss: 0.7779 Acc: 0.7760\n",
      "test Loss: 0.7449 Acc: 0.8400\n",
      "Epoch 721/1499\n",
      "----------\n",
      "train Loss: 0.7631 Acc: 0.8016\n",
      "val Loss: 0.7845 Acc: 0.7720\n",
      "test Loss: 0.7485 Acc: 0.8440\n",
      "Epoch 722/1499\n",
      "----------\n",
      "train Loss: 0.7614 Acc: 0.8044\n",
      "val Loss: 0.7732 Acc: 0.7920\n",
      "test Loss: 0.7531 Acc: 0.8280\n",
      "Epoch 723/1499\n",
      "----------\n",
      "train Loss: 0.7641 Acc: 0.8038\n",
      "val Loss: 0.7914 Acc: 0.7520\n",
      "test Loss: 0.7484 Acc: 0.8440\n",
      "Epoch 724/1499\n",
      "----------\n",
      "train Loss: 0.7603 Acc: 0.8076\n",
      "val Loss: 0.7828 Acc: 0.7880\n",
      "test Loss: 0.7479 Acc: 0.8320\n",
      "Epoch 725/1499\n",
      "----------\n",
      "train Loss: 0.7608 Acc: 0.8082\n",
      "val Loss: 0.7726 Acc: 0.7880\n",
      "test Loss: 0.7474 Acc: 0.8360\n",
      "Epoch 726/1499\n",
      "----------\n",
      "train Loss: 0.7642 Acc: 0.8042\n",
      "val Loss: 0.7715 Acc: 0.8040\n",
      "test Loss: 0.7522 Acc: 0.8280\n",
      "Epoch 727/1499\n",
      "----------\n",
      "train Loss: 0.7608 Acc: 0.8080\n",
      "val Loss: 0.7756 Acc: 0.7840\n",
      "test Loss: 0.7526 Acc: 0.8240\n",
      "Epoch 728/1499\n",
      "----------\n",
      "train Loss: 0.7619 Acc: 0.8073\n",
      "val Loss: 0.7713 Acc: 0.7840\n",
      "test Loss: 0.7592 Acc: 0.8240\n",
      "Epoch 729/1499\n",
      "----------\n",
      "train Loss: 0.7615 Acc: 0.8098\n",
      "val Loss: 0.7852 Acc: 0.7640\n",
      "test Loss: 0.7459 Acc: 0.8360\n",
      "Epoch 730/1499\n",
      "----------\n",
      "train Loss: 0.7632 Acc: 0.8044\n",
      "val Loss: 0.7841 Acc: 0.7800\n",
      "test Loss: 0.7477 Acc: 0.8360\n",
      "Epoch 731/1499\n",
      "----------\n",
      "train Loss: 0.7621 Acc: 0.8018\n",
      "val Loss: 0.7696 Acc: 0.7960\n",
      "test Loss: 0.7392 Acc: 0.8520\n",
      "Epoch 732/1499\n",
      "----------\n",
      "train Loss: 0.7614 Acc: 0.8051\n",
      "val Loss: 0.7827 Acc: 0.7760\n",
      "test Loss: 0.7461 Acc: 0.8480\n",
      "Epoch 733/1499\n",
      "----------\n",
      "train Loss: 0.7607 Acc: 0.8096\n",
      "val Loss: 0.7822 Acc: 0.7720\n",
      "test Loss: 0.7487 Acc: 0.8320\n",
      "Epoch 734/1499\n",
      "----------\n",
      "train Loss: 0.7628 Acc: 0.8042\n",
      "val Loss: 0.7731 Acc: 0.7720\n",
      "test Loss: 0.7497 Acc: 0.8280\n",
      "Epoch 735/1499\n",
      "----------\n",
      "train Loss: 0.7632 Acc: 0.8020\n",
      "val Loss: 0.7734 Acc: 0.7920\n",
      "test Loss: 0.7560 Acc: 0.8200\n",
      "Epoch 736/1499\n",
      "----------\n",
      "train Loss: 0.7640 Acc: 0.8004\n",
      "val Loss: 0.7888 Acc: 0.7880\n",
      "test Loss: 0.7451 Acc: 0.8200\n",
      "Epoch 737/1499\n",
      "----------\n",
      "train Loss: 0.7610 Acc: 0.8011\n",
      "val Loss: 0.7786 Acc: 0.7840\n",
      "test Loss: 0.7448 Acc: 0.8400\n",
      "Epoch 738/1499\n",
      "----------\n",
      "train Loss: 0.7639 Acc: 0.7998\n",
      "val Loss: 0.7685 Acc: 0.7960\n",
      "test Loss: 0.7347 Acc: 0.8400\n",
      "Epoch 739/1499\n",
      "----------\n",
      "train Loss: 0.7615 Acc: 0.8058\n",
      "val Loss: 0.7689 Acc: 0.8000\n",
      "test Loss: 0.7482 Acc: 0.8240\n",
      "Epoch 740/1499\n",
      "----------\n",
      "train Loss: 0.7645 Acc: 0.7964\n",
      "val Loss: 0.7809 Acc: 0.7720\n",
      "test Loss: 0.7438 Acc: 0.8480\n",
      "Epoch 741/1499\n",
      "----------\n",
      "train Loss: 0.7621 Acc: 0.8047\n",
      "val Loss: 0.7832 Acc: 0.7680\n",
      "test Loss: 0.7422 Acc: 0.8440\n",
      "Epoch 742/1499\n",
      "----------\n",
      "train Loss: 0.7601 Acc: 0.8044\n",
      "val Loss: 0.7767 Acc: 0.7720\n",
      "test Loss: 0.7488 Acc: 0.8360\n",
      "Epoch 743/1499\n",
      "----------\n",
      "train Loss: 0.7606 Acc: 0.8033\n",
      "val Loss: 0.7717 Acc: 0.8000\n",
      "test Loss: 0.7518 Acc: 0.8080\n",
      "Epoch 744/1499\n",
      "----------\n",
      "train Loss: 0.7607 Acc: 0.8087\n",
      "val Loss: 0.7855 Acc: 0.7800\n",
      "test Loss: 0.7425 Acc: 0.8240\n",
      "Epoch 745/1499\n",
      "----------\n",
      "train Loss: 0.7636 Acc: 0.8000\n",
      "val Loss: 0.7731 Acc: 0.7760\n",
      "test Loss: 0.7560 Acc: 0.8440\n",
      "Epoch 746/1499\n",
      "----------\n",
      "train Loss: 0.7618 Acc: 0.8036\n",
      "val Loss: 0.7728 Acc: 0.7680\n",
      "test Loss: 0.7473 Acc: 0.8240\n",
      "Epoch 747/1499\n",
      "----------\n",
      "train Loss: 0.7615 Acc: 0.8060\n",
      "val Loss: 0.7697 Acc: 0.7800\n",
      "test Loss: 0.7460 Acc: 0.8200\n",
      "Epoch 748/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.7601 Acc: 0.8051\n",
      "val Loss: 0.7779 Acc: 0.7760\n",
      "test Loss: 0.7462 Acc: 0.8200\n",
      "Epoch 749/1499\n",
      "----------\n",
      "train Loss: 0.7617 Acc: 0.8027\n",
      "val Loss: 0.7652 Acc: 0.8040\n",
      "test Loss: 0.7470 Acc: 0.8400\n",
      "Epoch 750/1499\n",
      "----------\n",
      "train Loss: 0.7605 Acc: 0.8073\n",
      "val Loss: 0.7737 Acc: 0.7840\n",
      "test Loss: 0.7482 Acc: 0.8280\n",
      "Epoch 751/1499\n",
      "----------\n",
      "train Loss: 0.7614 Acc: 0.8071\n",
      "val Loss: 0.7726 Acc: 0.7880\n",
      "test Loss: 0.7400 Acc: 0.8520\n",
      "Epoch 752/1499\n",
      "----------\n",
      "train Loss: 0.7604 Acc: 0.8013\n",
      "val Loss: 0.7755 Acc: 0.7800\n",
      "test Loss: 0.7408 Acc: 0.8320\n",
      "Epoch 753/1499\n",
      "----------\n",
      "train Loss: 0.7640 Acc: 0.8027\n",
      "val Loss: 0.7854 Acc: 0.7760\n",
      "test Loss: 0.7560 Acc: 0.8280\n",
      "Epoch 754/1499\n",
      "----------\n",
      "train Loss: 0.7614 Acc: 0.8031\n",
      "val Loss: 0.7725 Acc: 0.7800\n",
      "test Loss: 0.7363 Acc: 0.8400\n",
      "Epoch 755/1499\n",
      "----------\n",
      "train Loss: 0.7595 Acc: 0.8031\n",
      "val Loss: 0.7674 Acc: 0.7840\n",
      "test Loss: 0.7404 Acc: 0.8400\n",
      "Epoch 756/1499\n",
      "----------\n",
      "train Loss: 0.7597 Acc: 0.8049\n",
      "val Loss: 0.7804 Acc: 0.8000\n",
      "test Loss: 0.7387 Acc: 0.8360\n",
      "Epoch 757/1499\n",
      "----------\n",
      "train Loss: 0.7607 Acc: 0.8042\n",
      "val Loss: 0.7826 Acc: 0.7680\n",
      "test Loss: 0.7407 Acc: 0.8400\n",
      "Epoch 758/1499\n",
      "----------\n",
      "train Loss: 0.7598 Acc: 0.8060\n",
      "val Loss: 0.7738 Acc: 0.7440\n",
      "test Loss: 0.7470 Acc: 0.8080\n",
      "Epoch 759/1499\n",
      "----------\n",
      "train Loss: 0.7587 Acc: 0.8067\n",
      "val Loss: 0.7672 Acc: 0.7800\n",
      "test Loss: 0.7412 Acc: 0.8280\n",
      "Epoch 760/1499\n",
      "----------\n",
      "train Loss: 0.7604 Acc: 0.8036\n",
      "val Loss: 0.7677 Acc: 0.7960\n",
      "test Loss: 0.7455 Acc: 0.8360\n",
      "Epoch 761/1499\n",
      "----------\n",
      "train Loss: 0.7620 Acc: 0.8009\n",
      "val Loss: 0.7742 Acc: 0.7920\n",
      "test Loss: 0.7388 Acc: 0.8320\n",
      "Epoch 762/1499\n",
      "----------\n",
      "train Loss: 0.7589 Acc: 0.8033\n",
      "val Loss: 0.7748 Acc: 0.7720\n",
      "test Loss: 0.7608 Acc: 0.8040\n",
      "Epoch 763/1499\n",
      "----------\n",
      "train Loss: 0.7588 Acc: 0.8044\n",
      "val Loss: 0.7769 Acc: 0.7640\n",
      "test Loss: 0.7487 Acc: 0.8320\n",
      "Epoch 764/1499\n",
      "----------\n",
      "train Loss: 0.7572 Acc: 0.8049\n",
      "val Loss: 0.7857 Acc: 0.7680\n",
      "test Loss: 0.7382 Acc: 0.8360\n",
      "Epoch 765/1499\n",
      "----------\n",
      "train Loss: 0.7593 Acc: 0.8009\n",
      "val Loss: 0.7780 Acc: 0.7800\n",
      "test Loss: 0.7477 Acc: 0.8320\n",
      "Epoch 766/1499\n",
      "----------\n",
      "train Loss: 0.7603 Acc: 0.8036\n",
      "val Loss: 0.7841 Acc: 0.7560\n",
      "test Loss: 0.7465 Acc: 0.8080\n",
      "Epoch 767/1499\n",
      "----------\n",
      "train Loss: 0.7590 Acc: 0.8067\n",
      "val Loss: 0.7733 Acc: 0.7720\n",
      "test Loss: 0.7468 Acc: 0.8280\n",
      "Epoch 768/1499\n",
      "----------\n",
      "train Loss: 0.7592 Acc: 0.8040\n",
      "val Loss: 0.7743 Acc: 0.7840\n",
      "test Loss: 0.7434 Acc: 0.8320\n",
      "Epoch 769/1499\n",
      "----------\n",
      "train Loss: 0.7618 Acc: 0.8038\n",
      "val Loss: 0.7678 Acc: 0.7920\n",
      "test Loss: 0.7405 Acc: 0.8400\n",
      "Epoch 770/1499\n",
      "----------\n",
      "train Loss: 0.7600 Acc: 0.8053\n",
      "val Loss: 0.7709 Acc: 0.7720\n",
      "test Loss: 0.7411 Acc: 0.8400\n",
      "Epoch 771/1499\n",
      "----------\n",
      "train Loss: 0.7593 Acc: 0.8071\n",
      "val Loss: 0.7734 Acc: 0.8000\n",
      "test Loss: 0.7512 Acc: 0.8320\n",
      "Epoch 772/1499\n",
      "----------\n",
      "train Loss: 0.7596 Acc: 0.8027\n",
      "val Loss: 0.7795 Acc: 0.7800\n",
      "test Loss: 0.7487 Acc: 0.8320\n",
      "Epoch 773/1499\n",
      "----------\n",
      "train Loss: 0.7578 Acc: 0.8091\n",
      "val Loss: 0.7816 Acc: 0.7600\n",
      "test Loss: 0.7427 Acc: 0.8280\n",
      "Epoch 774/1499\n",
      "----------\n",
      "train Loss: 0.7581 Acc: 0.8102\n",
      "val Loss: 0.7814 Acc: 0.7440\n",
      "test Loss: 0.7567 Acc: 0.8200\n",
      "Epoch 775/1499\n",
      "----------\n",
      "train Loss: 0.7582 Acc: 0.8087\n",
      "val Loss: 0.7841 Acc: 0.7760\n",
      "test Loss: 0.7468 Acc: 0.8280\n",
      "Epoch 776/1499\n",
      "----------\n",
      "train Loss: 0.7600 Acc: 0.8047\n",
      "val Loss: 0.7663 Acc: 0.7840\n",
      "test Loss: 0.7404 Acc: 0.8280\n",
      "Epoch 777/1499\n",
      "----------\n",
      "train Loss: 0.7587 Acc: 0.8042\n",
      "val Loss: 0.7770 Acc: 0.7640\n",
      "test Loss: 0.7493 Acc: 0.8120\n",
      "Epoch 778/1499\n",
      "----------\n",
      "train Loss: 0.7594 Acc: 0.8062\n",
      "val Loss: 0.7727 Acc: 0.7760\n",
      "test Loss: 0.7405 Acc: 0.8280\n",
      "Epoch 779/1499\n",
      "----------\n",
      "train Loss: 0.7586 Acc: 0.8020\n",
      "val Loss: 0.7805 Acc: 0.7680\n",
      "test Loss: 0.7379 Acc: 0.8280\n",
      "Epoch 780/1499\n",
      "----------\n",
      "train Loss: 0.7580 Acc: 0.8062\n",
      "val Loss: 0.7809 Acc: 0.7720\n",
      "test Loss: 0.7421 Acc: 0.8200\n",
      "Epoch 781/1499\n",
      "----------\n",
      "train Loss: 0.7590 Acc: 0.8053\n",
      "val Loss: 0.7818 Acc: 0.7680\n",
      "test Loss: 0.7447 Acc: 0.8280\n",
      "Epoch 782/1499\n",
      "----------\n",
      "train Loss: 0.7581 Acc: 0.8020\n",
      "val Loss: 0.7800 Acc: 0.7800\n",
      "test Loss: 0.7446 Acc: 0.8240\n",
      "Epoch 783/1499\n",
      "----------\n",
      "train Loss: 0.7606 Acc: 0.8056\n",
      "val Loss: 0.7806 Acc: 0.7760\n",
      "test Loss: 0.7414 Acc: 0.8200\n",
      "Epoch 784/1499\n",
      "----------\n",
      "train Loss: 0.7577 Acc: 0.8049\n",
      "val Loss: 0.7769 Acc: 0.7840\n",
      "test Loss: 0.7514 Acc: 0.8160\n",
      "Epoch 785/1499\n",
      "----------\n",
      "train Loss: 0.7576 Acc: 0.8056\n",
      "val Loss: 0.7666 Acc: 0.7920\n",
      "test Loss: 0.7503 Acc: 0.8240\n",
      "Epoch 786/1499\n",
      "----------\n",
      "train Loss: 0.7586 Acc: 0.8056\n",
      "val Loss: 0.7665 Acc: 0.7960\n",
      "test Loss: 0.7434 Acc: 0.8480\n",
      "Epoch 787/1499\n",
      "----------\n",
      "train Loss: 0.7578 Acc: 0.8087\n",
      "val Loss: 0.7687 Acc: 0.7840\n",
      "test Loss: 0.7486 Acc: 0.8240\n",
      "Epoch 788/1499\n",
      "----------\n",
      "train Loss: 0.7573 Acc: 0.8064\n",
      "val Loss: 0.7700 Acc: 0.7880\n",
      "test Loss: 0.7443 Acc: 0.8200\n",
      "Epoch 789/1499\n",
      "----------\n",
      "train Loss: 0.7588 Acc: 0.8007\n",
      "val Loss: 0.7635 Acc: 0.7880\n",
      "test Loss: 0.7484 Acc: 0.8200\n",
      "Epoch 790/1499\n",
      "----------\n",
      "train Loss: 0.7611 Acc: 0.8000\n",
      "val Loss: 0.7726 Acc: 0.7880\n",
      "test Loss: 0.7455 Acc: 0.8280\n",
      "Epoch 791/1499\n",
      "----------\n",
      "train Loss: 0.7598 Acc: 0.8036\n",
      "val Loss: 0.7669 Acc: 0.7880\n",
      "test Loss: 0.7555 Acc: 0.8080\n",
      "Epoch 792/1499\n",
      "----------\n",
      "train Loss: 0.7566 Acc: 0.8082\n",
      "val Loss: 0.7631 Acc: 0.7920\n",
      "test Loss: 0.7528 Acc: 0.8120\n",
      "Epoch 793/1499\n",
      "----------\n",
      "train Loss: 0.7589 Acc: 0.8013\n",
      "val Loss: 0.7766 Acc: 0.7880\n",
      "test Loss: 0.7343 Acc: 0.8480\n",
      "Epoch 794/1499\n",
      "----------\n",
      "train Loss: 0.7564 Acc: 0.8080\n",
      "val Loss: 0.7793 Acc: 0.7680\n",
      "test Loss: 0.7480 Acc: 0.8240\n",
      "Epoch 795/1499\n",
      "----------\n",
      "train Loss: 0.7580 Acc: 0.8056\n",
      "val Loss: 0.7747 Acc: 0.7960\n",
      "test Loss: 0.7387 Acc: 0.8320\n",
      "Epoch 796/1499\n",
      "----------\n",
      "train Loss: 0.7571 Acc: 0.8049\n",
      "val Loss: 0.7713 Acc: 0.7720\n",
      "test Loss: 0.7401 Acc: 0.8400\n",
      "Epoch 797/1499\n",
      "----------\n",
      "train Loss: 0.7565 Acc: 0.8040\n",
      "val Loss: 0.7799 Acc: 0.7640\n",
      "test Loss: 0.7424 Acc: 0.8320\n",
      "Epoch 798/1499\n",
      "----------\n",
      "train Loss: 0.7569 Acc: 0.8044\n",
      "val Loss: 0.7678 Acc: 0.7920\n",
      "test Loss: 0.7560 Acc: 0.8160\n",
      "Epoch 799/1499\n",
      "----------\n",
      "train Loss: 0.7576 Acc: 0.8076\n",
      "val Loss: 0.7658 Acc: 0.8000\n",
      "test Loss: 0.7404 Acc: 0.8320\n",
      "Epoch 800/1499\n",
      "----------\n",
      "train Loss: 0.7577 Acc: 0.8036\n",
      "val Loss: 0.7650 Acc: 0.7840\n",
      "test Loss: 0.7497 Acc: 0.8000\n",
      "Epoch 801/1499\n",
      "----------\n",
      "train Loss: 0.7548 Acc: 0.8053\n",
      "val Loss: 0.7708 Acc: 0.7800\n",
      "test Loss: 0.7455 Acc: 0.8320\n",
      "Epoch 802/1499\n",
      "----------\n",
      "train Loss: 0.7577 Acc: 0.8007\n",
      "val Loss: 0.7715 Acc: 0.7720\n",
      "test Loss: 0.7409 Acc: 0.8360\n",
      "Epoch 803/1499\n",
      "----------\n",
      "train Loss: 0.7571 Acc: 0.8076\n",
      "val Loss: 0.7713 Acc: 0.7880\n",
      "test Loss: 0.7328 Acc: 0.8320\n",
      "Epoch 804/1499\n",
      "----------\n",
      "train Loss: 0.7572 Acc: 0.8018\n",
      "val Loss: 0.7785 Acc: 0.7720\n",
      "test Loss: 0.7428 Acc: 0.8480\n",
      "Epoch 805/1499\n",
      "----------\n",
      "train Loss: 0.7555 Acc: 0.8082\n",
      "val Loss: 0.7837 Acc: 0.7600\n",
      "test Loss: 0.7384 Acc: 0.8200\n",
      "Epoch 806/1499\n",
      "----------\n",
      "train Loss: 0.7563 Acc: 0.8029\n",
      "val Loss: 0.7711 Acc: 0.7880\n",
      "test Loss: 0.7343 Acc: 0.8240\n",
      "Epoch 807/1499\n",
      "----------\n",
      "train Loss: 0.7566 Acc: 0.8033\n",
      "val Loss: 0.7710 Acc: 0.7840\n",
      "test Loss: 0.7328 Acc: 0.8280\n",
      "Epoch 808/1499\n",
      "----------\n",
      "train Loss: 0.7573 Acc: 0.8051\n",
      "val Loss: 0.7608 Acc: 0.8040\n",
      "test Loss: 0.7308 Acc: 0.8600\n",
      "Epoch 809/1499\n",
      "----------\n",
      "train Loss: 0.7571 Acc: 0.8047\n",
      "val Loss: 0.7696 Acc: 0.7840\n",
      "test Loss: 0.7392 Acc: 0.8320\n",
      "Epoch 810/1499\n",
      "----------\n",
      "train Loss: 0.7554 Acc: 0.8069\n",
      "val Loss: 0.7691 Acc: 0.7800\n",
      "test Loss: 0.7412 Acc: 0.8360\n",
      "Epoch 811/1499\n",
      "----------\n",
      "train Loss: 0.7549 Acc: 0.8060\n",
      "val Loss: 0.7717 Acc: 0.7920\n",
      "test Loss: 0.7354 Acc: 0.8400\n",
      "Epoch 812/1499\n",
      "----------\n",
      "train Loss: 0.7557 Acc: 0.8062\n",
      "val Loss: 0.7610 Acc: 0.7760\n",
      "test Loss: 0.7385 Acc: 0.8320\n",
      "Epoch 813/1499\n",
      "----------\n",
      "train Loss: 0.7564 Acc: 0.8064\n",
      "val Loss: 0.7708 Acc: 0.7960\n",
      "test Loss: 0.7407 Acc: 0.8280\n",
      "Epoch 814/1499\n",
      "----------\n",
      "train Loss: 0.7561 Acc: 0.8040\n",
      "val Loss: 0.7721 Acc: 0.7880\n",
      "test Loss: 0.7339 Acc: 0.8360\n",
      "Epoch 815/1499\n",
      "----------\n",
      "train Loss: 0.7544 Acc: 0.8016\n",
      "val Loss: 0.7702 Acc: 0.7880\n",
      "test Loss: 0.7333 Acc: 0.8320\n",
      "Epoch 816/1499\n",
      "----------\n",
      "train Loss: 0.7572 Acc: 0.8022\n",
      "val Loss: 0.7653 Acc: 0.7800\n",
      "test Loss: 0.7395 Acc: 0.8320\n",
      "Epoch 817/1499\n",
      "----------\n",
      "train Loss: 0.7551 Acc: 0.8036\n",
      "val Loss: 0.7697 Acc: 0.8040\n",
      "test Loss: 0.7436 Acc: 0.8440\n",
      "Epoch 818/1499\n",
      "----------\n",
      "train Loss: 0.7562 Acc: 0.8060\n",
      "val Loss: 0.7823 Acc: 0.7760\n",
      "test Loss: 0.7506 Acc: 0.8080\n",
      "Epoch 819/1499\n",
      "----------\n",
      "train Loss: 0.7569 Acc: 0.8029\n",
      "val Loss: 0.7717 Acc: 0.7760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.7418 Acc: 0.8200\n",
      "Epoch 820/1499\n",
      "----------\n",
      "train Loss: 0.7572 Acc: 0.8047\n",
      "val Loss: 0.7675 Acc: 0.7840\n",
      "test Loss: 0.7508 Acc: 0.8200\n",
      "Epoch 821/1499\n",
      "----------\n",
      "train Loss: 0.7565 Acc: 0.8062\n",
      "val Loss: 0.7673 Acc: 0.7840\n",
      "test Loss: 0.7328 Acc: 0.8440\n",
      "Epoch 822/1499\n",
      "----------\n",
      "train Loss: 0.7594 Acc: 0.7993\n",
      "val Loss: 0.7757 Acc: 0.7680\n",
      "test Loss: 0.7319 Acc: 0.8400\n",
      "Epoch 823/1499\n",
      "----------\n",
      "train Loss: 0.7553 Acc: 0.8029\n",
      "val Loss: 0.7660 Acc: 0.7920\n",
      "test Loss: 0.7365 Acc: 0.8280\n",
      "Epoch 824/1499\n",
      "----------\n",
      "train Loss: 0.7550 Acc: 0.8051\n",
      "val Loss: 0.7695 Acc: 0.7840\n",
      "test Loss: 0.7414 Acc: 0.8160\n",
      "Epoch 825/1499\n",
      "----------\n",
      "train Loss: 0.7572 Acc: 0.8058\n",
      "val Loss: 0.7697 Acc: 0.7760\n",
      "test Loss: 0.7390 Acc: 0.8240\n",
      "Epoch 826/1499\n",
      "----------\n",
      "train Loss: 0.7576 Acc: 0.8042\n",
      "val Loss: 0.7813 Acc: 0.7800\n",
      "test Loss: 0.7455 Acc: 0.8160\n",
      "Epoch 827/1499\n",
      "----------\n",
      "train Loss: 0.7540 Acc: 0.8073\n",
      "val Loss: 0.7641 Acc: 0.7800\n",
      "test Loss: 0.7386 Acc: 0.8360\n",
      "Epoch 828/1499\n",
      "----------\n",
      "train Loss: 0.7538 Acc: 0.8071\n",
      "val Loss: 0.7667 Acc: 0.8040\n",
      "test Loss: 0.7370 Acc: 0.8320\n",
      "Epoch 829/1499\n",
      "----------\n",
      "train Loss: 0.7536 Acc: 0.8076\n",
      "val Loss: 0.7625 Acc: 0.7880\n",
      "test Loss: 0.7494 Acc: 0.8240\n",
      "Epoch 830/1499\n",
      "----------\n",
      "train Loss: 0.7556 Acc: 0.8040\n",
      "val Loss: 0.7597 Acc: 0.8040\n",
      "test Loss: 0.7319 Acc: 0.8440\n",
      "Epoch 831/1499\n",
      "----------\n",
      "train Loss: 0.7557 Acc: 0.8036\n",
      "val Loss: 0.7555 Acc: 0.8000\n",
      "test Loss: 0.7392 Acc: 0.8320\n",
      "Epoch 832/1499\n",
      "----------\n",
      "train Loss: 0.7532 Acc: 0.8042\n",
      "val Loss: 0.7646 Acc: 0.7840\n",
      "test Loss: 0.7407 Acc: 0.8240\n",
      "Epoch 833/1499\n",
      "----------\n",
      "train Loss: 0.7548 Acc: 0.8024\n",
      "val Loss: 0.7661 Acc: 0.7880\n",
      "test Loss: 0.7417 Acc: 0.8320\n",
      "Epoch 834/1499\n",
      "----------\n",
      "train Loss: 0.7538 Acc: 0.8071\n",
      "val Loss: 0.7699 Acc: 0.7840\n",
      "test Loss: 0.7470 Acc: 0.8200\n",
      "Epoch 835/1499\n",
      "----------\n",
      "train Loss: 0.7540 Acc: 0.8051\n",
      "val Loss: 0.7670 Acc: 0.7800\n",
      "test Loss: 0.7363 Acc: 0.8360\n",
      "Epoch 836/1499\n",
      "----------\n",
      "train Loss: 0.7547 Acc: 0.8038\n",
      "val Loss: 0.7711 Acc: 0.7960\n",
      "test Loss: 0.7408 Acc: 0.8280\n",
      "Epoch 837/1499\n",
      "----------\n",
      "train Loss: 0.7536 Acc: 0.8084\n",
      "val Loss: 0.7591 Acc: 0.7840\n",
      "test Loss: 0.7328 Acc: 0.8400\n",
      "Epoch 838/1499\n",
      "----------\n",
      "train Loss: 0.7536 Acc: 0.8087\n",
      "val Loss: 0.7587 Acc: 0.8000\n",
      "test Loss: 0.7392 Acc: 0.8320\n",
      "Epoch 839/1499\n",
      "----------\n",
      "train Loss: 0.7523 Acc: 0.8073\n",
      "val Loss: 0.7634 Acc: 0.7880\n",
      "test Loss: 0.7347 Acc: 0.8320\n",
      "Epoch 840/1499\n",
      "----------\n",
      "train Loss: 0.7526 Acc: 0.8087\n",
      "val Loss: 0.7679 Acc: 0.7880\n",
      "test Loss: 0.7367 Acc: 0.8440\n",
      "Epoch 841/1499\n",
      "----------\n",
      "train Loss: 0.7541 Acc: 0.8056\n",
      "val Loss: 0.7613 Acc: 0.7920\n",
      "test Loss: 0.7427 Acc: 0.8280\n",
      "Epoch 842/1499\n",
      "----------\n",
      "train Loss: 0.7551 Acc: 0.8020\n",
      "val Loss: 0.7648 Acc: 0.7840\n",
      "test Loss: 0.7499 Acc: 0.8040\n",
      "Epoch 843/1499\n",
      "----------\n",
      "train Loss: 0.7555 Acc: 0.8056\n",
      "val Loss: 0.7718 Acc: 0.7680\n",
      "test Loss: 0.7373 Acc: 0.8320\n",
      "Epoch 844/1499\n",
      "----------\n",
      "train Loss: 0.7558 Acc: 0.8053\n",
      "val Loss: 0.7738 Acc: 0.7760\n",
      "test Loss: 0.7468 Acc: 0.8080\n",
      "Epoch 845/1499\n",
      "----------\n",
      "train Loss: 0.7539 Acc: 0.8062\n",
      "val Loss: 0.7536 Acc: 0.8040\n",
      "test Loss: 0.7373 Acc: 0.8320\n",
      "Epoch 846/1499\n",
      "----------\n",
      "train Loss: 0.7521 Acc: 0.8064\n",
      "val Loss: 0.7703 Acc: 0.7760\n",
      "test Loss: 0.7328 Acc: 0.8480\n",
      "Epoch 847/1499\n",
      "----------\n",
      "train Loss: 0.7560 Acc: 0.8022\n",
      "val Loss: 0.7670 Acc: 0.7840\n",
      "test Loss: 0.7430 Acc: 0.8200\n",
      "Epoch 848/1499\n",
      "----------\n",
      "train Loss: 0.7543 Acc: 0.8051\n",
      "val Loss: 0.7720 Acc: 0.7840\n",
      "test Loss: 0.7430 Acc: 0.8280\n",
      "Epoch 849/1499\n",
      "----------\n",
      "train Loss: 0.7512 Acc: 0.8073\n",
      "val Loss: 0.7629 Acc: 0.7840\n",
      "test Loss: 0.7354 Acc: 0.8360\n",
      "Epoch 850/1499\n",
      "----------\n",
      "train Loss: 0.7538 Acc: 0.8022\n",
      "val Loss: 0.7662 Acc: 0.7800\n",
      "test Loss: 0.7400 Acc: 0.8320\n",
      "Epoch 851/1499\n",
      "----------\n",
      "train Loss: 0.7538 Acc: 0.8013\n",
      "val Loss: 0.7648 Acc: 0.7960\n",
      "test Loss: 0.7417 Acc: 0.8360\n",
      "Epoch 852/1499\n",
      "----------\n",
      "train Loss: 0.7563 Acc: 0.8011\n",
      "val Loss: 0.7614 Acc: 0.7840\n",
      "test Loss: 0.7541 Acc: 0.8080\n",
      "Epoch 853/1499\n",
      "----------\n",
      "train Loss: 0.7528 Acc: 0.8069\n",
      "val Loss: 0.7674 Acc: 0.7680\n",
      "test Loss: 0.7437 Acc: 0.8240\n",
      "Epoch 854/1499\n",
      "----------\n",
      "train Loss: 0.7540 Acc: 0.8027\n",
      "val Loss: 0.7748 Acc: 0.7680\n",
      "test Loss: 0.7412 Acc: 0.8280\n",
      "Epoch 855/1499\n",
      "----------\n",
      "train Loss: 0.7547 Acc: 0.8029\n",
      "val Loss: 0.7643 Acc: 0.7760\n",
      "test Loss: 0.7371 Acc: 0.8480\n",
      "Epoch 856/1499\n",
      "----------\n",
      "train Loss: 0.7525 Acc: 0.8047\n",
      "val Loss: 0.7698 Acc: 0.7760\n",
      "test Loss: 0.7349 Acc: 0.8360\n",
      "Epoch 857/1499\n",
      "----------\n",
      "train Loss: 0.7551 Acc: 0.8049\n",
      "val Loss: 0.7675 Acc: 0.7680\n",
      "test Loss: 0.7484 Acc: 0.8280\n",
      "Epoch 858/1499\n",
      "----------\n",
      "train Loss: 0.7503 Acc: 0.8116\n",
      "val Loss: 0.7792 Acc: 0.7760\n",
      "test Loss: 0.7470 Acc: 0.8320\n",
      "Epoch 859/1499\n",
      "----------\n",
      "train Loss: 0.7515 Acc: 0.8058\n",
      "val Loss: 0.7627 Acc: 0.7880\n",
      "test Loss: 0.7459 Acc: 0.8200\n",
      "Epoch 860/1499\n",
      "----------\n",
      "train Loss: 0.7543 Acc: 0.8033\n",
      "val Loss: 0.7640 Acc: 0.7920\n",
      "test Loss: 0.7411 Acc: 0.8240\n",
      "Epoch 861/1499\n",
      "----------\n",
      "train Loss: 0.7536 Acc: 0.8073\n",
      "val Loss: 0.7661 Acc: 0.7880\n",
      "test Loss: 0.7357 Acc: 0.8400\n",
      "Epoch 862/1499\n",
      "----------\n",
      "train Loss: 0.7530 Acc: 0.8027\n",
      "val Loss: 0.7637 Acc: 0.7800\n",
      "test Loss: 0.7467 Acc: 0.8280\n",
      "Epoch 863/1499\n",
      "----------\n",
      "train Loss: 0.7540 Acc: 0.8033\n",
      "val Loss: 0.7741 Acc: 0.7880\n",
      "test Loss: 0.7301 Acc: 0.8400\n",
      "Epoch 864/1499\n",
      "----------\n",
      "train Loss: 0.7553 Acc: 0.8027\n",
      "val Loss: 0.7621 Acc: 0.7960\n",
      "test Loss: 0.7463 Acc: 0.8120\n",
      "Epoch 865/1499\n",
      "----------\n",
      "train Loss: 0.7531 Acc: 0.8060\n",
      "val Loss: 0.7630 Acc: 0.7960\n",
      "test Loss: 0.7425 Acc: 0.8240\n",
      "Epoch 866/1499\n",
      "----------\n",
      "train Loss: 0.7553 Acc: 0.8004\n",
      "val Loss: 0.7643 Acc: 0.8000\n",
      "test Loss: 0.7397 Acc: 0.8320\n",
      "Epoch 867/1499\n",
      "----------\n",
      "train Loss: 0.7550 Acc: 0.8016\n",
      "val Loss: 0.7695 Acc: 0.7880\n",
      "test Loss: 0.7394 Acc: 0.8240\n",
      "Epoch 868/1499\n",
      "----------\n",
      "train Loss: 0.7532 Acc: 0.8038\n",
      "val Loss: 0.7686 Acc: 0.7800\n",
      "test Loss: 0.7345 Acc: 0.8320\n",
      "Epoch 869/1499\n",
      "----------\n",
      "train Loss: 0.7507 Acc: 0.8073\n",
      "val Loss: 0.7623 Acc: 0.7960\n",
      "test Loss: 0.7353 Acc: 0.8240\n",
      "Epoch 870/1499\n",
      "----------\n",
      "train Loss: 0.7540 Acc: 0.8076\n",
      "val Loss: 0.7628 Acc: 0.7880\n",
      "test Loss: 0.7367 Acc: 0.8320\n",
      "Epoch 871/1499\n",
      "----------\n",
      "train Loss: 0.7534 Acc: 0.8033\n",
      "val Loss: 0.7680 Acc: 0.7840\n",
      "test Loss: 0.7487 Acc: 0.8240\n",
      "Epoch 872/1499\n",
      "----------\n",
      "train Loss: 0.7519 Acc: 0.8084\n",
      "val Loss: 0.7757 Acc: 0.7520\n",
      "test Loss: 0.7406 Acc: 0.8120\n",
      "Epoch 873/1499\n",
      "----------\n",
      "train Loss: 0.7528 Acc: 0.8053\n",
      "val Loss: 0.7690 Acc: 0.7680\n",
      "test Loss: 0.7531 Acc: 0.7960\n",
      "Epoch 874/1499\n",
      "----------\n",
      "train Loss: 0.7539 Acc: 0.8020\n",
      "val Loss: 0.7581 Acc: 0.8040\n",
      "test Loss: 0.7373 Acc: 0.8120\n",
      "Epoch 875/1499\n",
      "----------\n",
      "train Loss: 0.7525 Acc: 0.8036\n",
      "val Loss: 0.7477 Acc: 0.8080\n",
      "test Loss: 0.7411 Acc: 0.8320\n",
      "Epoch 876/1499\n",
      "----------\n",
      "train Loss: 0.7511 Acc: 0.8087\n",
      "val Loss: 0.7706 Acc: 0.7680\n",
      "test Loss: 0.7271 Acc: 0.8600\n",
      "Epoch 877/1499\n",
      "----------\n",
      "train Loss: 0.7514 Acc: 0.8051\n",
      "val Loss: 0.7688 Acc: 0.7880\n",
      "test Loss: 0.7292 Acc: 0.8400\n",
      "Epoch 878/1499\n",
      "----------\n",
      "train Loss: 0.7549 Acc: 0.8051\n",
      "val Loss: 0.7770 Acc: 0.7600\n",
      "test Loss: 0.7351 Acc: 0.8280\n",
      "Epoch 879/1499\n",
      "----------\n",
      "train Loss: 0.7534 Acc: 0.8051\n",
      "val Loss: 0.7598 Acc: 0.7960\n",
      "test Loss: 0.7332 Acc: 0.8480\n",
      "Epoch 880/1499\n",
      "----------\n",
      "train Loss: 0.7523 Acc: 0.8089\n",
      "val Loss: 0.7659 Acc: 0.7880\n",
      "test Loss: 0.7353 Acc: 0.8400\n",
      "Epoch 881/1499\n",
      "----------\n",
      "train Loss: 0.7502 Acc: 0.8111\n",
      "val Loss: 0.7727 Acc: 0.7800\n",
      "test Loss: 0.7401 Acc: 0.8360\n",
      "Epoch 882/1499\n",
      "----------\n",
      "train Loss: 0.7508 Acc: 0.8076\n",
      "val Loss: 0.7557 Acc: 0.7960\n",
      "test Loss: 0.7350 Acc: 0.8200\n",
      "Epoch 883/1499\n",
      "----------\n",
      "train Loss: 0.7509 Acc: 0.8071\n",
      "val Loss: 0.7693 Acc: 0.7920\n",
      "test Loss: 0.7419 Acc: 0.8280\n",
      "Epoch 884/1499\n",
      "----------\n",
      "train Loss: 0.7523 Acc: 0.8071\n",
      "val Loss: 0.7728 Acc: 0.7800\n",
      "test Loss: 0.7334 Acc: 0.8280\n",
      "Epoch 885/1499\n",
      "----------\n",
      "train Loss: 0.7494 Acc: 0.8089\n",
      "val Loss: 0.7646 Acc: 0.7880\n",
      "test Loss: 0.7385 Acc: 0.8400\n",
      "Epoch 886/1499\n",
      "----------\n",
      "train Loss: 0.7506 Acc: 0.8107\n",
      "val Loss: 0.7658 Acc: 0.7760\n",
      "test Loss: 0.7406 Acc: 0.8280\n",
      "Epoch 887/1499\n",
      "----------\n",
      "train Loss: 0.7508 Acc: 0.8109\n",
      "val Loss: 0.7714 Acc: 0.7800\n",
      "test Loss: 0.7319 Acc: 0.8240\n",
      "Epoch 888/1499\n",
      "----------\n",
      "train Loss: 0.7514 Acc: 0.8051\n",
      "val Loss: 0.7636 Acc: 0.7880\n",
      "test Loss: 0.7307 Acc: 0.8400\n",
      "Epoch 889/1499\n",
      "----------\n",
      "train Loss: 0.7517 Acc: 0.8064\n",
      "val Loss: 0.7624 Acc: 0.7920\n",
      "test Loss: 0.7322 Acc: 0.8400\n",
      "Epoch 890/1499\n",
      "----------\n",
      "train Loss: 0.7493 Acc: 0.8107\n",
      "val Loss: 0.7646 Acc: 0.7920\n",
      "test Loss: 0.7403 Acc: 0.8200\n",
      "Epoch 891/1499\n",
      "----------\n",
      "train Loss: 0.7527 Acc: 0.8027\n",
      "val Loss: 0.7738 Acc: 0.7600\n",
      "test Loss: 0.7310 Acc: 0.8320\n",
      "Epoch 892/1499\n",
      "----------\n",
      "train Loss: 0.7502 Acc: 0.8089\n",
      "val Loss: 0.7647 Acc: 0.7840\n",
      "test Loss: 0.7265 Acc: 0.8560\n",
      "Epoch 893/1499\n",
      "----------\n",
      "train Loss: 0.7513 Acc: 0.8076\n",
      "val Loss: 0.7664 Acc: 0.7800\n",
      "test Loss: 0.7444 Acc: 0.8240\n",
      "Epoch 894/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.7504 Acc: 0.8060\n",
      "val Loss: 0.7641 Acc: 0.7640\n",
      "test Loss: 0.7345 Acc: 0.8400\n",
      "Epoch 895/1499\n",
      "----------\n",
      "train Loss: 0.7506 Acc: 0.8078\n",
      "val Loss: 0.7565 Acc: 0.7920\n",
      "test Loss: 0.7369 Acc: 0.8320\n",
      "Epoch 896/1499\n",
      "----------\n",
      "train Loss: 0.7498 Acc: 0.8124\n",
      "val Loss: 0.7656 Acc: 0.7880\n",
      "test Loss: 0.7359 Acc: 0.8400\n",
      "Epoch 897/1499\n",
      "----------\n",
      "train Loss: 0.7510 Acc: 0.8067\n",
      "val Loss: 0.7678 Acc: 0.7880\n",
      "test Loss: 0.7371 Acc: 0.8200\n",
      "Epoch 898/1499\n",
      "----------\n",
      "train Loss: 0.7529 Acc: 0.8029\n",
      "val Loss: 0.7565 Acc: 0.7960\n",
      "test Loss: 0.7318 Acc: 0.8400\n",
      "Epoch 899/1499\n",
      "----------\n",
      "train Loss: 0.7519 Acc: 0.8047\n",
      "val Loss: 0.7744 Acc: 0.7680\n",
      "test Loss: 0.7301 Acc: 0.8280\n",
      "Epoch 900/1499\n",
      "----------\n",
      "train Loss: 0.7504 Acc: 0.8082\n",
      "val Loss: 0.7614 Acc: 0.7800\n",
      "test Loss: 0.7445 Acc: 0.8240\n",
      "Epoch 901/1499\n",
      "----------\n",
      "train Loss: 0.7497 Acc: 0.8131\n",
      "val Loss: 0.7703 Acc: 0.7760\n",
      "test Loss: 0.7411 Acc: 0.8280\n",
      "Epoch 902/1499\n",
      "----------\n",
      "train Loss: 0.7507 Acc: 0.8096\n",
      "val Loss: 0.7677 Acc: 0.7720\n",
      "test Loss: 0.7369 Acc: 0.8400\n",
      "Epoch 903/1499\n",
      "----------\n",
      "train Loss: 0.7509 Acc: 0.8069\n",
      "val Loss: 0.7695 Acc: 0.7840\n",
      "test Loss: 0.7369 Acc: 0.8360\n",
      "Epoch 904/1499\n",
      "----------\n",
      "train Loss: 0.7518 Acc: 0.8031\n",
      "val Loss: 0.7678 Acc: 0.7720\n",
      "test Loss: 0.7337 Acc: 0.8240\n",
      "Epoch 905/1499\n",
      "----------\n",
      "train Loss: 0.7514 Acc: 0.8024\n",
      "val Loss: 0.7662 Acc: 0.8000\n",
      "test Loss: 0.7473 Acc: 0.8080\n",
      "Epoch 906/1499\n",
      "----------\n",
      "train Loss: 0.7497 Acc: 0.8087\n",
      "val Loss: 0.7635 Acc: 0.7840\n",
      "test Loss: 0.7302 Acc: 0.8480\n",
      "Epoch 907/1499\n",
      "----------\n",
      "train Loss: 0.7513 Acc: 0.8056\n",
      "val Loss: 0.7605 Acc: 0.7840\n",
      "test Loss: 0.7247 Acc: 0.8440\n",
      "Epoch 908/1499\n",
      "----------\n",
      "train Loss: 0.7503 Acc: 0.8067\n",
      "val Loss: 0.7735 Acc: 0.7800\n",
      "test Loss: 0.7326 Acc: 0.8240\n",
      "Epoch 909/1499\n",
      "----------\n",
      "train Loss: 0.7492 Acc: 0.8107\n",
      "val Loss: 0.7701 Acc: 0.7760\n",
      "test Loss: 0.7429 Acc: 0.8200\n",
      "Epoch 910/1499\n",
      "----------\n",
      "train Loss: 0.7508 Acc: 0.8047\n",
      "val Loss: 0.7686 Acc: 0.7720\n",
      "test Loss: 0.7331 Acc: 0.8200\n",
      "Epoch 911/1499\n",
      "----------\n",
      "train Loss: 0.7504 Acc: 0.8040\n",
      "val Loss: 0.7680 Acc: 0.7840\n",
      "test Loss: 0.7332 Acc: 0.8360\n",
      "Epoch 912/1499\n",
      "----------\n",
      "train Loss: 0.7487 Acc: 0.8093\n",
      "val Loss: 0.7602 Acc: 0.7960\n",
      "test Loss: 0.7375 Acc: 0.8280\n",
      "Epoch 913/1499\n",
      "----------\n",
      "train Loss: 0.7508 Acc: 0.8071\n",
      "val Loss: 0.7614 Acc: 0.7880\n",
      "test Loss: 0.7341 Acc: 0.8320\n",
      "Epoch 914/1499\n",
      "----------\n",
      "train Loss: 0.7508 Acc: 0.8051\n",
      "val Loss: 0.7700 Acc: 0.7720\n",
      "test Loss: 0.7327 Acc: 0.8360\n",
      "Epoch 915/1499\n",
      "----------\n",
      "train Loss: 0.7492 Acc: 0.8084\n",
      "val Loss: 0.7627 Acc: 0.7840\n",
      "test Loss: 0.7333 Acc: 0.8400\n",
      "Epoch 916/1499\n",
      "----------\n",
      "train Loss: 0.7514 Acc: 0.8047\n",
      "val Loss: 0.7579 Acc: 0.7920\n",
      "test Loss: 0.7404 Acc: 0.8280\n",
      "Epoch 917/1499\n",
      "----------\n",
      "train Loss: 0.7521 Acc: 0.8042\n",
      "val Loss: 0.7688 Acc: 0.7680\n",
      "test Loss: 0.7293 Acc: 0.8400\n",
      "Epoch 918/1499\n",
      "----------\n",
      "train Loss: 0.7490 Acc: 0.8087\n",
      "val Loss: 0.7657 Acc: 0.7840\n",
      "test Loss: 0.7314 Acc: 0.8280\n",
      "Epoch 919/1499\n",
      "----------\n",
      "train Loss: 0.7489 Acc: 0.8120\n",
      "val Loss: 0.7643 Acc: 0.7840\n",
      "test Loss: 0.7311 Acc: 0.8240\n",
      "Epoch 920/1499\n",
      "----------\n",
      "train Loss: 0.7494 Acc: 0.8087\n",
      "val Loss: 0.7598 Acc: 0.7920\n",
      "test Loss: 0.7347 Acc: 0.8360\n",
      "Epoch 921/1499\n",
      "----------\n",
      "train Loss: 0.7503 Acc: 0.8093\n",
      "val Loss: 0.7605 Acc: 0.8040\n",
      "test Loss: 0.7351 Acc: 0.8240\n",
      "Epoch 922/1499\n",
      "----------\n",
      "train Loss: 0.7458 Acc: 0.8102\n",
      "val Loss: 0.7602 Acc: 0.7960\n",
      "test Loss: 0.7286 Acc: 0.8320\n",
      "Epoch 923/1499\n",
      "----------\n",
      "train Loss: 0.7501 Acc: 0.8064\n",
      "val Loss: 0.7554 Acc: 0.7960\n",
      "test Loss: 0.7324 Acc: 0.8280\n",
      "Epoch 924/1499\n",
      "----------\n",
      "train Loss: 0.7488 Acc: 0.8098\n",
      "val Loss: 0.7593 Acc: 0.7920\n",
      "test Loss: 0.7330 Acc: 0.8320\n",
      "Epoch 925/1499\n",
      "----------\n",
      "train Loss: 0.7485 Acc: 0.8118\n",
      "val Loss: 0.7623 Acc: 0.7840\n",
      "test Loss: 0.7406 Acc: 0.8280\n",
      "Epoch 926/1499\n",
      "----------\n",
      "train Loss: 0.7506 Acc: 0.8073\n",
      "val Loss: 0.7539 Acc: 0.8000\n",
      "test Loss: 0.7336 Acc: 0.8280\n",
      "Epoch 927/1499\n",
      "----------\n",
      "train Loss: 0.7479 Acc: 0.8124\n",
      "val Loss: 0.7563 Acc: 0.7960\n",
      "test Loss: 0.7263 Acc: 0.8360\n",
      "Epoch 928/1499\n",
      "----------\n",
      "train Loss: 0.7480 Acc: 0.8104\n",
      "val Loss: 0.7653 Acc: 0.7760\n",
      "test Loss: 0.7346 Acc: 0.8200\n",
      "Epoch 929/1499\n",
      "----------\n",
      "train Loss: 0.7522 Acc: 0.8053\n",
      "val Loss: 0.7616 Acc: 0.7800\n",
      "test Loss: 0.7366 Acc: 0.8240\n",
      "Epoch 930/1499\n",
      "----------\n",
      "train Loss: 0.7472 Acc: 0.8091\n",
      "val Loss: 0.7553 Acc: 0.7920\n",
      "test Loss: 0.7401 Acc: 0.8240\n",
      "Epoch 931/1499\n",
      "----------\n",
      "train Loss: 0.7506 Acc: 0.8089\n",
      "val Loss: 0.7660 Acc: 0.7760\n",
      "test Loss: 0.7305 Acc: 0.8360\n",
      "Epoch 932/1499\n",
      "----------\n",
      "train Loss: 0.7492 Acc: 0.8091\n",
      "val Loss: 0.7631 Acc: 0.7880\n",
      "test Loss: 0.7351 Acc: 0.8160\n",
      "Epoch 933/1499\n",
      "----------\n",
      "train Loss: 0.7496 Acc: 0.8051\n",
      "val Loss: 0.7692 Acc: 0.7880\n",
      "test Loss: 0.7340 Acc: 0.8240\n",
      "Epoch 934/1499\n",
      "----------\n",
      "train Loss: 0.7472 Acc: 0.8064\n",
      "val Loss: 0.7599 Acc: 0.7880\n",
      "test Loss: 0.7416 Acc: 0.8240\n",
      "Epoch 935/1499\n",
      "----------\n",
      "train Loss: 0.7496 Acc: 0.8067\n",
      "val Loss: 0.7686 Acc: 0.7840\n",
      "test Loss: 0.7381 Acc: 0.8160\n",
      "Epoch 936/1499\n",
      "----------\n",
      "train Loss: 0.7501 Acc: 0.8053\n",
      "val Loss: 0.7583 Acc: 0.7960\n",
      "test Loss: 0.7370 Acc: 0.8280\n",
      "Epoch 937/1499\n",
      "----------\n",
      "train Loss: 0.7493 Acc: 0.8051\n",
      "val Loss: 0.7653 Acc: 0.7920\n",
      "test Loss: 0.7374 Acc: 0.8280\n",
      "Epoch 938/1499\n",
      "----------\n",
      "train Loss: 0.7492 Acc: 0.8078\n",
      "val Loss: 0.7640 Acc: 0.7840\n",
      "test Loss: 0.7296 Acc: 0.8240\n",
      "Epoch 939/1499\n",
      "----------\n",
      "train Loss: 0.7468 Acc: 0.8171\n",
      "val Loss: 0.7669 Acc: 0.7840\n",
      "test Loss: 0.7373 Acc: 0.8200\n",
      "Epoch 940/1499\n",
      "----------\n",
      "train Loss: 0.7466 Acc: 0.8104\n",
      "val Loss: 0.7703 Acc: 0.7800\n",
      "test Loss: 0.7387 Acc: 0.8200\n",
      "Epoch 941/1499\n",
      "----------\n",
      "train Loss: 0.7486 Acc: 0.8084\n",
      "val Loss: 0.7557 Acc: 0.8000\n",
      "test Loss: 0.7395 Acc: 0.8200\n",
      "Epoch 942/1499\n",
      "----------\n",
      "train Loss: 0.7484 Acc: 0.8100\n",
      "val Loss: 0.7616 Acc: 0.7880\n",
      "test Loss: 0.7288 Acc: 0.8320\n",
      "Epoch 943/1499\n",
      "----------\n",
      "train Loss: 0.7478 Acc: 0.8078\n",
      "val Loss: 0.7536 Acc: 0.7960\n",
      "test Loss: 0.7259 Acc: 0.8400\n",
      "Epoch 944/1499\n",
      "----------\n",
      "train Loss: 0.7489 Acc: 0.8080\n",
      "val Loss: 0.7621 Acc: 0.8000\n",
      "test Loss: 0.7419 Acc: 0.8120\n",
      "Epoch 945/1499\n",
      "----------\n",
      "train Loss: 0.7499 Acc: 0.8029\n",
      "val Loss: 0.7443 Acc: 0.8040\n",
      "test Loss: 0.7264 Acc: 0.8360\n",
      "Epoch 946/1499\n",
      "----------\n",
      "train Loss: 0.7509 Acc: 0.8033\n",
      "val Loss: 0.7591 Acc: 0.7880\n",
      "test Loss: 0.7300 Acc: 0.8400\n",
      "Epoch 947/1499\n",
      "----------\n",
      "train Loss: 0.7495 Acc: 0.8096\n",
      "val Loss: 0.7571 Acc: 0.8040\n",
      "test Loss: 0.7329 Acc: 0.8320\n",
      "Epoch 948/1499\n",
      "----------\n",
      "train Loss: 0.7485 Acc: 0.8087\n",
      "val Loss: 0.7608 Acc: 0.7920\n",
      "test Loss: 0.7366 Acc: 0.8360\n",
      "Epoch 949/1499\n",
      "----------\n",
      "train Loss: 0.7487 Acc: 0.8080\n",
      "val Loss: 0.7544 Acc: 0.8040\n",
      "test Loss: 0.7431 Acc: 0.8360\n",
      "Epoch 950/1499\n",
      "----------\n",
      "train Loss: 0.7470 Acc: 0.8076\n",
      "val Loss: 0.7653 Acc: 0.7920\n",
      "test Loss: 0.7311 Acc: 0.8280\n",
      "Epoch 951/1499\n",
      "----------\n",
      "train Loss: 0.7474 Acc: 0.8091\n",
      "val Loss: 0.7652 Acc: 0.7880\n",
      "test Loss: 0.7320 Acc: 0.8280\n",
      "Epoch 952/1499\n",
      "----------\n",
      "train Loss: 0.7459 Acc: 0.8124\n",
      "val Loss: 0.7618 Acc: 0.7840\n",
      "test Loss: 0.7286 Acc: 0.8280\n",
      "Epoch 953/1499\n",
      "----------\n",
      "train Loss: 0.7464 Acc: 0.8116\n",
      "val Loss: 0.7647 Acc: 0.7880\n",
      "test Loss: 0.7411 Acc: 0.8200\n",
      "Epoch 954/1499\n",
      "----------\n",
      "train Loss: 0.7492 Acc: 0.8058\n",
      "val Loss: 0.7587 Acc: 0.8000\n",
      "test Loss: 0.7371 Acc: 0.8160\n",
      "Epoch 955/1499\n",
      "----------\n",
      "train Loss: 0.7494 Acc: 0.8096\n",
      "val Loss: 0.7545 Acc: 0.7880\n",
      "test Loss: 0.7323 Acc: 0.8280\n",
      "Epoch 956/1499\n",
      "----------\n",
      "train Loss: 0.7471 Acc: 0.8098\n",
      "val Loss: 0.7615 Acc: 0.7960\n",
      "test Loss: 0.7371 Acc: 0.8280\n",
      "Epoch 957/1499\n",
      "----------\n",
      "train Loss: 0.7469 Acc: 0.8107\n",
      "val Loss: 0.7610 Acc: 0.7920\n",
      "test Loss: 0.7399 Acc: 0.8080\n",
      "Epoch 958/1499\n",
      "----------\n",
      "train Loss: 0.7461 Acc: 0.8093\n",
      "val Loss: 0.7569 Acc: 0.7920\n",
      "test Loss: 0.7306 Acc: 0.8200\n",
      "Epoch 959/1499\n",
      "----------\n",
      "train Loss: 0.7495 Acc: 0.8062\n",
      "val Loss: 0.7591 Acc: 0.7880\n",
      "test Loss: 0.7342 Acc: 0.8280\n",
      "Epoch 960/1499\n",
      "----------\n",
      "train Loss: 0.7492 Acc: 0.8080\n",
      "val Loss: 0.7615 Acc: 0.7800\n",
      "test Loss: 0.7358 Acc: 0.8280\n",
      "Epoch 961/1499\n",
      "----------\n",
      "train Loss: 0.7443 Acc: 0.8122\n",
      "val Loss: 0.7675 Acc: 0.7880\n",
      "test Loss: 0.7354 Acc: 0.8320\n",
      "Epoch 962/1499\n",
      "----------\n",
      "train Loss: 0.7473 Acc: 0.8078\n",
      "val Loss: 0.7582 Acc: 0.8040\n",
      "test Loss: 0.7383 Acc: 0.8320\n",
      "Epoch 963/1499\n",
      "----------\n",
      "train Loss: 0.7447 Acc: 0.8116\n",
      "val Loss: 0.7560 Acc: 0.7960\n",
      "test Loss: 0.7305 Acc: 0.8400\n",
      "Epoch 964/1499\n",
      "----------\n",
      "train Loss: 0.7498 Acc: 0.8029\n",
      "val Loss: 0.7620 Acc: 0.8000\n",
      "test Loss: 0.7315 Acc: 0.8200\n",
      "Epoch 965/1499\n",
      "----------\n",
      "train Loss: 0.7443 Acc: 0.8093\n",
      "val Loss: 0.7565 Acc: 0.7920\n",
      "test Loss: 0.7429 Acc: 0.8200\n",
      "Epoch 966/1499\n",
      "----------\n",
      "train Loss: 0.7472 Acc: 0.8093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.7666 Acc: 0.7680\n",
      "test Loss: 0.7458 Acc: 0.8240\n",
      "Epoch 967/1499\n",
      "----------\n",
      "train Loss: 0.7462 Acc: 0.8071\n",
      "val Loss: 0.7593 Acc: 0.8000\n",
      "test Loss: 0.7378 Acc: 0.8200\n",
      "Epoch 968/1499\n",
      "----------\n",
      "train Loss: 0.7500 Acc: 0.8064\n",
      "val Loss: 0.7629 Acc: 0.7920\n",
      "test Loss: 0.7233 Acc: 0.8520\n",
      "Epoch 969/1499\n",
      "----------\n",
      "train Loss: 0.7464 Acc: 0.8096\n",
      "val Loss: 0.7583 Acc: 0.7840\n",
      "test Loss: 0.7382 Acc: 0.8080\n",
      "Epoch 970/1499\n",
      "----------\n",
      "train Loss: 0.7459 Acc: 0.8133\n",
      "val Loss: 0.7678 Acc: 0.7720\n",
      "test Loss: 0.7368 Acc: 0.8200\n",
      "Epoch 971/1499\n",
      "----------\n",
      "train Loss: 0.7483 Acc: 0.8093\n",
      "val Loss: 0.7560 Acc: 0.7960\n",
      "test Loss: 0.7246 Acc: 0.8480\n",
      "Epoch 972/1499\n",
      "----------\n",
      "train Loss: 0.7488 Acc: 0.8038\n",
      "val Loss: 0.7666 Acc: 0.7760\n",
      "test Loss: 0.7270 Acc: 0.8360\n",
      "Epoch 973/1499\n",
      "----------\n",
      "train Loss: 0.7463 Acc: 0.8073\n",
      "val Loss: 0.7760 Acc: 0.7920\n",
      "test Loss: 0.7306 Acc: 0.8360\n",
      "Epoch 974/1499\n",
      "----------\n",
      "train Loss: 0.7468 Acc: 0.8098\n",
      "val Loss: 0.7578 Acc: 0.7880\n",
      "test Loss: 0.7352 Acc: 0.8360\n",
      "Epoch 975/1499\n",
      "----------\n",
      "train Loss: 0.7474 Acc: 0.8102\n",
      "val Loss: 0.7582 Acc: 0.8000\n",
      "test Loss: 0.7342 Acc: 0.8280\n",
      "Epoch 976/1499\n",
      "----------\n",
      "train Loss: 0.7471 Acc: 0.8091\n",
      "val Loss: 0.7591 Acc: 0.7960\n",
      "test Loss: 0.7249 Acc: 0.8520\n",
      "Epoch 977/1499\n",
      "----------\n",
      "train Loss: 0.7460 Acc: 0.8089\n",
      "val Loss: 0.7611 Acc: 0.7880\n",
      "test Loss: 0.7243 Acc: 0.8520\n",
      "Epoch 978/1499\n",
      "----------\n",
      "train Loss: 0.7467 Acc: 0.8093\n",
      "val Loss: 0.7537 Acc: 0.7960\n",
      "test Loss: 0.7275 Acc: 0.8360\n",
      "Epoch 979/1499\n",
      "----------\n",
      "train Loss: 0.7463 Acc: 0.8096\n",
      "val Loss: 0.7610 Acc: 0.7840\n",
      "test Loss: 0.7358 Acc: 0.8360\n",
      "Epoch 980/1499\n",
      "----------\n",
      "train Loss: 0.7471 Acc: 0.8096\n",
      "val Loss: 0.7637 Acc: 0.7840\n",
      "test Loss: 0.7261 Acc: 0.8280\n",
      "Epoch 981/1499\n",
      "----------\n",
      "train Loss: 0.7479 Acc: 0.8064\n",
      "val Loss: 0.7611 Acc: 0.7880\n",
      "test Loss: 0.7139 Acc: 0.8520\n",
      "Epoch 982/1499\n",
      "----------\n",
      "train Loss: 0.7467 Acc: 0.8053\n",
      "val Loss: 0.7591 Acc: 0.7960\n",
      "test Loss: 0.7251 Acc: 0.8160\n",
      "Epoch 983/1499\n",
      "----------\n",
      "train Loss: 0.7474 Acc: 0.8062\n",
      "val Loss: 0.7590 Acc: 0.8000\n",
      "test Loss: 0.7216 Acc: 0.8480\n",
      "Epoch 984/1499\n",
      "----------\n",
      "train Loss: 0.7473 Acc: 0.8051\n",
      "val Loss: 0.7685 Acc: 0.7640\n",
      "test Loss: 0.7335 Acc: 0.8440\n",
      "Epoch 985/1499\n",
      "----------\n",
      "train Loss: 0.7478 Acc: 0.8096\n",
      "val Loss: 0.7483 Acc: 0.7960\n",
      "test Loss: 0.7368 Acc: 0.8280\n",
      "Epoch 986/1499\n",
      "----------\n",
      "train Loss: 0.7480 Acc: 0.8058\n",
      "val Loss: 0.7525 Acc: 0.8000\n",
      "test Loss: 0.7296 Acc: 0.8280\n",
      "Epoch 987/1499\n",
      "----------\n",
      "train Loss: 0.7453 Acc: 0.8102\n",
      "val Loss: 0.7685 Acc: 0.7840\n",
      "test Loss: 0.7304 Acc: 0.8280\n",
      "Epoch 988/1499\n",
      "----------\n",
      "train Loss: 0.7469 Acc: 0.8087\n",
      "val Loss: 0.7604 Acc: 0.7920\n",
      "test Loss: 0.7254 Acc: 0.8240\n",
      "Epoch 989/1499\n",
      "----------\n",
      "train Loss: 0.7461 Acc: 0.8084\n",
      "val Loss: 0.7646 Acc: 0.7960\n",
      "test Loss: 0.7311 Acc: 0.8240\n",
      "Epoch 990/1499\n",
      "----------\n",
      "train Loss: 0.7446 Acc: 0.8120\n",
      "val Loss: 0.7624 Acc: 0.7800\n",
      "test Loss: 0.7321 Acc: 0.8360\n",
      "Epoch 991/1499\n",
      "----------\n",
      "train Loss: 0.7478 Acc: 0.8058\n",
      "val Loss: 0.7481 Acc: 0.7840\n",
      "test Loss: 0.7306 Acc: 0.8320\n",
      "Epoch 992/1499\n",
      "----------\n",
      "train Loss: 0.7449 Acc: 0.8084\n",
      "val Loss: 0.7528 Acc: 0.8080\n",
      "test Loss: 0.7364 Acc: 0.8200\n",
      "Epoch 993/1499\n",
      "----------\n",
      "train Loss: 0.7465 Acc: 0.8127\n",
      "val Loss: 0.7563 Acc: 0.7960\n",
      "test Loss: 0.7283 Acc: 0.8320\n",
      "Epoch 994/1499\n",
      "----------\n",
      "train Loss: 0.7435 Acc: 0.8127\n",
      "val Loss: 0.7628 Acc: 0.7840\n",
      "test Loss: 0.7372 Acc: 0.8080\n",
      "Epoch 995/1499\n",
      "----------\n",
      "train Loss: 0.7464 Acc: 0.8058\n",
      "val Loss: 0.7651 Acc: 0.7760\n",
      "test Loss: 0.7205 Acc: 0.8400\n",
      "Epoch 996/1499\n",
      "----------\n",
      "train Loss: 0.7469 Acc: 0.8080\n",
      "val Loss: 0.7705 Acc: 0.7760\n",
      "test Loss: 0.7374 Acc: 0.8160\n",
      "Epoch 997/1499\n",
      "----------\n",
      "train Loss: 0.7445 Acc: 0.8116\n",
      "val Loss: 0.7598 Acc: 0.7920\n",
      "test Loss: 0.7275 Acc: 0.8320\n",
      "Epoch 998/1499\n",
      "----------\n",
      "train Loss: 0.7479 Acc: 0.8091\n",
      "val Loss: 0.7590 Acc: 0.7960\n",
      "test Loss: 0.7339 Acc: 0.8280\n",
      "Epoch 999/1499\n",
      "----------\n",
      "train Loss: 0.7461 Acc: 0.8078\n",
      "val Loss: 0.7532 Acc: 0.8120\n",
      "test Loss: 0.7231 Acc: 0.8440\n",
      "Epoch 1000/1499\n",
      "----------\n",
      "train Loss: 0.7440 Acc: 0.8111\n",
      "val Loss: 0.7426 Acc: 0.8080\n",
      "test Loss: 0.7364 Acc: 0.8280\n",
      "Epoch 1001/1499\n",
      "----------\n",
      "train Loss: 0.7439 Acc: 0.8109\n",
      "val Loss: 0.7617 Acc: 0.7800\n",
      "test Loss: 0.7380 Acc: 0.8160\n",
      "Epoch 1002/1499\n",
      "----------\n",
      "train Loss: 0.7445 Acc: 0.8116\n",
      "val Loss: 0.7507 Acc: 0.8120\n",
      "test Loss: 0.7412 Acc: 0.8120\n",
      "Epoch 1003/1499\n",
      "----------\n",
      "train Loss: 0.7482 Acc: 0.8064\n",
      "val Loss: 0.7594 Acc: 0.7800\n",
      "test Loss: 0.7319 Acc: 0.8240\n",
      "Epoch 1004/1499\n",
      "----------\n",
      "train Loss: 0.7462 Acc: 0.8113\n",
      "val Loss: 0.7650 Acc: 0.7800\n",
      "test Loss: 0.7389 Acc: 0.8160\n",
      "Epoch 1005/1499\n",
      "----------\n",
      "train Loss: 0.7457 Acc: 0.8096\n",
      "val Loss: 0.7616 Acc: 0.7840\n",
      "test Loss: 0.7330 Acc: 0.8280\n",
      "Epoch 1006/1499\n",
      "----------\n",
      "train Loss: 0.7451 Acc: 0.8109\n",
      "val Loss: 0.7570 Acc: 0.7840\n",
      "test Loss: 0.7343 Acc: 0.8280\n",
      "Epoch 1007/1499\n",
      "----------\n",
      "train Loss: 0.7438 Acc: 0.8102\n",
      "val Loss: 0.7485 Acc: 0.8000\n",
      "test Loss: 0.7336 Acc: 0.8240\n",
      "Epoch 1008/1499\n",
      "----------\n",
      "train Loss: 0.7431 Acc: 0.8120\n",
      "val Loss: 0.7518 Acc: 0.8040\n",
      "test Loss: 0.7304 Acc: 0.8200\n",
      "Epoch 1009/1499\n",
      "----------\n",
      "train Loss: 0.7445 Acc: 0.8120\n",
      "val Loss: 0.7572 Acc: 0.8040\n",
      "test Loss: 0.7345 Acc: 0.8200\n",
      "Epoch 1010/1499\n",
      "----------\n",
      "train Loss: 0.7446 Acc: 0.8116\n",
      "val Loss: 0.7552 Acc: 0.7920\n",
      "test Loss: 0.7329 Acc: 0.8280\n",
      "Epoch 1011/1499\n",
      "----------\n",
      "train Loss: 0.7461 Acc: 0.8073\n",
      "val Loss: 0.7591 Acc: 0.7880\n",
      "test Loss: 0.7362 Acc: 0.8280\n",
      "Epoch 1012/1499\n",
      "----------\n",
      "train Loss: 0.7450 Acc: 0.8091\n",
      "val Loss: 0.7575 Acc: 0.8000\n",
      "test Loss: 0.7308 Acc: 0.8320\n",
      "Epoch 1013/1499\n",
      "----------\n",
      "train Loss: 0.7427 Acc: 0.8102\n",
      "val Loss: 0.7456 Acc: 0.8120\n",
      "test Loss: 0.7351 Acc: 0.8240\n",
      "Epoch 1014/1499\n",
      "----------\n",
      "train Loss: 0.7450 Acc: 0.8109\n",
      "val Loss: 0.7513 Acc: 0.8000\n",
      "test Loss: 0.7222 Acc: 0.8280\n",
      "Epoch 1015/1499\n",
      "----------\n",
      "train Loss: 0.7441 Acc: 0.8082\n",
      "val Loss: 0.7605 Acc: 0.7840\n",
      "test Loss: 0.7356 Acc: 0.8080\n",
      "Epoch 1016/1499\n",
      "----------\n",
      "train Loss: 0.7451 Acc: 0.8111\n",
      "val Loss: 0.7647 Acc: 0.8080\n",
      "test Loss: 0.7322 Acc: 0.8240\n",
      "Epoch 1017/1499\n",
      "----------\n",
      "train Loss: 0.7464 Acc: 0.8064\n",
      "val Loss: 0.7659 Acc: 0.7840\n",
      "test Loss: 0.7247 Acc: 0.8480\n",
      "Epoch 1018/1499\n",
      "----------\n",
      "train Loss: 0.7440 Acc: 0.8058\n",
      "val Loss: 0.7586 Acc: 0.7960\n",
      "test Loss: 0.7349 Acc: 0.8200\n",
      "Epoch 1019/1499\n",
      "----------\n",
      "train Loss: 0.7466 Acc: 0.8047\n",
      "val Loss: 0.7594 Acc: 0.8000\n",
      "test Loss: 0.7219 Acc: 0.8480\n",
      "Epoch 1020/1499\n",
      "----------\n",
      "train Loss: 0.7457 Acc: 0.8089\n",
      "val Loss: 0.7577 Acc: 0.7920\n",
      "test Loss: 0.7329 Acc: 0.8280\n",
      "Epoch 1021/1499\n",
      "----------\n",
      "train Loss: 0.7456 Acc: 0.8040\n",
      "val Loss: 0.7454 Acc: 0.8080\n",
      "test Loss: 0.7280 Acc: 0.8320\n",
      "Epoch 1022/1499\n",
      "----------\n",
      "train Loss: 0.7450 Acc: 0.8078\n",
      "val Loss: 0.7661 Acc: 0.7840\n",
      "test Loss: 0.7252 Acc: 0.8280\n",
      "Epoch 1023/1499\n",
      "----------\n",
      "train Loss: 0.7451 Acc: 0.8071\n",
      "val Loss: 0.7591 Acc: 0.7840\n",
      "test Loss: 0.7221 Acc: 0.8200\n",
      "Epoch 1024/1499\n",
      "----------\n",
      "train Loss: 0.7442 Acc: 0.8142\n",
      "val Loss: 0.7572 Acc: 0.7920\n",
      "test Loss: 0.7287 Acc: 0.8320\n",
      "Epoch 1025/1499\n",
      "----------\n",
      "train Loss: 0.7464 Acc: 0.8053\n",
      "val Loss: 0.7658 Acc: 0.7920\n",
      "test Loss: 0.7299 Acc: 0.8400\n",
      "Epoch 1026/1499\n",
      "----------\n",
      "train Loss: 0.7441 Acc: 0.8113\n",
      "val Loss: 0.7519 Acc: 0.7920\n",
      "test Loss: 0.7289 Acc: 0.8320\n",
      "Epoch 1027/1499\n",
      "----------\n",
      "train Loss: 0.7451 Acc: 0.8104\n",
      "val Loss: 0.7611 Acc: 0.7800\n",
      "test Loss: 0.7266 Acc: 0.8320\n",
      "Epoch 1028/1499\n",
      "----------\n",
      "train Loss: 0.7435 Acc: 0.8122\n",
      "val Loss: 0.7520 Acc: 0.8040\n",
      "test Loss: 0.7232 Acc: 0.8280\n",
      "Epoch 1029/1499\n",
      "----------\n",
      "train Loss: 0.7459 Acc: 0.8067\n",
      "val Loss: 0.7493 Acc: 0.7960\n",
      "test Loss: 0.7345 Acc: 0.8080\n",
      "Epoch 1030/1499\n",
      "----------\n",
      "train Loss: 0.7434 Acc: 0.8116\n",
      "val Loss: 0.7600 Acc: 0.7960\n",
      "test Loss: 0.7245 Acc: 0.8360\n",
      "Epoch 1031/1499\n",
      "----------\n",
      "train Loss: 0.7459 Acc: 0.8093\n",
      "val Loss: 0.7496 Acc: 0.8000\n",
      "test Loss: 0.7341 Acc: 0.8200\n",
      "Epoch 1032/1499\n",
      "----------\n",
      "train Loss: 0.7455 Acc: 0.8051\n",
      "val Loss: 0.7551 Acc: 0.8040\n",
      "test Loss: 0.7253 Acc: 0.8400\n",
      "Epoch 1033/1499\n",
      "----------\n",
      "train Loss: 0.7452 Acc: 0.8082\n",
      "val Loss: 0.7545 Acc: 0.8080\n",
      "test Loss: 0.7308 Acc: 0.8200\n",
      "Epoch 1034/1499\n",
      "----------\n",
      "train Loss: 0.7466 Acc: 0.8064\n",
      "val Loss: 0.7473 Acc: 0.8080\n",
      "test Loss: 0.7365 Acc: 0.8200\n",
      "Epoch 1035/1499\n",
      "----------\n",
      "train Loss: 0.7452 Acc: 0.8069\n",
      "val Loss: 0.7552 Acc: 0.8000\n",
      "test Loss: 0.7246 Acc: 0.8400\n",
      "Epoch 1036/1499\n",
      "----------\n",
      "train Loss: 0.7431 Acc: 0.8100\n",
      "val Loss: 0.7570 Acc: 0.8000\n",
      "test Loss: 0.7228 Acc: 0.8320\n",
      "Epoch 1037/1499\n",
      "----------\n",
      "train Loss: 0.7477 Acc: 0.8040\n",
      "val Loss: 0.7601 Acc: 0.8040\n",
      "test Loss: 0.7282 Acc: 0.8200\n",
      "Epoch 1038/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.7430 Acc: 0.8098\n",
      "val Loss: 0.7498 Acc: 0.8040\n",
      "test Loss: 0.7267 Acc: 0.8440\n",
      "Epoch 1039/1499\n",
      "----------\n",
      "train Loss: 0.7443 Acc: 0.8091\n",
      "val Loss: 0.7568 Acc: 0.7960\n",
      "test Loss: 0.7385 Acc: 0.8080\n",
      "Epoch 1040/1499\n",
      "----------\n",
      "train Loss: 0.7460 Acc: 0.8060\n",
      "val Loss: 0.7586 Acc: 0.7840\n",
      "test Loss: 0.7294 Acc: 0.8240\n",
      "Epoch 1041/1499\n",
      "----------\n",
      "train Loss: 0.7415 Acc: 0.8127\n",
      "val Loss: 0.7500 Acc: 0.7960\n",
      "test Loss: 0.7273 Acc: 0.8240\n",
      "Epoch 1042/1499\n",
      "----------\n",
      "train Loss: 0.7441 Acc: 0.8076\n",
      "val Loss: 0.7464 Acc: 0.8160\n",
      "test Loss: 0.7307 Acc: 0.8200\n",
      "Epoch 1043/1499\n",
      "----------\n",
      "train Loss: 0.7435 Acc: 0.8104\n",
      "val Loss: 0.7632 Acc: 0.7800\n",
      "test Loss: 0.7307 Acc: 0.8400\n",
      "Epoch 1044/1499\n",
      "----------\n",
      "train Loss: 0.7437 Acc: 0.8109\n",
      "val Loss: 0.7608 Acc: 0.7880\n",
      "test Loss: 0.7233 Acc: 0.8400\n",
      "Epoch 1045/1499\n",
      "----------\n",
      "train Loss: 0.7428 Acc: 0.8113\n",
      "val Loss: 0.7578 Acc: 0.7960\n",
      "test Loss: 0.7233 Acc: 0.8440\n",
      "Epoch 1046/1499\n",
      "----------\n",
      "train Loss: 0.7460 Acc: 0.8071\n",
      "val Loss: 0.7624 Acc: 0.7800\n",
      "test Loss: 0.7343 Acc: 0.8200\n",
      "Epoch 1047/1499\n",
      "----------\n",
      "train Loss: 0.7417 Acc: 0.8131\n",
      "val Loss: 0.7504 Acc: 0.7960\n",
      "test Loss: 0.7243 Acc: 0.8400\n",
      "Epoch 1048/1499\n",
      "----------\n",
      "train Loss: 0.7447 Acc: 0.8080\n",
      "val Loss: 0.7563 Acc: 0.7960\n",
      "test Loss: 0.7321 Acc: 0.8040\n",
      "Epoch 1049/1499\n",
      "----------\n",
      "train Loss: 0.7461 Acc: 0.8036\n",
      "val Loss: 0.7540 Acc: 0.7880\n",
      "test Loss: 0.7424 Acc: 0.8000\n",
      "Epoch 1050/1499\n",
      "----------\n",
      "train Loss: 0.7442 Acc: 0.8064\n",
      "val Loss: 0.7546 Acc: 0.7840\n",
      "test Loss: 0.7339 Acc: 0.8240\n",
      "Epoch 1051/1499\n",
      "----------\n",
      "train Loss: 0.7455 Acc: 0.8056\n",
      "val Loss: 0.7533 Acc: 0.8160\n",
      "test Loss: 0.7261 Acc: 0.8360\n",
      "Epoch 1052/1499\n",
      "----------\n",
      "train Loss: 0.7437 Acc: 0.8113\n",
      "val Loss: 0.7638 Acc: 0.7880\n",
      "test Loss: 0.7240 Acc: 0.8440\n",
      "Epoch 1053/1499\n",
      "----------\n",
      "train Loss: 0.7452 Acc: 0.8098\n",
      "val Loss: 0.7534 Acc: 0.8040\n",
      "test Loss: 0.7173 Acc: 0.8440\n",
      "Epoch 1054/1499\n",
      "----------\n",
      "train Loss: 0.7436 Acc: 0.8107\n",
      "val Loss: 0.7620 Acc: 0.7800\n",
      "test Loss: 0.7262 Acc: 0.8240\n",
      "Epoch 1055/1499\n",
      "----------\n",
      "train Loss: 0.7437 Acc: 0.8062\n",
      "val Loss: 0.7601 Acc: 0.7960\n",
      "test Loss: 0.7347 Acc: 0.8200\n",
      "Epoch 1056/1499\n",
      "----------\n",
      "train Loss: 0.7432 Acc: 0.8089\n",
      "val Loss: 0.7536 Acc: 0.7880\n",
      "test Loss: 0.7208 Acc: 0.8560\n",
      "Epoch 1057/1499\n",
      "----------\n",
      "train Loss: 0.7444 Acc: 0.8087\n",
      "val Loss: 0.7600 Acc: 0.7720\n",
      "test Loss: 0.7333 Acc: 0.8280\n",
      "Epoch 1058/1499\n",
      "----------\n",
      "train Loss: 0.7426 Acc: 0.8073\n",
      "val Loss: 0.7519 Acc: 0.7920\n",
      "test Loss: 0.7228 Acc: 0.8360\n",
      "Epoch 1059/1499\n",
      "----------\n",
      "train Loss: 0.7417 Acc: 0.8138\n",
      "val Loss: 0.7633 Acc: 0.7760\n",
      "test Loss: 0.7320 Acc: 0.8240\n",
      "Epoch 1060/1499\n",
      "----------\n",
      "train Loss: 0.7426 Acc: 0.8076\n",
      "val Loss: 0.7559 Acc: 0.7920\n",
      "test Loss: 0.7278 Acc: 0.8200\n",
      "Epoch 1061/1499\n",
      "----------\n",
      "train Loss: 0.7442 Acc: 0.8082\n",
      "val Loss: 0.7516 Acc: 0.8000\n",
      "test Loss: 0.7280 Acc: 0.8320\n",
      "Epoch 1062/1499\n",
      "----------\n",
      "train Loss: 0.7431 Acc: 0.8111\n",
      "val Loss: 0.7498 Acc: 0.7920\n",
      "test Loss: 0.7336 Acc: 0.8160\n",
      "Epoch 1063/1499\n",
      "----------\n",
      "train Loss: 0.7414 Acc: 0.8116\n",
      "val Loss: 0.7579 Acc: 0.7880\n",
      "test Loss: 0.7290 Acc: 0.8200\n",
      "Epoch 1064/1499\n",
      "----------\n",
      "train Loss: 0.7446 Acc: 0.8044\n",
      "val Loss: 0.7614 Acc: 0.7720\n",
      "test Loss: 0.7240 Acc: 0.8360\n",
      "Epoch 1065/1499\n",
      "----------\n",
      "train Loss: 0.7426 Acc: 0.8122\n",
      "val Loss: 0.7559 Acc: 0.7920\n",
      "test Loss: 0.7371 Acc: 0.8160\n",
      "Epoch 1066/1499\n",
      "----------\n",
      "train Loss: 0.7478 Acc: 0.8004\n",
      "val Loss: 0.7514 Acc: 0.7920\n",
      "test Loss: 0.7304 Acc: 0.8240\n",
      "Epoch 1067/1499\n",
      "----------\n",
      "train Loss: 0.7437 Acc: 0.8073\n",
      "val Loss: 0.7668 Acc: 0.7840\n",
      "test Loss: 0.7204 Acc: 0.8400\n",
      "Epoch 1068/1499\n",
      "----------\n",
      "train Loss: 0.7420 Acc: 0.8093\n",
      "val Loss: 0.7479 Acc: 0.8040\n",
      "test Loss: 0.7383 Acc: 0.8040\n",
      "Epoch 1069/1499\n",
      "----------\n",
      "train Loss: 0.7453 Acc: 0.8067\n",
      "val Loss: 0.7510 Acc: 0.7920\n",
      "test Loss: 0.7371 Acc: 0.8160\n",
      "Epoch 1070/1499\n",
      "----------\n",
      "train Loss: 0.7427 Acc: 0.8127\n",
      "val Loss: 0.7598 Acc: 0.7720\n",
      "test Loss: 0.7247 Acc: 0.8200\n",
      "Epoch 1071/1499\n",
      "----------\n",
      "train Loss: 0.7422 Acc: 0.8127\n",
      "val Loss: 0.7570 Acc: 0.7920\n",
      "test Loss: 0.7288 Acc: 0.8240\n",
      "Epoch 1072/1499\n",
      "----------\n",
      "train Loss: 0.7448 Acc: 0.8033\n",
      "val Loss: 0.7650 Acc: 0.7760\n",
      "test Loss: 0.7170 Acc: 0.8520\n",
      "Epoch 1073/1499\n",
      "----------\n",
      "train Loss: 0.7442 Acc: 0.8049\n",
      "val Loss: 0.7507 Acc: 0.8160\n",
      "test Loss: 0.7225 Acc: 0.8320\n",
      "Epoch 1074/1499\n",
      "----------\n",
      "train Loss: 0.7441 Acc: 0.8093\n",
      "val Loss: 0.7603 Acc: 0.7840\n",
      "test Loss: 0.7307 Acc: 0.8240\n",
      "Epoch 1075/1499\n",
      "----------\n",
      "train Loss: 0.7429 Acc: 0.8076\n",
      "val Loss: 0.7640 Acc: 0.7840\n",
      "test Loss: 0.7281 Acc: 0.8280\n",
      "Epoch 1076/1499\n",
      "----------\n",
      "train Loss: 0.7398 Acc: 0.8124\n",
      "val Loss: 0.7499 Acc: 0.8120\n",
      "test Loss: 0.7372 Acc: 0.8080\n",
      "Epoch 1077/1499\n",
      "----------\n",
      "train Loss: 0.7441 Acc: 0.8076\n",
      "val Loss: 0.7553 Acc: 0.7920\n",
      "test Loss: 0.7373 Acc: 0.8120\n",
      "Epoch 1078/1499\n",
      "----------\n",
      "train Loss: 0.7448 Acc: 0.8080\n",
      "val Loss: 0.7590 Acc: 0.7880\n",
      "test Loss: 0.7357 Acc: 0.8240\n",
      "Epoch 1079/1499\n",
      "----------\n",
      "train Loss: 0.7450 Acc: 0.8062\n",
      "val Loss: 0.7526 Acc: 0.7920\n",
      "test Loss: 0.7390 Acc: 0.8160\n",
      "Epoch 1080/1499\n",
      "----------\n",
      "train Loss: 0.7436 Acc: 0.8093\n",
      "val Loss: 0.7560 Acc: 0.7960\n",
      "test Loss: 0.7264 Acc: 0.8280\n",
      "Epoch 1081/1499\n",
      "----------\n",
      "train Loss: 0.7431 Acc: 0.8096\n",
      "val Loss: 0.7549 Acc: 0.8000\n",
      "test Loss: 0.7367 Acc: 0.8080\n",
      "Epoch 1082/1499\n",
      "----------\n",
      "train Loss: 0.7424 Acc: 0.8111\n",
      "val Loss: 0.7630 Acc: 0.7800\n",
      "test Loss: 0.7277 Acc: 0.8320\n",
      "Epoch 1083/1499\n",
      "----------\n",
      "train Loss: 0.7452 Acc: 0.8053\n",
      "val Loss: 0.7537 Acc: 0.7920\n",
      "test Loss: 0.7268 Acc: 0.8280\n",
      "Epoch 1084/1499\n",
      "----------\n",
      "train Loss: 0.7406 Acc: 0.8102\n",
      "val Loss: 0.7551 Acc: 0.8040\n",
      "test Loss: 0.7229 Acc: 0.8400\n",
      "Epoch 1085/1499\n",
      "----------\n",
      "train Loss: 0.7419 Acc: 0.8087\n",
      "val Loss: 0.7435 Acc: 0.8080\n",
      "test Loss: 0.7293 Acc: 0.8160\n",
      "Epoch 1086/1499\n",
      "----------\n",
      "train Loss: 0.7448 Acc: 0.8049\n",
      "val Loss: 0.7437 Acc: 0.8040\n",
      "test Loss: 0.7275 Acc: 0.8280\n",
      "Epoch 1087/1499\n",
      "----------\n",
      "train Loss: 0.7435 Acc: 0.8082\n",
      "val Loss: 0.7465 Acc: 0.7960\n",
      "test Loss: 0.7324 Acc: 0.8160\n",
      "Epoch 1088/1499\n",
      "----------\n",
      "train Loss: 0.7411 Acc: 0.8127\n",
      "val Loss: 0.7485 Acc: 0.7920\n",
      "test Loss: 0.7390 Acc: 0.8120\n",
      "Epoch 1089/1499\n",
      "----------\n",
      "train Loss: 0.7433 Acc: 0.8111\n",
      "val Loss: 0.7607 Acc: 0.8080\n",
      "test Loss: 0.7366 Acc: 0.8040\n",
      "Epoch 1090/1499\n",
      "----------\n",
      "train Loss: 0.7406 Acc: 0.8102\n",
      "val Loss: 0.7550 Acc: 0.7960\n",
      "test Loss: 0.7223 Acc: 0.8200\n",
      "Epoch 1091/1499\n",
      "----------\n",
      "train Loss: 0.7420 Acc: 0.8089\n",
      "val Loss: 0.7529 Acc: 0.7920\n",
      "test Loss: 0.7305 Acc: 0.8400\n",
      "Epoch 1092/1499\n",
      "----------\n",
      "train Loss: 0.7444 Acc: 0.8087\n",
      "val Loss: 0.7669 Acc: 0.7720\n",
      "test Loss: 0.7187 Acc: 0.8440\n",
      "Epoch 1093/1499\n",
      "----------\n",
      "train Loss: 0.7429 Acc: 0.8102\n",
      "val Loss: 0.7613 Acc: 0.7920\n",
      "test Loss: 0.7282 Acc: 0.8240\n",
      "Epoch 1094/1499\n",
      "----------\n",
      "train Loss: 0.7429 Acc: 0.8062\n",
      "val Loss: 0.7587 Acc: 0.7920\n",
      "test Loss: 0.7261 Acc: 0.8320\n",
      "Epoch 1095/1499\n",
      "----------\n",
      "train Loss: 0.7419 Acc: 0.8078\n",
      "val Loss: 0.7624 Acc: 0.7880\n",
      "test Loss: 0.7315 Acc: 0.8160\n",
      "Epoch 1096/1499\n",
      "----------\n",
      "train Loss: 0.7426 Acc: 0.8102\n",
      "val Loss: 0.7669 Acc: 0.7720\n",
      "test Loss: 0.7303 Acc: 0.8280\n",
      "Epoch 1097/1499\n",
      "----------\n",
      "train Loss: 0.7434 Acc: 0.8082\n",
      "val Loss: 0.7690 Acc: 0.7800\n",
      "test Loss: 0.7268 Acc: 0.8320\n",
      "Epoch 1098/1499\n",
      "----------\n",
      "train Loss: 0.7412 Acc: 0.8098\n",
      "val Loss: 0.7516 Acc: 0.7920\n",
      "test Loss: 0.7169 Acc: 0.8440\n",
      "Epoch 1099/1499\n",
      "----------\n",
      "train Loss: 0.7419 Acc: 0.8067\n",
      "val Loss: 0.7541 Acc: 0.7880\n",
      "test Loss: 0.7318 Acc: 0.8280\n",
      "Epoch 1100/1499\n",
      "----------\n",
      "train Loss: 0.7428 Acc: 0.8071\n",
      "val Loss: 0.7534 Acc: 0.7960\n",
      "test Loss: 0.7316 Acc: 0.8280\n",
      "Epoch 1101/1499\n",
      "----------\n",
      "train Loss: 0.7448 Acc: 0.8051\n",
      "val Loss: 0.7439 Acc: 0.8120\n",
      "test Loss: 0.7431 Acc: 0.8120\n",
      "Epoch 1102/1499\n",
      "----------\n",
      "train Loss: 0.7447 Acc: 0.8060\n",
      "val Loss: 0.7514 Acc: 0.8080\n",
      "test Loss: 0.7296 Acc: 0.8200\n",
      "Epoch 1103/1499\n",
      "----------\n",
      "train Loss: 0.7407 Acc: 0.8107\n",
      "val Loss: 0.7509 Acc: 0.8000\n",
      "test Loss: 0.7256 Acc: 0.8360\n",
      "Epoch 1104/1499\n",
      "----------\n",
      "train Loss: 0.7410 Acc: 0.8107\n",
      "val Loss: 0.7681 Acc: 0.7640\n",
      "test Loss: 0.7270 Acc: 0.8280\n",
      "Epoch 1105/1499\n",
      "----------\n",
      "train Loss: 0.7428 Acc: 0.8073\n",
      "val Loss: 0.7485 Acc: 0.7960\n",
      "test Loss: 0.7273 Acc: 0.8240\n",
      "Epoch 1106/1499\n",
      "----------\n",
      "train Loss: 0.7424 Acc: 0.8091\n",
      "val Loss: 0.7576 Acc: 0.7960\n",
      "test Loss: 0.7184 Acc: 0.8320\n",
      "Epoch 1107/1499\n",
      "----------\n",
      "train Loss: 0.7405 Acc: 0.8100\n",
      "val Loss: 0.7501 Acc: 0.7920\n",
      "test Loss: 0.7188 Acc: 0.8400\n",
      "Epoch 1108/1499\n",
      "----------\n",
      "train Loss: 0.7423 Acc: 0.8098\n",
      "val Loss: 0.7464 Acc: 0.8040\n",
      "test Loss: 0.7231 Acc: 0.8360\n",
      "Epoch 1109/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.7436 Acc: 0.8089\n",
      "val Loss: 0.7686 Acc: 0.7640\n",
      "test Loss: 0.7314 Acc: 0.8120\n",
      "Epoch 1110/1499\n",
      "----------\n",
      "train Loss: 0.7415 Acc: 0.8104\n",
      "val Loss: 0.7566 Acc: 0.8040\n",
      "test Loss: 0.7311 Acc: 0.8280\n",
      "Epoch 1111/1499\n",
      "----------\n",
      "train Loss: 0.7415 Acc: 0.8082\n",
      "val Loss: 0.7505 Acc: 0.8120\n",
      "test Loss: 0.7246 Acc: 0.8280\n",
      "Epoch 1112/1499\n",
      "----------\n",
      "train Loss: 0.7391 Acc: 0.8133\n",
      "val Loss: 0.7537 Acc: 0.7840\n",
      "test Loss: 0.7220 Acc: 0.8360\n",
      "Epoch 1113/1499\n",
      "----------\n",
      "train Loss: 0.7392 Acc: 0.8136\n",
      "val Loss: 0.7548 Acc: 0.7960\n",
      "test Loss: 0.7259 Acc: 0.8440\n",
      "Epoch 1114/1499\n",
      "----------\n",
      "train Loss: 0.7410 Acc: 0.8082\n",
      "val Loss: 0.7699 Acc: 0.7640\n",
      "test Loss: 0.7286 Acc: 0.8320\n",
      "Epoch 1115/1499\n",
      "----------\n",
      "train Loss: 0.7400 Acc: 0.8118\n",
      "val Loss: 0.7566 Acc: 0.8040\n",
      "test Loss: 0.7269 Acc: 0.8360\n",
      "Epoch 1116/1499\n",
      "----------\n",
      "train Loss: 0.7425 Acc: 0.8067\n",
      "val Loss: 0.7533 Acc: 0.7920\n",
      "test Loss: 0.7167 Acc: 0.8560\n",
      "Epoch 1117/1499\n",
      "----------\n",
      "train Loss: 0.7398 Acc: 0.8096\n",
      "val Loss: 0.7521 Acc: 0.7920\n",
      "test Loss: 0.7260 Acc: 0.8200\n",
      "Epoch 1118/1499\n",
      "----------\n",
      "train Loss: 0.7415 Acc: 0.8096\n",
      "val Loss: 0.7412 Acc: 0.8040\n",
      "test Loss: 0.7192 Acc: 0.8440\n",
      "Epoch 1119/1499\n",
      "----------\n",
      "train Loss: 0.7411 Acc: 0.8071\n",
      "val Loss: 0.7564 Acc: 0.7840\n",
      "test Loss: 0.7212 Acc: 0.8200\n",
      "Epoch 1120/1499\n",
      "----------\n",
      "train Loss: 0.7443 Acc: 0.8053\n",
      "val Loss: 0.7610 Acc: 0.7880\n",
      "test Loss: 0.7291 Acc: 0.8360\n",
      "Epoch 1121/1499\n",
      "----------\n",
      "train Loss: 0.7402 Acc: 0.8131\n",
      "val Loss: 0.7503 Acc: 0.7840\n",
      "test Loss: 0.7278 Acc: 0.8280\n",
      "Epoch 1122/1499\n",
      "----------\n",
      "train Loss: 0.7419 Acc: 0.8098\n",
      "val Loss: 0.7554 Acc: 0.7800\n",
      "test Loss: 0.7267 Acc: 0.8320\n",
      "Epoch 1123/1499\n",
      "----------\n",
      "train Loss: 0.7389 Acc: 0.8111\n",
      "val Loss: 0.7675 Acc: 0.7720\n",
      "test Loss: 0.7287 Acc: 0.8280\n",
      "Epoch 1124/1499\n",
      "----------\n",
      "train Loss: 0.7400 Acc: 0.8098\n",
      "val Loss: 0.7453 Acc: 0.8160\n",
      "test Loss: 0.7344 Acc: 0.8120\n",
      "Epoch 1125/1499\n",
      "----------\n",
      "train Loss: 0.7391 Acc: 0.8153\n",
      "val Loss: 0.7523 Acc: 0.7960\n",
      "test Loss: 0.7226 Acc: 0.8240\n",
      "Epoch 1126/1499\n",
      "----------\n",
      "train Loss: 0.7387 Acc: 0.8151\n",
      "val Loss: 0.7633 Acc: 0.7680\n",
      "test Loss: 0.7372 Acc: 0.8120\n",
      "Epoch 1127/1499\n",
      "----------\n",
      "train Loss: 0.7385 Acc: 0.8144\n",
      "val Loss: 0.7522 Acc: 0.8000\n",
      "test Loss: 0.7228 Acc: 0.8320\n",
      "Epoch 1128/1499\n",
      "----------\n",
      "train Loss: 0.7395 Acc: 0.8140\n",
      "val Loss: 0.7581 Acc: 0.8000\n",
      "test Loss: 0.7194 Acc: 0.8320\n",
      "Epoch 1129/1499\n",
      "----------\n",
      "train Loss: 0.7421 Acc: 0.8078\n",
      "val Loss: 0.7595 Acc: 0.7840\n",
      "test Loss: 0.7259 Acc: 0.8320\n",
      "Epoch 1130/1499\n",
      "----------\n",
      "train Loss: 0.7403 Acc: 0.8127\n",
      "val Loss: 0.7414 Acc: 0.8080\n",
      "test Loss: 0.7366 Acc: 0.8200\n",
      "Epoch 1131/1499\n",
      "----------\n",
      "train Loss: 0.7400 Acc: 0.8104\n",
      "val Loss: 0.7630 Acc: 0.7760\n",
      "test Loss: 0.7123 Acc: 0.8480\n",
      "Epoch 1132/1499\n",
      "----------\n",
      "train Loss: 0.7421 Acc: 0.8100\n",
      "val Loss: 0.7448 Acc: 0.8080\n",
      "test Loss: 0.7341 Acc: 0.8320\n",
      "Epoch 1133/1499\n",
      "----------\n",
      "train Loss: 0.7387 Acc: 0.8164\n",
      "val Loss: 0.7473 Acc: 0.7960\n",
      "test Loss: 0.7203 Acc: 0.8520\n",
      "Epoch 1134/1499\n",
      "----------\n",
      "train Loss: 0.7399 Acc: 0.8131\n",
      "val Loss: 0.7521 Acc: 0.8080\n",
      "test Loss: 0.7306 Acc: 0.8160\n",
      "Epoch 1135/1499\n",
      "----------\n",
      "train Loss: 0.7408 Acc: 0.8140\n",
      "val Loss: 0.7463 Acc: 0.8120\n",
      "test Loss: 0.7276 Acc: 0.8240\n",
      "Epoch 1136/1499\n",
      "----------\n",
      "train Loss: 0.7409 Acc: 0.8113\n",
      "val Loss: 0.7501 Acc: 0.7920\n",
      "test Loss: 0.7214 Acc: 0.8320\n",
      "Epoch 1137/1499\n",
      "----------\n",
      "train Loss: 0.7402 Acc: 0.8096\n",
      "val Loss: 0.7564 Acc: 0.7960\n",
      "test Loss: 0.7211 Acc: 0.8480\n",
      "Epoch 1138/1499\n",
      "----------\n",
      "train Loss: 0.7416 Acc: 0.8078\n",
      "val Loss: 0.7375 Acc: 0.8240\n",
      "test Loss: 0.7287 Acc: 0.8160\n",
      "Epoch 1139/1499\n",
      "----------\n",
      "train Loss: 0.7391 Acc: 0.8100\n",
      "val Loss: 0.7554 Acc: 0.8000\n",
      "test Loss: 0.7306 Acc: 0.8200\n",
      "Epoch 1140/1499\n",
      "----------\n",
      "train Loss: 0.7397 Acc: 0.8147\n",
      "val Loss: 0.7523 Acc: 0.7880\n",
      "test Loss: 0.7209 Acc: 0.8200\n",
      "Epoch 1141/1499\n",
      "----------\n",
      "train Loss: 0.7424 Acc: 0.8069\n",
      "val Loss: 0.7545 Acc: 0.7880\n",
      "test Loss: 0.7230 Acc: 0.8240\n",
      "Epoch 1142/1499\n",
      "----------\n",
      "train Loss: 0.7429 Acc: 0.8098\n",
      "val Loss: 0.7504 Acc: 0.8000\n",
      "test Loss: 0.7288 Acc: 0.8320\n",
      "Epoch 1143/1499\n",
      "----------\n",
      "train Loss: 0.7415 Acc: 0.8087\n",
      "val Loss: 0.7498 Acc: 0.8000\n",
      "test Loss: 0.7186 Acc: 0.8280\n",
      "Epoch 1144/1499\n",
      "----------\n",
      "train Loss: 0.7422 Acc: 0.8053\n",
      "val Loss: 0.7506 Acc: 0.7840\n",
      "test Loss: 0.7273 Acc: 0.8120\n",
      "Epoch 1145/1499\n",
      "----------\n",
      "train Loss: 0.7428 Acc: 0.8080\n",
      "val Loss: 0.7474 Acc: 0.7960\n",
      "test Loss: 0.7197 Acc: 0.8400\n",
      "Epoch 1146/1499\n",
      "----------\n",
      "train Loss: 0.7412 Acc: 0.8096\n",
      "val Loss: 0.7533 Acc: 0.7960\n",
      "test Loss: 0.7228 Acc: 0.8320\n",
      "Epoch 1147/1499\n",
      "----------\n",
      "train Loss: 0.7395 Acc: 0.8142\n",
      "val Loss: 0.7550 Acc: 0.8040\n",
      "test Loss: 0.7279 Acc: 0.8240\n",
      "Epoch 1148/1499\n",
      "----------\n",
      "train Loss: 0.7411 Acc: 0.8096\n",
      "val Loss: 0.7475 Acc: 0.8080\n",
      "test Loss: 0.7172 Acc: 0.8320\n",
      "Epoch 1149/1499\n",
      "----------\n",
      "train Loss: 0.7397 Acc: 0.8122\n",
      "val Loss: 0.7476 Acc: 0.8000\n",
      "test Loss: 0.7161 Acc: 0.8480\n",
      "Epoch 1150/1499\n",
      "----------\n",
      "train Loss: 0.7389 Acc: 0.8091\n",
      "val Loss: 0.7612 Acc: 0.7920\n",
      "test Loss: 0.7310 Acc: 0.8280\n",
      "Epoch 1151/1499\n",
      "----------\n",
      "train Loss: 0.7395 Acc: 0.8151\n",
      "val Loss: 0.7554 Acc: 0.8040\n",
      "test Loss: 0.7330 Acc: 0.8240\n",
      "Epoch 1152/1499\n",
      "----------\n",
      "train Loss: 0.7415 Acc: 0.8104\n",
      "val Loss: 0.7537 Acc: 0.7960\n",
      "test Loss: 0.7116 Acc: 0.8520\n",
      "Epoch 1153/1499\n",
      "----------\n",
      "train Loss: 0.7426 Acc: 0.8080\n",
      "val Loss: 0.7544 Acc: 0.7720\n",
      "test Loss: 0.7292 Acc: 0.8200\n",
      "Epoch 1154/1499\n",
      "----------\n",
      "train Loss: 0.7411 Acc: 0.8107\n",
      "val Loss: 0.7519 Acc: 0.8000\n",
      "test Loss: 0.7292 Acc: 0.8200\n",
      "Epoch 1155/1499\n",
      "----------\n",
      "train Loss: 0.7382 Acc: 0.8136\n",
      "val Loss: 0.7544 Acc: 0.7960\n",
      "test Loss: 0.7321 Acc: 0.8280\n",
      "Epoch 1156/1499\n",
      "----------\n",
      "train Loss: 0.7402 Acc: 0.8104\n",
      "val Loss: 0.7501 Acc: 0.8000\n",
      "test Loss: 0.7321 Acc: 0.8200\n",
      "Epoch 1157/1499\n",
      "----------\n",
      "train Loss: 0.7402 Acc: 0.8104\n",
      "val Loss: 0.7429 Acc: 0.8120\n",
      "test Loss: 0.7179 Acc: 0.8360\n",
      "Epoch 1158/1499\n",
      "----------\n",
      "train Loss: 0.7417 Acc: 0.8087\n",
      "val Loss: 0.7672 Acc: 0.7920\n",
      "test Loss: 0.7360 Acc: 0.8080\n",
      "Epoch 1159/1499\n",
      "----------\n",
      "train Loss: 0.7423 Acc: 0.8091\n",
      "val Loss: 0.7434 Acc: 0.8240\n",
      "test Loss: 0.7194 Acc: 0.8160\n",
      "Epoch 1160/1499\n",
      "----------\n",
      "train Loss: 0.7414 Acc: 0.8082\n",
      "val Loss: 0.7574 Acc: 0.8040\n",
      "test Loss: 0.7256 Acc: 0.8320\n",
      "Epoch 1161/1499\n",
      "----------\n",
      "train Loss: 0.7392 Acc: 0.8122\n",
      "val Loss: 0.7599 Acc: 0.7840\n",
      "test Loss: 0.7411 Acc: 0.8080\n",
      "Epoch 1162/1499\n",
      "----------\n",
      "train Loss: 0.7399 Acc: 0.8096\n",
      "val Loss: 0.7574 Acc: 0.7960\n",
      "test Loss: 0.7311 Acc: 0.8280\n",
      "Epoch 1163/1499\n",
      "----------\n",
      "train Loss: 0.7395 Acc: 0.8093\n",
      "val Loss: 0.7606 Acc: 0.7800\n",
      "test Loss: 0.7267 Acc: 0.8280\n",
      "Epoch 1164/1499\n",
      "----------\n",
      "train Loss: 0.7397 Acc: 0.8104\n",
      "val Loss: 0.7540 Acc: 0.7960\n",
      "test Loss: 0.7203 Acc: 0.8360\n",
      "Epoch 1165/1499\n",
      "----------\n",
      "train Loss: 0.7399 Acc: 0.8111\n",
      "val Loss: 0.7513 Acc: 0.8120\n",
      "test Loss: 0.7191 Acc: 0.8320\n",
      "Epoch 1166/1499\n",
      "----------\n",
      "train Loss: 0.7393 Acc: 0.8122\n",
      "val Loss: 0.7466 Acc: 0.8080\n",
      "test Loss: 0.7230 Acc: 0.8360\n",
      "Epoch 1167/1499\n",
      "----------\n",
      "train Loss: 0.7408 Acc: 0.8073\n",
      "val Loss: 0.7557 Acc: 0.7920\n",
      "test Loss: 0.7248 Acc: 0.8200\n",
      "Epoch 1168/1499\n",
      "----------\n",
      "train Loss: 0.7444 Acc: 0.8024\n",
      "val Loss: 0.7440 Acc: 0.8080\n",
      "test Loss: 0.7238 Acc: 0.8200\n",
      "Epoch 1169/1499\n",
      "----------\n",
      "train Loss: 0.7364 Acc: 0.8104\n",
      "val Loss: 0.7612 Acc: 0.7800\n",
      "test Loss: 0.7312 Acc: 0.8200\n",
      "Epoch 1170/1499\n",
      "----------\n",
      "train Loss: 0.7348 Acc: 0.8178\n",
      "val Loss: 0.7500 Acc: 0.8040\n",
      "test Loss: 0.7232 Acc: 0.8360\n",
      "Epoch 1171/1499\n",
      "----------\n",
      "train Loss: 0.7422 Acc: 0.8067\n",
      "val Loss: 0.7440 Acc: 0.8120\n",
      "test Loss: 0.7275 Acc: 0.8240\n",
      "Epoch 1172/1499\n",
      "----------\n",
      "train Loss: 0.7399 Acc: 0.8064\n",
      "val Loss: 0.7575 Acc: 0.7880\n",
      "test Loss: 0.7246 Acc: 0.8200\n",
      "Epoch 1173/1499\n",
      "----------\n",
      "train Loss: 0.7424 Acc: 0.8058\n",
      "val Loss: 0.7506 Acc: 0.7880\n",
      "test Loss: 0.7137 Acc: 0.8440\n",
      "Epoch 1174/1499\n",
      "----------\n",
      "train Loss: 0.7400 Acc: 0.8091\n",
      "val Loss: 0.7504 Acc: 0.8000\n",
      "test Loss: 0.7254 Acc: 0.8320\n",
      "Epoch 1175/1499\n",
      "----------\n",
      "train Loss: 0.7398 Acc: 0.8113\n",
      "val Loss: 0.7453 Acc: 0.8080\n",
      "test Loss: 0.7250 Acc: 0.8400\n",
      "Epoch 1176/1499\n",
      "----------\n",
      "train Loss: 0.7398 Acc: 0.8096\n",
      "val Loss: 0.7446 Acc: 0.8200\n",
      "test Loss: 0.7362 Acc: 0.8160\n",
      "Epoch 1177/1499\n",
      "----------\n",
      "train Loss: 0.7446 Acc: 0.8058\n",
      "val Loss: 0.7528 Acc: 0.7800\n",
      "test Loss: 0.7344 Acc: 0.8120\n",
      "Epoch 1178/1499\n",
      "----------\n",
      "train Loss: 0.7395 Acc: 0.8096\n",
      "val Loss: 0.7505 Acc: 0.8040\n",
      "test Loss: 0.7287 Acc: 0.8240\n",
      "Epoch 1179/1499\n",
      "----------\n",
      "train Loss: 0.7383 Acc: 0.8156\n",
      "val Loss: 0.7498 Acc: 0.8000\n",
      "test Loss: 0.7268 Acc: 0.8200\n",
      "Epoch 1180/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.7406 Acc: 0.8118\n",
      "val Loss: 0.7486 Acc: 0.8040\n",
      "test Loss: 0.7347 Acc: 0.8080\n",
      "Epoch 1181/1499\n",
      "----------\n",
      "train Loss: 0.7413 Acc: 0.8102\n",
      "val Loss: 0.7572 Acc: 0.7800\n",
      "test Loss: 0.7206 Acc: 0.8240\n",
      "Epoch 1182/1499\n",
      "----------\n",
      "train Loss: 0.7378 Acc: 0.8133\n",
      "val Loss: 0.7539 Acc: 0.7960\n",
      "test Loss: 0.7254 Acc: 0.8240\n",
      "Epoch 1183/1499\n",
      "----------\n",
      "train Loss: 0.7388 Acc: 0.8122\n",
      "val Loss: 0.7562 Acc: 0.7880\n",
      "test Loss: 0.7337 Acc: 0.8160\n",
      "Epoch 1184/1499\n",
      "----------\n",
      "train Loss: 0.7371 Acc: 0.8127\n",
      "val Loss: 0.7570 Acc: 0.7920\n",
      "test Loss: 0.7206 Acc: 0.8360\n",
      "Epoch 1185/1499\n",
      "----------\n",
      "train Loss: 0.7386 Acc: 0.8149\n",
      "val Loss: 0.7561 Acc: 0.7960\n",
      "test Loss: 0.7148 Acc: 0.8400\n",
      "Epoch 1186/1499\n",
      "----------\n",
      "train Loss: 0.7403 Acc: 0.8100\n",
      "val Loss: 0.7462 Acc: 0.8040\n",
      "test Loss: 0.7223 Acc: 0.8360\n",
      "Epoch 1187/1499\n",
      "----------\n",
      "train Loss: 0.7384 Acc: 0.8122\n",
      "val Loss: 0.7588 Acc: 0.7880\n",
      "test Loss: 0.7285 Acc: 0.8280\n",
      "Epoch 1188/1499\n",
      "----------\n",
      "train Loss: 0.7406 Acc: 0.8087\n",
      "val Loss: 0.7568 Acc: 0.7760\n",
      "test Loss: 0.7287 Acc: 0.8120\n",
      "Epoch 1189/1499\n",
      "----------\n",
      "train Loss: 0.7372 Acc: 0.8127\n",
      "val Loss: 0.7511 Acc: 0.8080\n",
      "test Loss: 0.7230 Acc: 0.8200\n",
      "Epoch 1190/1499\n",
      "----------\n",
      "train Loss: 0.7396 Acc: 0.8096\n",
      "val Loss: 0.7504 Acc: 0.8120\n",
      "test Loss: 0.7406 Acc: 0.7960\n",
      "Epoch 1191/1499\n",
      "----------\n",
      "train Loss: 0.7422 Acc: 0.8058\n",
      "val Loss: 0.7497 Acc: 0.7840\n",
      "test Loss: 0.7260 Acc: 0.8280\n",
      "Epoch 1192/1499\n",
      "----------\n",
      "train Loss: 0.7375 Acc: 0.8118\n",
      "val Loss: 0.7550 Acc: 0.7960\n",
      "test Loss: 0.7182 Acc: 0.8360\n",
      "Epoch 1193/1499\n",
      "----------\n",
      "train Loss: 0.7399 Acc: 0.8071\n",
      "val Loss: 0.7491 Acc: 0.8080\n",
      "test Loss: 0.7369 Acc: 0.8160\n",
      "Epoch 1194/1499\n",
      "----------\n",
      "train Loss: 0.7395 Acc: 0.8089\n",
      "val Loss: 0.7577 Acc: 0.7800\n",
      "test Loss: 0.7308 Acc: 0.8200\n",
      "Epoch 1195/1499\n",
      "----------\n",
      "train Loss: 0.7395 Acc: 0.8102\n",
      "val Loss: 0.7524 Acc: 0.7880\n",
      "test Loss: 0.7221 Acc: 0.8200\n",
      "Epoch 1196/1499\n",
      "----------\n",
      "train Loss: 0.7354 Acc: 0.8129\n",
      "val Loss: 0.7480 Acc: 0.8000\n",
      "test Loss: 0.7213 Acc: 0.8320\n",
      "Epoch 1197/1499\n",
      "----------\n",
      "train Loss: 0.7367 Acc: 0.8140\n",
      "val Loss: 0.7478 Acc: 0.7960\n",
      "test Loss: 0.7238 Acc: 0.8360\n",
      "Epoch 1198/1499\n",
      "----------\n",
      "train Loss: 0.7371 Acc: 0.8104\n",
      "val Loss: 0.7495 Acc: 0.7960\n",
      "test Loss: 0.7217 Acc: 0.8360\n",
      "Epoch 1199/1499\n",
      "----------\n",
      "train Loss: 0.7386 Acc: 0.8089\n",
      "val Loss: 0.7483 Acc: 0.8000\n",
      "test Loss: 0.7148 Acc: 0.8400\n",
      "Epoch 1200/1499\n",
      "----------\n",
      "train Loss: 0.7376 Acc: 0.8082\n",
      "val Loss: 0.7592 Acc: 0.7800\n",
      "test Loss: 0.7265 Acc: 0.8280\n",
      "Epoch 1201/1499\n",
      "----------\n",
      "train Loss: 0.7397 Acc: 0.8084\n",
      "val Loss: 0.7496 Acc: 0.8040\n",
      "test Loss: 0.7238 Acc: 0.8240\n",
      "Epoch 1202/1499\n",
      "----------\n",
      "train Loss: 0.7376 Acc: 0.8129\n",
      "val Loss: 0.7537 Acc: 0.7960\n",
      "test Loss: 0.7167 Acc: 0.8240\n",
      "Epoch 1203/1499\n",
      "----------\n",
      "train Loss: 0.7406 Acc: 0.8082\n",
      "val Loss: 0.7642 Acc: 0.7760\n",
      "test Loss: 0.7197 Acc: 0.8320\n",
      "Epoch 1204/1499\n",
      "----------\n",
      "train Loss: 0.7397 Acc: 0.8109\n",
      "val Loss: 0.7454 Acc: 0.8000\n",
      "test Loss: 0.7260 Acc: 0.8200\n",
      "Epoch 1205/1499\n",
      "----------\n",
      "train Loss: 0.7388 Acc: 0.8122\n",
      "val Loss: 0.7441 Acc: 0.8120\n",
      "test Loss: 0.7237 Acc: 0.8200\n",
      "Epoch 1206/1499\n",
      "----------\n",
      "train Loss: 0.7391 Acc: 0.8107\n",
      "val Loss: 0.7542 Acc: 0.7880\n",
      "test Loss: 0.7198 Acc: 0.8240\n",
      "Epoch 1207/1499\n",
      "----------\n",
      "train Loss: 0.7379 Acc: 0.8131\n",
      "val Loss: 0.7554 Acc: 0.7800\n",
      "test Loss: 0.7294 Acc: 0.8280\n",
      "Epoch 1208/1499\n",
      "----------\n",
      "train Loss: 0.7380 Acc: 0.8133\n",
      "val Loss: 0.7472 Acc: 0.8040\n",
      "test Loss: 0.7158 Acc: 0.8320\n",
      "Epoch 1209/1499\n",
      "----------\n",
      "train Loss: 0.7397 Acc: 0.8080\n",
      "val Loss: 0.7546 Acc: 0.7920\n",
      "test Loss: 0.7216 Acc: 0.8360\n",
      "Epoch 1210/1499\n",
      "----------\n",
      "train Loss: 0.7379 Acc: 0.8109\n",
      "val Loss: 0.7507 Acc: 0.7920\n",
      "test Loss: 0.7270 Acc: 0.8160\n",
      "Epoch 1211/1499\n",
      "----------\n",
      "train Loss: 0.7387 Acc: 0.8122\n",
      "val Loss: 0.7504 Acc: 0.8120\n",
      "test Loss: 0.7377 Acc: 0.8000\n",
      "Epoch 1212/1499\n",
      "----------\n",
      "train Loss: 0.7402 Acc: 0.8087\n",
      "val Loss: 0.7533 Acc: 0.7880\n",
      "test Loss: 0.7268 Acc: 0.8200\n",
      "Epoch 1213/1499\n",
      "----------\n",
      "train Loss: 0.7386 Acc: 0.8091\n",
      "val Loss: 0.7529 Acc: 0.8000\n",
      "test Loss: 0.7244 Acc: 0.8400\n",
      "Epoch 1214/1499\n",
      "----------\n",
      "train Loss: 0.7410 Acc: 0.8040\n",
      "val Loss: 0.7515 Acc: 0.7920\n",
      "test Loss: 0.7172 Acc: 0.8360\n",
      "Epoch 1215/1499\n",
      "----------\n",
      "train Loss: 0.7402 Acc: 0.8091\n",
      "val Loss: 0.7483 Acc: 0.8120\n",
      "test Loss: 0.7311 Acc: 0.8200\n",
      "Epoch 1216/1499\n",
      "----------\n",
      "train Loss: 0.7382 Acc: 0.8118\n",
      "val Loss: 0.7506 Acc: 0.7960\n",
      "test Loss: 0.7133 Acc: 0.8400\n",
      "Epoch 1217/1499\n",
      "----------\n",
      "train Loss: 0.7386 Acc: 0.8080\n",
      "val Loss: 0.7495 Acc: 0.7920\n",
      "test Loss: 0.7224 Acc: 0.8400\n",
      "Epoch 1218/1499\n",
      "----------\n",
      "train Loss: 0.7369 Acc: 0.8109\n",
      "val Loss: 0.7416 Acc: 0.8040\n",
      "test Loss: 0.7256 Acc: 0.8320\n",
      "Epoch 1219/1499\n",
      "----------\n",
      "train Loss: 0.7413 Acc: 0.8096\n",
      "val Loss: 0.7467 Acc: 0.8080\n",
      "test Loss: 0.7123 Acc: 0.8400\n",
      "Epoch 1220/1499\n",
      "----------\n",
      "train Loss: 0.7374 Acc: 0.8111\n",
      "val Loss: 0.7436 Acc: 0.8240\n",
      "test Loss: 0.7223 Acc: 0.8320\n",
      "Epoch 1221/1499\n",
      "----------\n",
      "train Loss: 0.7394 Acc: 0.8096\n",
      "val Loss: 0.7563 Acc: 0.7960\n",
      "test Loss: 0.7285 Acc: 0.8160\n",
      "Epoch 1222/1499\n",
      "----------\n",
      "train Loss: 0.7366 Acc: 0.8102\n",
      "val Loss: 0.7475 Acc: 0.7960\n",
      "test Loss: 0.7202 Acc: 0.8240\n",
      "Epoch 1223/1499\n",
      "----------\n",
      "train Loss: 0.7371 Acc: 0.8142\n",
      "val Loss: 0.7535 Acc: 0.7920\n",
      "test Loss: 0.7227 Acc: 0.8320\n",
      "Epoch 1224/1499\n",
      "----------\n",
      "train Loss: 0.7356 Acc: 0.8147\n",
      "val Loss: 0.7397 Acc: 0.8120\n",
      "test Loss: 0.7158 Acc: 0.8320\n",
      "Epoch 1225/1499\n",
      "----------\n",
      "train Loss: 0.7405 Acc: 0.8089\n",
      "val Loss: 0.7654 Acc: 0.7680\n",
      "test Loss: 0.7158 Acc: 0.8360\n",
      "Epoch 1226/1499\n",
      "----------\n",
      "train Loss: 0.7378 Acc: 0.8102\n",
      "val Loss: 0.7577 Acc: 0.7840\n",
      "test Loss: 0.7271 Acc: 0.8240\n",
      "Epoch 1227/1499\n",
      "----------\n",
      "train Loss: 0.7367 Acc: 0.8129\n",
      "val Loss: 0.7539 Acc: 0.7920\n",
      "test Loss: 0.7205 Acc: 0.8360\n",
      "Epoch 1228/1499\n",
      "----------\n",
      "train Loss: 0.7379 Acc: 0.8096\n",
      "val Loss: 0.7484 Acc: 0.7800\n",
      "test Loss: 0.7209 Acc: 0.8200\n",
      "Epoch 1229/1499\n",
      "----------\n",
      "train Loss: 0.7388 Acc: 0.8109\n",
      "val Loss: 0.7497 Acc: 0.7880\n",
      "test Loss: 0.7253 Acc: 0.8200\n",
      "Epoch 1230/1499\n",
      "----------\n",
      "train Loss: 0.7366 Acc: 0.8131\n",
      "val Loss: 0.7482 Acc: 0.8000\n",
      "test Loss: 0.7196 Acc: 0.8360\n",
      "Epoch 1231/1499\n",
      "----------\n",
      "train Loss: 0.7398 Acc: 0.8120\n",
      "val Loss: 0.7537 Acc: 0.7960\n",
      "test Loss: 0.7301 Acc: 0.8240\n",
      "Epoch 1232/1499\n",
      "----------\n",
      "train Loss: 0.7371 Acc: 0.8113\n",
      "val Loss: 0.7580 Acc: 0.8000\n",
      "test Loss: 0.7182 Acc: 0.8320\n",
      "Epoch 1233/1499\n",
      "----------\n",
      "train Loss: 0.7380 Acc: 0.8109\n",
      "val Loss: 0.7460 Acc: 0.7920\n",
      "test Loss: 0.7095 Acc: 0.8520\n",
      "Epoch 1234/1499\n",
      "----------\n",
      "train Loss: 0.7389 Acc: 0.8111\n",
      "val Loss: 0.7528 Acc: 0.8040\n",
      "test Loss: 0.7289 Acc: 0.8240\n",
      "Epoch 1235/1499\n",
      "----------\n",
      "train Loss: 0.7361 Acc: 0.8093\n",
      "val Loss: 0.7627 Acc: 0.7800\n",
      "test Loss: 0.7249 Acc: 0.8320\n",
      "Epoch 1236/1499\n",
      "----------\n",
      "train Loss: 0.7368 Acc: 0.8131\n",
      "val Loss: 0.7457 Acc: 0.7920\n",
      "test Loss: 0.7216 Acc: 0.8280\n",
      "Epoch 1237/1499\n",
      "----------\n",
      "train Loss: 0.7360 Acc: 0.8162\n",
      "val Loss: 0.7480 Acc: 0.7960\n",
      "test Loss: 0.7156 Acc: 0.8360\n",
      "Epoch 1238/1499\n",
      "----------\n",
      "train Loss: 0.7364 Acc: 0.8153\n",
      "val Loss: 0.7442 Acc: 0.8120\n",
      "test Loss: 0.7290 Acc: 0.8440\n",
      "Epoch 1239/1499\n",
      "----------\n",
      "train Loss: 0.7388 Acc: 0.8084\n",
      "val Loss: 0.7442 Acc: 0.8040\n",
      "test Loss: 0.7115 Acc: 0.8320\n",
      "Epoch 1240/1499\n",
      "----------\n",
      "train Loss: 0.7363 Acc: 0.8127\n",
      "val Loss: 0.7391 Acc: 0.8120\n",
      "test Loss: 0.7135 Acc: 0.8280\n",
      "Epoch 1241/1499\n",
      "----------\n",
      "train Loss: 0.7353 Acc: 0.8127\n",
      "val Loss: 0.7490 Acc: 0.8000\n",
      "test Loss: 0.7263 Acc: 0.8280\n",
      "Epoch 1242/1499\n",
      "----------\n",
      "train Loss: 0.7370 Acc: 0.8144\n",
      "val Loss: 0.7548 Acc: 0.8000\n",
      "test Loss: 0.7230 Acc: 0.8320\n",
      "Epoch 1243/1499\n",
      "----------\n",
      "train Loss: 0.7373 Acc: 0.8127\n",
      "val Loss: 0.7551 Acc: 0.7880\n",
      "test Loss: 0.7269 Acc: 0.8240\n",
      "Epoch 1244/1499\n",
      "----------\n",
      "train Loss: 0.7369 Acc: 0.8124\n",
      "val Loss: 0.7504 Acc: 0.8000\n",
      "test Loss: 0.7282 Acc: 0.8160\n",
      "Epoch 1245/1499\n",
      "----------\n",
      "train Loss: 0.7368 Acc: 0.8138\n",
      "val Loss: 0.7517 Acc: 0.7840\n",
      "test Loss: 0.7239 Acc: 0.8200\n",
      "Epoch 1246/1499\n",
      "----------\n",
      "train Loss: 0.7355 Acc: 0.8140\n",
      "val Loss: 0.7471 Acc: 0.7960\n",
      "test Loss: 0.7200 Acc: 0.8280\n",
      "Epoch 1247/1499\n",
      "----------\n",
      "train Loss: 0.7398 Acc: 0.8084\n",
      "val Loss: 0.7532 Acc: 0.7640\n",
      "test Loss: 0.7230 Acc: 0.8280\n",
      "Epoch 1248/1499\n",
      "----------\n",
      "train Loss: 0.7361 Acc: 0.8149\n",
      "val Loss: 0.7602 Acc: 0.7760\n",
      "test Loss: 0.7302 Acc: 0.8160\n",
      "Epoch 1249/1499\n",
      "----------\n",
      "train Loss: 0.7376 Acc: 0.8109\n",
      "val Loss: 0.7418 Acc: 0.7960\n",
      "test Loss: 0.7321 Acc: 0.8120\n",
      "Epoch 1250/1499\n",
      "----------\n",
      "train Loss: 0.7363 Acc: 0.8113\n",
      "val Loss: 0.7494 Acc: 0.7920\n",
      "test Loss: 0.7284 Acc: 0.8040\n",
      "Epoch 1251/1499\n",
      "----------\n",
      "train Loss: 0.7391 Acc: 0.8078\n",
      "val Loss: 0.7457 Acc: 0.8040\n",
      "test Loss: 0.7158 Acc: 0.8280\n",
      "Epoch 1252/1499\n",
      "----------\n",
      "train Loss: 0.7370 Acc: 0.8107\n",
      "val Loss: 0.7601 Acc: 0.7840\n",
      "test Loss: 0.7336 Acc: 0.8120\n",
      "Epoch 1253/1499\n",
      "----------\n",
      "train Loss: 0.7372 Acc: 0.8098\n",
      "val Loss: 0.7469 Acc: 0.7960\n",
      "test Loss: 0.7148 Acc: 0.8480\n",
      "Epoch 1254/1499\n",
      "----------\n",
      "train Loss: 0.7380 Acc: 0.8107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.7352 Acc: 0.8080\n",
      "test Loss: 0.7202 Acc: 0.8360\n",
      "Epoch 1255/1499\n",
      "----------\n",
      "train Loss: 0.7376 Acc: 0.8120\n",
      "val Loss: 0.7533 Acc: 0.7920\n",
      "test Loss: 0.7080 Acc: 0.8400\n",
      "Epoch 1256/1499\n",
      "----------\n",
      "train Loss: 0.7354 Acc: 0.8138\n",
      "val Loss: 0.7436 Acc: 0.8040\n",
      "test Loss: 0.7150 Acc: 0.8440\n",
      "Epoch 1257/1499\n",
      "----------\n",
      "train Loss: 0.7361 Acc: 0.8138\n",
      "val Loss: 0.7485 Acc: 0.7960\n",
      "test Loss: 0.7171 Acc: 0.8400\n",
      "Epoch 1258/1499\n",
      "----------\n",
      "train Loss: 0.7371 Acc: 0.8127\n",
      "val Loss: 0.7418 Acc: 0.8000\n",
      "test Loss: 0.7354 Acc: 0.8160\n",
      "Epoch 1259/1499\n",
      "----------\n",
      "train Loss: 0.7369 Acc: 0.8107\n",
      "val Loss: 0.7446 Acc: 0.7920\n",
      "test Loss: 0.7116 Acc: 0.8440\n",
      "Epoch 1260/1499\n",
      "----------\n",
      "train Loss: 0.7368 Acc: 0.8133\n",
      "val Loss: 0.7471 Acc: 0.8040\n",
      "test Loss: 0.7226 Acc: 0.8280\n",
      "Epoch 1261/1499\n",
      "----------\n",
      "train Loss: 0.7353 Acc: 0.8136\n",
      "val Loss: 0.7581 Acc: 0.7880\n",
      "test Loss: 0.7236 Acc: 0.8200\n",
      "Epoch 1262/1499\n",
      "----------\n",
      "train Loss: 0.7359 Acc: 0.8113\n",
      "val Loss: 0.7496 Acc: 0.8040\n",
      "test Loss: 0.7092 Acc: 0.8440\n",
      "Epoch 1263/1499\n",
      "----------\n",
      "train Loss: 0.7376 Acc: 0.8138\n",
      "val Loss: 0.7489 Acc: 0.8040\n",
      "test Loss: 0.7207 Acc: 0.8360\n",
      "Epoch 1264/1499\n",
      "----------\n",
      "train Loss: 0.7383 Acc: 0.8071\n",
      "val Loss: 0.7521 Acc: 0.7960\n",
      "test Loss: 0.7316 Acc: 0.8200\n",
      "Epoch 1265/1499\n",
      "----------\n",
      "train Loss: 0.7355 Acc: 0.8120\n",
      "val Loss: 0.7553 Acc: 0.8000\n",
      "test Loss: 0.7205 Acc: 0.8280\n",
      "Epoch 1266/1499\n",
      "----------\n",
      "train Loss: 0.7368 Acc: 0.8067\n",
      "val Loss: 0.7484 Acc: 0.7880\n",
      "test Loss: 0.7196 Acc: 0.8280\n",
      "Epoch 1267/1499\n",
      "----------\n",
      "train Loss: 0.7335 Acc: 0.8184\n",
      "val Loss: 0.7416 Acc: 0.8080\n",
      "test Loss: 0.7237 Acc: 0.8360\n",
      "Epoch 1268/1499\n",
      "----------\n",
      "train Loss: 0.7385 Acc: 0.8113\n",
      "val Loss: 0.7467 Acc: 0.8080\n",
      "test Loss: 0.7236 Acc: 0.8280\n",
      "Epoch 1269/1499\n",
      "----------\n",
      "train Loss: 0.7396 Acc: 0.8076\n",
      "val Loss: 0.7446 Acc: 0.7880\n",
      "test Loss: 0.7192 Acc: 0.8400\n",
      "Epoch 1270/1499\n",
      "----------\n",
      "train Loss: 0.7390 Acc: 0.8091\n",
      "val Loss: 0.7354 Acc: 0.8040\n",
      "test Loss: 0.7224 Acc: 0.8320\n",
      "Epoch 1271/1499\n",
      "----------\n",
      "train Loss: 0.7350 Acc: 0.8133\n",
      "val Loss: 0.7490 Acc: 0.7960\n",
      "test Loss: 0.7152 Acc: 0.8440\n",
      "Epoch 1272/1499\n",
      "----------\n",
      "train Loss: 0.7349 Acc: 0.8149\n",
      "val Loss: 0.7469 Acc: 0.8000\n",
      "test Loss: 0.7176 Acc: 0.8360\n",
      "Epoch 1273/1499\n",
      "----------\n",
      "train Loss: 0.7380 Acc: 0.8111\n",
      "val Loss: 0.7446 Acc: 0.8040\n",
      "test Loss: 0.7164 Acc: 0.8400\n",
      "Epoch 1274/1499\n",
      "----------\n",
      "train Loss: 0.7342 Acc: 0.8169\n",
      "val Loss: 0.7409 Acc: 0.8080\n",
      "test Loss: 0.7191 Acc: 0.8280\n",
      "Epoch 1275/1499\n",
      "----------\n",
      "train Loss: 0.7360 Acc: 0.8118\n",
      "val Loss: 0.7526 Acc: 0.7880\n",
      "test Loss: 0.7204 Acc: 0.8240\n",
      "Epoch 1276/1499\n",
      "----------\n",
      "train Loss: 0.7383 Acc: 0.8120\n",
      "val Loss: 0.7488 Acc: 0.8000\n",
      "test Loss: 0.7241 Acc: 0.8320\n",
      "Epoch 1277/1499\n",
      "----------\n",
      "train Loss: 0.7366 Acc: 0.8107\n",
      "val Loss: 0.7439 Acc: 0.8000\n",
      "test Loss: 0.7352 Acc: 0.8000\n",
      "Epoch 1278/1499\n",
      "----------\n",
      "train Loss: 0.7367 Acc: 0.8109\n",
      "val Loss: 0.7595 Acc: 0.7840\n",
      "test Loss: 0.7222 Acc: 0.8240\n",
      "Epoch 1279/1499\n",
      "----------\n",
      "train Loss: 0.7372 Acc: 0.8087\n",
      "val Loss: 0.7420 Acc: 0.8080\n",
      "test Loss: 0.7259 Acc: 0.8240\n",
      "Epoch 1280/1499\n",
      "----------\n",
      "train Loss: 0.7348 Acc: 0.8144\n",
      "val Loss: 0.7532 Acc: 0.7720\n",
      "test Loss: 0.7209 Acc: 0.8240\n",
      "Epoch 1281/1499\n",
      "----------\n",
      "train Loss: 0.7384 Acc: 0.8107\n",
      "val Loss: 0.7499 Acc: 0.7960\n",
      "test Loss: 0.7163 Acc: 0.8400\n",
      "Epoch 1282/1499\n",
      "----------\n",
      "train Loss: 0.7373 Acc: 0.8131\n",
      "val Loss: 0.7443 Acc: 0.8000\n",
      "test Loss: 0.7244 Acc: 0.8320\n",
      "Epoch 1283/1499\n",
      "----------\n",
      "train Loss: 0.7378 Acc: 0.8122\n",
      "val Loss: 0.7365 Acc: 0.8000\n",
      "test Loss: 0.7154 Acc: 0.8240\n",
      "Epoch 1284/1499\n",
      "----------\n",
      "train Loss: 0.7354 Acc: 0.8131\n",
      "val Loss: 0.7472 Acc: 0.8000\n",
      "test Loss: 0.7169 Acc: 0.8400\n",
      "Epoch 1285/1499\n",
      "----------\n",
      "train Loss: 0.7367 Acc: 0.8071\n",
      "val Loss: 0.7525 Acc: 0.7920\n",
      "test Loss: 0.7195 Acc: 0.8360\n",
      "Epoch 1286/1499\n",
      "----------\n",
      "train Loss: 0.7329 Acc: 0.8184\n",
      "val Loss: 0.7491 Acc: 0.7960\n",
      "test Loss: 0.7170 Acc: 0.8320\n",
      "Epoch 1287/1499\n",
      "----------\n",
      "train Loss: 0.7364 Acc: 0.8120\n",
      "val Loss: 0.7490 Acc: 0.7840\n",
      "test Loss: 0.7164 Acc: 0.8400\n",
      "Epoch 1288/1499\n",
      "----------\n",
      "train Loss: 0.7352 Acc: 0.8118\n",
      "val Loss: 0.7641 Acc: 0.7880\n",
      "test Loss: 0.7235 Acc: 0.8360\n",
      "Epoch 1289/1499\n",
      "----------\n",
      "train Loss: 0.7372 Acc: 0.8131\n",
      "val Loss: 0.7524 Acc: 0.7880\n",
      "test Loss: 0.7174 Acc: 0.8240\n",
      "Epoch 1290/1499\n",
      "----------\n",
      "train Loss: 0.7355 Acc: 0.8100\n",
      "val Loss: 0.7394 Acc: 0.8080\n",
      "test Loss: 0.7116 Acc: 0.8480\n",
      "Epoch 1291/1499\n",
      "----------\n",
      "train Loss: 0.7354 Acc: 0.8129\n",
      "val Loss: 0.7380 Acc: 0.8040\n",
      "test Loss: 0.7294 Acc: 0.8200\n",
      "Epoch 1292/1499\n",
      "----------\n",
      "train Loss: 0.7366 Acc: 0.8089\n",
      "val Loss: 0.7532 Acc: 0.7840\n",
      "test Loss: 0.7281 Acc: 0.8160\n",
      "Epoch 1293/1499\n",
      "----------\n",
      "train Loss: 0.7378 Acc: 0.8109\n",
      "val Loss: 0.7495 Acc: 0.7920\n",
      "test Loss: 0.7166 Acc: 0.8320\n",
      "Epoch 1294/1499\n",
      "----------\n",
      "train Loss: 0.7368 Acc: 0.8080\n",
      "val Loss: 0.7412 Acc: 0.7960\n",
      "test Loss: 0.7288 Acc: 0.8160\n",
      "Epoch 1295/1499\n",
      "----------\n",
      "train Loss: 0.7364 Acc: 0.8109\n",
      "val Loss: 0.7518 Acc: 0.7920\n",
      "test Loss: 0.7285 Acc: 0.8200\n",
      "Epoch 1296/1499\n",
      "----------\n",
      "train Loss: 0.7369 Acc: 0.8109\n",
      "val Loss: 0.7439 Acc: 0.7960\n",
      "test Loss: 0.6998 Acc: 0.8640\n",
      "Epoch 1297/1499\n",
      "----------\n",
      "train Loss: 0.7356 Acc: 0.8138\n",
      "val Loss: 0.7458 Acc: 0.7920\n",
      "test Loss: 0.7215 Acc: 0.8200\n",
      "Epoch 1298/1499\n",
      "----------\n",
      "train Loss: 0.7380 Acc: 0.8082\n",
      "val Loss: 0.7520 Acc: 0.8000\n",
      "test Loss: 0.7193 Acc: 0.8320\n",
      "Epoch 1299/1499\n",
      "----------\n",
      "train Loss: 0.7333 Acc: 0.8144\n",
      "val Loss: 0.7464 Acc: 0.7920\n",
      "test Loss: 0.7224 Acc: 0.8360\n",
      "Epoch 1300/1499\n",
      "----------\n",
      "train Loss: 0.7365 Acc: 0.8129\n",
      "val Loss: 0.7569 Acc: 0.7880\n",
      "test Loss: 0.7227 Acc: 0.8360\n",
      "Epoch 1301/1499\n",
      "----------\n",
      "train Loss: 0.7354 Acc: 0.8158\n",
      "val Loss: 0.7444 Acc: 0.8040\n",
      "test Loss: 0.7100 Acc: 0.8400\n",
      "Epoch 1302/1499\n",
      "----------\n",
      "train Loss: 0.7349 Acc: 0.8153\n",
      "val Loss: 0.7474 Acc: 0.8120\n",
      "test Loss: 0.7227 Acc: 0.8280\n",
      "Epoch 1303/1499\n",
      "----------\n",
      "train Loss: 0.7374 Acc: 0.8100\n",
      "val Loss: 0.7606 Acc: 0.7760\n",
      "test Loss: 0.7272 Acc: 0.8240\n",
      "Epoch 1304/1499\n",
      "----------\n",
      "train Loss: 0.7339 Acc: 0.8164\n",
      "val Loss: 0.7565 Acc: 0.7640\n",
      "test Loss: 0.7172 Acc: 0.8200\n",
      "Epoch 1305/1499\n",
      "----------\n",
      "train Loss: 0.7386 Acc: 0.8084\n",
      "val Loss: 0.7416 Acc: 0.7920\n",
      "test Loss: 0.7208 Acc: 0.8280\n",
      "Epoch 1306/1499\n",
      "----------\n",
      "train Loss: 0.7325 Acc: 0.8162\n",
      "val Loss: 0.7469 Acc: 0.7920\n",
      "test Loss: 0.7126 Acc: 0.8400\n",
      "Epoch 1307/1499\n",
      "----------\n",
      "train Loss: 0.7375 Acc: 0.8089\n",
      "val Loss: 0.7430 Acc: 0.8040\n",
      "test Loss: 0.7199 Acc: 0.8240\n",
      "Epoch 1308/1499\n",
      "----------\n",
      "train Loss: 0.7372 Acc: 0.8122\n",
      "val Loss: 0.7483 Acc: 0.7920\n",
      "test Loss: 0.7228 Acc: 0.8200\n",
      "Epoch 1309/1499\n",
      "----------\n",
      "train Loss: 0.7366 Acc: 0.8118\n",
      "val Loss: 0.7473 Acc: 0.7920\n",
      "test Loss: 0.7218 Acc: 0.8280\n",
      "Epoch 1310/1499\n",
      "----------\n",
      "train Loss: 0.7334 Acc: 0.8180\n",
      "val Loss: 0.7480 Acc: 0.8000\n",
      "test Loss: 0.7294 Acc: 0.8120\n",
      "Epoch 1311/1499\n",
      "----------\n",
      "train Loss: 0.7346 Acc: 0.8149\n",
      "val Loss: 0.7518 Acc: 0.7920\n",
      "test Loss: 0.7162 Acc: 0.8480\n",
      "Epoch 1312/1499\n",
      "----------\n",
      "train Loss: 0.7351 Acc: 0.8164\n",
      "val Loss: 0.7500 Acc: 0.8000\n",
      "test Loss: 0.7176 Acc: 0.8320\n",
      "Epoch 1313/1499\n",
      "----------\n",
      "train Loss: 0.7337 Acc: 0.8118\n",
      "val Loss: 0.7410 Acc: 0.8160\n",
      "test Loss: 0.7171 Acc: 0.8240\n",
      "Epoch 1314/1499\n",
      "----------\n",
      "train Loss: 0.7361 Acc: 0.8153\n",
      "val Loss: 0.7456 Acc: 0.7960\n",
      "test Loss: 0.7221 Acc: 0.8200\n",
      "Epoch 1315/1499\n",
      "----------\n",
      "train Loss: 0.7358 Acc: 0.8144\n",
      "val Loss: 0.7508 Acc: 0.7760\n",
      "test Loss: 0.7198 Acc: 0.8200\n",
      "Epoch 1316/1499\n",
      "----------\n",
      "train Loss: 0.7356 Acc: 0.8122\n",
      "val Loss: 0.7459 Acc: 0.7920\n",
      "test Loss: 0.7279 Acc: 0.8200\n",
      "Epoch 1317/1499\n",
      "----------\n",
      "train Loss: 0.7369 Acc: 0.8116\n",
      "val Loss: 0.7469 Acc: 0.7960\n",
      "test Loss: 0.7182 Acc: 0.8360\n",
      "Epoch 1318/1499\n",
      "----------\n",
      "train Loss: 0.7327 Acc: 0.8144\n",
      "val Loss: 0.7431 Acc: 0.8040\n",
      "test Loss: 0.7175 Acc: 0.8360\n",
      "Epoch 1319/1499\n",
      "----------\n",
      "train Loss: 0.7338 Acc: 0.8149\n",
      "val Loss: 0.7503 Acc: 0.7960\n",
      "test Loss: 0.7173 Acc: 0.8280\n",
      "Epoch 1320/1499\n",
      "----------\n",
      "train Loss: 0.7346 Acc: 0.8104\n",
      "val Loss: 0.7647 Acc: 0.7720\n",
      "test Loss: 0.7297 Acc: 0.8080\n",
      "Epoch 1321/1499\n",
      "----------\n",
      "train Loss: 0.7345 Acc: 0.8158\n",
      "val Loss: 0.7397 Acc: 0.7920\n",
      "test Loss: 0.7268 Acc: 0.8240\n",
      "Epoch 1322/1499\n",
      "----------\n",
      "train Loss: 0.7368 Acc: 0.8131\n",
      "val Loss: 0.7518 Acc: 0.8000\n",
      "test Loss: 0.7181 Acc: 0.8280\n",
      "Epoch 1323/1499\n",
      "----------\n",
      "train Loss: 0.7358 Acc: 0.8122\n",
      "val Loss: 0.7313 Acc: 0.8200\n",
      "test Loss: 0.7269 Acc: 0.8200\n",
      "Epoch 1324/1499\n",
      "----------\n",
      "train Loss: 0.7333 Acc: 0.8158\n",
      "val Loss: 0.7433 Acc: 0.7960\n",
      "test Loss: 0.7189 Acc: 0.8320\n",
      "Epoch 1325/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.7344 Acc: 0.8111\n",
      "val Loss: 0.7382 Acc: 0.8080\n",
      "test Loss: 0.7116 Acc: 0.8440\n",
      "Epoch 1326/1499\n",
      "----------\n",
      "train Loss: 0.7326 Acc: 0.8160\n",
      "val Loss: 0.7414 Acc: 0.7880\n",
      "test Loss: 0.7208 Acc: 0.8360\n",
      "Epoch 1327/1499\n",
      "----------\n",
      "train Loss: 0.7335 Acc: 0.8160\n",
      "val Loss: 0.7402 Acc: 0.8000\n",
      "test Loss: 0.7319 Acc: 0.8120\n",
      "Epoch 1328/1499\n",
      "----------\n",
      "train Loss: 0.7347 Acc: 0.8142\n",
      "val Loss: 0.7497 Acc: 0.8000\n",
      "test Loss: 0.7143 Acc: 0.8520\n",
      "Epoch 1329/1499\n",
      "----------\n",
      "train Loss: 0.7381 Acc: 0.8096\n",
      "val Loss: 0.7342 Acc: 0.8320\n",
      "test Loss: 0.7080 Acc: 0.8440\n",
      "Epoch 1330/1499\n",
      "----------\n",
      "train Loss: 0.7352 Acc: 0.8136\n",
      "val Loss: 0.7457 Acc: 0.8000\n",
      "test Loss: 0.7147 Acc: 0.8360\n",
      "Epoch 1331/1499\n",
      "----------\n",
      "train Loss: 0.7355 Acc: 0.8149\n",
      "val Loss: 0.7533 Acc: 0.7760\n",
      "test Loss: 0.7227 Acc: 0.8280\n",
      "Epoch 1332/1499\n",
      "----------\n",
      "train Loss: 0.7334 Acc: 0.8158\n",
      "val Loss: 0.7327 Acc: 0.8120\n",
      "test Loss: 0.7209 Acc: 0.8280\n",
      "Epoch 1333/1499\n",
      "----------\n",
      "train Loss: 0.7363 Acc: 0.8111\n",
      "val Loss: 0.7505 Acc: 0.7840\n",
      "test Loss: 0.7221 Acc: 0.8280\n",
      "Epoch 1334/1499\n",
      "----------\n",
      "train Loss: 0.7372 Acc: 0.8129\n",
      "val Loss: 0.7373 Acc: 0.8040\n",
      "test Loss: 0.7230 Acc: 0.8200\n",
      "Epoch 1335/1499\n",
      "----------\n",
      "train Loss: 0.7349 Acc: 0.8144\n",
      "val Loss: 0.7448 Acc: 0.8120\n",
      "test Loss: 0.7226 Acc: 0.8320\n",
      "Epoch 1336/1499\n",
      "----------\n",
      "train Loss: 0.7320 Acc: 0.8167\n",
      "val Loss: 0.7454 Acc: 0.8160\n",
      "test Loss: 0.7272 Acc: 0.8280\n",
      "Epoch 1337/1499\n",
      "----------\n",
      "train Loss: 0.7367 Acc: 0.8113\n",
      "val Loss: 0.7360 Acc: 0.8120\n",
      "test Loss: 0.7208 Acc: 0.8320\n",
      "Epoch 1338/1499\n",
      "----------\n",
      "train Loss: 0.7353 Acc: 0.8120\n",
      "val Loss: 0.7564 Acc: 0.8000\n",
      "test Loss: 0.7300 Acc: 0.8160\n",
      "Epoch 1339/1499\n",
      "----------\n",
      "train Loss: 0.7356 Acc: 0.8113\n",
      "val Loss: 0.7436 Acc: 0.8120\n",
      "test Loss: 0.7177 Acc: 0.8160\n",
      "Epoch 1340/1499\n",
      "----------\n",
      "train Loss: 0.7357 Acc: 0.8109\n",
      "val Loss: 0.7511 Acc: 0.7760\n",
      "test Loss: 0.7307 Acc: 0.8040\n",
      "Epoch 1341/1499\n",
      "----------\n",
      "train Loss: 0.7375 Acc: 0.8109\n",
      "val Loss: 0.7531 Acc: 0.7800\n",
      "test Loss: 0.7077 Acc: 0.8480\n",
      "Epoch 1342/1499\n",
      "----------\n",
      "train Loss: 0.7345 Acc: 0.8158\n",
      "val Loss: 0.7437 Acc: 0.7960\n",
      "test Loss: 0.7253 Acc: 0.8280\n",
      "Epoch 1343/1499\n",
      "----------\n",
      "train Loss: 0.7360 Acc: 0.8122\n",
      "val Loss: 0.7391 Acc: 0.8040\n",
      "test Loss: 0.7082 Acc: 0.8600\n",
      "Epoch 1344/1499\n",
      "----------\n",
      "train Loss: 0.7354 Acc: 0.8118\n",
      "val Loss: 0.7400 Acc: 0.8080\n",
      "test Loss: 0.7199 Acc: 0.8280\n",
      "Epoch 1345/1499\n",
      "----------\n",
      "train Loss: 0.7334 Acc: 0.8142\n",
      "val Loss: 0.7545 Acc: 0.7840\n",
      "test Loss: 0.7229 Acc: 0.8120\n",
      "Epoch 1346/1499\n",
      "----------\n",
      "train Loss: 0.7340 Acc: 0.8138\n",
      "val Loss: 0.7447 Acc: 0.7880\n",
      "test Loss: 0.7174 Acc: 0.8320\n",
      "Epoch 1347/1499\n",
      "----------\n",
      "train Loss: 0.7365 Acc: 0.8076\n",
      "val Loss: 0.7397 Acc: 0.8080\n",
      "test Loss: 0.7221 Acc: 0.8240\n",
      "Epoch 1348/1499\n",
      "----------\n",
      "train Loss: 0.7356 Acc: 0.8116\n",
      "val Loss: 0.7465 Acc: 0.7960\n",
      "test Loss: 0.7234 Acc: 0.8240\n",
      "Epoch 1349/1499\n",
      "----------\n",
      "train Loss: 0.7357 Acc: 0.8151\n",
      "val Loss: 0.7439 Acc: 0.8040\n",
      "test Loss: 0.7245 Acc: 0.8280\n",
      "Epoch 1350/1499\n",
      "----------\n",
      "train Loss: 0.7366 Acc: 0.8111\n",
      "val Loss: 0.7449 Acc: 0.7960\n",
      "test Loss: 0.7221 Acc: 0.8400\n",
      "Epoch 1351/1499\n",
      "----------\n",
      "train Loss: 0.7325 Acc: 0.8191\n",
      "val Loss: 0.7449 Acc: 0.7960\n",
      "test Loss: 0.7265 Acc: 0.8160\n",
      "Epoch 1352/1499\n",
      "----------\n",
      "train Loss: 0.7343 Acc: 0.8102\n",
      "val Loss: 0.7482 Acc: 0.7960\n",
      "test Loss: 0.7284 Acc: 0.8080\n",
      "Epoch 1353/1499\n",
      "----------\n",
      "train Loss: 0.7355 Acc: 0.8113\n",
      "val Loss: 0.7431 Acc: 0.8120\n",
      "test Loss: 0.7159 Acc: 0.8280\n",
      "Epoch 1354/1499\n",
      "----------\n",
      "train Loss: 0.7339 Acc: 0.8156\n",
      "val Loss: 0.7390 Acc: 0.8040\n",
      "test Loss: 0.7125 Acc: 0.8440\n",
      "Epoch 1355/1499\n",
      "----------\n",
      "train Loss: 0.7340 Acc: 0.8153\n",
      "val Loss: 0.7494 Acc: 0.7920\n",
      "test Loss: 0.7358 Acc: 0.8000\n",
      "Epoch 1356/1499\n",
      "----------\n",
      "train Loss: 0.7348 Acc: 0.8138\n",
      "val Loss: 0.7385 Acc: 0.8160\n",
      "test Loss: 0.7119 Acc: 0.8400\n",
      "Epoch 1357/1499\n",
      "----------\n",
      "train Loss: 0.7338 Acc: 0.8158\n",
      "val Loss: 0.7445 Acc: 0.7960\n",
      "test Loss: 0.7193 Acc: 0.8360\n",
      "Epoch 1358/1499\n",
      "----------\n",
      "train Loss: 0.7344 Acc: 0.8158\n",
      "val Loss: 0.7343 Acc: 0.8160\n",
      "test Loss: 0.7270 Acc: 0.8320\n",
      "Epoch 1359/1499\n",
      "----------\n",
      "train Loss: 0.7357 Acc: 0.8129\n",
      "val Loss: 0.7450 Acc: 0.8080\n",
      "test Loss: 0.7123 Acc: 0.8320\n",
      "Epoch 1360/1499\n",
      "----------\n",
      "train Loss: 0.7357 Acc: 0.8160\n",
      "val Loss: 0.7471 Acc: 0.7880\n",
      "test Loss: 0.7141 Acc: 0.8440\n",
      "Epoch 1361/1499\n",
      "----------\n",
      "train Loss: 0.7347 Acc: 0.8107\n",
      "val Loss: 0.7425 Acc: 0.8040\n",
      "test Loss: 0.7228 Acc: 0.8360\n",
      "Epoch 1362/1499\n",
      "----------\n",
      "train Loss: 0.7334 Acc: 0.8127\n",
      "val Loss: 0.7548 Acc: 0.7920\n",
      "test Loss: 0.7204 Acc: 0.8240\n",
      "Epoch 1363/1499\n",
      "----------\n",
      "train Loss: 0.7353 Acc: 0.8133\n",
      "val Loss: 0.7382 Acc: 0.8040\n",
      "test Loss: 0.7235 Acc: 0.8280\n",
      "Epoch 1364/1499\n",
      "----------\n",
      "train Loss: 0.7346 Acc: 0.8122\n",
      "val Loss: 0.7454 Acc: 0.8000\n",
      "test Loss: 0.7301 Acc: 0.8080\n",
      "Epoch 1365/1499\n",
      "----------\n",
      "train Loss: 0.7345 Acc: 0.8140\n",
      "val Loss: 0.7474 Acc: 0.8000\n",
      "test Loss: 0.7190 Acc: 0.8240\n",
      "Epoch 1366/1499\n",
      "----------\n",
      "train Loss: 0.7369 Acc: 0.8122\n",
      "val Loss: 0.7471 Acc: 0.7880\n",
      "test Loss: 0.7093 Acc: 0.8440\n",
      "Epoch 1367/1499\n",
      "----------\n",
      "train Loss: 0.7346 Acc: 0.8118\n",
      "val Loss: 0.7483 Acc: 0.7880\n",
      "test Loss: 0.7169 Acc: 0.8320\n",
      "Epoch 1368/1499\n",
      "----------\n",
      "train Loss: 0.7352 Acc: 0.8096\n",
      "val Loss: 0.7512 Acc: 0.8000\n",
      "test Loss: 0.7141 Acc: 0.8320\n",
      "Epoch 1369/1499\n",
      "----------\n",
      "train Loss: 0.7320 Acc: 0.8187\n",
      "val Loss: 0.7437 Acc: 0.7960\n",
      "test Loss: 0.7277 Acc: 0.8120\n",
      "Epoch 1370/1499\n",
      "----------\n",
      "train Loss: 0.7319 Acc: 0.8171\n",
      "val Loss: 0.7504 Acc: 0.7960\n",
      "test Loss: 0.7317 Acc: 0.8160\n",
      "Epoch 1371/1499\n",
      "----------\n",
      "train Loss: 0.7329 Acc: 0.8136\n",
      "val Loss: 0.7531 Acc: 0.7760\n",
      "test Loss: 0.7148 Acc: 0.8440\n",
      "Epoch 1372/1499\n",
      "----------\n",
      "train Loss: 0.7326 Acc: 0.8138\n",
      "val Loss: 0.7361 Acc: 0.8080\n",
      "test Loss: 0.7241 Acc: 0.8280\n",
      "Epoch 1373/1499\n",
      "----------\n",
      "train Loss: 0.7344 Acc: 0.8140\n",
      "val Loss: 0.7441 Acc: 0.8120\n",
      "test Loss: 0.7169 Acc: 0.8280\n",
      "Epoch 1374/1499\n",
      "----------\n",
      "train Loss: 0.7340 Acc: 0.8160\n",
      "val Loss: 0.7541 Acc: 0.7720\n",
      "test Loss: 0.7170 Acc: 0.8320\n",
      "Epoch 1375/1499\n",
      "----------\n",
      "train Loss: 0.7318 Acc: 0.8133\n",
      "val Loss: 0.7341 Acc: 0.8200\n",
      "test Loss: 0.7261 Acc: 0.8240\n",
      "Epoch 1376/1499\n",
      "----------\n",
      "train Loss: 0.7344 Acc: 0.8127\n",
      "val Loss: 0.7421 Acc: 0.8040\n",
      "test Loss: 0.7262 Acc: 0.8320\n",
      "Epoch 1377/1499\n",
      "----------\n",
      "train Loss: 0.7319 Acc: 0.8178\n",
      "val Loss: 0.7447 Acc: 0.7880\n",
      "test Loss: 0.7125 Acc: 0.8480\n",
      "Epoch 1378/1499\n",
      "----------\n",
      "train Loss: 0.7329 Acc: 0.8147\n",
      "val Loss: 0.7573 Acc: 0.7920\n",
      "test Loss: 0.7198 Acc: 0.8280\n",
      "Epoch 1379/1499\n",
      "----------\n",
      "train Loss: 0.7331 Acc: 0.8160\n",
      "val Loss: 0.7520 Acc: 0.7840\n",
      "test Loss: 0.7146 Acc: 0.8240\n",
      "Epoch 1380/1499\n",
      "----------\n",
      "train Loss: 0.7364 Acc: 0.8089\n",
      "val Loss: 0.7464 Acc: 0.8000\n",
      "test Loss: 0.7206 Acc: 0.8280\n",
      "Epoch 1381/1499\n",
      "----------\n",
      "train Loss: 0.7353 Acc: 0.8147\n",
      "val Loss: 0.7472 Acc: 0.7960\n",
      "test Loss: 0.7138 Acc: 0.8440\n",
      "Epoch 1382/1499\n",
      "----------\n",
      "train Loss: 0.7336 Acc: 0.8160\n",
      "val Loss: 0.7353 Acc: 0.8160\n",
      "test Loss: 0.7136 Acc: 0.8360\n",
      "Epoch 1383/1499\n",
      "----------\n",
      "train Loss: 0.7328 Acc: 0.8129\n",
      "val Loss: 0.7487 Acc: 0.7880\n",
      "test Loss: 0.7247 Acc: 0.8240\n",
      "Epoch 1384/1499\n",
      "----------\n",
      "train Loss: 0.7347 Acc: 0.8124\n",
      "val Loss: 0.7489 Acc: 0.7920\n",
      "test Loss: 0.7144 Acc: 0.8320\n",
      "Epoch 1385/1499\n",
      "----------\n",
      "train Loss: 0.7347 Acc: 0.8098\n",
      "val Loss: 0.7502 Acc: 0.8000\n",
      "test Loss: 0.7195 Acc: 0.8280\n",
      "Epoch 1386/1499\n",
      "----------\n",
      "train Loss: 0.7322 Acc: 0.8160\n",
      "val Loss: 0.7537 Acc: 0.7840\n",
      "test Loss: 0.7220 Acc: 0.8200\n",
      "Epoch 1387/1499\n",
      "----------\n",
      "train Loss: 0.7334 Acc: 0.8120\n",
      "val Loss: 0.7349 Acc: 0.8120\n",
      "test Loss: 0.7149 Acc: 0.8320\n",
      "Epoch 1388/1499\n",
      "----------\n",
      "train Loss: 0.7347 Acc: 0.8124\n",
      "val Loss: 0.7507 Acc: 0.8000\n",
      "test Loss: 0.7158 Acc: 0.8400\n",
      "Epoch 1389/1499\n",
      "----------\n",
      "train Loss: 0.7338 Acc: 0.8142\n",
      "val Loss: 0.7501 Acc: 0.7920\n",
      "test Loss: 0.7217 Acc: 0.8360\n",
      "Epoch 1390/1499\n",
      "----------\n",
      "train Loss: 0.7345 Acc: 0.8138\n",
      "val Loss: 0.7427 Acc: 0.8120\n",
      "test Loss: 0.7106 Acc: 0.8440\n",
      "Epoch 1391/1499\n",
      "----------\n",
      "train Loss: 0.7307 Acc: 0.8158\n",
      "val Loss: 0.7482 Acc: 0.7800\n",
      "test Loss: 0.7191 Acc: 0.8200\n",
      "Epoch 1392/1499\n",
      "----------\n",
      "train Loss: 0.7351 Acc: 0.8129\n",
      "val Loss: 0.7424 Acc: 0.8040\n",
      "test Loss: 0.7149 Acc: 0.8360\n",
      "Epoch 1393/1499\n",
      "----------\n",
      "train Loss: 0.7357 Acc: 0.8091\n",
      "val Loss: 0.7559 Acc: 0.7800\n",
      "test Loss: 0.7179 Acc: 0.8280\n",
      "Epoch 1394/1499\n",
      "----------\n",
      "train Loss: 0.7328 Acc: 0.8158\n",
      "val Loss: 0.7432 Acc: 0.8000\n",
      "test Loss: 0.7258 Acc: 0.8200\n",
      "Epoch 1395/1499\n",
      "----------\n",
      "train Loss: 0.7353 Acc: 0.8122\n",
      "val Loss: 0.7573 Acc: 0.7920\n",
      "test Loss: 0.7185 Acc: 0.8320\n",
      "Epoch 1396/1499\n",
      "----------\n",
      "train Loss: 0.7337 Acc: 0.8151\n",
      "val Loss: 0.7376 Acc: 0.8080\n",
      "test Loss: 0.7070 Acc: 0.8520\n",
      "Epoch 1397/1499\n",
      "----------\n",
      "train Loss: 0.7331 Acc: 0.8153\n",
      "val Loss: 0.7501 Acc: 0.7880\n",
      "test Loss: 0.7166 Acc: 0.8440\n",
      "Epoch 1398/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.7341 Acc: 0.8160\n",
      "val Loss: 0.7500 Acc: 0.7960\n",
      "test Loss: 0.7191 Acc: 0.8440\n",
      "Epoch 1399/1499\n",
      "----------\n",
      "train Loss: 0.7336 Acc: 0.8156\n",
      "val Loss: 0.7457 Acc: 0.7920\n",
      "test Loss: 0.7193 Acc: 0.8240\n",
      "Epoch 1400/1499\n",
      "----------\n",
      "train Loss: 0.7332 Acc: 0.8129\n",
      "val Loss: 0.7353 Acc: 0.8080\n",
      "test Loss: 0.7132 Acc: 0.8360\n",
      "Epoch 1401/1499\n",
      "----------\n",
      "train Loss: 0.7341 Acc: 0.8136\n",
      "val Loss: 0.7504 Acc: 0.7920\n",
      "test Loss: 0.7141 Acc: 0.8320\n",
      "Epoch 1402/1499\n",
      "----------\n",
      "train Loss: 0.7306 Acc: 0.8162\n",
      "val Loss: 0.7478 Acc: 0.8000\n",
      "test Loss: 0.7110 Acc: 0.8480\n",
      "Epoch 1403/1499\n",
      "----------\n",
      "train Loss: 0.7333 Acc: 0.8144\n",
      "val Loss: 0.7401 Acc: 0.8080\n",
      "test Loss: 0.7179 Acc: 0.8360\n",
      "Epoch 1404/1499\n",
      "----------\n",
      "train Loss: 0.7341 Acc: 0.8138\n",
      "val Loss: 0.7497 Acc: 0.7800\n",
      "test Loss: 0.7203 Acc: 0.8280\n",
      "Epoch 1405/1499\n",
      "----------\n",
      "train Loss: 0.7334 Acc: 0.8140\n",
      "val Loss: 0.7478 Acc: 0.8080\n",
      "test Loss: 0.7150 Acc: 0.8200\n",
      "Epoch 1406/1499\n",
      "----------\n",
      "train Loss: 0.7354 Acc: 0.8102\n",
      "val Loss: 0.7315 Acc: 0.8160\n",
      "test Loss: 0.7184 Acc: 0.8360\n",
      "Epoch 1407/1499\n",
      "----------\n",
      "train Loss: 0.7341 Acc: 0.8127\n",
      "val Loss: 0.7416 Acc: 0.8000\n",
      "test Loss: 0.7172 Acc: 0.8280\n",
      "Epoch 1408/1499\n",
      "----------\n",
      "train Loss: 0.7350 Acc: 0.8136\n",
      "val Loss: 0.7406 Acc: 0.8040\n",
      "test Loss: 0.7136 Acc: 0.8440\n",
      "Epoch 1409/1499\n",
      "----------\n",
      "train Loss: 0.7337 Acc: 0.8147\n",
      "val Loss: 0.7438 Acc: 0.8080\n",
      "test Loss: 0.7154 Acc: 0.8240\n",
      "Epoch 1410/1499\n",
      "----------\n",
      "train Loss: 0.7330 Acc: 0.8153\n",
      "val Loss: 0.7455 Acc: 0.7880\n",
      "test Loss: 0.7267 Acc: 0.8200\n",
      "Epoch 1411/1499\n",
      "----------\n",
      "train Loss: 0.7331 Acc: 0.8122\n",
      "val Loss: 0.7448 Acc: 0.8040\n",
      "test Loss: 0.7163 Acc: 0.8360\n",
      "Epoch 1412/1499\n",
      "----------\n",
      "train Loss: 0.7341 Acc: 0.8113\n",
      "val Loss: 0.7583 Acc: 0.7920\n",
      "test Loss: 0.7227 Acc: 0.8240\n",
      "Epoch 1413/1499\n",
      "----------\n",
      "train Loss: 0.7346 Acc: 0.8136\n",
      "val Loss: 0.7557 Acc: 0.7800\n",
      "test Loss: 0.7331 Acc: 0.8120\n",
      "Epoch 1414/1499\n",
      "----------\n",
      "train Loss: 0.7320 Acc: 0.8164\n",
      "val Loss: 0.7402 Acc: 0.8080\n",
      "test Loss: 0.7322 Acc: 0.8160\n",
      "Epoch 1415/1499\n",
      "----------\n",
      "train Loss: 0.7330 Acc: 0.8156\n",
      "val Loss: 0.7503 Acc: 0.7720\n",
      "test Loss: 0.7102 Acc: 0.8360\n",
      "Epoch 1416/1499\n",
      "----------\n",
      "train Loss: 0.7343 Acc: 0.8109\n",
      "val Loss: 0.7522 Acc: 0.7960\n",
      "test Loss: 0.7152 Acc: 0.8280\n",
      "Epoch 1417/1499\n",
      "----------\n",
      "train Loss: 0.7327 Acc: 0.8156\n",
      "val Loss: 0.7510 Acc: 0.7960\n",
      "test Loss: 0.7200 Acc: 0.8120\n",
      "Epoch 1418/1499\n",
      "----------\n",
      "train Loss: 0.7327 Acc: 0.8149\n",
      "val Loss: 0.7386 Acc: 0.8080\n",
      "test Loss: 0.7158 Acc: 0.8440\n",
      "Epoch 1419/1499\n",
      "----------\n",
      "train Loss: 0.7320 Acc: 0.8184\n",
      "val Loss: 0.7556 Acc: 0.7920\n",
      "test Loss: 0.7148 Acc: 0.8400\n",
      "Epoch 1420/1499\n",
      "----------\n",
      "train Loss: 0.7346 Acc: 0.8133\n",
      "val Loss: 0.7465 Acc: 0.8040\n",
      "test Loss: 0.7218 Acc: 0.8240\n",
      "Epoch 1421/1499\n",
      "----------\n",
      "train Loss: 0.7324 Acc: 0.8171\n",
      "val Loss: 0.7477 Acc: 0.8040\n",
      "test Loss: 0.7099 Acc: 0.8560\n",
      "Epoch 1422/1499\n",
      "----------\n",
      "train Loss: 0.7322 Acc: 0.8169\n",
      "val Loss: 0.7448 Acc: 0.8000\n",
      "test Loss: 0.7171 Acc: 0.8440\n",
      "Epoch 1423/1499\n",
      "----------\n",
      "train Loss: 0.7303 Acc: 0.8202\n",
      "val Loss: 0.7451 Acc: 0.8000\n",
      "test Loss: 0.7158 Acc: 0.8440\n",
      "Epoch 1424/1499\n",
      "----------\n",
      "train Loss: 0.7321 Acc: 0.8173\n",
      "val Loss: 0.7415 Acc: 0.8000\n",
      "test Loss: 0.7207 Acc: 0.8200\n",
      "Epoch 1425/1499\n",
      "----------\n",
      "train Loss: 0.7316 Acc: 0.8144\n",
      "val Loss: 0.7413 Acc: 0.7960\n",
      "test Loss: 0.7177 Acc: 0.8280\n",
      "Epoch 1426/1499\n",
      "----------\n",
      "train Loss: 0.7317 Acc: 0.8191\n",
      "val Loss: 0.7480 Acc: 0.7960\n",
      "test Loss: 0.7345 Acc: 0.8000\n",
      "Epoch 1427/1499\n",
      "----------\n",
      "train Loss: 0.7337 Acc: 0.8144\n",
      "val Loss: 0.7374 Acc: 0.7960\n",
      "test Loss: 0.7071 Acc: 0.8440\n",
      "Epoch 1428/1499\n",
      "----------\n",
      "train Loss: 0.7355 Acc: 0.8129\n",
      "val Loss: 0.7517 Acc: 0.7760\n",
      "test Loss: 0.7067 Acc: 0.8400\n",
      "Epoch 1429/1499\n",
      "----------\n",
      "train Loss: 0.7346 Acc: 0.8102\n",
      "val Loss: 0.7456 Acc: 0.8000\n",
      "test Loss: 0.7247 Acc: 0.8200\n",
      "Epoch 1430/1499\n",
      "----------\n",
      "train Loss: 0.7313 Acc: 0.8182\n",
      "val Loss: 0.7349 Acc: 0.8080\n",
      "test Loss: 0.7307 Acc: 0.8040\n",
      "Epoch 1431/1499\n",
      "----------\n",
      "train Loss: 0.7314 Acc: 0.8187\n",
      "val Loss: 0.7425 Acc: 0.7960\n",
      "test Loss: 0.7326 Acc: 0.8120\n",
      "Epoch 1432/1499\n",
      "----------\n",
      "train Loss: 0.7327 Acc: 0.8169\n",
      "val Loss: 0.7517 Acc: 0.7880\n",
      "test Loss: 0.7073 Acc: 0.8480\n",
      "Epoch 1433/1499\n",
      "----------\n",
      "train Loss: 0.7307 Acc: 0.8171\n",
      "val Loss: 0.7524 Acc: 0.7920\n",
      "test Loss: 0.7184 Acc: 0.8360\n",
      "Epoch 1434/1499\n",
      "----------\n",
      "train Loss: 0.7349 Acc: 0.8142\n",
      "val Loss: 0.7464 Acc: 0.7880\n",
      "test Loss: 0.7361 Acc: 0.8080\n",
      "Epoch 1435/1499\n",
      "----------\n",
      "train Loss: 0.7321 Acc: 0.8171\n",
      "val Loss: 0.7518 Acc: 0.7960\n",
      "test Loss: 0.7188 Acc: 0.8320\n",
      "Epoch 1436/1499\n",
      "----------\n",
      "train Loss: 0.7338 Acc: 0.8142\n",
      "val Loss: 0.7450 Acc: 0.7960\n",
      "test Loss: 0.7171 Acc: 0.8280\n",
      "Epoch 1437/1499\n",
      "----------\n",
      "train Loss: 0.7312 Acc: 0.8160\n",
      "val Loss: 0.7416 Acc: 0.8040\n",
      "test Loss: 0.7148 Acc: 0.8280\n",
      "Epoch 1438/1499\n",
      "----------\n",
      "train Loss: 0.7331 Acc: 0.8149\n",
      "val Loss: 0.7405 Acc: 0.8040\n",
      "test Loss: 0.7087 Acc: 0.8520\n",
      "Epoch 1439/1499\n",
      "----------\n",
      "train Loss: 0.7330 Acc: 0.8149\n",
      "val Loss: 0.7386 Acc: 0.7960\n",
      "test Loss: 0.7061 Acc: 0.8520\n",
      "Epoch 1440/1499\n",
      "----------\n",
      "train Loss: 0.7347 Acc: 0.8124\n",
      "val Loss: 0.7622 Acc: 0.7800\n",
      "test Loss: 0.7224 Acc: 0.8240\n",
      "Epoch 1441/1499\n",
      "----------\n",
      "train Loss: 0.7326 Acc: 0.8184\n",
      "val Loss: 0.7513 Acc: 0.7880\n",
      "test Loss: 0.7163 Acc: 0.8360\n",
      "Epoch 1442/1499\n",
      "----------\n",
      "train Loss: 0.7350 Acc: 0.8116\n",
      "val Loss: 0.7568 Acc: 0.7800\n",
      "test Loss: 0.7289 Acc: 0.8120\n",
      "Epoch 1443/1499\n",
      "----------\n",
      "train Loss: 0.7338 Acc: 0.8107\n",
      "val Loss: 0.7447 Acc: 0.7920\n",
      "test Loss: 0.7160 Acc: 0.8160\n",
      "Epoch 1444/1499\n",
      "----------\n",
      "train Loss: 0.7317 Acc: 0.8158\n",
      "val Loss: 0.7567 Acc: 0.7840\n",
      "test Loss: 0.7154 Acc: 0.8360\n",
      "Epoch 1445/1499\n",
      "----------\n",
      "train Loss: 0.7342 Acc: 0.8136\n",
      "val Loss: 0.7368 Acc: 0.8080\n",
      "test Loss: 0.7252 Acc: 0.8200\n",
      "Epoch 1446/1499\n",
      "----------\n",
      "train Loss: 0.7337 Acc: 0.8178\n",
      "val Loss: 0.7458 Acc: 0.8000\n",
      "test Loss: 0.7247 Acc: 0.8320\n",
      "Epoch 1447/1499\n",
      "----------\n",
      "train Loss: 0.7328 Acc: 0.8136\n",
      "val Loss: 0.7388 Acc: 0.8080\n",
      "test Loss: 0.7100 Acc: 0.8320\n",
      "Epoch 1448/1499\n",
      "----------\n",
      "train Loss: 0.7320 Acc: 0.8158\n",
      "val Loss: 0.7485 Acc: 0.7960\n",
      "test Loss: 0.7104 Acc: 0.8520\n",
      "Epoch 1449/1499\n",
      "----------\n",
      "train Loss: 0.7320 Acc: 0.8164\n",
      "val Loss: 0.7400 Acc: 0.8120\n",
      "test Loss: 0.7165 Acc: 0.8400\n",
      "Epoch 1450/1499\n",
      "----------\n",
      "train Loss: 0.7343 Acc: 0.8127\n",
      "val Loss: 0.7415 Acc: 0.8000\n",
      "test Loss: 0.7156 Acc: 0.8360\n",
      "Epoch 1451/1499\n",
      "----------\n",
      "train Loss: 0.7299 Acc: 0.8149\n",
      "val Loss: 0.7441 Acc: 0.8000\n",
      "test Loss: 0.7239 Acc: 0.8200\n",
      "Epoch 1452/1499\n",
      "----------\n",
      "train Loss: 0.7306 Acc: 0.8193\n",
      "val Loss: 0.7504 Acc: 0.8000\n",
      "test Loss: 0.7170 Acc: 0.8280\n",
      "Epoch 1453/1499\n",
      "----------\n",
      "train Loss: 0.7325 Acc: 0.8156\n",
      "val Loss: 0.7482 Acc: 0.7880\n",
      "test Loss: 0.7202 Acc: 0.8240\n",
      "Epoch 1454/1499\n",
      "----------\n",
      "train Loss: 0.7342 Acc: 0.8156\n",
      "val Loss: 0.7497 Acc: 0.8000\n",
      "test Loss: 0.7148 Acc: 0.8200\n",
      "Epoch 1455/1499\n",
      "----------\n",
      "train Loss: 0.7283 Acc: 0.8189\n",
      "val Loss: 0.7451 Acc: 0.8000\n",
      "test Loss: 0.7113 Acc: 0.8400\n",
      "Epoch 1456/1499\n",
      "----------\n",
      "train Loss: 0.7326 Acc: 0.8120\n",
      "val Loss: 0.7380 Acc: 0.8000\n",
      "test Loss: 0.7269 Acc: 0.8160\n",
      "Epoch 1457/1499\n",
      "----------\n",
      "train Loss: 0.7320 Acc: 0.8173\n",
      "val Loss: 0.7490 Acc: 0.7920\n",
      "test Loss: 0.7247 Acc: 0.8240\n",
      "Epoch 1458/1499\n",
      "----------\n",
      "train Loss: 0.7310 Acc: 0.8144\n",
      "val Loss: 0.7525 Acc: 0.7840\n",
      "test Loss: 0.7160 Acc: 0.8280\n",
      "Epoch 1459/1499\n",
      "----------\n",
      "train Loss: 0.7346 Acc: 0.8118\n",
      "val Loss: 0.7417 Acc: 0.7960\n",
      "test Loss: 0.7232 Acc: 0.8280\n",
      "Epoch 1460/1499\n",
      "----------\n",
      "train Loss: 0.7300 Acc: 0.8198\n",
      "val Loss: 0.7342 Acc: 0.8040\n",
      "test Loss: 0.7299 Acc: 0.8160\n",
      "Epoch 1461/1499\n",
      "----------\n",
      "train Loss: 0.7318 Acc: 0.8176\n",
      "val Loss: 0.7537 Acc: 0.7960\n",
      "test Loss: 0.7229 Acc: 0.8240\n",
      "Epoch 1462/1499\n",
      "----------\n",
      "train Loss: 0.7328 Acc: 0.8162\n",
      "val Loss: 0.7353 Acc: 0.8120\n",
      "test Loss: 0.7148 Acc: 0.8280\n",
      "Epoch 1463/1499\n",
      "----------\n",
      "train Loss: 0.7333 Acc: 0.8142\n",
      "val Loss: 0.7400 Acc: 0.8040\n",
      "test Loss: 0.7178 Acc: 0.8360\n",
      "Epoch 1464/1499\n",
      "----------\n",
      "train Loss: 0.7313 Acc: 0.8169\n",
      "val Loss: 0.7301 Acc: 0.8160\n",
      "test Loss: 0.7222 Acc: 0.8160\n",
      "Epoch 1465/1499\n",
      "----------\n",
      "train Loss: 0.7320 Acc: 0.8127\n",
      "val Loss: 0.7553 Acc: 0.7920\n",
      "test Loss: 0.7304 Acc: 0.8120\n",
      "Epoch 1466/1499\n",
      "----------\n",
      "train Loss: 0.7300 Acc: 0.8173\n",
      "val Loss: 0.7430 Acc: 0.8000\n",
      "test Loss: 0.7102 Acc: 0.8440\n",
      "Epoch 1467/1499\n",
      "----------\n",
      "train Loss: 0.7325 Acc: 0.8127\n",
      "val Loss: 0.7435 Acc: 0.8120\n",
      "test Loss: 0.7278 Acc: 0.8120\n",
      "Epoch 1468/1499\n",
      "----------\n",
      "train Loss: 0.7318 Acc: 0.8144\n",
      "val Loss: 0.7354 Acc: 0.8120\n",
      "test Loss: 0.7200 Acc: 0.8280\n",
      "Epoch 1469/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.7336 Acc: 0.8142\n",
      "val Loss: 0.7444 Acc: 0.7960\n",
      "test Loss: 0.7283 Acc: 0.8160\n",
      "Epoch 1470/1499\n",
      "----------\n",
      "train Loss: 0.7337 Acc: 0.8136\n",
      "val Loss: 0.7493 Acc: 0.7960\n",
      "test Loss: 0.7183 Acc: 0.8480\n",
      "Epoch 1471/1499\n",
      "----------\n",
      "train Loss: 0.7303 Acc: 0.8191\n",
      "val Loss: 0.7349 Acc: 0.8240\n",
      "test Loss: 0.7271 Acc: 0.8200\n",
      "Epoch 1472/1499\n",
      "----------\n",
      "train Loss: 0.7326 Acc: 0.8147\n",
      "val Loss: 0.7376 Acc: 0.8160\n",
      "test Loss: 0.7171 Acc: 0.8400\n",
      "Epoch 1473/1499\n",
      "----------\n",
      "train Loss: 0.7305 Acc: 0.8169\n",
      "val Loss: 0.7493 Acc: 0.7840\n",
      "test Loss: 0.7288 Acc: 0.8120\n",
      "Epoch 1474/1499\n",
      "----------\n",
      "train Loss: 0.7307 Acc: 0.8196\n",
      "val Loss: 0.7466 Acc: 0.7920\n",
      "test Loss: 0.7208 Acc: 0.8320\n",
      "Epoch 1475/1499\n",
      "----------\n",
      "train Loss: 0.7328 Acc: 0.8120\n",
      "val Loss: 0.7493 Acc: 0.8080\n",
      "test Loss: 0.7193 Acc: 0.8360\n",
      "Epoch 1476/1499\n",
      "----------\n",
      "train Loss: 0.7345 Acc: 0.8153\n",
      "val Loss: 0.7367 Acc: 0.8160\n",
      "test Loss: 0.7099 Acc: 0.8440\n",
      "Epoch 1477/1499\n",
      "----------\n",
      "train Loss: 0.7321 Acc: 0.8167\n",
      "val Loss: 0.7475 Acc: 0.7880\n",
      "test Loss: 0.7185 Acc: 0.8160\n",
      "Epoch 1478/1499\n",
      "----------\n",
      "train Loss: 0.7289 Acc: 0.8169\n",
      "val Loss: 0.7460 Acc: 0.7920\n",
      "test Loss: 0.7075 Acc: 0.8400\n",
      "Epoch 1479/1499\n",
      "----------\n",
      "train Loss: 0.7324 Acc: 0.8162\n",
      "val Loss: 0.7414 Acc: 0.8000\n",
      "test Loss: 0.7234 Acc: 0.8360\n",
      "Epoch 1480/1499\n",
      "----------\n",
      "train Loss: 0.7327 Acc: 0.8140\n",
      "val Loss: 0.7334 Acc: 0.8160\n",
      "test Loss: 0.7271 Acc: 0.8160\n",
      "Epoch 1481/1499\n",
      "----------\n",
      "train Loss: 0.7299 Acc: 0.8211\n",
      "val Loss: 0.7486 Acc: 0.8040\n",
      "test Loss: 0.7237 Acc: 0.8240\n",
      "Epoch 1482/1499\n",
      "----------\n",
      "train Loss: 0.7321 Acc: 0.8160\n",
      "val Loss: 0.7418 Acc: 0.8080\n",
      "test Loss: 0.7213 Acc: 0.8240\n",
      "Epoch 1483/1499\n",
      "----------\n",
      "train Loss: 0.7329 Acc: 0.8127\n",
      "val Loss: 0.7501 Acc: 0.7680\n",
      "test Loss: 0.7202 Acc: 0.8240\n",
      "Epoch 1484/1499\n",
      "----------\n",
      "train Loss: 0.7330 Acc: 0.8133\n",
      "val Loss: 0.7401 Acc: 0.7960\n",
      "test Loss: 0.7212 Acc: 0.8280\n",
      "Epoch 1485/1499\n",
      "----------\n",
      "train Loss: 0.7316 Acc: 0.8131\n",
      "val Loss: 0.7542 Acc: 0.7920\n",
      "test Loss: 0.7265 Acc: 0.8320\n",
      "Epoch 1486/1499\n",
      "----------\n",
      "train Loss: 0.7321 Acc: 0.8169\n",
      "val Loss: 0.7422 Acc: 0.7920\n",
      "test Loss: 0.7279 Acc: 0.8080\n",
      "Epoch 1487/1499\n",
      "----------\n",
      "train Loss: 0.7323 Acc: 0.8178\n",
      "val Loss: 0.7411 Acc: 0.8120\n",
      "test Loss: 0.7140 Acc: 0.8280\n",
      "Epoch 1488/1499\n",
      "----------\n",
      "train Loss: 0.7298 Acc: 0.8184\n",
      "val Loss: 0.7390 Acc: 0.8000\n",
      "test Loss: 0.7164 Acc: 0.8320\n",
      "Epoch 1489/1499\n",
      "----------\n",
      "train Loss: 0.7310 Acc: 0.8189\n",
      "val Loss: 0.7378 Acc: 0.8080\n",
      "test Loss: 0.7191 Acc: 0.8120\n",
      "Epoch 1490/1499\n",
      "----------\n",
      "train Loss: 0.7308 Acc: 0.8180\n",
      "val Loss: 0.7419 Acc: 0.7920\n",
      "test Loss: 0.7120 Acc: 0.8320\n",
      "Epoch 1491/1499\n",
      "----------\n",
      "train Loss: 0.7333 Acc: 0.8087\n",
      "val Loss: 0.7492 Acc: 0.7880\n",
      "test Loss: 0.7058 Acc: 0.8360\n",
      "Epoch 1492/1499\n",
      "----------\n",
      "train Loss: 0.7321 Acc: 0.8156\n",
      "val Loss: 0.7426 Acc: 0.8040\n",
      "test Loss: 0.7315 Acc: 0.8280\n",
      "Epoch 1493/1499\n",
      "----------\n",
      "train Loss: 0.7315 Acc: 0.8187\n",
      "val Loss: 0.7357 Acc: 0.8080\n",
      "test Loss: 0.7159 Acc: 0.8440\n",
      "Epoch 1494/1499\n",
      "----------\n",
      "train Loss: 0.7289 Acc: 0.8191\n",
      "val Loss: 0.7392 Acc: 0.8040\n",
      "test Loss: 0.7204 Acc: 0.8280\n",
      "Epoch 1495/1499\n",
      "----------\n",
      "train Loss: 0.7323 Acc: 0.8180\n",
      "val Loss: 0.7417 Acc: 0.7920\n",
      "test Loss: 0.7089 Acc: 0.8440\n",
      "Epoch 1496/1499\n",
      "----------\n",
      "train Loss: 0.7327 Acc: 0.8147\n",
      "val Loss: 0.7351 Acc: 0.8040\n",
      "test Loss: 0.7279 Acc: 0.8240\n",
      "Epoch 1497/1499\n",
      "----------\n",
      "train Loss: 0.7306 Acc: 0.8173\n",
      "val Loss: 0.7412 Acc: 0.8000\n",
      "test Loss: 0.7174 Acc: 0.8320\n",
      "Epoch 1498/1499\n",
      "----------\n",
      "train Loss: 0.7311 Acc: 0.8147\n",
      "val Loss: 0.7502 Acc: 0.7960\n",
      "test Loss: 0.7297 Acc: 0.8280\n",
      "Epoch 1499/1499\n",
      "----------\n",
      "train Loss: 0.7326 Acc: 0.8118\n",
      "val Loss: 0.7411 Acc: 0.8040\n",
      "test Loss: 0.7214 Acc: 0.8240\n",
      "Training complete in 1m 23s\n",
      "Best test Acc: 0.864000\n",
      "Epoch 0/1499\n",
      "----------\n",
      "train Loss: 1.0999 Acc: 0.3329\n",
      "val Loss: 1.1021 Acc: 0.3200\n",
      "test Loss: 1.0981 Acc: 0.3520\n",
      "Epoch 1/1499\n",
      "----------\n",
      "train Loss: 1.0999 Acc: 0.3329\n",
      "val Loss: 1.1026 Acc: 0.3200\n",
      "test Loss: 1.0984 Acc: 0.3520\n",
      "Epoch 2/1499\n",
      "----------\n",
      "train Loss: 1.0998 Acc: 0.3329\n",
      "val Loss: 1.1021 Acc: 0.3200\n",
      "test Loss: 1.0983 Acc: 0.3520\n",
      "Epoch 3/1499\n",
      "----------\n",
      "train Loss: 1.0997 Acc: 0.3329\n",
      "val Loss: 1.1021 Acc: 0.3200\n",
      "test Loss: 1.0984 Acc: 0.3520\n",
      "Epoch 4/1499\n",
      "----------\n",
      "train Loss: 1.0997 Acc: 0.3329\n",
      "val Loss: 1.1021 Acc: 0.3200\n",
      "test Loss: 1.0975 Acc: 0.3520\n",
      "Epoch 5/1499\n",
      "----------\n",
      "train Loss: 1.0994 Acc: 0.3329\n",
      "val Loss: 1.1020 Acc: 0.3200\n",
      "test Loss: 1.0981 Acc: 0.3520\n",
      "Epoch 6/1499\n",
      "----------\n",
      "train Loss: 1.0996 Acc: 0.3329\n",
      "val Loss: 1.1018 Acc: 0.3200\n",
      "test Loss: 1.0980 Acc: 0.3520\n",
      "Epoch 7/1499\n",
      "----------\n",
      "train Loss: 1.0995 Acc: 0.3329\n",
      "val Loss: 1.1016 Acc: 0.3200\n",
      "test Loss: 1.0979 Acc: 0.3520\n",
      "Epoch 8/1499\n",
      "----------\n",
      "train Loss: 1.0994 Acc: 0.3329\n",
      "val Loss: 1.1020 Acc: 0.3200\n",
      "test Loss: 1.0980 Acc: 0.3520\n",
      "Epoch 9/1499\n",
      "----------\n",
      "train Loss: 1.0993 Acc: 0.3329\n",
      "val Loss: 1.1020 Acc: 0.3200\n",
      "test Loss: 1.0974 Acc: 0.3520\n",
      "Epoch 10/1499\n",
      "----------\n",
      "train Loss: 1.0993 Acc: 0.3329\n",
      "val Loss: 1.1015 Acc: 0.3200\n",
      "test Loss: 1.0973 Acc: 0.3520\n",
      "Epoch 11/1499\n",
      "----------\n",
      "train Loss: 1.0992 Acc: 0.3329\n",
      "val Loss: 1.1014 Acc: 0.3200\n",
      "test Loss: 1.0976 Acc: 0.3520\n",
      "Epoch 12/1499\n",
      "----------\n",
      "train Loss: 1.0991 Acc: 0.3329\n",
      "val Loss: 1.1014 Acc: 0.3200\n",
      "test Loss: 1.0976 Acc: 0.3520\n",
      "Epoch 13/1499\n",
      "----------\n",
      "train Loss: 1.0990 Acc: 0.3329\n",
      "val Loss: 1.1011 Acc: 0.3200\n",
      "test Loss: 1.0978 Acc: 0.3520\n",
      "Epoch 14/1499\n",
      "----------\n",
      "train Loss: 1.0990 Acc: 0.3329\n",
      "val Loss: 1.1015 Acc: 0.3200\n",
      "test Loss: 1.0973 Acc: 0.3520\n",
      "Epoch 15/1499\n",
      "----------\n",
      "train Loss: 1.0989 Acc: 0.3329\n",
      "val Loss: 1.1012 Acc: 0.3200\n",
      "test Loss: 1.0972 Acc: 0.3520\n",
      "Epoch 16/1499\n",
      "----------\n",
      "train Loss: 1.0988 Acc: 0.3329\n",
      "val Loss: 1.1013 Acc: 0.3200\n",
      "test Loss: 1.0978 Acc: 0.3520\n",
      "Epoch 17/1499\n",
      "----------\n",
      "train Loss: 1.0987 Acc: 0.3329\n",
      "val Loss: 1.1008 Acc: 0.3200\n",
      "test Loss: 1.0972 Acc: 0.3520\n",
      "Epoch 18/1499\n",
      "----------\n",
      "train Loss: 1.0987 Acc: 0.3329\n",
      "val Loss: 1.1008 Acc: 0.3200\n",
      "test Loss: 1.0970 Acc: 0.3520\n",
      "Epoch 19/1499\n",
      "----------\n",
      "train Loss: 1.0987 Acc: 0.3329\n",
      "val Loss: 1.1006 Acc: 0.3200\n",
      "test Loss: 1.0971 Acc: 0.3520\n",
      "Epoch 20/1499\n",
      "----------\n",
      "train Loss: 1.0986 Acc: 0.3329\n",
      "val Loss: 1.1012 Acc: 0.3200\n",
      "test Loss: 1.0974 Acc: 0.3520\n",
      "Epoch 21/1499\n",
      "----------\n",
      "train Loss: 1.0984 Acc: 0.3329\n",
      "val Loss: 1.1010 Acc: 0.3200\n",
      "test Loss: 1.0971 Acc: 0.3520\n",
      "Epoch 22/1499\n",
      "----------\n",
      "train Loss: 1.0984 Acc: 0.3329\n",
      "val Loss: 1.1006 Acc: 0.3200\n",
      "test Loss: 1.0967 Acc: 0.3520\n",
      "Epoch 23/1499\n",
      "----------\n",
      "train Loss: 1.0984 Acc: 0.3329\n",
      "val Loss: 1.1009 Acc: 0.3200\n",
      "test Loss: 1.0971 Acc: 0.3520\n",
      "Epoch 24/1499\n",
      "----------\n",
      "train Loss: 1.0983 Acc: 0.3329\n",
      "val Loss: 1.1004 Acc: 0.3200\n",
      "test Loss: 1.0967 Acc: 0.3520\n",
      "Epoch 25/1499\n",
      "----------\n",
      "train Loss: 1.0982 Acc: 0.3329\n",
      "val Loss: 1.1002 Acc: 0.3200\n",
      "test Loss: 1.0968 Acc: 0.3520\n",
      "Epoch 26/1499\n",
      "----------\n",
      "train Loss: 1.0980 Acc: 0.3329\n",
      "val Loss: 1.0998 Acc: 0.3200\n",
      "test Loss: 1.0968 Acc: 0.3520\n",
      "Epoch 27/1499\n",
      "----------\n",
      "train Loss: 1.0981 Acc: 0.3329\n",
      "val Loss: 1.0999 Acc: 0.3200\n",
      "test Loss: 1.0969 Acc: 0.3520\n",
      "Epoch 28/1499\n",
      "----------\n",
      "train Loss: 1.0978 Acc: 0.3329\n",
      "val Loss: 1.0998 Acc: 0.3200\n",
      "test Loss: 1.0965 Acc: 0.3520\n",
      "Epoch 29/1499\n",
      "----------\n",
      "train Loss: 1.0977 Acc: 0.3329\n",
      "val Loss: 1.0998 Acc: 0.3200\n",
      "test Loss: 1.0963 Acc: 0.3520\n",
      "Epoch 30/1499\n",
      "----------\n",
      "train Loss: 1.0977 Acc: 0.3329\n",
      "val Loss: 1.0996 Acc: 0.3200\n",
      "test Loss: 1.0959 Acc: 0.3520\n",
      "Epoch 31/1499\n",
      "----------\n",
      "train Loss: 1.0975 Acc: 0.3329\n",
      "val Loss: 1.0995 Acc: 0.3200\n",
      "test Loss: 1.0958 Acc: 0.3520\n",
      "Epoch 32/1499\n",
      "----------\n",
      "train Loss: 1.0974 Acc: 0.3329\n",
      "val Loss: 1.0996 Acc: 0.3200\n",
      "test Loss: 1.0961 Acc: 0.3520\n",
      "Epoch 33/1499\n",
      "----------\n",
      "train Loss: 1.0973 Acc: 0.3329\n",
      "val Loss: 1.0994 Acc: 0.3200\n",
      "test Loss: 1.0956 Acc: 0.3520\n",
      "Epoch 34/1499\n",
      "----------\n",
      "train Loss: 1.0972 Acc: 0.3329\n",
      "val Loss: 1.0997 Acc: 0.3200\n",
      "test Loss: 1.0960 Acc: 0.3520\n",
      "Epoch 35/1499\n",
      "----------\n",
      "train Loss: 1.0970 Acc: 0.3329\n",
      "val Loss: 1.0988 Acc: 0.3200\n",
      "test Loss: 1.0955 Acc: 0.3520\n",
      "Epoch 36/1499\n",
      "----------\n",
      "train Loss: 1.0968 Acc: 0.3329\n",
      "val Loss: 1.0984 Acc: 0.3200\n",
      "test Loss: 1.0954 Acc: 0.3520\n",
      "Epoch 37/1499\n",
      "----------\n",
      "train Loss: 1.0967 Acc: 0.3331\n",
      "val Loss: 1.0991 Acc: 0.3200\n",
      "test Loss: 1.0950 Acc: 0.3520\n",
      "Epoch 38/1499\n",
      "----------\n",
      "train Loss: 1.0965 Acc: 0.3329\n",
      "val Loss: 1.0988 Acc: 0.3200\n",
      "test Loss: 1.0951 Acc: 0.3520\n",
      "Epoch 39/1499\n",
      "----------\n",
      "train Loss: 1.0964 Acc: 0.3329\n",
      "val Loss: 1.0981 Acc: 0.3200\n",
      "test Loss: 1.0954 Acc: 0.3520\n",
      "Epoch 40/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0961 Acc: 0.3329\n",
      "val Loss: 1.0981 Acc: 0.3200\n",
      "test Loss: 1.0945 Acc: 0.3520\n",
      "Epoch 41/1499\n",
      "----------\n",
      "train Loss: 1.0959 Acc: 0.3329\n",
      "val Loss: 1.0979 Acc: 0.3200\n",
      "test Loss: 1.0946 Acc: 0.3520\n",
      "Epoch 42/1499\n",
      "----------\n",
      "train Loss: 1.0958 Acc: 0.3336\n",
      "val Loss: 1.0977 Acc: 0.3200\n",
      "test Loss: 1.0941 Acc: 0.3520\n",
      "Epoch 43/1499\n",
      "----------\n",
      "train Loss: 1.0955 Acc: 0.3331\n",
      "val Loss: 1.0975 Acc: 0.3200\n",
      "test Loss: 1.0940 Acc: 0.3560\n",
      "Epoch 44/1499\n",
      "----------\n",
      "train Loss: 1.0953 Acc: 0.3336\n",
      "val Loss: 1.0973 Acc: 0.3200\n",
      "test Loss: 1.0940 Acc: 0.3520\n",
      "Epoch 45/1499\n",
      "----------\n",
      "train Loss: 1.0949 Acc: 0.3329\n",
      "val Loss: 1.0970 Acc: 0.3200\n",
      "test Loss: 1.0932 Acc: 0.3520\n",
      "Epoch 46/1499\n",
      "----------\n",
      "train Loss: 1.0948 Acc: 0.3331\n",
      "val Loss: 1.0962 Acc: 0.3200\n",
      "test Loss: 1.0935 Acc: 0.3520\n",
      "Epoch 47/1499\n",
      "----------\n",
      "train Loss: 1.0944 Acc: 0.3333\n",
      "val Loss: 1.0968 Acc: 0.3200\n",
      "test Loss: 1.0927 Acc: 0.3560\n",
      "Epoch 48/1499\n",
      "----------\n",
      "train Loss: 1.0942 Acc: 0.3336\n",
      "val Loss: 1.0962 Acc: 0.3200\n",
      "test Loss: 1.0930 Acc: 0.3560\n",
      "Epoch 49/1499\n",
      "----------\n",
      "train Loss: 1.0941 Acc: 0.3329\n",
      "val Loss: 1.0963 Acc: 0.3200\n",
      "test Loss: 1.0923 Acc: 0.3520\n",
      "Epoch 50/1499\n",
      "----------\n",
      "train Loss: 1.0938 Acc: 0.3338\n",
      "val Loss: 1.0952 Acc: 0.3200\n",
      "test Loss: 1.0918 Acc: 0.3640\n",
      "Epoch 51/1499\n",
      "----------\n",
      "train Loss: 1.0934 Acc: 0.3338\n",
      "val Loss: 1.0957 Acc: 0.3200\n",
      "test Loss: 1.0917 Acc: 0.3520\n",
      "Epoch 52/1499\n",
      "----------\n",
      "train Loss: 1.0930 Acc: 0.3353\n",
      "val Loss: 1.0941 Acc: 0.3200\n",
      "test Loss: 1.0915 Acc: 0.3600\n",
      "Epoch 53/1499\n",
      "----------\n",
      "train Loss: 1.0927 Acc: 0.3362\n",
      "val Loss: 1.0940 Acc: 0.3240\n",
      "test Loss: 1.0906 Acc: 0.3560\n",
      "Epoch 54/1499\n",
      "----------\n",
      "train Loss: 1.0923 Acc: 0.3369\n",
      "val Loss: 1.0947 Acc: 0.3200\n",
      "test Loss: 1.0900 Acc: 0.3640\n",
      "Epoch 55/1499\n",
      "----------\n",
      "train Loss: 1.0918 Acc: 0.3376\n",
      "val Loss: 1.0931 Acc: 0.3240\n",
      "test Loss: 1.0903 Acc: 0.3680\n",
      "Epoch 56/1499\n",
      "----------\n",
      "train Loss: 1.0915 Acc: 0.3422\n",
      "val Loss: 1.0935 Acc: 0.3240\n",
      "test Loss: 1.0893 Acc: 0.3760\n",
      "Epoch 57/1499\n",
      "----------\n",
      "train Loss: 1.0910 Acc: 0.3469\n",
      "val Loss: 1.0927 Acc: 0.3280\n",
      "test Loss: 1.0890 Acc: 0.3840\n",
      "Epoch 58/1499\n",
      "----------\n",
      "train Loss: 1.0904 Acc: 0.3500\n",
      "val Loss: 1.0921 Acc: 0.3360\n",
      "test Loss: 1.0883 Acc: 0.3880\n",
      "Epoch 59/1499\n",
      "----------\n",
      "train Loss: 1.0901 Acc: 0.3578\n",
      "val Loss: 1.0917 Acc: 0.3440\n",
      "test Loss: 1.0876 Acc: 0.4000\n",
      "Epoch 60/1499\n",
      "----------\n",
      "train Loss: 1.0894 Acc: 0.3642\n",
      "val Loss: 1.0905 Acc: 0.3480\n",
      "test Loss: 1.0876 Acc: 0.4120\n",
      "Epoch 61/1499\n",
      "----------\n",
      "train Loss: 1.0890 Acc: 0.3682\n",
      "val Loss: 1.0906 Acc: 0.3560\n",
      "test Loss: 1.0866 Acc: 0.4120\n",
      "Epoch 62/1499\n",
      "----------\n",
      "train Loss: 1.0885 Acc: 0.3771\n",
      "val Loss: 1.0914 Acc: 0.3520\n",
      "test Loss: 1.0856 Acc: 0.4080\n",
      "Epoch 63/1499\n",
      "----------\n",
      "train Loss: 1.0878 Acc: 0.3844\n",
      "val Loss: 1.0895 Acc: 0.3640\n",
      "test Loss: 1.0853 Acc: 0.4160\n",
      "Epoch 64/1499\n",
      "----------\n",
      "train Loss: 1.0873 Acc: 0.3896\n",
      "val Loss: 1.0884 Acc: 0.3720\n",
      "test Loss: 1.0849 Acc: 0.4280\n",
      "Epoch 65/1499\n",
      "----------\n",
      "train Loss: 1.0865 Acc: 0.3927\n",
      "val Loss: 1.0887 Acc: 0.3680\n",
      "test Loss: 1.0844 Acc: 0.4240\n",
      "Epoch 66/1499\n",
      "----------\n",
      "train Loss: 1.0857 Acc: 0.3958\n",
      "val Loss: 1.0876 Acc: 0.3560\n",
      "test Loss: 1.0832 Acc: 0.4200\n",
      "Epoch 67/1499\n",
      "----------\n",
      "train Loss: 1.0851 Acc: 0.4013\n",
      "val Loss: 1.0873 Acc: 0.3680\n",
      "test Loss: 1.0819 Acc: 0.4320\n",
      "Epoch 68/1499\n",
      "----------\n",
      "train Loss: 1.0844 Acc: 0.4056\n",
      "val Loss: 1.0861 Acc: 0.3680\n",
      "test Loss: 1.0811 Acc: 0.4240\n",
      "Epoch 69/1499\n",
      "----------\n",
      "train Loss: 1.0836 Acc: 0.4044\n",
      "val Loss: 1.0856 Acc: 0.3680\n",
      "test Loss: 1.0810 Acc: 0.4280\n",
      "Epoch 70/1499\n",
      "----------\n",
      "train Loss: 1.0829 Acc: 0.4096\n",
      "val Loss: 1.0846 Acc: 0.3720\n",
      "test Loss: 1.0799 Acc: 0.4280\n",
      "Epoch 71/1499\n",
      "----------\n",
      "train Loss: 1.0820 Acc: 0.4149\n",
      "val Loss: 1.0845 Acc: 0.3760\n",
      "test Loss: 1.0795 Acc: 0.4400\n",
      "Epoch 72/1499\n",
      "----------\n",
      "train Loss: 1.0812 Acc: 0.4147\n",
      "val Loss: 1.0840 Acc: 0.3720\n",
      "test Loss: 1.0782 Acc: 0.4400\n",
      "Epoch 73/1499\n",
      "----------\n",
      "train Loss: 1.0806 Acc: 0.4202\n",
      "val Loss: 1.0829 Acc: 0.3800\n",
      "test Loss: 1.0778 Acc: 0.4240\n",
      "Epoch 74/1499\n",
      "----------\n",
      "train Loss: 1.0798 Acc: 0.4144\n",
      "val Loss: 1.0823 Acc: 0.3760\n",
      "test Loss: 1.0766 Acc: 0.4360\n",
      "Epoch 75/1499\n",
      "----------\n",
      "train Loss: 1.0788 Acc: 0.4204\n",
      "val Loss: 1.0813 Acc: 0.3720\n",
      "test Loss: 1.0747 Acc: 0.4440\n",
      "Epoch 76/1499\n",
      "----------\n",
      "train Loss: 1.0779 Acc: 0.4218\n",
      "val Loss: 1.0796 Acc: 0.3760\n",
      "test Loss: 1.0749 Acc: 0.4360\n",
      "Epoch 77/1499\n",
      "----------\n",
      "train Loss: 1.0769 Acc: 0.4253\n",
      "val Loss: 1.0793 Acc: 0.3680\n",
      "test Loss: 1.0742 Acc: 0.4560\n",
      "Epoch 78/1499\n",
      "----------\n",
      "train Loss: 1.0760 Acc: 0.4211\n",
      "val Loss: 1.0789 Acc: 0.3800\n",
      "test Loss: 1.0723 Acc: 0.4680\n",
      "Epoch 79/1499\n",
      "----------\n",
      "train Loss: 1.0750 Acc: 0.4233\n",
      "val Loss: 1.0774 Acc: 0.3840\n",
      "test Loss: 1.0715 Acc: 0.4600\n",
      "Epoch 80/1499\n",
      "----------\n",
      "train Loss: 1.0739 Acc: 0.4271\n",
      "val Loss: 1.0766 Acc: 0.3800\n",
      "test Loss: 1.0695 Acc: 0.4720\n",
      "Epoch 81/1499\n",
      "----------\n",
      "train Loss: 1.0729 Acc: 0.4291\n",
      "val Loss: 1.0755 Acc: 0.3880\n",
      "test Loss: 1.0693 Acc: 0.4640\n",
      "Epoch 82/1499\n",
      "----------\n",
      "train Loss: 1.0719 Acc: 0.4271\n",
      "val Loss: 1.0743 Acc: 0.3960\n",
      "test Loss: 1.0677 Acc: 0.4720\n",
      "Epoch 83/1499\n",
      "----------\n",
      "train Loss: 1.0709 Acc: 0.4278\n",
      "val Loss: 1.0730 Acc: 0.3880\n",
      "test Loss: 1.0671 Acc: 0.4640\n",
      "Epoch 84/1499\n",
      "----------\n",
      "train Loss: 1.0696 Acc: 0.4320\n",
      "val Loss: 1.0714 Acc: 0.3800\n",
      "test Loss: 1.0663 Acc: 0.4680\n",
      "Epoch 85/1499\n",
      "----------\n",
      "train Loss: 1.0684 Acc: 0.4316\n",
      "val Loss: 1.0703 Acc: 0.3920\n",
      "test Loss: 1.0634 Acc: 0.4720\n",
      "Epoch 86/1499\n",
      "----------\n",
      "train Loss: 1.0672 Acc: 0.4347\n",
      "val Loss: 1.0697 Acc: 0.4040\n",
      "test Loss: 1.0625 Acc: 0.4600\n",
      "Epoch 87/1499\n",
      "----------\n",
      "train Loss: 1.0660 Acc: 0.4287\n",
      "val Loss: 1.0681 Acc: 0.3960\n",
      "test Loss: 1.0606 Acc: 0.4760\n",
      "Epoch 88/1499\n",
      "----------\n",
      "train Loss: 1.0645 Acc: 0.4318\n",
      "val Loss: 1.0676 Acc: 0.4080\n",
      "test Loss: 1.0601 Acc: 0.4720\n",
      "Epoch 89/1499\n",
      "----------\n",
      "train Loss: 1.0632 Acc: 0.4342\n",
      "val Loss: 1.0649 Acc: 0.3960\n",
      "test Loss: 1.0581 Acc: 0.4560\n",
      "Epoch 90/1499\n",
      "----------\n",
      "train Loss: 1.0621 Acc: 0.4329\n",
      "val Loss: 1.0645 Acc: 0.3880\n",
      "test Loss: 1.0558 Acc: 0.4760\n",
      "Epoch 91/1499\n",
      "----------\n",
      "train Loss: 1.0602 Acc: 0.4351\n",
      "val Loss: 1.0636 Acc: 0.4080\n",
      "test Loss: 1.0559 Acc: 0.4800\n",
      "Epoch 92/1499\n",
      "----------\n",
      "train Loss: 1.0590 Acc: 0.4380\n",
      "val Loss: 1.0613 Acc: 0.4000\n",
      "test Loss: 1.0533 Acc: 0.4760\n",
      "Epoch 93/1499\n",
      "----------\n",
      "train Loss: 1.0577 Acc: 0.4369\n",
      "val Loss: 1.0601 Acc: 0.4040\n",
      "test Loss: 1.0508 Acc: 0.4800\n",
      "Epoch 94/1499\n",
      "----------\n",
      "train Loss: 1.0559 Acc: 0.4380\n",
      "val Loss: 1.0588 Acc: 0.4080\n",
      "test Loss: 1.0506 Acc: 0.4840\n",
      "Epoch 95/1499\n",
      "----------\n",
      "train Loss: 1.0544 Acc: 0.4440\n",
      "val Loss: 1.0563 Acc: 0.4040\n",
      "test Loss: 1.0493 Acc: 0.4640\n",
      "Epoch 96/1499\n",
      "----------\n",
      "train Loss: 1.0529 Acc: 0.4438\n",
      "val Loss: 1.0564 Acc: 0.4040\n",
      "test Loss: 1.0469 Acc: 0.4920\n",
      "Epoch 97/1499\n",
      "----------\n",
      "train Loss: 1.0511 Acc: 0.4453\n",
      "val Loss: 1.0558 Acc: 0.4200\n",
      "test Loss: 1.0456 Acc: 0.4720\n",
      "Epoch 98/1499\n",
      "----------\n",
      "train Loss: 1.0499 Acc: 0.4547\n",
      "val Loss: 1.0516 Acc: 0.4120\n",
      "test Loss: 1.0426 Acc: 0.4880\n",
      "Epoch 99/1499\n",
      "----------\n",
      "train Loss: 1.0478 Acc: 0.4760\n",
      "val Loss: 1.0501 Acc: 0.4280\n",
      "test Loss: 1.0417 Acc: 0.5240\n",
      "Epoch 100/1499\n",
      "----------\n",
      "train Loss: 1.0459 Acc: 0.4987\n",
      "val Loss: 1.0475 Acc: 0.4840\n",
      "test Loss: 1.0396 Acc: 0.5240\n",
      "Epoch 101/1499\n",
      "----------\n",
      "train Loss: 1.0448 Acc: 0.5162\n",
      "val Loss: 1.0482 Acc: 0.4640\n",
      "test Loss: 1.0366 Acc: 0.5560\n",
      "Epoch 102/1499\n",
      "----------\n",
      "train Loss: 1.0424 Acc: 0.5418\n",
      "val Loss: 1.0455 Acc: 0.5000\n",
      "test Loss: 1.0347 Acc: 0.5800\n",
      "Epoch 103/1499\n",
      "----------\n",
      "train Loss: 1.0412 Acc: 0.5462\n",
      "val Loss: 1.0441 Acc: 0.5120\n",
      "test Loss: 1.0335 Acc: 0.6200\n",
      "Epoch 104/1499\n",
      "----------\n",
      "train Loss: 1.0391 Acc: 0.5624\n",
      "val Loss: 1.0423 Acc: 0.4920\n",
      "test Loss: 1.0322 Acc: 0.6080\n",
      "Epoch 105/1499\n",
      "----------\n",
      "train Loss: 1.0374 Acc: 0.5731\n",
      "val Loss: 1.0429 Acc: 0.5000\n",
      "test Loss: 1.0300 Acc: 0.5960\n",
      "Epoch 106/1499\n",
      "----------\n",
      "train Loss: 1.0346 Acc: 0.5887\n",
      "val Loss: 1.0379 Acc: 0.5160\n",
      "test Loss: 1.0280 Acc: 0.6240\n",
      "Epoch 107/1499\n",
      "----------\n",
      "train Loss: 1.0332 Acc: 0.5804\n",
      "val Loss: 1.0351 Acc: 0.5400\n",
      "test Loss: 1.0267 Acc: 0.5920\n",
      "Epoch 108/1499\n",
      "----------\n",
      "train Loss: 1.0307 Acc: 0.5933\n",
      "val Loss: 1.0342 Acc: 0.5400\n",
      "test Loss: 1.0225 Acc: 0.6200\n",
      "Epoch 109/1499\n",
      "----------\n",
      "train Loss: 1.0290 Acc: 0.6009\n",
      "val Loss: 1.0341 Acc: 0.5200\n",
      "test Loss: 1.0192 Acc: 0.6480\n",
      "Epoch 110/1499\n",
      "----------\n",
      "train Loss: 1.0262 Acc: 0.6029\n",
      "val Loss: 1.0306 Acc: 0.5440\n",
      "test Loss: 1.0155 Acc: 0.6600\n",
      "Epoch 111/1499\n",
      "----------\n",
      "train Loss: 1.0248 Acc: 0.6040\n",
      "val Loss: 1.0310 Acc: 0.5400\n",
      "test Loss: 1.0156 Acc: 0.6680\n",
      "Epoch 112/1499\n",
      "----------\n",
      "train Loss: 1.0234 Acc: 0.6071\n",
      "val Loss: 1.0278 Acc: 0.5480\n",
      "test Loss: 1.0171 Acc: 0.6400\n",
      "Epoch 113/1499\n",
      "----------\n",
      "train Loss: 1.0202 Acc: 0.6120\n",
      "val Loss: 1.0258 Acc: 0.5440\n",
      "test Loss: 1.0100 Acc: 0.6600\n",
      "Epoch 114/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0183 Acc: 0.6184\n",
      "val Loss: 1.0221 Acc: 0.5320\n",
      "test Loss: 1.0124 Acc: 0.6520\n",
      "Epoch 115/1499\n",
      "----------\n",
      "train Loss: 1.0160 Acc: 0.6256\n",
      "val Loss: 1.0220 Acc: 0.5680\n",
      "test Loss: 1.0068 Acc: 0.6640\n",
      "Epoch 116/1499\n",
      "----------\n",
      "train Loss: 1.0138 Acc: 0.6260\n",
      "val Loss: 1.0187 Acc: 0.5560\n",
      "test Loss: 1.0048 Acc: 0.6880\n",
      "Epoch 117/1499\n",
      "----------\n",
      "train Loss: 1.0112 Acc: 0.6264\n",
      "val Loss: 1.0177 Acc: 0.5680\n",
      "test Loss: 1.0008 Acc: 0.6920\n",
      "Epoch 118/1499\n",
      "----------\n",
      "train Loss: 1.0092 Acc: 0.6307\n",
      "val Loss: 1.0135 Acc: 0.5960\n",
      "test Loss: 0.9984 Acc: 0.6760\n",
      "Epoch 119/1499\n",
      "----------\n",
      "train Loss: 1.0067 Acc: 0.6269\n",
      "val Loss: 1.0121 Acc: 0.5640\n",
      "test Loss: 0.9960 Acc: 0.6840\n",
      "Epoch 120/1499\n",
      "----------\n",
      "train Loss: 1.0039 Acc: 0.6351\n",
      "val Loss: 1.0092 Acc: 0.5760\n",
      "test Loss: 0.9937 Acc: 0.7040\n",
      "Epoch 121/1499\n",
      "----------\n",
      "train Loss: 1.0026 Acc: 0.6429\n",
      "val Loss: 1.0063 Acc: 0.5920\n",
      "test Loss: 0.9912 Acc: 0.7040\n",
      "Epoch 122/1499\n",
      "----------\n",
      "train Loss: 1.0000 Acc: 0.6447\n",
      "val Loss: 1.0049 Acc: 0.5800\n",
      "test Loss: 0.9908 Acc: 0.6960\n",
      "Epoch 123/1499\n",
      "----------\n",
      "train Loss: 0.9968 Acc: 0.6529\n",
      "val Loss: 1.0034 Acc: 0.5840\n",
      "test Loss: 0.9861 Acc: 0.7040\n",
      "Epoch 124/1499\n",
      "----------\n",
      "train Loss: 0.9950 Acc: 0.6538\n",
      "val Loss: 1.0000 Acc: 0.6000\n",
      "test Loss: 0.9836 Acc: 0.7080\n",
      "Epoch 125/1499\n",
      "----------\n",
      "train Loss: 0.9919 Acc: 0.6598\n",
      "val Loss: 0.9992 Acc: 0.6360\n",
      "test Loss: 0.9813 Acc: 0.7000\n",
      "Epoch 126/1499\n",
      "----------\n",
      "train Loss: 0.9894 Acc: 0.6600\n",
      "val Loss: 0.9936 Acc: 0.6160\n",
      "test Loss: 0.9776 Acc: 0.7080\n",
      "Epoch 127/1499\n",
      "----------\n",
      "train Loss: 0.9872 Acc: 0.6651\n",
      "val Loss: 0.9926 Acc: 0.6200\n",
      "test Loss: 0.9763 Acc: 0.7080\n",
      "Epoch 128/1499\n",
      "----------\n",
      "train Loss: 0.9848 Acc: 0.6738\n",
      "val Loss: 0.9916 Acc: 0.5920\n",
      "test Loss: 0.9749 Acc: 0.7040\n",
      "Epoch 129/1499\n",
      "----------\n",
      "train Loss: 0.9824 Acc: 0.6673\n",
      "val Loss: 0.9861 Acc: 0.6320\n",
      "test Loss: 0.9750 Acc: 0.7000\n",
      "Epoch 130/1499\n",
      "----------\n",
      "train Loss: 0.9799 Acc: 0.6773\n",
      "val Loss: 0.9864 Acc: 0.6400\n",
      "test Loss: 0.9665 Acc: 0.7240\n",
      "Epoch 131/1499\n",
      "----------\n",
      "train Loss: 0.9779 Acc: 0.6927\n",
      "val Loss: 0.9846 Acc: 0.6480\n",
      "test Loss: 0.9619 Acc: 0.7440\n",
      "Epoch 132/1499\n",
      "----------\n",
      "train Loss: 0.9745 Acc: 0.6993\n",
      "val Loss: 0.9802 Acc: 0.6640\n",
      "test Loss: 0.9602 Acc: 0.7480\n",
      "Epoch 133/1499\n",
      "----------\n",
      "train Loss: 0.9715 Acc: 0.7051\n",
      "val Loss: 0.9777 Acc: 0.6520\n",
      "test Loss: 0.9613 Acc: 0.7200\n",
      "Epoch 134/1499\n",
      "----------\n",
      "train Loss: 0.9701 Acc: 0.7144\n",
      "val Loss: 0.9762 Acc: 0.6560\n",
      "test Loss: 0.9580 Acc: 0.7600\n",
      "Epoch 135/1499\n",
      "----------\n",
      "train Loss: 0.9668 Acc: 0.7122\n",
      "val Loss: 0.9730 Acc: 0.6680\n",
      "test Loss: 0.9523 Acc: 0.7600\n",
      "Epoch 136/1499\n",
      "----------\n",
      "train Loss: 0.9642 Acc: 0.7191\n",
      "val Loss: 0.9716 Acc: 0.6920\n",
      "test Loss: 0.9556 Acc: 0.7440\n",
      "Epoch 137/1499\n",
      "----------\n",
      "train Loss: 0.9613 Acc: 0.7260\n",
      "val Loss: 0.9640 Acc: 0.7080\n",
      "test Loss: 0.9495 Acc: 0.7920\n",
      "Epoch 138/1499\n",
      "----------\n",
      "train Loss: 0.9597 Acc: 0.7296\n",
      "val Loss: 0.9659 Acc: 0.7040\n",
      "test Loss: 0.9476 Acc: 0.7760\n",
      "Epoch 139/1499\n",
      "----------\n",
      "train Loss: 0.9560 Acc: 0.7336\n",
      "val Loss: 0.9659 Acc: 0.6800\n",
      "test Loss: 0.9478 Acc: 0.7680\n",
      "Epoch 140/1499\n",
      "----------\n",
      "train Loss: 0.9534 Acc: 0.7351\n",
      "val Loss: 0.9609 Acc: 0.6800\n",
      "test Loss: 0.9460 Acc: 0.7480\n",
      "Epoch 141/1499\n",
      "----------\n",
      "train Loss: 0.9506 Acc: 0.7440\n",
      "val Loss: 0.9578 Acc: 0.7160\n",
      "test Loss: 0.9382 Acc: 0.7840\n",
      "Epoch 142/1499\n",
      "----------\n",
      "train Loss: 0.9483 Acc: 0.7449\n",
      "val Loss: 0.9550 Acc: 0.7120\n",
      "test Loss: 0.9294 Acc: 0.8040\n",
      "Epoch 143/1499\n",
      "----------\n",
      "train Loss: 0.9456 Acc: 0.7487\n",
      "val Loss: 0.9505 Acc: 0.7280\n",
      "test Loss: 0.9309 Acc: 0.7800\n",
      "Epoch 144/1499\n",
      "----------\n",
      "train Loss: 0.9435 Acc: 0.7449\n",
      "val Loss: 0.9551 Acc: 0.7000\n",
      "test Loss: 0.9316 Acc: 0.7840\n",
      "Epoch 145/1499\n",
      "----------\n",
      "train Loss: 0.9403 Acc: 0.7509\n",
      "val Loss: 0.9499 Acc: 0.7000\n",
      "test Loss: 0.9272 Acc: 0.7920\n",
      "Epoch 146/1499\n",
      "----------\n",
      "train Loss: 0.9379 Acc: 0.7600\n",
      "val Loss: 0.9479 Acc: 0.6960\n",
      "test Loss: 0.9227 Acc: 0.8000\n",
      "Epoch 147/1499\n",
      "----------\n",
      "train Loss: 0.9351 Acc: 0.7633\n",
      "val Loss: 0.9409 Acc: 0.7440\n",
      "test Loss: 0.9240 Acc: 0.7880\n",
      "Epoch 148/1499\n",
      "----------\n",
      "train Loss: 0.9321 Acc: 0.7647\n",
      "val Loss: 0.9447 Acc: 0.7240\n",
      "test Loss: 0.9180 Acc: 0.8000\n",
      "Epoch 149/1499\n",
      "----------\n",
      "train Loss: 0.9294 Acc: 0.7693\n",
      "val Loss: 0.9428 Acc: 0.7440\n",
      "test Loss: 0.9127 Acc: 0.8040\n",
      "Epoch 150/1499\n",
      "----------\n",
      "train Loss: 0.9273 Acc: 0.7689\n",
      "val Loss: 0.9351 Acc: 0.7320\n",
      "test Loss: 0.9116 Acc: 0.7960\n",
      "Epoch 151/1499\n",
      "----------\n",
      "train Loss: 0.9240 Acc: 0.7729\n",
      "val Loss: 0.9285 Acc: 0.7400\n",
      "test Loss: 0.9096 Acc: 0.8040\n",
      "Epoch 152/1499\n",
      "----------\n",
      "train Loss: 0.9195 Acc: 0.7749\n",
      "val Loss: 0.9256 Acc: 0.7480\n",
      "test Loss: 0.9036 Acc: 0.8320\n",
      "Epoch 153/1499\n",
      "----------\n",
      "train Loss: 0.9171 Acc: 0.7787\n",
      "val Loss: 0.9297 Acc: 0.7280\n",
      "test Loss: 0.9038 Acc: 0.8040\n",
      "Epoch 154/1499\n",
      "----------\n",
      "train Loss: 0.9141 Acc: 0.7809\n",
      "val Loss: 0.9242 Acc: 0.7200\n",
      "test Loss: 0.9028 Acc: 0.7880\n",
      "Epoch 155/1499\n",
      "----------\n",
      "train Loss: 0.9103 Acc: 0.7873\n",
      "val Loss: 0.9240 Acc: 0.7440\n",
      "test Loss: 0.8988 Acc: 0.8080\n",
      "Epoch 156/1499\n",
      "----------\n",
      "train Loss: 0.9079 Acc: 0.7882\n",
      "val Loss: 0.9197 Acc: 0.7480\n",
      "test Loss: 0.8941 Acc: 0.8200\n",
      "Epoch 157/1499\n",
      "----------\n",
      "train Loss: 0.9045 Acc: 0.7844\n",
      "val Loss: 0.9193 Acc: 0.7760\n",
      "test Loss: 0.8927 Acc: 0.8160\n",
      "Epoch 158/1499\n",
      "----------\n",
      "train Loss: 0.9007 Acc: 0.7893\n",
      "val Loss: 0.9129 Acc: 0.7480\n",
      "test Loss: 0.8829 Acc: 0.8240\n",
      "Epoch 159/1499\n",
      "----------\n",
      "train Loss: 0.8981 Acc: 0.7933\n",
      "val Loss: 0.9076 Acc: 0.7560\n",
      "test Loss: 0.8833 Acc: 0.8160\n",
      "Epoch 160/1499\n",
      "----------\n",
      "train Loss: 0.8943 Acc: 0.7976\n",
      "val Loss: 0.9068 Acc: 0.7720\n",
      "test Loss: 0.8817 Acc: 0.8120\n",
      "Epoch 161/1499\n",
      "----------\n",
      "train Loss: 0.8925 Acc: 0.7996\n",
      "val Loss: 0.9086 Acc: 0.7680\n",
      "test Loss: 0.8729 Acc: 0.8320\n",
      "Epoch 162/1499\n",
      "----------\n",
      "train Loss: 0.8891 Acc: 0.8011\n",
      "val Loss: 0.8951 Acc: 0.7560\n",
      "test Loss: 0.8680 Acc: 0.8360\n",
      "Epoch 163/1499\n",
      "----------\n",
      "train Loss: 0.8859 Acc: 0.7940\n",
      "val Loss: 0.8979 Acc: 0.7400\n",
      "test Loss: 0.8699 Acc: 0.8240\n",
      "Epoch 164/1499\n",
      "----------\n",
      "train Loss: 0.8826 Acc: 0.7958\n",
      "val Loss: 0.8925 Acc: 0.7840\n",
      "test Loss: 0.8605 Acc: 0.8240\n",
      "Epoch 165/1499\n",
      "----------\n",
      "train Loss: 0.8796 Acc: 0.8011\n",
      "val Loss: 0.8848 Acc: 0.7760\n",
      "test Loss: 0.8647 Acc: 0.8320\n",
      "Epoch 166/1499\n",
      "----------\n",
      "train Loss: 0.8761 Acc: 0.8027\n",
      "val Loss: 0.8920 Acc: 0.7640\n",
      "test Loss: 0.8605 Acc: 0.8280\n",
      "Epoch 167/1499\n",
      "----------\n",
      "train Loss: 0.8723 Acc: 0.8022\n",
      "val Loss: 0.8794 Acc: 0.7800\n",
      "test Loss: 0.8554 Acc: 0.8480\n",
      "Epoch 168/1499\n",
      "----------\n",
      "train Loss: 0.8706 Acc: 0.8024\n",
      "val Loss: 0.8782 Acc: 0.7600\n",
      "test Loss: 0.8542 Acc: 0.8480\n",
      "Epoch 169/1499\n",
      "----------\n",
      "train Loss: 0.8661 Acc: 0.8107\n",
      "val Loss: 0.8687 Acc: 0.7840\n",
      "test Loss: 0.8477 Acc: 0.8480\n",
      "Epoch 170/1499\n",
      "----------\n",
      "train Loss: 0.8628 Acc: 0.8076\n",
      "val Loss: 0.8789 Acc: 0.7720\n",
      "test Loss: 0.8477 Acc: 0.8480\n",
      "Epoch 171/1499\n",
      "----------\n",
      "train Loss: 0.8598 Acc: 0.8093\n",
      "val Loss: 0.8716 Acc: 0.7680\n",
      "test Loss: 0.8476 Acc: 0.8400\n",
      "Epoch 172/1499\n",
      "----------\n",
      "train Loss: 0.8566 Acc: 0.8111\n",
      "val Loss: 0.8748 Acc: 0.7840\n",
      "test Loss: 0.8380 Acc: 0.8200\n",
      "Epoch 173/1499\n",
      "----------\n",
      "train Loss: 0.8535 Acc: 0.8107\n",
      "val Loss: 0.8578 Acc: 0.7840\n",
      "test Loss: 0.8397 Acc: 0.8400\n",
      "Epoch 174/1499\n",
      "----------\n",
      "train Loss: 0.8492 Acc: 0.8176\n",
      "val Loss: 0.8610 Acc: 0.7720\n",
      "test Loss: 0.8317 Acc: 0.8320\n",
      "Epoch 175/1499\n",
      "----------\n",
      "train Loss: 0.8463 Acc: 0.8158\n",
      "val Loss: 0.8612 Acc: 0.8040\n",
      "test Loss: 0.8247 Acc: 0.8440\n",
      "Epoch 176/1499\n",
      "----------\n",
      "train Loss: 0.8436 Acc: 0.8189\n",
      "val Loss: 0.8538 Acc: 0.8120\n",
      "test Loss: 0.8237 Acc: 0.8360\n",
      "Epoch 177/1499\n",
      "----------\n",
      "train Loss: 0.8409 Acc: 0.8202\n",
      "val Loss: 0.8532 Acc: 0.8000\n",
      "test Loss: 0.8243 Acc: 0.8320\n",
      "Epoch 178/1499\n",
      "----------\n",
      "train Loss: 0.8346 Acc: 0.8224\n",
      "val Loss: 0.8483 Acc: 0.8160\n",
      "test Loss: 0.8165 Acc: 0.8480\n",
      "Epoch 179/1499\n",
      "----------\n",
      "train Loss: 0.8326 Acc: 0.8269\n",
      "val Loss: 0.8465 Acc: 0.8120\n",
      "test Loss: 0.8171 Acc: 0.8520\n",
      "Epoch 180/1499\n",
      "----------\n",
      "train Loss: 0.8313 Acc: 0.8216\n",
      "val Loss: 0.8475 Acc: 0.7800\n",
      "test Loss: 0.8179 Acc: 0.8440\n",
      "Epoch 181/1499\n",
      "----------\n",
      "train Loss: 0.8256 Acc: 0.8280\n",
      "val Loss: 0.8377 Acc: 0.8000\n",
      "test Loss: 0.8147 Acc: 0.8480\n",
      "Epoch 182/1499\n",
      "----------\n",
      "train Loss: 0.8245 Acc: 0.8296\n",
      "val Loss: 0.8371 Acc: 0.7920\n",
      "test Loss: 0.8098 Acc: 0.8520\n",
      "Epoch 183/1499\n",
      "----------\n",
      "train Loss: 0.8213 Acc: 0.8296\n",
      "val Loss: 0.8322 Acc: 0.8040\n",
      "test Loss: 0.8052 Acc: 0.8440\n",
      "Epoch 184/1499\n",
      "----------\n",
      "train Loss: 0.8186 Acc: 0.8251\n",
      "val Loss: 0.8328 Acc: 0.7920\n",
      "test Loss: 0.8000 Acc: 0.8480\n",
      "Epoch 185/1499\n",
      "----------\n",
      "train Loss: 0.8158 Acc: 0.8287\n",
      "val Loss: 0.8301 Acc: 0.7760\n",
      "test Loss: 0.7962 Acc: 0.8520\n",
      "Epoch 186/1499\n",
      "----------\n",
      "train Loss: 0.8136 Acc: 0.8342\n",
      "val Loss: 0.8208 Acc: 0.8120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.8028 Acc: 0.8480\n",
      "Epoch 187/1499\n",
      "----------\n",
      "train Loss: 0.8081 Acc: 0.8398\n",
      "val Loss: 0.8208 Acc: 0.8160\n",
      "test Loss: 0.8004 Acc: 0.8400\n",
      "Epoch 188/1499\n",
      "----------\n",
      "train Loss: 0.8062 Acc: 0.8376\n",
      "val Loss: 0.8166 Acc: 0.8320\n",
      "test Loss: 0.7948 Acc: 0.8400\n",
      "Epoch 189/1499\n",
      "----------\n",
      "train Loss: 0.8035 Acc: 0.8391\n",
      "val Loss: 0.8031 Acc: 0.8080\n",
      "test Loss: 0.7879 Acc: 0.8560\n",
      "Epoch 190/1499\n",
      "----------\n",
      "train Loss: 0.8001 Acc: 0.8387\n",
      "val Loss: 0.8110 Acc: 0.8200\n",
      "test Loss: 0.7800 Acc: 0.8720\n",
      "Epoch 191/1499\n",
      "----------\n",
      "train Loss: 0.7967 Acc: 0.8404\n",
      "val Loss: 0.8106 Acc: 0.8160\n",
      "test Loss: 0.7827 Acc: 0.8560\n",
      "Epoch 192/1499\n",
      "----------\n",
      "train Loss: 0.7938 Acc: 0.8413\n",
      "val Loss: 0.7941 Acc: 0.8520\n",
      "test Loss: 0.7849 Acc: 0.8560\n",
      "Epoch 193/1499\n",
      "----------\n",
      "train Loss: 0.7922 Acc: 0.8471\n",
      "val Loss: 0.8076 Acc: 0.8200\n",
      "test Loss: 0.7785 Acc: 0.8520\n",
      "Epoch 194/1499\n",
      "----------\n",
      "train Loss: 0.7902 Acc: 0.8420\n",
      "val Loss: 0.8009 Acc: 0.8280\n",
      "test Loss: 0.7659 Acc: 0.8760\n",
      "Epoch 195/1499\n",
      "----------\n",
      "train Loss: 0.7853 Acc: 0.8424\n",
      "val Loss: 0.7883 Acc: 0.8480\n",
      "test Loss: 0.7749 Acc: 0.8800\n",
      "Epoch 196/1499\n",
      "----------\n",
      "train Loss: 0.7828 Acc: 0.8447\n",
      "val Loss: 0.7900 Acc: 0.8320\n",
      "test Loss: 0.7787 Acc: 0.8600\n",
      "Epoch 197/1499\n",
      "----------\n",
      "train Loss: 0.7823 Acc: 0.8418\n",
      "val Loss: 0.7892 Acc: 0.8480\n",
      "test Loss: 0.7803 Acc: 0.8480\n",
      "Epoch 198/1499\n",
      "----------\n",
      "train Loss: 0.7783 Acc: 0.8453\n",
      "val Loss: 0.7848 Acc: 0.8480\n",
      "test Loss: 0.7714 Acc: 0.8680\n",
      "Epoch 199/1499\n",
      "----------\n",
      "train Loss: 0.7771 Acc: 0.8440\n",
      "val Loss: 0.7814 Acc: 0.8320\n",
      "test Loss: 0.7675 Acc: 0.8600\n",
      "Epoch 200/1499\n",
      "----------\n",
      "train Loss: 0.7727 Acc: 0.8487\n",
      "val Loss: 0.7822 Acc: 0.8360\n",
      "test Loss: 0.7626 Acc: 0.8640\n",
      "Epoch 201/1499\n",
      "----------\n",
      "train Loss: 0.7699 Acc: 0.8484\n",
      "val Loss: 0.7835 Acc: 0.8280\n",
      "test Loss: 0.7575 Acc: 0.8720\n",
      "Epoch 202/1499\n",
      "----------\n",
      "train Loss: 0.7679 Acc: 0.8478\n",
      "val Loss: 0.7691 Acc: 0.8280\n",
      "test Loss: 0.7625 Acc: 0.8680\n",
      "Epoch 203/1499\n",
      "----------\n",
      "train Loss: 0.7653 Acc: 0.8482\n",
      "val Loss: 0.7731 Acc: 0.8360\n",
      "test Loss: 0.7507 Acc: 0.8760\n",
      "Epoch 204/1499\n",
      "----------\n",
      "train Loss: 0.7649 Acc: 0.8453\n",
      "val Loss: 0.7707 Acc: 0.8400\n",
      "test Loss: 0.7508 Acc: 0.8640\n",
      "Epoch 205/1499\n",
      "----------\n",
      "train Loss: 0.7603 Acc: 0.8480\n",
      "val Loss: 0.7653 Acc: 0.8480\n",
      "test Loss: 0.7576 Acc: 0.8640\n",
      "Epoch 206/1499\n",
      "----------\n",
      "train Loss: 0.7566 Acc: 0.8529\n",
      "val Loss: 0.7672 Acc: 0.8440\n",
      "test Loss: 0.7535 Acc: 0.8640\n",
      "Epoch 207/1499\n",
      "----------\n",
      "train Loss: 0.7591 Acc: 0.8507\n",
      "val Loss: 0.7543 Acc: 0.8520\n",
      "test Loss: 0.7471 Acc: 0.8560\n",
      "Epoch 208/1499\n",
      "----------\n",
      "train Loss: 0.7551 Acc: 0.8496\n",
      "val Loss: 0.7623 Acc: 0.8360\n",
      "test Loss: 0.7474 Acc: 0.8640\n",
      "Epoch 209/1499\n",
      "----------\n",
      "train Loss: 0.7539 Acc: 0.8536\n",
      "val Loss: 0.7582 Acc: 0.8480\n",
      "test Loss: 0.7407 Acc: 0.8680\n",
      "Epoch 210/1499\n",
      "----------\n",
      "train Loss: 0.7487 Acc: 0.8549\n",
      "val Loss: 0.7545 Acc: 0.8520\n",
      "test Loss: 0.7441 Acc: 0.8600\n",
      "Epoch 211/1499\n",
      "----------\n",
      "train Loss: 0.7466 Acc: 0.8582\n",
      "val Loss: 0.7610 Acc: 0.8360\n",
      "test Loss: 0.7393 Acc: 0.8680\n",
      "Epoch 212/1499\n",
      "----------\n",
      "train Loss: 0.7454 Acc: 0.8507\n",
      "val Loss: 0.7565 Acc: 0.8280\n",
      "test Loss: 0.7343 Acc: 0.8680\n",
      "Epoch 213/1499\n",
      "----------\n",
      "train Loss: 0.7450 Acc: 0.8524\n",
      "val Loss: 0.7515 Acc: 0.8560\n",
      "test Loss: 0.7351 Acc: 0.8520\n",
      "Epoch 214/1499\n",
      "----------\n",
      "train Loss: 0.7444 Acc: 0.8553\n",
      "val Loss: 0.7487 Acc: 0.8520\n",
      "test Loss: 0.7387 Acc: 0.8440\n",
      "Epoch 215/1499\n",
      "----------\n",
      "train Loss: 0.7413 Acc: 0.8562\n",
      "val Loss: 0.7545 Acc: 0.8440\n",
      "test Loss: 0.7291 Acc: 0.8720\n",
      "Epoch 216/1499\n",
      "----------\n",
      "train Loss: 0.7385 Acc: 0.8531\n",
      "val Loss: 0.7483 Acc: 0.8480\n",
      "test Loss: 0.7290 Acc: 0.8720\n",
      "Epoch 217/1499\n",
      "----------\n",
      "train Loss: 0.7382 Acc: 0.8544\n",
      "val Loss: 0.7425 Acc: 0.8560\n",
      "test Loss: 0.7312 Acc: 0.8680\n",
      "Epoch 218/1499\n",
      "----------\n",
      "train Loss: 0.7359 Acc: 0.8576\n",
      "val Loss: 0.7323 Acc: 0.8600\n",
      "test Loss: 0.7335 Acc: 0.8680\n",
      "Epoch 219/1499\n",
      "----------\n",
      "train Loss: 0.7326 Acc: 0.8542\n",
      "val Loss: 0.7373 Acc: 0.8480\n",
      "test Loss: 0.7245 Acc: 0.8680\n",
      "Epoch 220/1499\n",
      "----------\n",
      "train Loss: 0.7337 Acc: 0.8529\n",
      "val Loss: 0.7413 Acc: 0.8600\n",
      "test Loss: 0.7270 Acc: 0.8680\n",
      "Epoch 221/1499\n",
      "----------\n",
      "train Loss: 0.7306 Acc: 0.8611\n",
      "val Loss: 0.7412 Acc: 0.8240\n",
      "test Loss: 0.7220 Acc: 0.8560\n",
      "Epoch 222/1499\n",
      "----------\n",
      "train Loss: 0.7303 Acc: 0.8580\n",
      "val Loss: 0.7346 Acc: 0.8600\n",
      "test Loss: 0.7245 Acc: 0.8520\n",
      "Epoch 223/1499\n",
      "----------\n",
      "train Loss: 0.7274 Acc: 0.8576\n",
      "val Loss: 0.7367 Acc: 0.8360\n",
      "test Loss: 0.7200 Acc: 0.8520\n",
      "Epoch 224/1499\n",
      "----------\n",
      "train Loss: 0.7259 Acc: 0.8609\n",
      "val Loss: 0.7423 Acc: 0.8440\n",
      "test Loss: 0.7281 Acc: 0.8480\n",
      "Epoch 225/1499\n",
      "----------\n",
      "train Loss: 0.7256 Acc: 0.8573\n",
      "val Loss: 0.7236 Acc: 0.8480\n",
      "test Loss: 0.7145 Acc: 0.8640\n",
      "Epoch 226/1499\n",
      "----------\n",
      "train Loss: 0.7233 Acc: 0.8582\n",
      "val Loss: 0.7214 Acc: 0.8600\n",
      "test Loss: 0.7198 Acc: 0.8680\n",
      "Epoch 227/1499\n",
      "----------\n",
      "train Loss: 0.7224 Acc: 0.8593\n",
      "val Loss: 0.7251 Acc: 0.8680\n",
      "test Loss: 0.7186 Acc: 0.8560\n",
      "Epoch 228/1499\n",
      "----------\n",
      "train Loss: 0.7227 Acc: 0.8573\n",
      "val Loss: 0.7269 Acc: 0.8440\n",
      "test Loss: 0.7127 Acc: 0.8760\n",
      "Epoch 229/1499\n",
      "----------\n",
      "train Loss: 0.7186 Acc: 0.8631\n",
      "val Loss: 0.7338 Acc: 0.8520\n",
      "test Loss: 0.7107 Acc: 0.8760\n",
      "Epoch 230/1499\n",
      "----------\n",
      "train Loss: 0.7205 Acc: 0.8587\n",
      "val Loss: 0.7303 Acc: 0.8480\n",
      "test Loss: 0.7105 Acc: 0.8680\n",
      "Epoch 231/1499\n",
      "----------\n",
      "train Loss: 0.7171 Acc: 0.8607\n",
      "val Loss: 0.7176 Acc: 0.8520\n",
      "test Loss: 0.7102 Acc: 0.8640\n",
      "Epoch 232/1499\n",
      "----------\n",
      "train Loss: 0.7153 Acc: 0.8624\n",
      "val Loss: 0.7201 Acc: 0.8520\n",
      "test Loss: 0.7063 Acc: 0.8640\n",
      "Epoch 233/1499\n",
      "----------\n",
      "train Loss: 0.7145 Acc: 0.8611\n",
      "val Loss: 0.7208 Acc: 0.8480\n",
      "test Loss: 0.7083 Acc: 0.8560\n",
      "Epoch 234/1499\n",
      "----------\n",
      "train Loss: 0.7126 Acc: 0.8651\n",
      "val Loss: 0.7153 Acc: 0.8720\n",
      "test Loss: 0.7102 Acc: 0.8640\n",
      "Epoch 235/1499\n",
      "----------\n",
      "train Loss: 0.7139 Acc: 0.8620\n",
      "val Loss: 0.7183 Acc: 0.8640\n",
      "test Loss: 0.7124 Acc: 0.8520\n",
      "Epoch 236/1499\n",
      "----------\n",
      "train Loss: 0.7129 Acc: 0.8644\n",
      "val Loss: 0.7264 Acc: 0.8480\n",
      "test Loss: 0.7050 Acc: 0.8720\n",
      "Epoch 237/1499\n",
      "----------\n",
      "train Loss: 0.7115 Acc: 0.8638\n",
      "val Loss: 0.7119 Acc: 0.8640\n",
      "test Loss: 0.7012 Acc: 0.8680\n",
      "Epoch 238/1499\n",
      "----------\n",
      "train Loss: 0.7092 Acc: 0.8667\n",
      "val Loss: 0.7125 Acc: 0.8520\n",
      "test Loss: 0.7049 Acc: 0.8720\n",
      "Epoch 239/1499\n",
      "----------\n",
      "train Loss: 0.7068 Acc: 0.8658\n",
      "val Loss: 0.7171 Acc: 0.8560\n",
      "test Loss: 0.7035 Acc: 0.8800\n",
      "Epoch 240/1499\n",
      "----------\n",
      "train Loss: 0.7091 Acc: 0.8647\n",
      "val Loss: 0.7162 Acc: 0.8600\n",
      "test Loss: 0.7046 Acc: 0.8720\n",
      "Epoch 241/1499\n",
      "----------\n",
      "train Loss: 0.7080 Acc: 0.8636\n",
      "val Loss: 0.7152 Acc: 0.8520\n",
      "test Loss: 0.7006 Acc: 0.8840\n",
      "Epoch 242/1499\n",
      "----------\n",
      "train Loss: 0.7057 Acc: 0.8682\n",
      "val Loss: 0.7144 Acc: 0.8600\n",
      "test Loss: 0.7170 Acc: 0.8640\n",
      "Epoch 243/1499\n",
      "----------\n",
      "train Loss: 0.7049 Acc: 0.8707\n",
      "val Loss: 0.7076 Acc: 0.8680\n",
      "test Loss: 0.7033 Acc: 0.8720\n",
      "Epoch 244/1499\n",
      "----------\n",
      "train Loss: 0.7052 Acc: 0.8682\n",
      "val Loss: 0.7041 Acc: 0.8760\n",
      "test Loss: 0.6961 Acc: 0.8680\n",
      "Epoch 245/1499\n",
      "----------\n",
      "train Loss: 0.7049 Acc: 0.8669\n",
      "val Loss: 0.7023 Acc: 0.8680\n",
      "test Loss: 0.7006 Acc: 0.8720\n",
      "Epoch 246/1499\n",
      "----------\n",
      "train Loss: 0.7016 Acc: 0.8720\n",
      "val Loss: 0.7137 Acc: 0.8480\n",
      "test Loss: 0.6979 Acc: 0.8680\n",
      "Epoch 247/1499\n",
      "----------\n",
      "train Loss: 0.7026 Acc: 0.8698\n",
      "val Loss: 0.7036 Acc: 0.8800\n",
      "test Loss: 0.6954 Acc: 0.8760\n",
      "Epoch 248/1499\n",
      "----------\n",
      "train Loss: 0.6994 Acc: 0.8720\n",
      "val Loss: 0.6958 Acc: 0.8760\n",
      "test Loss: 0.7024 Acc: 0.8640\n",
      "Epoch 249/1499\n",
      "----------\n",
      "train Loss: 0.6991 Acc: 0.8702\n",
      "val Loss: 0.7145 Acc: 0.8640\n",
      "test Loss: 0.6900 Acc: 0.8760\n",
      "Epoch 250/1499\n",
      "----------\n",
      "train Loss: 0.7017 Acc: 0.8667\n",
      "val Loss: 0.6989 Acc: 0.8760\n",
      "test Loss: 0.7004 Acc: 0.8720\n",
      "Epoch 251/1499\n",
      "----------\n",
      "train Loss: 0.6992 Acc: 0.8684\n",
      "val Loss: 0.7042 Acc: 0.8640\n",
      "test Loss: 0.6938 Acc: 0.8800\n",
      "Epoch 252/1499\n",
      "----------\n",
      "train Loss: 0.6970 Acc: 0.8727\n",
      "val Loss: 0.7058 Acc: 0.8680\n",
      "test Loss: 0.6876 Acc: 0.9040\n",
      "Epoch 253/1499\n",
      "----------\n",
      "train Loss: 0.6971 Acc: 0.8691\n",
      "val Loss: 0.7071 Acc: 0.8640\n",
      "test Loss: 0.7009 Acc: 0.8520\n",
      "Epoch 254/1499\n",
      "----------\n",
      "train Loss: 0.6967 Acc: 0.8671\n",
      "val Loss: 0.6989 Acc: 0.8640\n",
      "test Loss: 0.6953 Acc: 0.8600\n",
      "Epoch 255/1499\n",
      "----------\n",
      "train Loss: 0.6964 Acc: 0.8711\n",
      "val Loss: 0.7008 Acc: 0.8640\n",
      "test Loss: 0.6962 Acc: 0.8680\n",
      "Epoch 256/1499\n",
      "----------\n",
      "train Loss: 0.6958 Acc: 0.8711\n",
      "val Loss: 0.7015 Acc: 0.8560\n",
      "test Loss: 0.6887 Acc: 0.8760\n",
      "Epoch 257/1499\n",
      "----------\n",
      "train Loss: 0.6953 Acc: 0.8716\n",
      "val Loss: 0.6993 Acc: 0.8720\n",
      "test Loss: 0.6880 Acc: 0.8800\n",
      "Epoch 258/1499\n",
      "----------\n",
      "train Loss: 0.6945 Acc: 0.8716\n",
      "val Loss: 0.6972 Acc: 0.8640\n",
      "test Loss: 0.6887 Acc: 0.8800\n",
      "Epoch 259/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6938 Acc: 0.8727\n",
      "val Loss: 0.7107 Acc: 0.8560\n",
      "test Loss: 0.6920 Acc: 0.8640\n",
      "Epoch 260/1499\n",
      "----------\n",
      "train Loss: 0.6937 Acc: 0.8716\n",
      "val Loss: 0.6982 Acc: 0.8720\n",
      "test Loss: 0.6954 Acc: 0.8720\n",
      "Epoch 261/1499\n",
      "----------\n",
      "train Loss: 0.6936 Acc: 0.8713\n",
      "val Loss: 0.6934 Acc: 0.8720\n",
      "test Loss: 0.6947 Acc: 0.8800\n",
      "Epoch 262/1499\n",
      "----------\n",
      "train Loss: 0.6918 Acc: 0.8713\n",
      "val Loss: 0.6965 Acc: 0.8680\n",
      "test Loss: 0.6925 Acc: 0.8800\n",
      "Epoch 263/1499\n",
      "----------\n",
      "train Loss: 0.6912 Acc: 0.8733\n",
      "val Loss: 0.7001 Acc: 0.8760\n",
      "test Loss: 0.6965 Acc: 0.8680\n",
      "Epoch 264/1499\n",
      "----------\n",
      "train Loss: 0.6924 Acc: 0.8716\n",
      "val Loss: 0.6937 Acc: 0.8760\n",
      "test Loss: 0.6904 Acc: 0.8840\n",
      "Epoch 265/1499\n",
      "----------\n",
      "train Loss: 0.6900 Acc: 0.8740\n",
      "val Loss: 0.7026 Acc: 0.8520\n",
      "test Loss: 0.6919 Acc: 0.8720\n",
      "Epoch 266/1499\n",
      "----------\n",
      "train Loss: 0.6889 Acc: 0.8769\n",
      "val Loss: 0.6956 Acc: 0.8600\n",
      "test Loss: 0.6912 Acc: 0.8800\n",
      "Epoch 267/1499\n",
      "----------\n",
      "train Loss: 0.6905 Acc: 0.8704\n",
      "val Loss: 0.6957 Acc: 0.8560\n",
      "test Loss: 0.6952 Acc: 0.8800\n",
      "Epoch 268/1499\n",
      "----------\n",
      "train Loss: 0.6893 Acc: 0.8749\n",
      "val Loss: 0.6957 Acc: 0.8560\n",
      "test Loss: 0.6855 Acc: 0.8880\n",
      "Epoch 269/1499\n",
      "----------\n",
      "train Loss: 0.6909 Acc: 0.8731\n",
      "val Loss: 0.6955 Acc: 0.8720\n",
      "test Loss: 0.6888 Acc: 0.8800\n",
      "Epoch 270/1499\n",
      "----------\n",
      "train Loss: 0.6875 Acc: 0.8751\n",
      "val Loss: 0.6890 Acc: 0.8800\n",
      "test Loss: 0.6866 Acc: 0.8800\n",
      "Epoch 271/1499\n",
      "----------\n",
      "train Loss: 0.6885 Acc: 0.8762\n",
      "val Loss: 0.7037 Acc: 0.8480\n",
      "test Loss: 0.6883 Acc: 0.8680\n",
      "Epoch 272/1499\n",
      "----------\n",
      "train Loss: 0.6889 Acc: 0.8740\n",
      "val Loss: 0.6938 Acc: 0.8600\n",
      "test Loss: 0.6825 Acc: 0.8840\n",
      "Epoch 273/1499\n",
      "----------\n",
      "train Loss: 0.6876 Acc: 0.8742\n",
      "val Loss: 0.6942 Acc: 0.8720\n",
      "test Loss: 0.6835 Acc: 0.8840\n",
      "Epoch 274/1499\n",
      "----------\n",
      "train Loss: 0.6884 Acc: 0.8740\n",
      "val Loss: 0.7015 Acc: 0.8560\n",
      "test Loss: 0.6921 Acc: 0.8720\n",
      "Epoch 275/1499\n",
      "----------\n",
      "train Loss: 0.6850 Acc: 0.8793\n",
      "val Loss: 0.6948 Acc: 0.8760\n",
      "test Loss: 0.6812 Acc: 0.8840\n",
      "Epoch 276/1499\n",
      "----------\n",
      "train Loss: 0.6856 Acc: 0.8744\n",
      "val Loss: 0.6921 Acc: 0.8680\n",
      "test Loss: 0.6818 Acc: 0.8880\n",
      "Epoch 277/1499\n",
      "----------\n",
      "train Loss: 0.6859 Acc: 0.8720\n",
      "val Loss: 0.6927 Acc: 0.8720\n",
      "test Loss: 0.6827 Acc: 0.8880\n",
      "Epoch 278/1499\n",
      "----------\n",
      "train Loss: 0.6845 Acc: 0.8767\n",
      "val Loss: 0.6868 Acc: 0.8720\n",
      "test Loss: 0.6770 Acc: 0.8880\n",
      "Epoch 279/1499\n",
      "----------\n",
      "train Loss: 0.6856 Acc: 0.8749\n",
      "val Loss: 0.6900 Acc: 0.8640\n",
      "test Loss: 0.6802 Acc: 0.8920\n",
      "Epoch 280/1499\n",
      "----------\n",
      "train Loss: 0.6848 Acc: 0.8758\n",
      "val Loss: 0.6884 Acc: 0.8720\n",
      "test Loss: 0.6796 Acc: 0.8800\n",
      "Epoch 281/1499\n",
      "----------\n",
      "train Loss: 0.6840 Acc: 0.8787\n",
      "val Loss: 0.6951 Acc: 0.8560\n",
      "test Loss: 0.6813 Acc: 0.8840\n",
      "Epoch 282/1499\n",
      "----------\n",
      "train Loss: 0.6840 Acc: 0.8782\n",
      "val Loss: 0.6864 Acc: 0.8640\n",
      "test Loss: 0.6767 Acc: 0.8920\n",
      "Epoch 283/1499\n",
      "----------\n",
      "train Loss: 0.6839 Acc: 0.8778\n",
      "val Loss: 0.6849 Acc: 0.8520\n",
      "test Loss: 0.6834 Acc: 0.8880\n",
      "Epoch 284/1499\n",
      "----------\n",
      "train Loss: 0.6842 Acc: 0.8769\n",
      "val Loss: 0.6934 Acc: 0.8680\n",
      "test Loss: 0.6843 Acc: 0.8760\n",
      "Epoch 285/1499\n",
      "----------\n",
      "train Loss: 0.6813 Acc: 0.8789\n",
      "val Loss: 0.6900 Acc: 0.8680\n",
      "test Loss: 0.6873 Acc: 0.8760\n",
      "Epoch 286/1499\n",
      "----------\n",
      "train Loss: 0.6828 Acc: 0.8764\n",
      "val Loss: 0.6859 Acc: 0.8560\n",
      "test Loss: 0.6788 Acc: 0.8880\n",
      "Epoch 287/1499\n",
      "----------\n",
      "train Loss: 0.6811 Acc: 0.8793\n",
      "val Loss: 0.6907 Acc: 0.8600\n",
      "test Loss: 0.6737 Acc: 0.8960\n",
      "Epoch 288/1499\n",
      "----------\n",
      "train Loss: 0.6832 Acc: 0.8764\n",
      "val Loss: 0.6956 Acc: 0.8520\n",
      "test Loss: 0.6806 Acc: 0.8920\n",
      "Epoch 289/1499\n",
      "----------\n",
      "train Loss: 0.6821 Acc: 0.8778\n",
      "val Loss: 0.6858 Acc: 0.8640\n",
      "test Loss: 0.6841 Acc: 0.8800\n",
      "Epoch 290/1499\n",
      "----------\n",
      "train Loss: 0.6809 Acc: 0.8811\n",
      "val Loss: 0.6923 Acc: 0.8640\n",
      "test Loss: 0.6800 Acc: 0.8920\n",
      "Epoch 291/1499\n",
      "----------\n",
      "train Loss: 0.6826 Acc: 0.8747\n",
      "val Loss: 0.6840 Acc: 0.8640\n",
      "test Loss: 0.6778 Acc: 0.8840\n",
      "Epoch 292/1499\n",
      "----------\n",
      "train Loss: 0.6820 Acc: 0.8769\n",
      "val Loss: 0.6819 Acc: 0.8680\n",
      "test Loss: 0.6814 Acc: 0.8880\n",
      "Epoch 293/1499\n",
      "----------\n",
      "train Loss: 0.6806 Acc: 0.8778\n",
      "val Loss: 0.6798 Acc: 0.8760\n",
      "test Loss: 0.6769 Acc: 0.8880\n",
      "Epoch 294/1499\n",
      "----------\n",
      "train Loss: 0.6816 Acc: 0.8753\n",
      "val Loss: 0.6834 Acc: 0.8600\n",
      "test Loss: 0.6790 Acc: 0.8800\n",
      "Epoch 295/1499\n",
      "----------\n",
      "train Loss: 0.6791 Acc: 0.8787\n",
      "val Loss: 0.6808 Acc: 0.8680\n",
      "test Loss: 0.6782 Acc: 0.8960\n",
      "Epoch 296/1499\n",
      "----------\n",
      "train Loss: 0.6787 Acc: 0.8789\n",
      "val Loss: 0.6829 Acc: 0.8760\n",
      "test Loss: 0.6787 Acc: 0.8840\n",
      "Epoch 297/1499\n",
      "----------\n",
      "train Loss: 0.6771 Acc: 0.8818\n",
      "val Loss: 0.6918 Acc: 0.8640\n",
      "test Loss: 0.6751 Acc: 0.8920\n",
      "Epoch 298/1499\n",
      "----------\n",
      "train Loss: 0.6809 Acc: 0.8751\n",
      "val Loss: 0.6806 Acc: 0.8720\n",
      "test Loss: 0.6733 Acc: 0.9000\n",
      "Epoch 299/1499\n",
      "----------\n",
      "train Loss: 0.6789 Acc: 0.8793\n",
      "val Loss: 0.6921 Acc: 0.8600\n",
      "test Loss: 0.6767 Acc: 0.8920\n",
      "Epoch 300/1499\n",
      "----------\n",
      "train Loss: 0.6798 Acc: 0.8809\n",
      "val Loss: 0.6800 Acc: 0.8640\n",
      "test Loss: 0.6783 Acc: 0.8880\n",
      "Epoch 301/1499\n",
      "----------\n",
      "train Loss: 0.6792 Acc: 0.8796\n",
      "val Loss: 0.6795 Acc: 0.8680\n",
      "test Loss: 0.6781 Acc: 0.8880\n",
      "Epoch 302/1499\n",
      "----------\n",
      "train Loss: 0.6800 Acc: 0.8769\n",
      "val Loss: 0.6792 Acc: 0.8680\n",
      "test Loss: 0.6828 Acc: 0.8880\n",
      "Epoch 303/1499\n",
      "----------\n",
      "train Loss: 0.6789 Acc: 0.8798\n",
      "val Loss: 0.6914 Acc: 0.8600\n",
      "test Loss: 0.6788 Acc: 0.8880\n",
      "Epoch 304/1499\n",
      "----------\n",
      "train Loss: 0.6783 Acc: 0.8804\n",
      "val Loss: 0.6881 Acc: 0.8600\n",
      "test Loss: 0.6826 Acc: 0.8800\n",
      "Epoch 305/1499\n",
      "----------\n",
      "train Loss: 0.6769 Acc: 0.8778\n",
      "val Loss: 0.6910 Acc: 0.8600\n",
      "test Loss: 0.6836 Acc: 0.8840\n",
      "Epoch 306/1499\n",
      "----------\n",
      "train Loss: 0.6774 Acc: 0.8796\n",
      "val Loss: 0.6839 Acc: 0.8680\n",
      "test Loss: 0.6756 Acc: 0.8840\n",
      "Epoch 307/1499\n",
      "----------\n",
      "train Loss: 0.6779 Acc: 0.8762\n",
      "val Loss: 0.6796 Acc: 0.8720\n",
      "test Loss: 0.6785 Acc: 0.8840\n",
      "Epoch 308/1499\n",
      "----------\n",
      "train Loss: 0.6785 Acc: 0.8784\n",
      "val Loss: 0.6809 Acc: 0.8560\n",
      "test Loss: 0.6765 Acc: 0.8920\n",
      "Epoch 309/1499\n",
      "----------\n",
      "train Loss: 0.6765 Acc: 0.8820\n",
      "val Loss: 0.6833 Acc: 0.8800\n",
      "test Loss: 0.6742 Acc: 0.9000\n",
      "Epoch 310/1499\n",
      "----------\n",
      "train Loss: 0.6769 Acc: 0.8800\n",
      "val Loss: 0.6841 Acc: 0.8720\n",
      "test Loss: 0.6686 Acc: 0.8960\n",
      "Epoch 311/1499\n",
      "----------\n",
      "train Loss: 0.6771 Acc: 0.8800\n",
      "val Loss: 0.6874 Acc: 0.8680\n",
      "test Loss: 0.6733 Acc: 0.8920\n",
      "Epoch 312/1499\n",
      "----------\n",
      "train Loss: 0.6777 Acc: 0.8809\n",
      "val Loss: 0.6886 Acc: 0.8720\n",
      "test Loss: 0.6805 Acc: 0.8880\n",
      "Epoch 313/1499\n",
      "----------\n",
      "train Loss: 0.6756 Acc: 0.8829\n",
      "val Loss: 0.6900 Acc: 0.8560\n",
      "test Loss: 0.6775 Acc: 0.8880\n",
      "Epoch 314/1499\n",
      "----------\n",
      "train Loss: 0.6741 Acc: 0.8836\n",
      "val Loss: 0.6864 Acc: 0.8600\n",
      "test Loss: 0.6766 Acc: 0.8880\n",
      "Epoch 315/1499\n",
      "----------\n",
      "train Loss: 0.6773 Acc: 0.8791\n",
      "val Loss: 0.6790 Acc: 0.8600\n",
      "test Loss: 0.6755 Acc: 0.8960\n",
      "Epoch 316/1499\n",
      "----------\n",
      "train Loss: 0.6761 Acc: 0.8807\n",
      "val Loss: 0.6810 Acc: 0.8760\n",
      "test Loss: 0.6808 Acc: 0.8920\n",
      "Epoch 317/1499\n",
      "----------\n",
      "train Loss: 0.6739 Acc: 0.8822\n",
      "val Loss: 0.6926 Acc: 0.8560\n",
      "test Loss: 0.6775 Acc: 0.8800\n",
      "Epoch 318/1499\n",
      "----------\n",
      "train Loss: 0.6754 Acc: 0.8849\n",
      "val Loss: 0.6827 Acc: 0.8720\n",
      "test Loss: 0.6674 Acc: 0.8960\n",
      "Epoch 319/1499\n",
      "----------\n",
      "train Loss: 0.6754 Acc: 0.8802\n",
      "val Loss: 0.6846 Acc: 0.8680\n",
      "test Loss: 0.6779 Acc: 0.8880\n",
      "Epoch 320/1499\n",
      "----------\n",
      "train Loss: 0.6744 Acc: 0.8813\n",
      "val Loss: 0.6844 Acc: 0.8640\n",
      "test Loss: 0.6707 Acc: 0.8880\n",
      "Epoch 321/1499\n",
      "----------\n",
      "train Loss: 0.6746 Acc: 0.8809\n",
      "val Loss: 0.6808 Acc: 0.8680\n",
      "test Loss: 0.6700 Acc: 0.8920\n",
      "Epoch 322/1499\n",
      "----------\n",
      "train Loss: 0.6747 Acc: 0.8822\n",
      "val Loss: 0.6850 Acc: 0.8760\n",
      "test Loss: 0.6739 Acc: 0.8840\n",
      "Epoch 323/1499\n",
      "----------\n",
      "train Loss: 0.6767 Acc: 0.8771\n",
      "val Loss: 0.6792 Acc: 0.8680\n",
      "test Loss: 0.6751 Acc: 0.8840\n",
      "Epoch 324/1499\n",
      "----------\n",
      "train Loss: 0.6756 Acc: 0.8800\n",
      "val Loss: 0.6810 Acc: 0.8640\n",
      "test Loss: 0.6695 Acc: 0.9000\n",
      "Epoch 325/1499\n",
      "----------\n",
      "train Loss: 0.6731 Acc: 0.8816\n",
      "val Loss: 0.6786 Acc: 0.8680\n",
      "test Loss: 0.6771 Acc: 0.8840\n",
      "Epoch 326/1499\n",
      "----------\n",
      "train Loss: 0.6725 Acc: 0.8829\n",
      "val Loss: 0.6792 Acc: 0.8680\n",
      "test Loss: 0.6677 Acc: 0.9000\n",
      "Epoch 327/1499\n",
      "----------\n",
      "train Loss: 0.6733 Acc: 0.8833\n",
      "val Loss: 0.6841 Acc: 0.8720\n",
      "test Loss: 0.6755 Acc: 0.8800\n",
      "Epoch 328/1499\n",
      "----------\n",
      "train Loss: 0.6724 Acc: 0.8840\n",
      "val Loss: 0.6788 Acc: 0.8760\n",
      "test Loss: 0.6749 Acc: 0.8800\n",
      "Epoch 329/1499\n",
      "----------\n",
      "train Loss: 0.6725 Acc: 0.8833\n",
      "val Loss: 0.6715 Acc: 0.8760\n",
      "test Loss: 0.6754 Acc: 0.8920\n",
      "Epoch 330/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6720 Acc: 0.8856\n",
      "val Loss: 0.6806 Acc: 0.8680\n",
      "test Loss: 0.6773 Acc: 0.8840\n",
      "Epoch 331/1499\n",
      "----------\n",
      "train Loss: 0.6734 Acc: 0.8804\n",
      "val Loss: 0.6799 Acc: 0.8720\n",
      "test Loss: 0.6760 Acc: 0.8920\n",
      "Epoch 332/1499\n",
      "----------\n",
      "train Loss: 0.6734 Acc: 0.8804\n",
      "val Loss: 0.6782 Acc: 0.8800\n",
      "test Loss: 0.6714 Acc: 0.8960\n",
      "Epoch 333/1499\n",
      "----------\n",
      "train Loss: 0.6727 Acc: 0.8858\n",
      "val Loss: 0.6769 Acc: 0.8720\n",
      "test Loss: 0.6705 Acc: 0.8920\n",
      "Epoch 334/1499\n",
      "----------\n",
      "train Loss: 0.6739 Acc: 0.8820\n",
      "val Loss: 0.6803 Acc: 0.8800\n",
      "test Loss: 0.6717 Acc: 0.8960\n",
      "Epoch 335/1499\n",
      "----------\n",
      "train Loss: 0.6709 Acc: 0.8831\n",
      "val Loss: 0.6751 Acc: 0.8800\n",
      "test Loss: 0.6719 Acc: 0.8880\n",
      "Epoch 336/1499\n",
      "----------\n",
      "train Loss: 0.6714 Acc: 0.8847\n",
      "val Loss: 0.6805 Acc: 0.8720\n",
      "test Loss: 0.6709 Acc: 0.8880\n",
      "Epoch 337/1499\n",
      "----------\n",
      "train Loss: 0.6716 Acc: 0.8844\n",
      "val Loss: 0.6749 Acc: 0.8760\n",
      "test Loss: 0.6698 Acc: 0.8880\n",
      "Epoch 338/1499\n",
      "----------\n",
      "train Loss: 0.6716 Acc: 0.8836\n",
      "val Loss: 0.6700 Acc: 0.8880\n",
      "test Loss: 0.6681 Acc: 0.8920\n",
      "Epoch 339/1499\n",
      "----------\n",
      "train Loss: 0.6708 Acc: 0.8842\n",
      "val Loss: 0.6746 Acc: 0.8720\n",
      "test Loss: 0.6656 Acc: 0.8960\n",
      "Epoch 340/1499\n",
      "----------\n",
      "train Loss: 0.6720 Acc: 0.8842\n",
      "val Loss: 0.6725 Acc: 0.8800\n",
      "test Loss: 0.6642 Acc: 0.9000\n",
      "Epoch 341/1499\n",
      "----------\n",
      "train Loss: 0.6715 Acc: 0.8838\n",
      "val Loss: 0.6756 Acc: 0.8840\n",
      "test Loss: 0.6656 Acc: 0.8880\n",
      "Epoch 342/1499\n",
      "----------\n",
      "train Loss: 0.6716 Acc: 0.8818\n",
      "val Loss: 0.6649 Acc: 0.8880\n",
      "test Loss: 0.6766 Acc: 0.8800\n",
      "Epoch 343/1499\n",
      "----------\n",
      "train Loss: 0.6714 Acc: 0.8847\n",
      "val Loss: 0.6719 Acc: 0.8840\n",
      "test Loss: 0.6751 Acc: 0.8880\n",
      "Epoch 344/1499\n",
      "----------\n",
      "train Loss: 0.6732 Acc: 0.8822\n",
      "val Loss: 0.6801 Acc: 0.8720\n",
      "test Loss: 0.6735 Acc: 0.8880\n",
      "Epoch 345/1499\n",
      "----------\n",
      "train Loss: 0.6686 Acc: 0.8847\n",
      "val Loss: 0.6771 Acc: 0.8800\n",
      "test Loss: 0.6719 Acc: 0.8920\n",
      "Epoch 346/1499\n",
      "----------\n",
      "train Loss: 0.6708 Acc: 0.8844\n",
      "val Loss: 0.6726 Acc: 0.8680\n",
      "test Loss: 0.6756 Acc: 0.8880\n",
      "Epoch 347/1499\n",
      "----------\n",
      "train Loss: 0.6688 Acc: 0.8858\n",
      "val Loss: 0.6760 Acc: 0.8800\n",
      "test Loss: 0.6776 Acc: 0.8800\n",
      "Epoch 348/1499\n",
      "----------\n",
      "train Loss: 0.6704 Acc: 0.8824\n",
      "val Loss: 0.6744 Acc: 0.8760\n",
      "test Loss: 0.6698 Acc: 0.8920\n",
      "Epoch 349/1499\n",
      "----------\n",
      "train Loss: 0.6702 Acc: 0.8842\n",
      "val Loss: 0.6697 Acc: 0.8800\n",
      "test Loss: 0.6646 Acc: 0.8960\n",
      "Epoch 350/1499\n",
      "----------\n",
      "train Loss: 0.6700 Acc: 0.8836\n",
      "val Loss: 0.6764 Acc: 0.8880\n",
      "test Loss: 0.6761 Acc: 0.8880\n",
      "Epoch 351/1499\n",
      "----------\n",
      "train Loss: 0.6692 Acc: 0.8844\n",
      "val Loss: 0.6774 Acc: 0.8720\n",
      "test Loss: 0.6691 Acc: 0.8920\n",
      "Epoch 352/1499\n",
      "----------\n",
      "train Loss: 0.6699 Acc: 0.8858\n",
      "val Loss: 0.6796 Acc: 0.8680\n",
      "test Loss: 0.6721 Acc: 0.8760\n",
      "Epoch 353/1499\n",
      "----------\n",
      "train Loss: 0.6710 Acc: 0.8831\n",
      "val Loss: 0.6733 Acc: 0.8760\n",
      "test Loss: 0.6728 Acc: 0.8920\n",
      "Epoch 354/1499\n",
      "----------\n",
      "train Loss: 0.6687 Acc: 0.8847\n",
      "val Loss: 0.6781 Acc: 0.8720\n",
      "test Loss: 0.6663 Acc: 0.8800\n",
      "Epoch 355/1499\n",
      "----------\n",
      "train Loss: 0.6691 Acc: 0.8840\n",
      "val Loss: 0.6752 Acc: 0.8720\n",
      "test Loss: 0.6668 Acc: 0.9000\n",
      "Epoch 356/1499\n",
      "----------\n",
      "train Loss: 0.6707 Acc: 0.8838\n",
      "val Loss: 0.6731 Acc: 0.8720\n",
      "test Loss: 0.6624 Acc: 0.9000\n",
      "Epoch 357/1499\n",
      "----------\n",
      "train Loss: 0.6692 Acc: 0.8836\n",
      "val Loss: 0.6737 Acc: 0.8760\n",
      "test Loss: 0.6690 Acc: 0.8880\n",
      "Epoch 358/1499\n",
      "----------\n",
      "train Loss: 0.6675 Acc: 0.8878\n",
      "val Loss: 0.6752 Acc: 0.8840\n",
      "test Loss: 0.6648 Acc: 0.8960\n",
      "Epoch 359/1499\n",
      "----------\n",
      "train Loss: 0.6695 Acc: 0.8849\n",
      "val Loss: 0.6763 Acc: 0.8680\n",
      "test Loss: 0.6644 Acc: 0.9000\n",
      "Epoch 360/1499\n",
      "----------\n",
      "train Loss: 0.6695 Acc: 0.8856\n",
      "val Loss: 0.6700 Acc: 0.8800\n",
      "test Loss: 0.6716 Acc: 0.8880\n",
      "Epoch 361/1499\n",
      "----------\n",
      "train Loss: 0.6698 Acc: 0.8838\n",
      "val Loss: 0.6775 Acc: 0.8720\n",
      "test Loss: 0.6762 Acc: 0.8840\n",
      "Epoch 362/1499\n",
      "----------\n",
      "train Loss: 0.6666 Acc: 0.8882\n",
      "val Loss: 0.6715 Acc: 0.8760\n",
      "test Loss: 0.6754 Acc: 0.8840\n",
      "Epoch 363/1499\n",
      "----------\n",
      "train Loss: 0.6694 Acc: 0.8827\n",
      "val Loss: 0.6651 Acc: 0.8920\n",
      "test Loss: 0.6660 Acc: 0.8960\n",
      "Epoch 364/1499\n",
      "----------\n",
      "train Loss: 0.6674 Acc: 0.8887\n",
      "val Loss: 0.6800 Acc: 0.8720\n",
      "test Loss: 0.6666 Acc: 0.8960\n",
      "Epoch 365/1499\n",
      "----------\n",
      "train Loss: 0.6687 Acc: 0.8838\n",
      "val Loss: 0.6696 Acc: 0.8840\n",
      "test Loss: 0.6682 Acc: 0.8960\n",
      "Epoch 366/1499\n",
      "----------\n",
      "train Loss: 0.6667 Acc: 0.8884\n",
      "val Loss: 0.6742 Acc: 0.8880\n",
      "test Loss: 0.6716 Acc: 0.8880\n",
      "Epoch 367/1499\n",
      "----------\n",
      "train Loss: 0.6669 Acc: 0.8851\n",
      "val Loss: 0.6683 Acc: 0.8880\n",
      "test Loss: 0.6664 Acc: 0.8920\n",
      "Epoch 368/1499\n",
      "----------\n",
      "train Loss: 0.6674 Acc: 0.8882\n",
      "val Loss: 0.6743 Acc: 0.8800\n",
      "test Loss: 0.6700 Acc: 0.9000\n",
      "Epoch 369/1499\n",
      "----------\n",
      "train Loss: 0.6675 Acc: 0.8851\n",
      "val Loss: 0.6688 Acc: 0.8920\n",
      "test Loss: 0.6723 Acc: 0.8920\n",
      "Epoch 370/1499\n",
      "----------\n",
      "train Loss: 0.6679 Acc: 0.8844\n",
      "val Loss: 0.6728 Acc: 0.8880\n",
      "test Loss: 0.6637 Acc: 0.8960\n",
      "Epoch 371/1499\n",
      "----------\n",
      "train Loss: 0.6674 Acc: 0.8871\n",
      "val Loss: 0.6696 Acc: 0.8800\n",
      "test Loss: 0.6705 Acc: 0.8840\n",
      "Epoch 372/1499\n",
      "----------\n",
      "train Loss: 0.6674 Acc: 0.8856\n",
      "val Loss: 0.6742 Acc: 0.8800\n",
      "test Loss: 0.6670 Acc: 0.9000\n",
      "Epoch 373/1499\n",
      "----------\n",
      "train Loss: 0.6675 Acc: 0.8856\n",
      "val Loss: 0.6719 Acc: 0.8800\n",
      "test Loss: 0.6723 Acc: 0.8840\n",
      "Epoch 374/1499\n",
      "----------\n",
      "train Loss: 0.6666 Acc: 0.8876\n",
      "val Loss: 0.6760 Acc: 0.8840\n",
      "test Loss: 0.6691 Acc: 0.8960\n",
      "Epoch 375/1499\n",
      "----------\n",
      "train Loss: 0.6674 Acc: 0.8858\n",
      "val Loss: 0.6769 Acc: 0.8720\n",
      "test Loss: 0.6730 Acc: 0.8840\n",
      "Epoch 376/1499\n",
      "----------\n",
      "train Loss: 0.6674 Acc: 0.8864\n",
      "val Loss: 0.6694 Acc: 0.8760\n",
      "test Loss: 0.6674 Acc: 0.8920\n",
      "Epoch 377/1499\n",
      "----------\n",
      "train Loss: 0.6657 Acc: 0.8864\n",
      "val Loss: 0.6698 Acc: 0.8880\n",
      "test Loss: 0.6701 Acc: 0.8920\n",
      "Epoch 378/1499\n",
      "----------\n",
      "train Loss: 0.6669 Acc: 0.8851\n",
      "val Loss: 0.6763 Acc: 0.8800\n",
      "test Loss: 0.6699 Acc: 0.8920\n",
      "Epoch 379/1499\n",
      "----------\n",
      "train Loss: 0.6654 Acc: 0.8878\n",
      "val Loss: 0.6726 Acc: 0.8680\n",
      "test Loss: 0.6655 Acc: 0.8920\n",
      "Epoch 380/1499\n",
      "----------\n",
      "train Loss: 0.6671 Acc: 0.8853\n",
      "val Loss: 0.6677 Acc: 0.8840\n",
      "test Loss: 0.6701 Acc: 0.8920\n",
      "Epoch 381/1499\n",
      "----------\n",
      "train Loss: 0.6669 Acc: 0.8856\n",
      "val Loss: 0.6737 Acc: 0.8800\n",
      "test Loss: 0.6723 Acc: 0.8800\n",
      "Epoch 382/1499\n",
      "----------\n",
      "train Loss: 0.6648 Acc: 0.8838\n",
      "val Loss: 0.6728 Acc: 0.8880\n",
      "test Loss: 0.6621 Acc: 0.8960\n",
      "Epoch 383/1499\n",
      "----------\n",
      "train Loss: 0.6669 Acc: 0.8867\n",
      "val Loss: 0.6770 Acc: 0.8720\n",
      "test Loss: 0.6693 Acc: 0.8920\n",
      "Epoch 384/1499\n",
      "----------\n",
      "train Loss: 0.6661 Acc: 0.8860\n",
      "val Loss: 0.6734 Acc: 0.8880\n",
      "test Loss: 0.6636 Acc: 0.8920\n",
      "Epoch 385/1499\n",
      "----------\n",
      "train Loss: 0.6653 Acc: 0.8851\n",
      "val Loss: 0.6739 Acc: 0.8880\n",
      "test Loss: 0.6639 Acc: 0.8960\n",
      "Epoch 386/1499\n",
      "----------\n",
      "train Loss: 0.6645 Acc: 0.8858\n",
      "val Loss: 0.6701 Acc: 0.8920\n",
      "test Loss: 0.6720 Acc: 0.8920\n",
      "Epoch 387/1499\n",
      "----------\n",
      "train Loss: 0.6657 Acc: 0.8853\n",
      "val Loss: 0.6772 Acc: 0.8840\n",
      "test Loss: 0.6736 Acc: 0.8800\n",
      "Epoch 388/1499\n",
      "----------\n",
      "train Loss: 0.6672 Acc: 0.8847\n",
      "val Loss: 0.6677 Acc: 0.8880\n",
      "test Loss: 0.6658 Acc: 0.8880\n",
      "Epoch 389/1499\n",
      "----------\n",
      "train Loss: 0.6664 Acc: 0.8844\n",
      "val Loss: 0.6729 Acc: 0.8760\n",
      "test Loss: 0.6662 Acc: 0.8880\n",
      "Epoch 390/1499\n",
      "----------\n",
      "train Loss: 0.6648 Acc: 0.8864\n",
      "val Loss: 0.6601 Acc: 0.8920\n",
      "test Loss: 0.6650 Acc: 0.8880\n",
      "Epoch 391/1499\n",
      "----------\n",
      "train Loss: 0.6649 Acc: 0.8882\n",
      "val Loss: 0.6673 Acc: 0.8880\n",
      "test Loss: 0.6635 Acc: 0.8920\n",
      "Epoch 392/1499\n",
      "----------\n",
      "train Loss: 0.6648 Acc: 0.8869\n",
      "val Loss: 0.6736 Acc: 0.8840\n",
      "test Loss: 0.6641 Acc: 0.8920\n",
      "Epoch 393/1499\n",
      "----------\n",
      "train Loss: 0.6657 Acc: 0.8860\n",
      "val Loss: 0.6668 Acc: 0.8920\n",
      "test Loss: 0.6611 Acc: 0.8960\n",
      "Epoch 394/1499\n",
      "----------\n",
      "train Loss: 0.6652 Acc: 0.8887\n",
      "val Loss: 0.6726 Acc: 0.8800\n",
      "test Loss: 0.6620 Acc: 0.8960\n",
      "Epoch 395/1499\n",
      "----------\n",
      "train Loss: 0.6640 Acc: 0.8858\n",
      "val Loss: 0.6722 Acc: 0.8840\n",
      "test Loss: 0.6650 Acc: 0.8960\n",
      "Epoch 396/1499\n",
      "----------\n",
      "train Loss: 0.6655 Acc: 0.8851\n",
      "val Loss: 0.6683 Acc: 0.8920\n",
      "test Loss: 0.6630 Acc: 0.8960\n",
      "Epoch 397/1499\n",
      "----------\n",
      "train Loss: 0.6621 Acc: 0.8876\n",
      "val Loss: 0.6664 Acc: 0.8920\n",
      "test Loss: 0.6692 Acc: 0.8920\n",
      "Epoch 398/1499\n",
      "----------\n",
      "train Loss: 0.6650 Acc: 0.8882\n",
      "val Loss: 0.6765 Acc: 0.8760\n",
      "test Loss: 0.6690 Acc: 0.8920\n",
      "Epoch 399/1499\n",
      "----------\n",
      "train Loss: 0.6652 Acc: 0.8858\n",
      "val Loss: 0.6608 Acc: 0.8920\n",
      "test Loss: 0.6633 Acc: 0.8960\n",
      "Epoch 400/1499\n",
      "----------\n",
      "train Loss: 0.6665 Acc: 0.8842\n",
      "val Loss: 0.6679 Acc: 0.8920\n",
      "test Loss: 0.6613 Acc: 0.8880\n",
      "Epoch 401/1499\n",
      "----------\n",
      "train Loss: 0.6648 Acc: 0.8849\n",
      "val Loss: 0.6675 Acc: 0.8840\n",
      "test Loss: 0.6683 Acc: 0.8840\n",
      "Epoch 402/1499\n",
      "----------\n",
      "train Loss: 0.6631 Acc: 0.8898\n",
      "val Loss: 0.6687 Acc: 0.8800\n",
      "test Loss: 0.6665 Acc: 0.8920\n",
      "Epoch 403/1499\n",
      "----------\n",
      "train Loss: 0.6644 Acc: 0.8884\n",
      "val Loss: 0.6673 Acc: 0.8840\n",
      "test Loss: 0.6702 Acc: 0.8880\n",
      "Epoch 404/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6648 Acc: 0.8871\n",
      "val Loss: 0.6705 Acc: 0.8840\n",
      "test Loss: 0.6664 Acc: 0.8920\n",
      "Epoch 405/1499\n",
      "----------\n",
      "train Loss: 0.6639 Acc: 0.8876\n",
      "val Loss: 0.6681 Acc: 0.8880\n",
      "test Loss: 0.6686 Acc: 0.8880\n",
      "Epoch 406/1499\n",
      "----------\n",
      "train Loss: 0.6642 Acc: 0.8856\n",
      "val Loss: 0.6632 Acc: 0.9000\n",
      "test Loss: 0.6579 Acc: 0.9040\n",
      "Epoch 407/1499\n",
      "----------\n",
      "train Loss: 0.6638 Acc: 0.8893\n",
      "val Loss: 0.6650 Acc: 0.8840\n",
      "test Loss: 0.6591 Acc: 0.8960\n",
      "Epoch 408/1499\n",
      "----------\n",
      "train Loss: 0.6647 Acc: 0.8864\n",
      "val Loss: 0.6657 Acc: 0.8960\n",
      "test Loss: 0.6622 Acc: 0.8960\n",
      "Epoch 409/1499\n",
      "----------\n",
      "train Loss: 0.6642 Acc: 0.8864\n",
      "val Loss: 0.6648 Acc: 0.8920\n",
      "test Loss: 0.6653 Acc: 0.8920\n",
      "Epoch 410/1499\n",
      "----------\n",
      "train Loss: 0.6650 Acc: 0.8860\n",
      "val Loss: 0.6675 Acc: 0.8920\n",
      "test Loss: 0.6648 Acc: 0.8840\n",
      "Epoch 411/1499\n",
      "----------\n",
      "train Loss: 0.6661 Acc: 0.8833\n",
      "val Loss: 0.6687 Acc: 0.8880\n",
      "test Loss: 0.6638 Acc: 0.8960\n",
      "Epoch 412/1499\n",
      "----------\n",
      "train Loss: 0.6648 Acc: 0.8878\n",
      "val Loss: 0.6663 Acc: 0.8880\n",
      "test Loss: 0.6679 Acc: 0.8840\n",
      "Epoch 413/1499\n",
      "----------\n",
      "train Loss: 0.6658 Acc: 0.8844\n",
      "val Loss: 0.6632 Acc: 0.8960\n",
      "test Loss: 0.6680 Acc: 0.8840\n",
      "Epoch 414/1499\n",
      "----------\n",
      "train Loss: 0.6626 Acc: 0.8891\n",
      "val Loss: 0.6578 Acc: 0.9000\n",
      "test Loss: 0.6636 Acc: 0.8920\n",
      "Epoch 415/1499\n",
      "----------\n",
      "train Loss: 0.6635 Acc: 0.8873\n",
      "val Loss: 0.6735 Acc: 0.8800\n",
      "test Loss: 0.6603 Acc: 0.9000\n",
      "Epoch 416/1499\n",
      "----------\n",
      "train Loss: 0.6634 Acc: 0.8849\n",
      "val Loss: 0.6627 Acc: 0.8880\n",
      "test Loss: 0.6645 Acc: 0.8880\n",
      "Epoch 417/1499\n",
      "----------\n",
      "train Loss: 0.6628 Acc: 0.8887\n",
      "val Loss: 0.6689 Acc: 0.8840\n",
      "test Loss: 0.6594 Acc: 0.9000\n",
      "Epoch 418/1499\n",
      "----------\n",
      "train Loss: 0.6621 Acc: 0.8893\n",
      "val Loss: 0.6723 Acc: 0.8880\n",
      "test Loss: 0.6670 Acc: 0.8920\n",
      "Epoch 419/1499\n",
      "----------\n",
      "train Loss: 0.6644 Acc: 0.8847\n",
      "val Loss: 0.6678 Acc: 0.8920\n",
      "test Loss: 0.6677 Acc: 0.8840\n",
      "Epoch 420/1499\n",
      "----------\n",
      "train Loss: 0.6640 Acc: 0.8840\n",
      "val Loss: 0.6706 Acc: 0.8880\n",
      "test Loss: 0.6623 Acc: 0.8840\n",
      "Epoch 421/1499\n",
      "----------\n",
      "train Loss: 0.6618 Acc: 0.8907\n",
      "val Loss: 0.6732 Acc: 0.8880\n",
      "test Loss: 0.6609 Acc: 0.8960\n",
      "Epoch 422/1499\n",
      "----------\n",
      "train Loss: 0.6634 Acc: 0.8887\n",
      "val Loss: 0.6742 Acc: 0.8800\n",
      "test Loss: 0.6601 Acc: 0.8960\n",
      "Epoch 423/1499\n",
      "----------\n",
      "train Loss: 0.6626 Acc: 0.8871\n",
      "val Loss: 0.6637 Acc: 0.8920\n",
      "test Loss: 0.6645 Acc: 0.8960\n",
      "Epoch 424/1499\n",
      "----------\n",
      "train Loss: 0.6602 Acc: 0.8889\n",
      "val Loss: 0.6619 Acc: 0.8960\n",
      "test Loss: 0.6630 Acc: 0.8880\n",
      "Epoch 425/1499\n",
      "----------\n",
      "train Loss: 0.6637 Acc: 0.8873\n",
      "val Loss: 0.6722 Acc: 0.8840\n",
      "test Loss: 0.6636 Acc: 0.8880\n",
      "Epoch 426/1499\n",
      "----------\n",
      "train Loss: 0.6609 Acc: 0.8900\n",
      "val Loss: 0.6661 Acc: 0.8920\n",
      "test Loss: 0.6642 Acc: 0.8960\n",
      "Epoch 427/1499\n",
      "----------\n",
      "train Loss: 0.6627 Acc: 0.8887\n",
      "val Loss: 0.6677 Acc: 0.8840\n",
      "test Loss: 0.6628 Acc: 0.8960\n",
      "Epoch 428/1499\n",
      "----------\n",
      "train Loss: 0.6613 Acc: 0.8902\n",
      "val Loss: 0.6763 Acc: 0.8760\n",
      "test Loss: 0.6643 Acc: 0.8840\n",
      "Epoch 429/1499\n",
      "----------\n",
      "train Loss: 0.6616 Acc: 0.8876\n",
      "val Loss: 0.6643 Acc: 0.8920\n",
      "test Loss: 0.6651 Acc: 0.8920\n",
      "Epoch 430/1499\n",
      "----------\n",
      "train Loss: 0.6636 Acc: 0.8864\n",
      "val Loss: 0.6668 Acc: 0.8920\n",
      "test Loss: 0.6617 Acc: 0.8960\n",
      "Epoch 431/1499\n",
      "----------\n",
      "train Loss: 0.6617 Acc: 0.8896\n",
      "val Loss: 0.6614 Acc: 0.8880\n",
      "test Loss: 0.6654 Acc: 0.8960\n",
      "Epoch 432/1499\n",
      "----------\n",
      "train Loss: 0.6617 Acc: 0.8871\n",
      "val Loss: 0.6640 Acc: 0.8840\n",
      "test Loss: 0.6608 Acc: 0.8920\n",
      "Epoch 433/1499\n",
      "----------\n",
      "train Loss: 0.6622 Acc: 0.8876\n",
      "val Loss: 0.6614 Acc: 0.8920\n",
      "test Loss: 0.6598 Acc: 0.8920\n",
      "Epoch 434/1499\n",
      "----------\n",
      "train Loss: 0.6608 Acc: 0.8893\n",
      "val Loss: 0.6687 Acc: 0.8800\n",
      "test Loss: 0.6634 Acc: 0.8880\n",
      "Epoch 435/1499\n",
      "----------\n",
      "train Loss: 0.6619 Acc: 0.8860\n",
      "val Loss: 0.6661 Acc: 0.8880\n",
      "test Loss: 0.6645 Acc: 0.8960\n",
      "Epoch 436/1499\n",
      "----------\n",
      "train Loss: 0.6620 Acc: 0.8864\n",
      "val Loss: 0.6555 Acc: 0.9000\n",
      "test Loss: 0.6634 Acc: 0.8920\n",
      "Epoch 437/1499\n",
      "----------\n",
      "train Loss: 0.6616 Acc: 0.8869\n",
      "val Loss: 0.6659 Acc: 0.9000\n",
      "test Loss: 0.6618 Acc: 0.8960\n",
      "Epoch 438/1499\n",
      "----------\n",
      "train Loss: 0.6612 Acc: 0.8887\n",
      "val Loss: 0.6667 Acc: 0.8840\n",
      "test Loss: 0.6666 Acc: 0.8880\n",
      "Epoch 439/1499\n",
      "----------\n",
      "train Loss: 0.6600 Acc: 0.8907\n",
      "val Loss: 0.6607 Acc: 0.8880\n",
      "test Loss: 0.6644 Acc: 0.8880\n",
      "Epoch 440/1499\n",
      "----------\n",
      "train Loss: 0.6628 Acc: 0.8864\n",
      "val Loss: 0.6634 Acc: 0.8880\n",
      "test Loss: 0.6720 Acc: 0.8720\n",
      "Epoch 441/1499\n",
      "----------\n",
      "train Loss: 0.6619 Acc: 0.8880\n",
      "val Loss: 0.6592 Acc: 0.8920\n",
      "test Loss: 0.6657 Acc: 0.8840\n",
      "Epoch 442/1499\n",
      "----------\n",
      "train Loss: 0.6612 Acc: 0.8887\n",
      "val Loss: 0.6593 Acc: 0.8920\n",
      "test Loss: 0.6674 Acc: 0.8880\n",
      "Epoch 443/1499\n",
      "----------\n",
      "train Loss: 0.6601 Acc: 0.8896\n",
      "val Loss: 0.6658 Acc: 0.8920\n",
      "test Loss: 0.6565 Acc: 0.9000\n",
      "Epoch 444/1499\n",
      "----------\n",
      "train Loss: 0.6596 Acc: 0.8916\n",
      "val Loss: 0.6715 Acc: 0.8800\n",
      "test Loss: 0.6627 Acc: 0.8960\n",
      "Epoch 445/1499\n",
      "----------\n",
      "train Loss: 0.6622 Acc: 0.8884\n",
      "val Loss: 0.6702 Acc: 0.8840\n",
      "test Loss: 0.6635 Acc: 0.8880\n",
      "Epoch 446/1499\n",
      "----------\n",
      "train Loss: 0.6601 Acc: 0.8913\n",
      "val Loss: 0.6681 Acc: 0.8800\n",
      "test Loss: 0.6624 Acc: 0.8920\n",
      "Epoch 447/1499\n",
      "----------\n",
      "train Loss: 0.6604 Acc: 0.8898\n",
      "val Loss: 0.6635 Acc: 0.8840\n",
      "test Loss: 0.6598 Acc: 0.9000\n",
      "Epoch 448/1499\n",
      "----------\n",
      "train Loss: 0.6613 Acc: 0.8884\n",
      "val Loss: 0.6672 Acc: 0.8840\n",
      "test Loss: 0.6644 Acc: 0.8920\n",
      "Epoch 449/1499\n",
      "----------\n",
      "train Loss: 0.6608 Acc: 0.8898\n",
      "val Loss: 0.6687 Acc: 0.8800\n",
      "test Loss: 0.6610 Acc: 0.8880\n",
      "Epoch 450/1499\n",
      "----------\n",
      "train Loss: 0.6609 Acc: 0.8909\n",
      "val Loss: 0.6681 Acc: 0.8680\n",
      "test Loss: 0.6672 Acc: 0.8840\n",
      "Epoch 451/1499\n",
      "----------\n",
      "train Loss: 0.6616 Acc: 0.8880\n",
      "val Loss: 0.6614 Acc: 0.8920\n",
      "test Loss: 0.6623 Acc: 0.8840\n",
      "Epoch 452/1499\n",
      "----------\n",
      "train Loss: 0.6586 Acc: 0.8900\n",
      "val Loss: 0.6667 Acc: 0.8800\n",
      "test Loss: 0.6637 Acc: 0.8880\n",
      "Epoch 453/1499\n",
      "----------\n",
      "train Loss: 0.6607 Acc: 0.8896\n",
      "val Loss: 0.6619 Acc: 0.8920\n",
      "test Loss: 0.6590 Acc: 0.8920\n",
      "Epoch 454/1499\n",
      "----------\n",
      "train Loss: 0.6602 Acc: 0.8887\n",
      "val Loss: 0.6654 Acc: 0.8920\n",
      "test Loss: 0.6573 Acc: 0.8960\n",
      "Epoch 455/1499\n",
      "----------\n",
      "train Loss: 0.6591 Acc: 0.8909\n",
      "val Loss: 0.6587 Acc: 0.8920\n",
      "test Loss: 0.6646 Acc: 0.8960\n",
      "Epoch 456/1499\n",
      "----------\n",
      "train Loss: 0.6595 Acc: 0.8882\n",
      "val Loss: 0.6625 Acc: 0.8880\n",
      "test Loss: 0.6628 Acc: 0.8880\n",
      "Epoch 457/1499\n",
      "----------\n",
      "train Loss: 0.6601 Acc: 0.8882\n",
      "val Loss: 0.6622 Acc: 0.8880\n",
      "test Loss: 0.6669 Acc: 0.8880\n",
      "Epoch 458/1499\n",
      "----------\n",
      "train Loss: 0.6594 Acc: 0.8896\n",
      "val Loss: 0.6655 Acc: 0.8840\n",
      "test Loss: 0.6613 Acc: 0.8920\n",
      "Epoch 459/1499\n",
      "----------\n",
      "train Loss: 0.6608 Acc: 0.8876\n",
      "val Loss: 0.6709 Acc: 0.8760\n",
      "test Loss: 0.6664 Acc: 0.8920\n",
      "Epoch 460/1499\n",
      "----------\n",
      "train Loss: 0.6598 Acc: 0.8887\n",
      "val Loss: 0.6639 Acc: 0.8800\n",
      "test Loss: 0.6600 Acc: 0.8960\n",
      "Epoch 461/1499\n",
      "----------\n",
      "train Loss: 0.6608 Acc: 0.8869\n",
      "val Loss: 0.6577 Acc: 0.8960\n",
      "test Loss: 0.6630 Acc: 0.8920\n",
      "Epoch 462/1499\n",
      "----------\n",
      "train Loss: 0.6616 Acc: 0.8882\n",
      "val Loss: 0.6591 Acc: 0.8920\n",
      "test Loss: 0.6631 Acc: 0.8960\n",
      "Epoch 463/1499\n",
      "----------\n",
      "train Loss: 0.6598 Acc: 0.8880\n",
      "val Loss: 0.6628 Acc: 0.8960\n",
      "test Loss: 0.6630 Acc: 0.8920\n",
      "Epoch 464/1499\n",
      "----------\n",
      "train Loss: 0.6604 Acc: 0.8909\n",
      "val Loss: 0.6660 Acc: 0.8880\n",
      "test Loss: 0.6635 Acc: 0.8880\n",
      "Epoch 465/1499\n",
      "----------\n",
      "train Loss: 0.6587 Acc: 0.8927\n",
      "val Loss: 0.6618 Acc: 0.8880\n",
      "test Loss: 0.6610 Acc: 0.8920\n",
      "Epoch 466/1499\n",
      "----------\n",
      "train Loss: 0.6601 Acc: 0.8887\n",
      "val Loss: 0.6688 Acc: 0.8800\n",
      "test Loss: 0.6634 Acc: 0.8880\n",
      "Epoch 467/1499\n",
      "----------\n",
      "train Loss: 0.6600 Acc: 0.8891\n",
      "val Loss: 0.6565 Acc: 0.8880\n",
      "test Loss: 0.6549 Acc: 0.9000\n",
      "Epoch 468/1499\n",
      "----------\n",
      "train Loss: 0.6604 Acc: 0.8896\n",
      "val Loss: 0.6603 Acc: 0.8920\n",
      "test Loss: 0.6594 Acc: 0.8960\n",
      "Epoch 469/1499\n",
      "----------\n",
      "train Loss: 0.6579 Acc: 0.8913\n",
      "val Loss: 0.6637 Acc: 0.8920\n",
      "test Loss: 0.6718 Acc: 0.8720\n",
      "Epoch 470/1499\n",
      "----------\n",
      "train Loss: 0.6592 Acc: 0.8891\n",
      "val Loss: 0.6589 Acc: 0.8880\n",
      "test Loss: 0.6606 Acc: 0.8920\n",
      "Epoch 471/1499\n",
      "----------\n",
      "train Loss: 0.6593 Acc: 0.8913\n",
      "val Loss: 0.6592 Acc: 0.8920\n",
      "test Loss: 0.6634 Acc: 0.8840\n",
      "Epoch 472/1499\n",
      "----------\n",
      "train Loss: 0.6582 Acc: 0.8922\n",
      "val Loss: 0.6630 Acc: 0.8920\n",
      "test Loss: 0.6589 Acc: 0.8960\n",
      "Epoch 473/1499\n",
      "----------\n",
      "train Loss: 0.6592 Acc: 0.8909\n",
      "val Loss: 0.6606 Acc: 0.8880\n",
      "test Loss: 0.6609 Acc: 0.8920\n",
      "Epoch 474/1499\n",
      "----------\n",
      "train Loss: 0.6593 Acc: 0.8896\n",
      "val Loss: 0.6586 Acc: 0.9040\n",
      "test Loss: 0.6676 Acc: 0.8840\n",
      "Epoch 475/1499\n",
      "----------\n",
      "train Loss: 0.6575 Acc: 0.8931\n",
      "val Loss: 0.6585 Acc: 0.8880\n",
      "test Loss: 0.6655 Acc: 0.8800\n",
      "Epoch 476/1499\n",
      "----------\n",
      "train Loss: 0.6594 Acc: 0.8909\n",
      "val Loss: 0.6628 Acc: 0.8920\n",
      "test Loss: 0.6634 Acc: 0.8960\n",
      "Epoch 477/1499\n",
      "----------\n",
      "train Loss: 0.6580 Acc: 0.8909\n",
      "val Loss: 0.6611 Acc: 0.8960\n",
      "test Loss: 0.6619 Acc: 0.8960\n",
      "Epoch 478/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6572 Acc: 0.8920\n",
      "val Loss: 0.6579 Acc: 0.8920\n",
      "test Loss: 0.6597 Acc: 0.8960\n",
      "Epoch 479/1499\n",
      "----------\n",
      "train Loss: 0.6594 Acc: 0.8916\n",
      "val Loss: 0.6638 Acc: 0.8880\n",
      "test Loss: 0.6570 Acc: 0.9000\n",
      "Epoch 480/1499\n",
      "----------\n",
      "train Loss: 0.6590 Acc: 0.8909\n",
      "val Loss: 0.6691 Acc: 0.8840\n",
      "test Loss: 0.6583 Acc: 0.9000\n",
      "Epoch 481/1499\n",
      "----------\n",
      "train Loss: 0.6578 Acc: 0.8920\n",
      "val Loss: 0.6602 Acc: 0.8960\n",
      "test Loss: 0.6605 Acc: 0.8920\n",
      "Epoch 482/1499\n",
      "----------\n",
      "train Loss: 0.6582 Acc: 0.8896\n",
      "val Loss: 0.6529 Acc: 0.9040\n",
      "test Loss: 0.6658 Acc: 0.8880\n",
      "Epoch 483/1499\n",
      "----------\n",
      "train Loss: 0.6590 Acc: 0.8904\n",
      "val Loss: 0.6578 Acc: 0.8920\n",
      "test Loss: 0.6683 Acc: 0.8840\n",
      "Epoch 484/1499\n",
      "----------\n",
      "train Loss: 0.6587 Acc: 0.8898\n",
      "val Loss: 0.6624 Acc: 0.8920\n",
      "test Loss: 0.6614 Acc: 0.8920\n",
      "Epoch 485/1499\n",
      "----------\n",
      "train Loss: 0.6580 Acc: 0.8913\n",
      "val Loss: 0.6599 Acc: 0.8840\n",
      "test Loss: 0.6649 Acc: 0.8920\n",
      "Epoch 486/1499\n",
      "----------\n",
      "train Loss: 0.6573 Acc: 0.8924\n",
      "val Loss: 0.6572 Acc: 0.8920\n",
      "test Loss: 0.6628 Acc: 0.8880\n",
      "Epoch 487/1499\n",
      "----------\n",
      "train Loss: 0.6582 Acc: 0.8918\n",
      "val Loss: 0.6648 Acc: 0.8960\n",
      "test Loss: 0.6632 Acc: 0.8960\n",
      "Epoch 488/1499\n",
      "----------\n",
      "train Loss: 0.6568 Acc: 0.8929\n",
      "val Loss: 0.6605 Acc: 0.8880\n",
      "test Loss: 0.6610 Acc: 0.8960\n",
      "Epoch 489/1499\n",
      "----------\n",
      "train Loss: 0.6594 Acc: 0.8898\n",
      "val Loss: 0.6590 Acc: 0.8960\n",
      "test Loss: 0.6578 Acc: 0.8960\n",
      "Epoch 490/1499\n",
      "----------\n",
      "train Loss: 0.6579 Acc: 0.8920\n",
      "val Loss: 0.6638 Acc: 0.8920\n",
      "test Loss: 0.6625 Acc: 0.8920\n",
      "Epoch 491/1499\n",
      "----------\n",
      "train Loss: 0.6575 Acc: 0.8916\n",
      "val Loss: 0.6673 Acc: 0.8800\n",
      "test Loss: 0.6605 Acc: 0.8960\n",
      "Epoch 492/1499\n",
      "----------\n",
      "train Loss: 0.6575 Acc: 0.8911\n",
      "val Loss: 0.6575 Acc: 0.9000\n",
      "test Loss: 0.6672 Acc: 0.8840\n",
      "Epoch 493/1499\n",
      "----------\n",
      "train Loss: 0.6578 Acc: 0.8922\n",
      "val Loss: 0.6561 Acc: 0.9080\n",
      "test Loss: 0.6622 Acc: 0.8960\n",
      "Epoch 494/1499\n",
      "----------\n",
      "train Loss: 0.6565 Acc: 0.8931\n",
      "val Loss: 0.6582 Acc: 0.8960\n",
      "test Loss: 0.6644 Acc: 0.8840\n",
      "Epoch 495/1499\n",
      "----------\n",
      "train Loss: 0.6589 Acc: 0.8893\n",
      "val Loss: 0.6663 Acc: 0.8800\n",
      "test Loss: 0.6582 Acc: 0.9040\n",
      "Epoch 496/1499\n",
      "----------\n",
      "train Loss: 0.6578 Acc: 0.8916\n",
      "val Loss: 0.6602 Acc: 0.8840\n",
      "test Loss: 0.6561 Acc: 0.8920\n",
      "Epoch 497/1499\n",
      "----------\n",
      "train Loss: 0.6581 Acc: 0.8920\n",
      "val Loss: 0.6593 Acc: 0.8840\n",
      "test Loss: 0.6630 Acc: 0.8920\n",
      "Epoch 498/1499\n",
      "----------\n",
      "train Loss: 0.6586 Acc: 0.8907\n",
      "val Loss: 0.6629 Acc: 0.8800\n",
      "test Loss: 0.6601 Acc: 0.8920\n",
      "Epoch 499/1499\n",
      "----------\n",
      "train Loss: 0.6575 Acc: 0.8916\n",
      "val Loss: 0.6589 Acc: 0.8880\n",
      "test Loss: 0.6600 Acc: 0.8880\n",
      "Epoch 500/1499\n",
      "----------\n",
      "train Loss: 0.6580 Acc: 0.8920\n",
      "val Loss: 0.6612 Acc: 0.8880\n",
      "test Loss: 0.6617 Acc: 0.8960\n",
      "Epoch 501/1499\n",
      "----------\n",
      "train Loss: 0.6570 Acc: 0.8938\n",
      "val Loss: 0.6631 Acc: 0.8880\n",
      "test Loss: 0.6595 Acc: 0.9000\n",
      "Epoch 502/1499\n",
      "----------\n",
      "train Loss: 0.6558 Acc: 0.8920\n",
      "val Loss: 0.6637 Acc: 0.8880\n",
      "test Loss: 0.6609 Acc: 0.9000\n",
      "Epoch 503/1499\n",
      "----------\n",
      "train Loss: 0.6571 Acc: 0.8920\n",
      "val Loss: 0.6615 Acc: 0.8960\n",
      "test Loss: 0.6594 Acc: 0.8960\n",
      "Epoch 504/1499\n",
      "----------\n",
      "train Loss: 0.6563 Acc: 0.8920\n",
      "val Loss: 0.6534 Acc: 0.9040\n",
      "test Loss: 0.6602 Acc: 0.8920\n",
      "Epoch 505/1499\n",
      "----------\n",
      "train Loss: 0.6575 Acc: 0.8927\n",
      "val Loss: 0.6561 Acc: 0.9040\n",
      "test Loss: 0.6623 Acc: 0.8880\n",
      "Epoch 506/1499\n",
      "----------\n",
      "train Loss: 0.6565 Acc: 0.8936\n",
      "val Loss: 0.6612 Acc: 0.8880\n",
      "test Loss: 0.6612 Acc: 0.8920\n",
      "Epoch 507/1499\n",
      "----------\n",
      "train Loss: 0.6570 Acc: 0.8922\n",
      "val Loss: 0.6562 Acc: 0.9000\n",
      "test Loss: 0.6591 Acc: 0.9000\n",
      "Epoch 508/1499\n",
      "----------\n",
      "train Loss: 0.6578 Acc: 0.8933\n",
      "val Loss: 0.6610 Acc: 0.8800\n",
      "test Loss: 0.6611 Acc: 0.8960\n",
      "Epoch 509/1499\n",
      "----------\n",
      "train Loss: 0.6584 Acc: 0.8896\n",
      "val Loss: 0.6568 Acc: 0.8960\n",
      "test Loss: 0.6597 Acc: 0.8960\n",
      "Epoch 510/1499\n",
      "----------\n",
      "train Loss: 0.6548 Acc: 0.8969\n",
      "val Loss: 0.6536 Acc: 0.9040\n",
      "test Loss: 0.6594 Acc: 0.8960\n",
      "Epoch 511/1499\n",
      "----------\n",
      "train Loss: 0.6567 Acc: 0.8927\n",
      "val Loss: 0.6579 Acc: 0.8960\n",
      "test Loss: 0.6635 Acc: 0.8960\n",
      "Epoch 512/1499\n",
      "----------\n",
      "train Loss: 0.6564 Acc: 0.8927\n",
      "val Loss: 0.6587 Acc: 0.8720\n",
      "test Loss: 0.6605 Acc: 0.8960\n",
      "Epoch 513/1499\n",
      "----------\n",
      "train Loss: 0.6570 Acc: 0.8936\n",
      "val Loss: 0.6581 Acc: 0.8960\n",
      "test Loss: 0.6581 Acc: 0.8960\n",
      "Epoch 514/1499\n",
      "----------\n",
      "train Loss: 0.6561 Acc: 0.8947\n",
      "val Loss: 0.6559 Acc: 0.8960\n",
      "test Loss: 0.6604 Acc: 0.9000\n",
      "Epoch 515/1499\n",
      "----------\n",
      "train Loss: 0.6571 Acc: 0.8916\n",
      "val Loss: 0.6575 Acc: 0.8960\n",
      "test Loss: 0.6622 Acc: 0.8920\n",
      "Epoch 516/1499\n",
      "----------\n",
      "train Loss: 0.6571 Acc: 0.8918\n",
      "val Loss: 0.6570 Acc: 0.8960\n",
      "test Loss: 0.6593 Acc: 0.8960\n",
      "Epoch 517/1499\n",
      "----------\n",
      "train Loss: 0.6575 Acc: 0.8922\n",
      "val Loss: 0.6563 Acc: 0.8960\n",
      "test Loss: 0.6596 Acc: 0.8960\n",
      "Epoch 518/1499\n",
      "----------\n",
      "train Loss: 0.6572 Acc: 0.8916\n",
      "val Loss: 0.6577 Acc: 0.8920\n",
      "test Loss: 0.6589 Acc: 0.8960\n",
      "Epoch 519/1499\n",
      "----------\n",
      "train Loss: 0.6561 Acc: 0.8953\n",
      "val Loss: 0.6593 Acc: 0.8880\n",
      "test Loss: 0.6598 Acc: 0.8920\n",
      "Epoch 520/1499\n",
      "----------\n",
      "train Loss: 0.6545 Acc: 0.8967\n",
      "val Loss: 0.6612 Acc: 0.8840\n",
      "test Loss: 0.6609 Acc: 0.8960\n",
      "Epoch 521/1499\n",
      "----------\n",
      "train Loss: 0.6566 Acc: 0.8922\n",
      "val Loss: 0.6646 Acc: 0.8880\n",
      "test Loss: 0.6586 Acc: 0.8960\n",
      "Epoch 522/1499\n",
      "----------\n",
      "train Loss: 0.6561 Acc: 0.8942\n",
      "val Loss: 0.6622 Acc: 0.8840\n",
      "test Loss: 0.6626 Acc: 0.8920\n",
      "Epoch 523/1499\n",
      "----------\n",
      "train Loss: 0.6556 Acc: 0.8931\n",
      "val Loss: 0.6589 Acc: 0.8840\n",
      "test Loss: 0.6617 Acc: 0.8880\n",
      "Epoch 524/1499\n",
      "----------\n",
      "train Loss: 0.6559 Acc: 0.8920\n",
      "val Loss: 0.6588 Acc: 0.8880\n",
      "test Loss: 0.6613 Acc: 0.8880\n",
      "Epoch 525/1499\n",
      "----------\n",
      "train Loss: 0.6578 Acc: 0.8927\n",
      "val Loss: 0.6586 Acc: 0.8840\n",
      "test Loss: 0.6610 Acc: 0.8960\n",
      "Epoch 526/1499\n",
      "----------\n",
      "train Loss: 0.6544 Acc: 0.8951\n",
      "val Loss: 0.6519 Acc: 0.8960\n",
      "test Loss: 0.6597 Acc: 0.9000\n",
      "Epoch 527/1499\n",
      "----------\n",
      "train Loss: 0.6564 Acc: 0.8904\n",
      "val Loss: 0.6570 Acc: 0.8880\n",
      "test Loss: 0.6609 Acc: 0.8880\n",
      "Epoch 528/1499\n",
      "----------\n",
      "train Loss: 0.6564 Acc: 0.8916\n",
      "val Loss: 0.6546 Acc: 0.8880\n",
      "test Loss: 0.6594 Acc: 0.8880\n",
      "Epoch 529/1499\n",
      "----------\n",
      "train Loss: 0.6559 Acc: 0.8922\n",
      "val Loss: 0.6541 Acc: 0.8880\n",
      "test Loss: 0.6605 Acc: 0.8880\n",
      "Epoch 530/1499\n",
      "----------\n",
      "train Loss: 0.6562 Acc: 0.8922\n",
      "val Loss: 0.6576 Acc: 0.8880\n",
      "test Loss: 0.6585 Acc: 0.8880\n",
      "Epoch 531/1499\n",
      "----------\n",
      "train Loss: 0.6553 Acc: 0.8949\n",
      "val Loss: 0.6588 Acc: 0.8920\n",
      "test Loss: 0.6547 Acc: 0.9040\n",
      "Epoch 532/1499\n",
      "----------\n",
      "train Loss: 0.6557 Acc: 0.8958\n",
      "val Loss: 0.6615 Acc: 0.8800\n",
      "test Loss: 0.6589 Acc: 0.8960\n",
      "Epoch 533/1499\n",
      "----------\n",
      "train Loss: 0.6548 Acc: 0.8940\n",
      "val Loss: 0.6582 Acc: 0.8960\n",
      "test Loss: 0.6605 Acc: 0.8920\n",
      "Epoch 534/1499\n",
      "----------\n",
      "train Loss: 0.6562 Acc: 0.8909\n",
      "val Loss: 0.6675 Acc: 0.8760\n",
      "test Loss: 0.6615 Acc: 0.8920\n",
      "Epoch 535/1499\n",
      "----------\n",
      "train Loss: 0.6555 Acc: 0.8936\n",
      "val Loss: 0.6550 Acc: 0.8960\n",
      "test Loss: 0.6528 Acc: 0.9000\n",
      "Epoch 536/1499\n",
      "----------\n",
      "train Loss: 0.6557 Acc: 0.8931\n",
      "val Loss: 0.6590 Acc: 0.8960\n",
      "test Loss: 0.6608 Acc: 0.8920\n",
      "Epoch 537/1499\n",
      "----------\n",
      "train Loss: 0.6543 Acc: 0.8951\n",
      "val Loss: 0.6562 Acc: 0.9040\n",
      "test Loss: 0.6613 Acc: 0.9000\n",
      "Epoch 538/1499\n",
      "----------\n",
      "train Loss: 0.6544 Acc: 0.8953\n",
      "val Loss: 0.6577 Acc: 0.8920\n",
      "test Loss: 0.6621 Acc: 0.8960\n",
      "Epoch 539/1499\n",
      "----------\n",
      "train Loss: 0.6558 Acc: 0.8938\n",
      "val Loss: 0.6587 Acc: 0.8880\n",
      "test Loss: 0.6605 Acc: 0.8880\n",
      "Epoch 540/1499\n",
      "----------\n",
      "train Loss: 0.6544 Acc: 0.8960\n",
      "val Loss: 0.6585 Acc: 0.8840\n",
      "test Loss: 0.6557 Acc: 0.9000\n",
      "Epoch 541/1499\n",
      "----------\n",
      "train Loss: 0.6545 Acc: 0.8940\n",
      "val Loss: 0.6558 Acc: 0.9000\n",
      "test Loss: 0.6579 Acc: 0.8960\n",
      "Epoch 542/1499\n",
      "----------\n",
      "train Loss: 0.6546 Acc: 0.8962\n",
      "val Loss: 0.6535 Acc: 0.9040\n",
      "test Loss: 0.6553 Acc: 0.8960\n",
      "Epoch 543/1499\n",
      "----------\n",
      "train Loss: 0.6546 Acc: 0.8929\n",
      "val Loss: 0.6567 Acc: 0.8840\n",
      "test Loss: 0.6644 Acc: 0.8840\n",
      "Epoch 544/1499\n",
      "----------\n",
      "train Loss: 0.6547 Acc: 0.8949\n",
      "val Loss: 0.6545 Acc: 0.9000\n",
      "test Loss: 0.6650 Acc: 0.8880\n",
      "Epoch 545/1499\n",
      "----------\n",
      "train Loss: 0.6542 Acc: 0.8947\n",
      "val Loss: 0.6584 Acc: 0.8800\n",
      "test Loss: 0.6607 Acc: 0.8920\n",
      "Epoch 546/1499\n",
      "----------\n",
      "train Loss: 0.6554 Acc: 0.8936\n",
      "val Loss: 0.6602 Acc: 0.8920\n",
      "test Loss: 0.6612 Acc: 0.8920\n",
      "Epoch 547/1499\n",
      "----------\n",
      "train Loss: 0.6539 Acc: 0.8971\n",
      "val Loss: 0.6594 Acc: 0.8880\n",
      "test Loss: 0.6569 Acc: 0.8960\n",
      "Epoch 548/1499\n",
      "----------\n",
      "train Loss: 0.6547 Acc: 0.8933\n",
      "val Loss: 0.6589 Acc: 0.8840\n",
      "test Loss: 0.6630 Acc: 0.8920\n",
      "Epoch 549/1499\n",
      "----------\n",
      "train Loss: 0.6546 Acc: 0.8929\n",
      "val Loss: 0.6533 Acc: 0.8920\n",
      "test Loss: 0.6594 Acc: 0.8840\n",
      "Epoch 550/1499\n",
      "----------\n",
      "train Loss: 0.6541 Acc: 0.8942\n",
      "val Loss: 0.6557 Acc: 0.8880\n",
      "test Loss: 0.6566 Acc: 0.8920\n",
      "Epoch 551/1499\n",
      "----------\n",
      "train Loss: 0.6546 Acc: 0.8953\n",
      "val Loss: 0.6554 Acc: 0.8920\n",
      "test Loss: 0.6590 Acc: 0.9040\n",
      "Epoch 552/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6546 Acc: 0.8960\n",
      "val Loss: 0.6569 Acc: 0.8880\n",
      "test Loss: 0.6645 Acc: 0.8880\n",
      "Epoch 553/1499\n",
      "----------\n",
      "train Loss: 0.6537 Acc: 0.8967\n",
      "val Loss: 0.6567 Acc: 0.8840\n",
      "test Loss: 0.6587 Acc: 0.8960\n",
      "Epoch 554/1499\n",
      "----------\n",
      "train Loss: 0.6550 Acc: 0.8962\n",
      "val Loss: 0.6516 Acc: 0.8880\n",
      "test Loss: 0.6616 Acc: 0.8960\n",
      "Epoch 555/1499\n",
      "----------\n",
      "train Loss: 0.6543 Acc: 0.8956\n",
      "val Loss: 0.6603 Acc: 0.8960\n",
      "test Loss: 0.6558 Acc: 0.8920\n",
      "Epoch 556/1499\n",
      "----------\n",
      "train Loss: 0.6561 Acc: 0.8936\n",
      "val Loss: 0.6494 Acc: 0.9000\n",
      "test Loss: 0.6595 Acc: 0.8920\n",
      "Epoch 557/1499\n",
      "----------\n",
      "train Loss: 0.6534 Acc: 0.8947\n",
      "val Loss: 0.6558 Acc: 0.9000\n",
      "test Loss: 0.6601 Acc: 0.8920\n",
      "Epoch 558/1499\n",
      "----------\n",
      "train Loss: 0.6529 Acc: 0.8953\n",
      "val Loss: 0.6584 Acc: 0.8880\n",
      "test Loss: 0.6562 Acc: 0.8960\n",
      "Epoch 559/1499\n",
      "----------\n",
      "train Loss: 0.6532 Acc: 0.8964\n",
      "val Loss: 0.6508 Acc: 0.9040\n",
      "test Loss: 0.6583 Acc: 0.8920\n",
      "Epoch 560/1499\n",
      "----------\n",
      "train Loss: 0.6549 Acc: 0.8947\n",
      "val Loss: 0.6510 Acc: 0.9040\n",
      "test Loss: 0.6588 Acc: 0.8960\n",
      "Epoch 561/1499\n",
      "----------\n",
      "train Loss: 0.6518 Acc: 0.8996\n",
      "val Loss: 0.6538 Acc: 0.8960\n",
      "test Loss: 0.6570 Acc: 0.8960\n",
      "Epoch 562/1499\n",
      "----------\n",
      "train Loss: 0.6534 Acc: 0.8953\n",
      "val Loss: 0.6535 Acc: 0.8960\n",
      "test Loss: 0.6581 Acc: 0.8960\n",
      "Epoch 563/1499\n",
      "----------\n",
      "train Loss: 0.6540 Acc: 0.8953\n",
      "val Loss: 0.6527 Acc: 0.9000\n",
      "test Loss: 0.6607 Acc: 0.9000\n",
      "Epoch 564/1499\n",
      "----------\n",
      "train Loss: 0.6535 Acc: 0.8944\n",
      "val Loss: 0.6593 Acc: 0.8880\n",
      "test Loss: 0.6587 Acc: 0.8960\n",
      "Epoch 565/1499\n",
      "----------\n",
      "train Loss: 0.6541 Acc: 0.8962\n",
      "val Loss: 0.6530 Acc: 0.8920\n",
      "test Loss: 0.6586 Acc: 0.9000\n",
      "Epoch 566/1499\n",
      "----------\n",
      "train Loss: 0.6530 Acc: 0.8956\n",
      "val Loss: 0.6576 Acc: 0.8920\n",
      "test Loss: 0.6590 Acc: 0.9000\n",
      "Epoch 567/1499\n",
      "----------\n",
      "train Loss: 0.6534 Acc: 0.8967\n",
      "val Loss: 0.6563 Acc: 0.9080\n",
      "test Loss: 0.6609 Acc: 0.8960\n",
      "Epoch 568/1499\n",
      "----------\n",
      "train Loss: 0.6528 Acc: 0.8951\n",
      "val Loss: 0.6542 Acc: 0.9000\n",
      "test Loss: 0.6610 Acc: 0.8920\n",
      "Epoch 569/1499\n",
      "----------\n",
      "train Loss: 0.6529 Acc: 0.8953\n",
      "val Loss: 0.6619 Acc: 0.8840\n",
      "test Loss: 0.6632 Acc: 0.8960\n",
      "Epoch 570/1499\n",
      "----------\n",
      "train Loss: 0.6539 Acc: 0.8960\n",
      "val Loss: 0.6553 Acc: 0.8920\n",
      "test Loss: 0.6613 Acc: 0.8920\n",
      "Epoch 571/1499\n",
      "----------\n",
      "train Loss: 0.6528 Acc: 0.8982\n",
      "val Loss: 0.6559 Acc: 0.8960\n",
      "test Loss: 0.6567 Acc: 0.9000\n",
      "Epoch 572/1499\n",
      "----------\n",
      "train Loss: 0.6537 Acc: 0.8929\n",
      "val Loss: 0.6520 Acc: 0.9080\n",
      "test Loss: 0.6606 Acc: 0.8920\n",
      "Epoch 573/1499\n",
      "----------\n",
      "train Loss: 0.6539 Acc: 0.8947\n",
      "val Loss: 0.6530 Acc: 0.8960\n",
      "test Loss: 0.6635 Acc: 0.8920\n",
      "Epoch 574/1499\n",
      "----------\n",
      "train Loss: 0.6522 Acc: 0.8991\n",
      "val Loss: 0.6566 Acc: 0.8880\n",
      "test Loss: 0.6636 Acc: 0.9000\n",
      "Epoch 575/1499\n",
      "----------\n",
      "train Loss: 0.6526 Acc: 0.8976\n",
      "val Loss: 0.6596 Acc: 0.8960\n",
      "test Loss: 0.6589 Acc: 0.8960\n",
      "Epoch 576/1499\n",
      "----------\n",
      "train Loss: 0.6546 Acc: 0.8913\n",
      "val Loss: 0.6558 Acc: 0.8960\n",
      "test Loss: 0.6609 Acc: 0.8920\n",
      "Epoch 577/1499\n",
      "----------\n",
      "train Loss: 0.6532 Acc: 0.8953\n",
      "val Loss: 0.6594 Acc: 0.8920\n",
      "test Loss: 0.6586 Acc: 0.8960\n",
      "Epoch 578/1499\n",
      "----------\n",
      "train Loss: 0.6535 Acc: 0.8940\n",
      "val Loss: 0.6517 Acc: 0.9040\n",
      "test Loss: 0.6582 Acc: 0.9000\n",
      "Epoch 579/1499\n",
      "----------\n",
      "train Loss: 0.6527 Acc: 0.8953\n",
      "val Loss: 0.6566 Acc: 0.8960\n",
      "test Loss: 0.6558 Acc: 0.9000\n",
      "Epoch 580/1499\n",
      "----------\n",
      "train Loss: 0.6533 Acc: 0.8949\n",
      "val Loss: 0.6553 Acc: 0.8920\n",
      "test Loss: 0.6533 Acc: 0.9000\n",
      "Epoch 581/1499\n",
      "----------\n",
      "train Loss: 0.6527 Acc: 0.8960\n",
      "val Loss: 0.6570 Acc: 0.9000\n",
      "test Loss: 0.6606 Acc: 0.8920\n",
      "Epoch 582/1499\n",
      "----------\n",
      "train Loss: 0.6528 Acc: 0.8973\n",
      "val Loss: 0.6558 Acc: 0.9000\n",
      "test Loss: 0.6608 Acc: 0.8880\n",
      "Epoch 583/1499\n",
      "----------\n",
      "train Loss: 0.6519 Acc: 0.8982\n",
      "val Loss: 0.6552 Acc: 0.9040\n",
      "test Loss: 0.6624 Acc: 0.8880\n",
      "Epoch 584/1499\n",
      "----------\n",
      "train Loss: 0.6506 Acc: 0.8989\n",
      "val Loss: 0.6508 Acc: 0.9040\n",
      "test Loss: 0.6572 Acc: 0.8920\n",
      "Epoch 585/1499\n",
      "----------\n",
      "train Loss: 0.6526 Acc: 0.8964\n",
      "val Loss: 0.6542 Acc: 0.8960\n",
      "test Loss: 0.6575 Acc: 0.8960\n",
      "Epoch 586/1499\n",
      "----------\n",
      "train Loss: 0.6507 Acc: 0.8969\n",
      "val Loss: 0.6516 Acc: 0.9000\n",
      "test Loss: 0.6583 Acc: 0.8960\n",
      "Epoch 587/1499\n",
      "----------\n",
      "train Loss: 0.6520 Acc: 0.8953\n",
      "val Loss: 0.6643 Acc: 0.8960\n",
      "test Loss: 0.6590 Acc: 0.9000\n",
      "Epoch 588/1499\n",
      "----------\n",
      "train Loss: 0.6533 Acc: 0.8947\n",
      "val Loss: 0.6546 Acc: 0.8960\n",
      "test Loss: 0.6598 Acc: 0.8920\n",
      "Epoch 589/1499\n",
      "----------\n",
      "train Loss: 0.6530 Acc: 0.8951\n",
      "val Loss: 0.6608 Acc: 0.8960\n",
      "test Loss: 0.6604 Acc: 0.8880\n",
      "Epoch 590/1499\n",
      "----------\n",
      "train Loss: 0.6545 Acc: 0.8931\n",
      "val Loss: 0.6537 Acc: 0.8920\n",
      "test Loss: 0.6597 Acc: 0.8960\n",
      "Epoch 591/1499\n",
      "----------\n",
      "train Loss: 0.6520 Acc: 0.8940\n",
      "val Loss: 0.6489 Acc: 0.9120\n",
      "test Loss: 0.6563 Acc: 0.9000\n",
      "Epoch 592/1499\n",
      "----------\n",
      "train Loss: 0.6533 Acc: 0.8953\n",
      "val Loss: 0.6506 Acc: 0.9040\n",
      "test Loss: 0.6613 Acc: 0.8880\n",
      "Epoch 593/1499\n",
      "----------\n",
      "train Loss: 0.6517 Acc: 0.8953\n",
      "val Loss: 0.6587 Acc: 0.9040\n",
      "test Loss: 0.6602 Acc: 0.9000\n",
      "Epoch 594/1499\n",
      "----------\n",
      "train Loss: 0.6525 Acc: 0.8947\n",
      "val Loss: 0.6513 Acc: 0.9040\n",
      "test Loss: 0.6585 Acc: 0.8960\n",
      "Epoch 595/1499\n",
      "----------\n",
      "train Loss: 0.6521 Acc: 0.8956\n",
      "val Loss: 0.6542 Acc: 0.8960\n",
      "test Loss: 0.6576 Acc: 0.9000\n",
      "Epoch 596/1499\n",
      "----------\n",
      "train Loss: 0.6521 Acc: 0.8967\n",
      "val Loss: 0.6546 Acc: 0.8960\n",
      "test Loss: 0.6564 Acc: 0.8920\n",
      "Epoch 597/1499\n",
      "----------\n",
      "train Loss: 0.6527 Acc: 0.8962\n",
      "val Loss: 0.6543 Acc: 0.9040\n",
      "test Loss: 0.6661 Acc: 0.8920\n",
      "Epoch 598/1499\n",
      "----------\n",
      "train Loss: 0.6506 Acc: 0.8973\n",
      "val Loss: 0.6523 Acc: 0.9000\n",
      "test Loss: 0.6518 Acc: 0.9000\n",
      "Epoch 599/1499\n",
      "----------\n",
      "train Loss: 0.6512 Acc: 0.8973\n",
      "val Loss: 0.6495 Acc: 0.9000\n",
      "test Loss: 0.6560 Acc: 0.9000\n",
      "Epoch 600/1499\n",
      "----------\n",
      "train Loss: 0.6517 Acc: 0.8967\n",
      "val Loss: 0.6482 Acc: 0.9000\n",
      "test Loss: 0.6629 Acc: 0.8960\n",
      "Epoch 601/1499\n",
      "----------\n",
      "train Loss: 0.6527 Acc: 0.8969\n",
      "val Loss: 0.6558 Acc: 0.9080\n",
      "test Loss: 0.6583 Acc: 0.9040\n",
      "Epoch 602/1499\n",
      "----------\n",
      "train Loss: 0.6519 Acc: 0.8980\n",
      "val Loss: 0.6574 Acc: 0.8840\n",
      "test Loss: 0.6574 Acc: 0.9000\n",
      "Epoch 603/1499\n",
      "----------\n",
      "train Loss: 0.6518 Acc: 0.8964\n",
      "val Loss: 0.6582 Acc: 0.8960\n",
      "test Loss: 0.6548 Acc: 0.9000\n",
      "Epoch 604/1499\n",
      "----------\n",
      "train Loss: 0.6526 Acc: 0.8956\n",
      "val Loss: 0.6533 Acc: 0.8960\n",
      "test Loss: 0.6603 Acc: 0.9000\n",
      "Epoch 605/1499\n",
      "----------\n",
      "train Loss: 0.6508 Acc: 0.8976\n",
      "val Loss: 0.6511 Acc: 0.9040\n",
      "test Loss: 0.6640 Acc: 0.8920\n",
      "Epoch 606/1499\n",
      "----------\n",
      "train Loss: 0.6522 Acc: 0.8982\n",
      "val Loss: 0.6596 Acc: 0.9000\n",
      "test Loss: 0.6569 Acc: 0.9000\n",
      "Epoch 607/1499\n",
      "----------\n",
      "train Loss: 0.6512 Acc: 0.8982\n",
      "val Loss: 0.6579 Acc: 0.8920\n",
      "test Loss: 0.6553 Acc: 0.9040\n",
      "Epoch 608/1499\n",
      "----------\n",
      "train Loss: 0.6512 Acc: 0.8984\n",
      "val Loss: 0.6542 Acc: 0.8960\n",
      "test Loss: 0.6600 Acc: 0.8960\n",
      "Epoch 609/1499\n",
      "----------\n",
      "train Loss: 0.6506 Acc: 0.8971\n",
      "val Loss: 0.6561 Acc: 0.9000\n",
      "test Loss: 0.6595 Acc: 0.8960\n",
      "Epoch 610/1499\n",
      "----------\n",
      "train Loss: 0.6524 Acc: 0.8936\n",
      "val Loss: 0.6525 Acc: 0.8960\n",
      "test Loss: 0.6602 Acc: 0.8880\n",
      "Epoch 611/1499\n",
      "----------\n",
      "train Loss: 0.6510 Acc: 0.8964\n",
      "val Loss: 0.6487 Acc: 0.9040\n",
      "test Loss: 0.6532 Acc: 0.9040\n",
      "Epoch 612/1499\n",
      "----------\n",
      "train Loss: 0.6510 Acc: 0.8993\n",
      "val Loss: 0.6587 Acc: 0.8920\n",
      "test Loss: 0.6572 Acc: 0.8960\n",
      "Epoch 613/1499\n",
      "----------\n",
      "train Loss: 0.6518 Acc: 0.8969\n",
      "val Loss: 0.6470 Acc: 0.9080\n",
      "test Loss: 0.6647 Acc: 0.8880\n",
      "Epoch 614/1499\n",
      "----------\n",
      "train Loss: 0.6517 Acc: 0.8962\n",
      "val Loss: 0.6525 Acc: 0.8960\n",
      "test Loss: 0.6557 Acc: 0.8960\n",
      "Epoch 615/1499\n",
      "----------\n",
      "train Loss: 0.6507 Acc: 0.8976\n",
      "val Loss: 0.6562 Acc: 0.8920\n",
      "test Loss: 0.6606 Acc: 0.8840\n",
      "Epoch 616/1499\n",
      "----------\n",
      "train Loss: 0.6505 Acc: 0.8967\n",
      "val Loss: 0.6480 Acc: 0.9080\n",
      "test Loss: 0.6586 Acc: 0.8960\n",
      "Epoch 617/1499\n",
      "----------\n",
      "train Loss: 0.6510 Acc: 0.8996\n",
      "val Loss: 0.6528 Acc: 0.9040\n",
      "test Loss: 0.6557 Acc: 0.9000\n",
      "Epoch 618/1499\n",
      "----------\n",
      "train Loss: 0.6507 Acc: 0.8978\n",
      "val Loss: 0.6557 Acc: 0.8960\n",
      "test Loss: 0.6585 Acc: 0.9000\n",
      "Epoch 619/1499\n",
      "----------\n",
      "train Loss: 0.6503 Acc: 0.8989\n",
      "val Loss: 0.6526 Acc: 0.9040\n",
      "test Loss: 0.6627 Acc: 0.8840\n",
      "Epoch 620/1499\n",
      "----------\n",
      "train Loss: 0.6499 Acc: 0.8980\n",
      "val Loss: 0.6530 Acc: 0.8960\n",
      "test Loss: 0.6622 Acc: 0.8960\n",
      "Epoch 621/1499\n",
      "----------\n",
      "train Loss: 0.6513 Acc: 0.8947\n",
      "val Loss: 0.6538 Acc: 0.8960\n",
      "test Loss: 0.6585 Acc: 0.8960\n",
      "Epoch 622/1499\n",
      "----------\n",
      "train Loss: 0.6503 Acc: 0.8958\n",
      "val Loss: 0.6553 Acc: 0.8960\n",
      "test Loss: 0.6595 Acc: 0.8960\n",
      "Epoch 623/1499\n",
      "----------\n",
      "train Loss: 0.6512 Acc: 0.8980\n",
      "val Loss: 0.6537 Acc: 0.9000\n",
      "test Loss: 0.6556 Acc: 0.8960\n",
      "Epoch 624/1499\n",
      "----------\n",
      "train Loss: 0.6497 Acc: 0.8989\n",
      "val Loss: 0.6544 Acc: 0.8960\n",
      "test Loss: 0.6538 Acc: 0.9000\n",
      "Epoch 625/1499\n",
      "----------\n",
      "train Loss: 0.6508 Acc: 0.8973\n",
      "val Loss: 0.6493 Acc: 0.9120\n",
      "test Loss: 0.6552 Acc: 0.8960\n",
      "Epoch 626/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6494 Acc: 0.8998\n",
      "val Loss: 0.6566 Acc: 0.9000\n",
      "test Loss: 0.6574 Acc: 0.9000\n",
      "Epoch 627/1499\n",
      "----------\n",
      "train Loss: 0.6490 Acc: 0.8989\n",
      "val Loss: 0.6539 Acc: 0.9040\n",
      "test Loss: 0.6568 Acc: 0.8960\n",
      "Epoch 628/1499\n",
      "----------\n",
      "train Loss: 0.6485 Acc: 0.9000\n",
      "val Loss: 0.6526 Acc: 0.9000\n",
      "test Loss: 0.6560 Acc: 0.8920\n",
      "Epoch 629/1499\n",
      "----------\n",
      "train Loss: 0.6509 Acc: 0.8984\n",
      "val Loss: 0.6504 Acc: 0.9040\n",
      "test Loss: 0.6606 Acc: 0.9000\n",
      "Epoch 630/1499\n",
      "----------\n",
      "train Loss: 0.6501 Acc: 0.8998\n",
      "val Loss: 0.6529 Acc: 0.9080\n",
      "test Loss: 0.6560 Acc: 0.8960\n",
      "Epoch 631/1499\n",
      "----------\n",
      "train Loss: 0.6497 Acc: 0.9000\n",
      "val Loss: 0.6513 Acc: 0.9000\n",
      "test Loss: 0.6598 Acc: 0.8920\n",
      "Epoch 632/1499\n",
      "----------\n",
      "train Loss: 0.6494 Acc: 0.8971\n",
      "val Loss: 0.6503 Acc: 0.9000\n",
      "test Loss: 0.6567 Acc: 0.8960\n",
      "Epoch 633/1499\n",
      "----------\n",
      "train Loss: 0.6495 Acc: 0.8989\n",
      "val Loss: 0.6547 Acc: 0.9040\n",
      "test Loss: 0.6604 Acc: 0.8880\n",
      "Epoch 634/1499\n",
      "----------\n",
      "train Loss: 0.6496 Acc: 0.9009\n",
      "val Loss: 0.6557 Acc: 0.8960\n",
      "test Loss: 0.6604 Acc: 0.8880\n",
      "Epoch 635/1499\n",
      "----------\n",
      "train Loss: 0.6486 Acc: 0.9013\n",
      "val Loss: 0.6521 Acc: 0.9000\n",
      "test Loss: 0.6576 Acc: 0.8960\n",
      "Epoch 636/1499\n",
      "----------\n",
      "train Loss: 0.6500 Acc: 0.8978\n",
      "val Loss: 0.6539 Acc: 0.8960\n",
      "test Loss: 0.6600 Acc: 0.8960\n",
      "Epoch 637/1499\n",
      "----------\n",
      "train Loss: 0.6487 Acc: 0.8993\n",
      "val Loss: 0.6529 Acc: 0.9040\n",
      "test Loss: 0.6599 Acc: 0.8920\n",
      "Epoch 638/1499\n",
      "----------\n",
      "train Loss: 0.6490 Acc: 0.9033\n",
      "val Loss: 0.6589 Acc: 0.8960\n",
      "test Loss: 0.6612 Acc: 0.8920\n",
      "Epoch 639/1499\n",
      "----------\n",
      "train Loss: 0.6487 Acc: 0.9000\n",
      "val Loss: 0.6510 Acc: 0.9040\n",
      "test Loss: 0.6576 Acc: 0.9000\n",
      "Epoch 640/1499\n",
      "----------\n",
      "train Loss: 0.6505 Acc: 0.8987\n",
      "val Loss: 0.6532 Acc: 0.9040\n",
      "test Loss: 0.6591 Acc: 0.8920\n",
      "Epoch 641/1499\n",
      "----------\n",
      "train Loss: 0.6495 Acc: 0.8987\n",
      "val Loss: 0.6522 Acc: 0.9000\n",
      "test Loss: 0.6597 Acc: 0.8960\n",
      "Epoch 642/1499\n",
      "----------\n",
      "train Loss: 0.6496 Acc: 0.8980\n",
      "val Loss: 0.6500 Acc: 0.8960\n",
      "test Loss: 0.6572 Acc: 0.9000\n",
      "Epoch 643/1499\n",
      "----------\n",
      "train Loss: 0.6489 Acc: 0.9007\n",
      "val Loss: 0.6487 Acc: 0.9040\n",
      "test Loss: 0.6578 Acc: 0.8960\n",
      "Epoch 644/1499\n",
      "----------\n",
      "train Loss: 0.6488 Acc: 0.9016\n",
      "val Loss: 0.6475 Acc: 0.9000\n",
      "test Loss: 0.6550 Acc: 0.8960\n",
      "Epoch 645/1499\n",
      "----------\n",
      "train Loss: 0.6490 Acc: 0.8993\n",
      "val Loss: 0.6464 Acc: 0.9000\n",
      "test Loss: 0.6559 Acc: 0.9000\n",
      "Epoch 646/1499\n",
      "----------\n",
      "train Loss: 0.6483 Acc: 0.8993\n",
      "val Loss: 0.6506 Acc: 0.9040\n",
      "test Loss: 0.6582 Acc: 0.8880\n",
      "Epoch 647/1499\n",
      "----------\n",
      "train Loss: 0.6482 Acc: 0.8998\n",
      "val Loss: 0.6528 Acc: 0.9000\n",
      "test Loss: 0.6544 Acc: 0.8960\n",
      "Epoch 648/1499\n",
      "----------\n",
      "train Loss: 0.6495 Acc: 0.8973\n",
      "val Loss: 0.6511 Acc: 0.9040\n",
      "test Loss: 0.6585 Acc: 0.9000\n",
      "Epoch 649/1499\n",
      "----------\n",
      "train Loss: 0.6487 Acc: 0.8998\n",
      "val Loss: 0.6520 Acc: 0.8960\n",
      "test Loss: 0.6547 Acc: 0.9000\n",
      "Epoch 650/1499\n",
      "----------\n",
      "train Loss: 0.6488 Acc: 0.9016\n",
      "val Loss: 0.6475 Acc: 0.9080\n",
      "test Loss: 0.6574 Acc: 0.9000\n",
      "Epoch 651/1499\n",
      "----------\n",
      "train Loss: 0.6483 Acc: 0.8998\n",
      "val Loss: 0.6509 Acc: 0.9040\n",
      "test Loss: 0.6538 Acc: 0.9040\n",
      "Epoch 652/1499\n",
      "----------\n",
      "train Loss: 0.6511 Acc: 0.8956\n",
      "val Loss: 0.6513 Acc: 0.9000\n",
      "test Loss: 0.6583 Acc: 0.8920\n",
      "Epoch 653/1499\n",
      "----------\n",
      "train Loss: 0.6484 Acc: 0.8989\n",
      "val Loss: 0.6494 Acc: 0.9040\n",
      "test Loss: 0.6540 Acc: 0.8960\n",
      "Epoch 654/1499\n",
      "----------\n",
      "train Loss: 0.6478 Acc: 0.9013\n",
      "val Loss: 0.6441 Acc: 0.9120\n",
      "test Loss: 0.6551 Acc: 0.9000\n",
      "Epoch 655/1499\n",
      "----------\n",
      "train Loss: 0.6484 Acc: 0.8980\n",
      "val Loss: 0.6515 Acc: 0.9080\n",
      "test Loss: 0.6564 Acc: 0.8960\n",
      "Epoch 656/1499\n",
      "----------\n",
      "train Loss: 0.6482 Acc: 0.9007\n",
      "val Loss: 0.6507 Acc: 0.9000\n",
      "test Loss: 0.6603 Acc: 0.8960\n",
      "Epoch 657/1499\n",
      "----------\n",
      "train Loss: 0.6480 Acc: 0.9009\n",
      "val Loss: 0.6491 Acc: 0.9040\n",
      "test Loss: 0.6612 Acc: 0.9040\n",
      "Epoch 658/1499\n",
      "----------\n",
      "train Loss: 0.6493 Acc: 0.9009\n",
      "val Loss: 0.6514 Acc: 0.9000\n",
      "test Loss: 0.6592 Acc: 0.8960\n",
      "Epoch 659/1499\n",
      "----------\n",
      "train Loss: 0.6488 Acc: 0.8978\n",
      "val Loss: 0.6489 Acc: 0.9000\n",
      "test Loss: 0.6528 Acc: 0.9000\n",
      "Epoch 660/1499\n",
      "----------\n",
      "train Loss: 0.6485 Acc: 0.8993\n",
      "val Loss: 0.6577 Acc: 0.8960\n",
      "test Loss: 0.6570 Acc: 0.9000\n",
      "Epoch 661/1499\n",
      "----------\n",
      "train Loss: 0.6464 Acc: 0.9033\n",
      "val Loss: 0.6528 Acc: 0.9000\n",
      "test Loss: 0.6601 Acc: 0.8960\n",
      "Epoch 662/1499\n",
      "----------\n",
      "train Loss: 0.6471 Acc: 0.9013\n",
      "val Loss: 0.6473 Acc: 0.9000\n",
      "test Loss: 0.6594 Acc: 0.9000\n",
      "Epoch 663/1499\n",
      "----------\n",
      "train Loss: 0.6484 Acc: 0.8980\n",
      "val Loss: 0.6503 Acc: 0.9040\n",
      "test Loss: 0.6527 Acc: 0.9040\n",
      "Epoch 664/1499\n",
      "----------\n",
      "train Loss: 0.6464 Acc: 0.9033\n",
      "val Loss: 0.6532 Acc: 0.9040\n",
      "test Loss: 0.6585 Acc: 0.8880\n",
      "Epoch 665/1499\n",
      "----------\n",
      "train Loss: 0.6487 Acc: 0.9002\n",
      "val Loss: 0.6494 Acc: 0.9000\n",
      "test Loss: 0.6608 Acc: 0.8960\n",
      "Epoch 666/1499\n",
      "----------\n",
      "train Loss: 0.6481 Acc: 0.9011\n",
      "val Loss: 0.6462 Acc: 0.9080\n",
      "test Loss: 0.6577 Acc: 0.8960\n",
      "Epoch 667/1499\n",
      "----------\n",
      "train Loss: 0.6476 Acc: 0.8993\n",
      "val Loss: 0.6500 Acc: 0.8960\n",
      "test Loss: 0.6583 Acc: 0.8960\n",
      "Epoch 668/1499\n",
      "----------\n",
      "train Loss: 0.6482 Acc: 0.9013\n",
      "val Loss: 0.6527 Acc: 0.9000\n",
      "test Loss: 0.6598 Acc: 0.8880\n",
      "Epoch 669/1499\n",
      "----------\n",
      "train Loss: 0.6481 Acc: 0.9007\n",
      "val Loss: 0.6476 Acc: 0.9040\n",
      "test Loss: 0.6574 Acc: 0.8960\n",
      "Epoch 670/1499\n",
      "----------\n",
      "train Loss: 0.6474 Acc: 0.9002\n",
      "val Loss: 0.6518 Acc: 0.8920\n",
      "test Loss: 0.6593 Acc: 0.8920\n",
      "Epoch 671/1499\n",
      "----------\n",
      "train Loss: 0.6472 Acc: 0.9016\n",
      "val Loss: 0.6464 Acc: 0.9120\n",
      "test Loss: 0.6576 Acc: 0.8960\n",
      "Epoch 672/1499\n",
      "----------\n",
      "train Loss: 0.6481 Acc: 0.9000\n",
      "val Loss: 0.6485 Acc: 0.9120\n",
      "test Loss: 0.6575 Acc: 0.8960\n",
      "Epoch 673/1499\n",
      "----------\n",
      "train Loss: 0.6481 Acc: 0.9024\n",
      "val Loss: 0.6455 Acc: 0.9080\n",
      "test Loss: 0.6592 Acc: 0.8920\n",
      "Epoch 674/1499\n",
      "----------\n",
      "train Loss: 0.6471 Acc: 0.9009\n",
      "val Loss: 0.6483 Acc: 0.9080\n",
      "test Loss: 0.6556 Acc: 0.9000\n",
      "Epoch 675/1499\n",
      "----------\n",
      "train Loss: 0.6473 Acc: 0.9009\n",
      "val Loss: 0.6534 Acc: 0.8920\n",
      "test Loss: 0.6594 Acc: 0.8920\n",
      "Epoch 676/1499\n",
      "----------\n",
      "train Loss: 0.6474 Acc: 0.9036\n",
      "val Loss: 0.6465 Acc: 0.9000\n",
      "test Loss: 0.6560 Acc: 0.9000\n",
      "Epoch 677/1499\n",
      "----------\n",
      "train Loss: 0.6481 Acc: 0.8989\n",
      "val Loss: 0.6509 Acc: 0.9000\n",
      "test Loss: 0.6602 Acc: 0.8960\n",
      "Epoch 678/1499\n",
      "----------\n",
      "train Loss: 0.6475 Acc: 0.9040\n",
      "val Loss: 0.6517 Acc: 0.8960\n",
      "test Loss: 0.6578 Acc: 0.9000\n",
      "Epoch 679/1499\n",
      "----------\n",
      "train Loss: 0.6482 Acc: 0.8998\n",
      "val Loss: 0.6499 Acc: 0.8960\n",
      "test Loss: 0.6595 Acc: 0.8960\n",
      "Epoch 680/1499\n",
      "----------\n",
      "train Loss: 0.6473 Acc: 0.9002\n",
      "val Loss: 0.6486 Acc: 0.9080\n",
      "test Loss: 0.6567 Acc: 0.8920\n",
      "Epoch 681/1499\n",
      "----------\n",
      "train Loss: 0.6488 Acc: 0.8998\n",
      "val Loss: 0.6400 Acc: 0.9160\n",
      "test Loss: 0.6562 Acc: 0.9000\n",
      "Epoch 682/1499\n",
      "----------\n",
      "train Loss: 0.6470 Acc: 0.9016\n",
      "val Loss: 0.6519 Acc: 0.9080\n",
      "test Loss: 0.6594 Acc: 0.8920\n",
      "Epoch 683/1499\n",
      "----------\n",
      "train Loss: 0.6469 Acc: 0.9047\n",
      "val Loss: 0.6501 Acc: 0.9120\n",
      "test Loss: 0.6574 Acc: 0.8960\n",
      "Epoch 684/1499\n",
      "----------\n",
      "train Loss: 0.6466 Acc: 0.9002\n",
      "val Loss: 0.6482 Acc: 0.9080\n",
      "test Loss: 0.6588 Acc: 0.8960\n",
      "Epoch 685/1499\n",
      "----------\n",
      "train Loss: 0.6465 Acc: 0.9042\n",
      "val Loss: 0.6512 Acc: 0.9000\n",
      "test Loss: 0.6579 Acc: 0.8960\n",
      "Epoch 686/1499\n",
      "----------\n",
      "train Loss: 0.6453 Acc: 0.9053\n",
      "val Loss: 0.6527 Acc: 0.9000\n",
      "test Loss: 0.6575 Acc: 0.8880\n",
      "Epoch 687/1499\n",
      "----------\n",
      "train Loss: 0.6468 Acc: 0.9038\n",
      "val Loss: 0.6546 Acc: 0.8960\n",
      "test Loss: 0.6549 Acc: 0.8920\n",
      "Epoch 688/1499\n",
      "----------\n",
      "train Loss: 0.6464 Acc: 0.9031\n",
      "val Loss: 0.6499 Acc: 0.9000\n",
      "test Loss: 0.6542 Acc: 0.9000\n",
      "Epoch 689/1499\n",
      "----------\n",
      "train Loss: 0.6482 Acc: 0.9002\n",
      "val Loss: 0.6509 Acc: 0.8960\n",
      "test Loss: 0.6550 Acc: 0.8960\n",
      "Epoch 690/1499\n",
      "----------\n",
      "train Loss: 0.6461 Acc: 0.9036\n",
      "val Loss: 0.6418 Acc: 0.9120\n",
      "test Loss: 0.6588 Acc: 0.8920\n",
      "Epoch 691/1499\n",
      "----------\n",
      "train Loss: 0.6468 Acc: 0.9011\n",
      "val Loss: 0.6491 Acc: 0.9000\n",
      "test Loss: 0.6567 Acc: 0.8880\n",
      "Epoch 692/1499\n",
      "----------\n",
      "train Loss: 0.6474 Acc: 0.9024\n",
      "val Loss: 0.6470 Acc: 0.9120\n",
      "test Loss: 0.6601 Acc: 0.9000\n",
      "Epoch 693/1499\n",
      "----------\n",
      "train Loss: 0.6463 Acc: 0.9036\n",
      "val Loss: 0.6518 Acc: 0.9040\n",
      "test Loss: 0.6555 Acc: 0.9000\n",
      "Epoch 694/1499\n",
      "----------\n",
      "train Loss: 0.6481 Acc: 0.9011\n",
      "val Loss: 0.6512 Acc: 0.9000\n",
      "test Loss: 0.6573 Acc: 0.8960\n",
      "Epoch 695/1499\n",
      "----------\n",
      "train Loss: 0.6471 Acc: 0.9024\n",
      "val Loss: 0.6510 Acc: 0.8880\n",
      "test Loss: 0.6595 Acc: 0.8920\n",
      "Epoch 696/1499\n",
      "----------\n",
      "train Loss: 0.6478 Acc: 0.9011\n",
      "val Loss: 0.6481 Acc: 0.9040\n",
      "test Loss: 0.6572 Acc: 0.9000\n",
      "Epoch 697/1499\n",
      "----------\n",
      "train Loss: 0.6452 Acc: 0.9029\n",
      "val Loss: 0.6502 Acc: 0.9000\n",
      "test Loss: 0.6548 Acc: 0.8960\n",
      "Epoch 698/1499\n",
      "----------\n",
      "train Loss: 0.6456 Acc: 0.9044\n",
      "val Loss: 0.6496 Acc: 0.9000\n",
      "test Loss: 0.6538 Acc: 0.9000\n",
      "Epoch 699/1499\n",
      "----------\n",
      "train Loss: 0.6453 Acc: 0.9033\n",
      "val Loss: 0.6477 Acc: 0.9000\n",
      "test Loss: 0.6558 Acc: 0.9000\n",
      "Epoch 700/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6459 Acc: 0.9042\n",
      "val Loss: 0.6488 Acc: 0.9040\n",
      "test Loss: 0.6541 Acc: 0.9000\n",
      "Epoch 701/1499\n",
      "----------\n",
      "train Loss: 0.6468 Acc: 0.9051\n",
      "val Loss: 0.6522 Acc: 0.9000\n",
      "test Loss: 0.6542 Acc: 0.8920\n",
      "Epoch 702/1499\n",
      "----------\n",
      "train Loss: 0.6476 Acc: 0.8996\n",
      "val Loss: 0.6462 Acc: 0.9080\n",
      "test Loss: 0.6553 Acc: 0.9000\n",
      "Epoch 703/1499\n",
      "----------\n",
      "train Loss: 0.6446 Acc: 0.9058\n",
      "val Loss: 0.6467 Acc: 0.9080\n",
      "test Loss: 0.6592 Acc: 0.8960\n",
      "Epoch 704/1499\n",
      "----------\n",
      "train Loss: 0.6471 Acc: 0.9024\n",
      "val Loss: 0.6492 Acc: 0.9040\n",
      "test Loss: 0.6537 Acc: 0.8920\n",
      "Epoch 705/1499\n",
      "----------\n",
      "train Loss: 0.6468 Acc: 0.9002\n",
      "val Loss: 0.6482 Acc: 0.9040\n",
      "test Loss: 0.6664 Acc: 0.8880\n",
      "Epoch 706/1499\n",
      "----------\n",
      "train Loss: 0.6449 Acc: 0.9038\n",
      "val Loss: 0.6497 Acc: 0.9000\n",
      "test Loss: 0.6594 Acc: 0.8880\n",
      "Epoch 707/1499\n",
      "----------\n",
      "train Loss: 0.6465 Acc: 0.9036\n",
      "val Loss: 0.6495 Acc: 0.9120\n",
      "test Loss: 0.6595 Acc: 0.8960\n",
      "Epoch 708/1499\n",
      "----------\n",
      "train Loss: 0.6450 Acc: 0.9031\n",
      "val Loss: 0.6532 Acc: 0.8960\n",
      "test Loss: 0.6572 Acc: 0.9000\n",
      "Epoch 709/1499\n",
      "----------\n",
      "train Loss: 0.6463 Acc: 0.9038\n",
      "val Loss: 0.6523 Acc: 0.8880\n",
      "test Loss: 0.6532 Acc: 0.9000\n",
      "Epoch 710/1499\n",
      "----------\n",
      "train Loss: 0.6460 Acc: 0.9038\n",
      "val Loss: 0.6517 Acc: 0.8920\n",
      "test Loss: 0.6580 Acc: 0.8960\n",
      "Epoch 711/1499\n",
      "----------\n",
      "train Loss: 0.6457 Acc: 0.9044\n",
      "val Loss: 0.6489 Acc: 0.9040\n",
      "test Loss: 0.6608 Acc: 0.8880\n",
      "Epoch 712/1499\n",
      "----------\n",
      "train Loss: 0.6462 Acc: 0.9020\n",
      "val Loss: 0.6495 Acc: 0.9000\n",
      "test Loss: 0.6550 Acc: 0.9000\n",
      "Epoch 713/1499\n",
      "----------\n",
      "train Loss: 0.6445 Acc: 0.9058\n",
      "val Loss: 0.6487 Acc: 0.9040\n",
      "test Loss: 0.6569 Acc: 0.8920\n",
      "Epoch 714/1499\n",
      "----------\n",
      "train Loss: 0.6455 Acc: 0.9024\n",
      "val Loss: 0.6528 Acc: 0.8960\n",
      "test Loss: 0.6566 Acc: 0.8920\n",
      "Epoch 715/1499\n",
      "----------\n",
      "train Loss: 0.6443 Acc: 0.9060\n",
      "val Loss: 0.6493 Acc: 0.8920\n",
      "test Loss: 0.6602 Acc: 0.8880\n",
      "Epoch 716/1499\n",
      "----------\n",
      "train Loss: 0.6449 Acc: 0.9049\n",
      "val Loss: 0.6504 Acc: 0.8920\n",
      "test Loss: 0.6561 Acc: 0.8960\n",
      "Epoch 717/1499\n",
      "----------\n",
      "train Loss: 0.6462 Acc: 0.9038\n",
      "val Loss: 0.6463 Acc: 0.9080\n",
      "test Loss: 0.6537 Acc: 0.9000\n",
      "Epoch 718/1499\n",
      "----------\n",
      "train Loss: 0.6446 Acc: 0.9038\n",
      "val Loss: 0.6481 Acc: 0.9000\n",
      "test Loss: 0.6554 Acc: 0.9000\n",
      "Epoch 719/1499\n",
      "----------\n",
      "train Loss: 0.6463 Acc: 0.9027\n",
      "val Loss: 0.6461 Acc: 0.9040\n",
      "test Loss: 0.6589 Acc: 0.8920\n",
      "Epoch 720/1499\n",
      "----------\n",
      "train Loss: 0.6443 Acc: 0.9051\n",
      "val Loss: 0.6539 Acc: 0.8920\n",
      "test Loss: 0.6607 Acc: 0.8960\n",
      "Epoch 721/1499\n",
      "----------\n",
      "train Loss: 0.6438 Acc: 0.9047\n",
      "val Loss: 0.6525 Acc: 0.9040\n",
      "test Loss: 0.6611 Acc: 0.8920\n",
      "Epoch 722/1499\n",
      "----------\n",
      "train Loss: 0.6442 Acc: 0.9069\n",
      "val Loss: 0.6529 Acc: 0.8960\n",
      "test Loss: 0.6539 Acc: 0.8880\n",
      "Epoch 723/1499\n",
      "----------\n",
      "train Loss: 0.6450 Acc: 0.9040\n",
      "val Loss: 0.6498 Acc: 0.9000\n",
      "test Loss: 0.6571 Acc: 0.8920\n",
      "Epoch 724/1499\n",
      "----------\n",
      "train Loss: 0.6436 Acc: 0.9058\n",
      "val Loss: 0.6508 Acc: 0.8960\n",
      "test Loss: 0.6580 Acc: 0.8960\n",
      "Epoch 725/1499\n",
      "----------\n",
      "train Loss: 0.6429 Acc: 0.9047\n",
      "val Loss: 0.6505 Acc: 0.8960\n",
      "test Loss: 0.6548 Acc: 0.9040\n",
      "Epoch 726/1499\n",
      "----------\n",
      "train Loss: 0.6448 Acc: 0.9058\n",
      "val Loss: 0.6487 Acc: 0.8920\n",
      "test Loss: 0.6575 Acc: 0.8960\n",
      "Epoch 727/1499\n",
      "----------\n",
      "train Loss: 0.6431 Acc: 0.9089\n",
      "val Loss: 0.6504 Acc: 0.9000\n",
      "test Loss: 0.6546 Acc: 0.8960\n",
      "Epoch 728/1499\n",
      "----------\n",
      "train Loss: 0.6454 Acc: 0.9022\n",
      "val Loss: 0.6513 Acc: 0.8920\n",
      "test Loss: 0.6586 Acc: 0.8880\n",
      "Epoch 729/1499\n",
      "----------\n",
      "train Loss: 0.6441 Acc: 0.9056\n",
      "val Loss: 0.6474 Acc: 0.9080\n",
      "test Loss: 0.6582 Acc: 0.9000\n",
      "Epoch 730/1499\n",
      "----------\n",
      "train Loss: 0.6449 Acc: 0.9056\n",
      "val Loss: 0.6510 Acc: 0.8960\n",
      "test Loss: 0.6578 Acc: 0.9000\n",
      "Epoch 731/1499\n",
      "----------\n",
      "train Loss: 0.6450 Acc: 0.9051\n",
      "val Loss: 0.6448 Acc: 0.9080\n",
      "test Loss: 0.6604 Acc: 0.8920\n",
      "Epoch 732/1499\n",
      "----------\n",
      "train Loss: 0.6443 Acc: 0.9067\n",
      "val Loss: 0.6487 Acc: 0.9000\n",
      "test Loss: 0.6597 Acc: 0.8960\n",
      "Epoch 733/1499\n",
      "----------\n",
      "train Loss: 0.6452 Acc: 0.9009\n",
      "val Loss: 0.6459 Acc: 0.9080\n",
      "test Loss: 0.6611 Acc: 0.8840\n",
      "Epoch 734/1499\n",
      "----------\n",
      "train Loss: 0.6437 Acc: 0.9080\n",
      "val Loss: 0.6492 Acc: 0.9000\n",
      "test Loss: 0.6573 Acc: 0.8960\n",
      "Epoch 735/1499\n",
      "----------\n",
      "train Loss: 0.6435 Acc: 0.9047\n",
      "val Loss: 0.6480 Acc: 0.8960\n",
      "test Loss: 0.6537 Acc: 0.9040\n",
      "Epoch 736/1499\n",
      "----------\n",
      "train Loss: 0.6448 Acc: 0.9036\n",
      "val Loss: 0.6435 Acc: 0.9080\n",
      "test Loss: 0.6608 Acc: 0.8880\n",
      "Epoch 737/1499\n",
      "----------\n",
      "train Loss: 0.6445 Acc: 0.9044\n",
      "val Loss: 0.6487 Acc: 0.9000\n",
      "test Loss: 0.6558 Acc: 0.8960\n",
      "Epoch 738/1499\n",
      "----------\n",
      "train Loss: 0.6450 Acc: 0.9040\n",
      "val Loss: 0.6496 Acc: 0.9120\n",
      "test Loss: 0.6528 Acc: 0.8960\n",
      "Epoch 739/1499\n",
      "----------\n",
      "train Loss: 0.6432 Acc: 0.9064\n",
      "val Loss: 0.6488 Acc: 0.9000\n",
      "test Loss: 0.6626 Acc: 0.8840\n",
      "Epoch 740/1499\n",
      "----------\n",
      "train Loss: 0.6434 Acc: 0.9080\n",
      "val Loss: 0.6481 Acc: 0.8960\n",
      "test Loss: 0.6610 Acc: 0.8840\n",
      "Epoch 741/1499\n",
      "----------\n",
      "train Loss: 0.6442 Acc: 0.9060\n",
      "val Loss: 0.6478 Acc: 0.8960\n",
      "test Loss: 0.6524 Acc: 0.8960\n",
      "Epoch 742/1499\n",
      "----------\n",
      "train Loss: 0.6427 Acc: 0.9049\n",
      "val Loss: 0.6475 Acc: 0.9040\n",
      "test Loss: 0.6532 Acc: 0.9000\n",
      "Epoch 743/1499\n",
      "----------\n",
      "train Loss: 0.6433 Acc: 0.9076\n",
      "val Loss: 0.6495 Acc: 0.9000\n",
      "test Loss: 0.6570 Acc: 0.9000\n",
      "Epoch 744/1499\n",
      "----------\n",
      "train Loss: 0.6433 Acc: 0.9084\n",
      "val Loss: 0.6497 Acc: 0.9000\n",
      "test Loss: 0.6551 Acc: 0.8960\n",
      "Epoch 745/1499\n",
      "----------\n",
      "train Loss: 0.6425 Acc: 0.9056\n",
      "val Loss: 0.6493 Acc: 0.8960\n",
      "test Loss: 0.6573 Acc: 0.8960\n",
      "Epoch 746/1499\n",
      "----------\n",
      "train Loss: 0.6440 Acc: 0.9042\n",
      "val Loss: 0.6480 Acc: 0.9000\n",
      "test Loss: 0.6556 Acc: 0.9040\n",
      "Epoch 747/1499\n",
      "----------\n",
      "train Loss: 0.6430 Acc: 0.9069\n",
      "val Loss: 0.6453 Acc: 0.9000\n",
      "test Loss: 0.6530 Acc: 0.9000\n",
      "Epoch 748/1499\n",
      "----------\n",
      "train Loss: 0.6428 Acc: 0.9053\n",
      "val Loss: 0.6419 Acc: 0.9000\n",
      "test Loss: 0.6581 Acc: 0.8960\n",
      "Epoch 749/1499\n",
      "----------\n",
      "train Loss: 0.6436 Acc: 0.9071\n",
      "val Loss: 0.6475 Acc: 0.9040\n",
      "test Loss: 0.6580 Acc: 0.8960\n",
      "Epoch 750/1499\n",
      "----------\n",
      "train Loss: 0.6428 Acc: 0.9073\n",
      "val Loss: 0.6565 Acc: 0.8960\n",
      "test Loss: 0.6607 Acc: 0.8960\n",
      "Epoch 751/1499\n",
      "----------\n",
      "train Loss: 0.6435 Acc: 0.9080\n",
      "val Loss: 0.6473 Acc: 0.9000\n",
      "test Loss: 0.6612 Acc: 0.8960\n",
      "Epoch 752/1499\n",
      "----------\n",
      "train Loss: 0.6432 Acc: 0.9064\n",
      "val Loss: 0.6484 Acc: 0.8920\n",
      "test Loss: 0.6589 Acc: 0.8920\n",
      "Epoch 753/1499\n",
      "----------\n",
      "train Loss: 0.6426 Acc: 0.9047\n",
      "val Loss: 0.6498 Acc: 0.8920\n",
      "test Loss: 0.6577 Acc: 0.8960\n",
      "Epoch 754/1499\n",
      "----------\n",
      "train Loss: 0.6436 Acc: 0.9080\n",
      "val Loss: 0.6517 Acc: 0.8840\n",
      "test Loss: 0.6564 Acc: 0.9040\n",
      "Epoch 755/1499\n",
      "----------\n",
      "train Loss: 0.6427 Acc: 0.9056\n",
      "val Loss: 0.6542 Acc: 0.8960\n",
      "test Loss: 0.6546 Acc: 0.8920\n",
      "Epoch 756/1499\n",
      "----------\n",
      "train Loss: 0.6432 Acc: 0.9049\n",
      "val Loss: 0.6473 Acc: 0.8960\n",
      "test Loss: 0.6525 Acc: 0.9000\n",
      "Epoch 757/1499\n",
      "----------\n",
      "train Loss: 0.6436 Acc: 0.9058\n",
      "val Loss: 0.6469 Acc: 0.8880\n",
      "test Loss: 0.6580 Acc: 0.8880\n",
      "Epoch 758/1499\n",
      "----------\n",
      "train Loss: 0.6434 Acc: 0.9053\n",
      "val Loss: 0.6487 Acc: 0.9040\n",
      "test Loss: 0.6554 Acc: 0.8960\n",
      "Epoch 759/1499\n",
      "----------\n",
      "train Loss: 0.6425 Acc: 0.9064\n",
      "val Loss: 0.6484 Acc: 0.8960\n",
      "test Loss: 0.6616 Acc: 0.8920\n",
      "Epoch 760/1499\n",
      "----------\n",
      "train Loss: 0.6432 Acc: 0.9058\n",
      "val Loss: 0.6530 Acc: 0.8840\n",
      "test Loss: 0.6536 Acc: 0.8960\n",
      "Epoch 761/1499\n",
      "----------\n",
      "train Loss: 0.6435 Acc: 0.9040\n",
      "val Loss: 0.6441 Acc: 0.9040\n",
      "test Loss: 0.6567 Acc: 0.8880\n",
      "Epoch 762/1499\n",
      "----------\n",
      "train Loss: 0.6416 Acc: 0.9084\n",
      "val Loss: 0.6489 Acc: 0.8960\n",
      "test Loss: 0.6584 Acc: 0.8920\n",
      "Epoch 763/1499\n",
      "----------\n",
      "train Loss: 0.6433 Acc: 0.9060\n",
      "val Loss: 0.6502 Acc: 0.8960\n",
      "test Loss: 0.6563 Acc: 0.8880\n",
      "Epoch 764/1499\n",
      "----------\n",
      "train Loss: 0.6422 Acc: 0.9062\n",
      "val Loss: 0.6566 Acc: 0.8880\n",
      "test Loss: 0.6547 Acc: 0.8960\n",
      "Epoch 765/1499\n",
      "----------\n",
      "train Loss: 0.6402 Acc: 0.9116\n",
      "val Loss: 0.6529 Acc: 0.8960\n",
      "test Loss: 0.6569 Acc: 0.9040\n",
      "Epoch 766/1499\n",
      "----------\n",
      "train Loss: 0.6417 Acc: 0.9078\n",
      "val Loss: 0.6444 Acc: 0.9040\n",
      "test Loss: 0.6575 Acc: 0.9000\n",
      "Epoch 767/1499\n",
      "----------\n",
      "train Loss: 0.6418 Acc: 0.9093\n",
      "val Loss: 0.6454 Acc: 0.9080\n",
      "test Loss: 0.6554 Acc: 0.8920\n",
      "Epoch 768/1499\n",
      "----------\n",
      "train Loss: 0.6421 Acc: 0.9098\n",
      "val Loss: 0.6457 Acc: 0.9040\n",
      "test Loss: 0.6541 Acc: 0.9040\n",
      "Epoch 769/1499\n",
      "----------\n",
      "train Loss: 0.6424 Acc: 0.9082\n",
      "val Loss: 0.6464 Acc: 0.9000\n",
      "test Loss: 0.6557 Acc: 0.9000\n",
      "Epoch 770/1499\n",
      "----------\n",
      "train Loss: 0.6424 Acc: 0.9080\n",
      "val Loss: 0.6472 Acc: 0.9000\n",
      "test Loss: 0.6550 Acc: 0.9000\n",
      "Epoch 771/1499\n",
      "----------\n",
      "train Loss: 0.6410 Acc: 0.9096\n",
      "val Loss: 0.6528 Acc: 0.8840\n",
      "test Loss: 0.6591 Acc: 0.8880\n",
      "Epoch 772/1499\n",
      "----------\n",
      "train Loss: 0.6433 Acc: 0.9078\n",
      "val Loss: 0.6468 Acc: 0.8960\n",
      "test Loss: 0.6591 Acc: 0.8960\n",
      "Epoch 773/1499\n",
      "----------\n",
      "train Loss: 0.6414 Acc: 0.9104\n",
      "val Loss: 0.6460 Acc: 0.9040\n",
      "test Loss: 0.6499 Acc: 0.8920\n",
      "Epoch 774/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6415 Acc: 0.9107\n",
      "val Loss: 0.6560 Acc: 0.8920\n",
      "test Loss: 0.6579 Acc: 0.8880\n",
      "Epoch 775/1499\n",
      "----------\n",
      "train Loss: 0.6412 Acc: 0.9109\n",
      "val Loss: 0.6496 Acc: 0.9000\n",
      "test Loss: 0.6519 Acc: 0.9040\n",
      "Epoch 776/1499\n",
      "----------\n",
      "train Loss: 0.6415 Acc: 0.9122\n",
      "val Loss: 0.6476 Acc: 0.8960\n",
      "test Loss: 0.6558 Acc: 0.8920\n",
      "Epoch 777/1499\n",
      "----------\n",
      "train Loss: 0.6422 Acc: 0.9084\n",
      "val Loss: 0.6487 Acc: 0.9000\n",
      "test Loss: 0.6589 Acc: 0.8880\n",
      "Epoch 778/1499\n",
      "----------\n",
      "train Loss: 0.6411 Acc: 0.9107\n",
      "val Loss: 0.6505 Acc: 0.8960\n",
      "test Loss: 0.6584 Acc: 0.8880\n",
      "Epoch 779/1499\n",
      "----------\n",
      "train Loss: 0.6419 Acc: 0.9109\n",
      "val Loss: 0.6506 Acc: 0.8920\n",
      "test Loss: 0.6616 Acc: 0.8920\n",
      "Epoch 780/1499\n",
      "----------\n",
      "train Loss: 0.6425 Acc: 0.9102\n",
      "val Loss: 0.6521 Acc: 0.8960\n",
      "test Loss: 0.6562 Acc: 0.8960\n",
      "Epoch 781/1499\n",
      "----------\n",
      "train Loss: 0.6416 Acc: 0.9087\n",
      "val Loss: 0.6475 Acc: 0.8960\n",
      "test Loss: 0.6558 Acc: 0.8960\n",
      "Epoch 782/1499\n",
      "----------\n",
      "train Loss: 0.6409 Acc: 0.9100\n",
      "val Loss: 0.6512 Acc: 0.8920\n",
      "test Loss: 0.6567 Acc: 0.8960\n",
      "Epoch 783/1499\n",
      "----------\n",
      "train Loss: 0.6415 Acc: 0.9089\n",
      "val Loss: 0.6493 Acc: 0.8880\n",
      "test Loss: 0.6577 Acc: 0.8960\n",
      "Epoch 784/1499\n",
      "----------\n",
      "train Loss: 0.6415 Acc: 0.9078\n",
      "val Loss: 0.6517 Acc: 0.8920\n",
      "test Loss: 0.6559 Acc: 0.8960\n",
      "Epoch 785/1499\n",
      "----------\n",
      "train Loss: 0.6410 Acc: 0.9118\n",
      "val Loss: 0.6451 Acc: 0.9040\n",
      "test Loss: 0.6560 Acc: 0.8960\n",
      "Epoch 786/1499\n",
      "----------\n",
      "train Loss: 0.6408 Acc: 0.9116\n",
      "val Loss: 0.6463 Acc: 0.9000\n",
      "test Loss: 0.6545 Acc: 0.8960\n",
      "Epoch 787/1499\n",
      "----------\n",
      "train Loss: 0.6414 Acc: 0.9089\n",
      "val Loss: 0.6499 Acc: 0.8960\n",
      "test Loss: 0.6542 Acc: 0.8960\n",
      "Epoch 788/1499\n",
      "----------\n",
      "train Loss: 0.6409 Acc: 0.9111\n",
      "val Loss: 0.6458 Acc: 0.9000\n",
      "test Loss: 0.6581 Acc: 0.8920\n",
      "Epoch 789/1499\n",
      "----------\n",
      "train Loss: 0.6412 Acc: 0.9098\n",
      "val Loss: 0.6490 Acc: 0.8920\n",
      "test Loss: 0.6583 Acc: 0.8960\n",
      "Epoch 790/1499\n",
      "----------\n",
      "train Loss: 0.6404 Acc: 0.9104\n",
      "val Loss: 0.6497 Acc: 0.8960\n",
      "test Loss: 0.6531 Acc: 0.8920\n",
      "Epoch 791/1499\n",
      "----------\n",
      "train Loss: 0.6411 Acc: 0.9082\n",
      "val Loss: 0.6432 Acc: 0.9040\n",
      "test Loss: 0.6548 Acc: 0.8960\n",
      "Epoch 792/1499\n",
      "----------\n",
      "train Loss: 0.6403 Acc: 0.9127\n",
      "val Loss: 0.6459 Acc: 0.8960\n",
      "test Loss: 0.6584 Acc: 0.8920\n",
      "Epoch 793/1499\n",
      "----------\n",
      "train Loss: 0.6407 Acc: 0.9098\n",
      "val Loss: 0.6454 Acc: 0.9000\n",
      "test Loss: 0.6560 Acc: 0.8960\n",
      "Epoch 794/1499\n",
      "----------\n",
      "train Loss: 0.6409 Acc: 0.9120\n",
      "val Loss: 0.6469 Acc: 0.8960\n",
      "test Loss: 0.6560 Acc: 0.8960\n",
      "Epoch 795/1499\n",
      "----------\n",
      "train Loss: 0.6426 Acc: 0.9093\n",
      "val Loss: 0.6478 Acc: 0.8960\n",
      "test Loss: 0.6559 Acc: 0.8960\n",
      "Epoch 796/1499\n",
      "----------\n",
      "train Loss: 0.6430 Acc: 0.9089\n",
      "val Loss: 0.6525 Acc: 0.8880\n",
      "test Loss: 0.6573 Acc: 0.8960\n",
      "Epoch 797/1499\n",
      "----------\n",
      "train Loss: 0.6406 Acc: 0.9100\n",
      "val Loss: 0.6504 Acc: 0.8960\n",
      "test Loss: 0.6566 Acc: 0.8920\n",
      "Epoch 798/1499\n",
      "----------\n",
      "train Loss: 0.6414 Acc: 0.9089\n",
      "val Loss: 0.6476 Acc: 0.8880\n",
      "test Loss: 0.6563 Acc: 0.8960\n",
      "Epoch 799/1499\n",
      "----------\n",
      "train Loss: 0.6408 Acc: 0.9124\n",
      "val Loss: 0.6465 Acc: 0.9080\n",
      "test Loss: 0.6563 Acc: 0.9000\n",
      "Epoch 800/1499\n",
      "----------\n",
      "train Loss: 0.6417 Acc: 0.9102\n",
      "val Loss: 0.6481 Acc: 0.8960\n",
      "test Loss: 0.6540 Acc: 0.8960\n",
      "Epoch 801/1499\n",
      "----------\n",
      "train Loss: 0.6407 Acc: 0.9098\n",
      "val Loss: 0.6465 Acc: 0.8960\n",
      "test Loss: 0.6540 Acc: 0.9000\n",
      "Epoch 802/1499\n",
      "----------\n",
      "train Loss: 0.6391 Acc: 0.9113\n",
      "val Loss: 0.6500 Acc: 0.8880\n",
      "test Loss: 0.6595 Acc: 0.8880\n",
      "Epoch 803/1499\n",
      "----------\n",
      "train Loss: 0.6412 Acc: 0.9124\n",
      "val Loss: 0.6439 Acc: 0.8960\n",
      "test Loss: 0.6631 Acc: 0.8800\n",
      "Epoch 804/1499\n",
      "----------\n",
      "train Loss: 0.6409 Acc: 0.9107\n",
      "val Loss: 0.6509 Acc: 0.8960\n",
      "test Loss: 0.6569 Acc: 0.8960\n",
      "Epoch 805/1499\n",
      "----------\n",
      "train Loss: 0.6411 Acc: 0.9118\n",
      "val Loss: 0.6541 Acc: 0.8960\n",
      "test Loss: 0.6525 Acc: 0.9040\n",
      "Epoch 806/1499\n",
      "----------\n",
      "train Loss: 0.6405 Acc: 0.9107\n",
      "val Loss: 0.6527 Acc: 0.8880\n",
      "test Loss: 0.6544 Acc: 0.8960\n",
      "Epoch 807/1499\n",
      "----------\n",
      "train Loss: 0.6396 Acc: 0.9127\n",
      "val Loss: 0.6455 Acc: 0.8920\n",
      "test Loss: 0.6619 Acc: 0.8960\n",
      "Epoch 808/1499\n",
      "----------\n",
      "train Loss: 0.6410 Acc: 0.9096\n",
      "val Loss: 0.6397 Acc: 0.9080\n",
      "test Loss: 0.6572 Acc: 0.8960\n",
      "Epoch 809/1499\n",
      "----------\n",
      "train Loss: 0.6410 Acc: 0.9093\n",
      "val Loss: 0.6449 Acc: 0.9000\n",
      "test Loss: 0.6555 Acc: 0.8920\n",
      "Epoch 810/1499\n",
      "----------\n",
      "train Loss: 0.6407 Acc: 0.9122\n",
      "val Loss: 0.6478 Acc: 0.8920\n",
      "test Loss: 0.6574 Acc: 0.8960\n",
      "Epoch 811/1499\n",
      "----------\n",
      "train Loss: 0.6413 Acc: 0.9107\n",
      "val Loss: 0.6481 Acc: 0.8880\n",
      "test Loss: 0.6550 Acc: 0.8960\n",
      "Epoch 812/1499\n",
      "----------\n",
      "train Loss: 0.6402 Acc: 0.9107\n",
      "val Loss: 0.6467 Acc: 0.9000\n",
      "test Loss: 0.6561 Acc: 0.8960\n",
      "Epoch 813/1499\n",
      "----------\n",
      "train Loss: 0.6406 Acc: 0.9138\n",
      "val Loss: 0.6465 Acc: 0.8960\n",
      "test Loss: 0.6552 Acc: 0.8960\n",
      "Epoch 814/1499\n",
      "----------\n",
      "train Loss: 0.6401 Acc: 0.9120\n",
      "val Loss: 0.6501 Acc: 0.8960\n",
      "test Loss: 0.6530 Acc: 0.8960\n",
      "Epoch 815/1499\n",
      "----------\n",
      "train Loss: 0.6404 Acc: 0.9111\n",
      "val Loss: 0.6492 Acc: 0.9000\n",
      "test Loss: 0.6534 Acc: 0.8960\n",
      "Epoch 816/1499\n",
      "----------\n",
      "train Loss: 0.6416 Acc: 0.9087\n",
      "val Loss: 0.6517 Acc: 0.8920\n",
      "test Loss: 0.6516 Acc: 0.8960\n",
      "Epoch 817/1499\n",
      "----------\n",
      "train Loss: 0.6418 Acc: 0.9111\n",
      "val Loss: 0.6482 Acc: 0.8920\n",
      "test Loss: 0.6554 Acc: 0.9000\n",
      "Epoch 818/1499\n",
      "----------\n",
      "train Loss: 0.6394 Acc: 0.9140\n",
      "val Loss: 0.6470 Acc: 0.9000\n",
      "test Loss: 0.6581 Acc: 0.8880\n",
      "Epoch 819/1499\n",
      "----------\n",
      "train Loss: 0.6403 Acc: 0.9111\n",
      "val Loss: 0.6483 Acc: 0.8920\n",
      "test Loss: 0.6541 Acc: 0.8960\n",
      "Epoch 820/1499\n",
      "----------\n",
      "train Loss: 0.6408 Acc: 0.9107\n",
      "val Loss: 0.6440 Acc: 0.9000\n",
      "test Loss: 0.6550 Acc: 0.8880\n",
      "Epoch 821/1499\n",
      "----------\n",
      "train Loss: 0.6403 Acc: 0.9127\n",
      "val Loss: 0.6472 Acc: 0.8960\n",
      "test Loss: 0.6536 Acc: 0.8960\n",
      "Epoch 822/1499\n",
      "----------\n",
      "train Loss: 0.6405 Acc: 0.9136\n",
      "val Loss: 0.6476 Acc: 0.8960\n",
      "test Loss: 0.6633 Acc: 0.8960\n",
      "Epoch 823/1499\n",
      "----------\n",
      "train Loss: 0.6391 Acc: 0.9120\n",
      "val Loss: 0.6493 Acc: 0.9000\n",
      "test Loss: 0.6575 Acc: 0.8960\n",
      "Epoch 824/1499\n",
      "----------\n",
      "train Loss: 0.6401 Acc: 0.9124\n",
      "val Loss: 0.6495 Acc: 0.9000\n",
      "test Loss: 0.6592 Acc: 0.8920\n",
      "Epoch 825/1499\n",
      "----------\n",
      "train Loss: 0.6398 Acc: 0.9116\n",
      "val Loss: 0.6471 Acc: 0.9080\n",
      "test Loss: 0.6539 Acc: 0.8960\n",
      "Epoch 826/1499\n",
      "----------\n",
      "train Loss: 0.6401 Acc: 0.9120\n",
      "val Loss: 0.6442 Acc: 0.9000\n",
      "test Loss: 0.6547 Acc: 0.8960\n",
      "Epoch 827/1499\n",
      "----------\n",
      "train Loss: 0.6395 Acc: 0.9131\n",
      "val Loss: 0.6448 Acc: 0.9000\n",
      "test Loss: 0.6522 Acc: 0.9040\n",
      "Epoch 828/1499\n",
      "----------\n",
      "train Loss: 0.6395 Acc: 0.9122\n",
      "val Loss: 0.6430 Acc: 0.8960\n",
      "test Loss: 0.6569 Acc: 0.8880\n",
      "Epoch 829/1499\n",
      "----------\n",
      "train Loss: 0.6390 Acc: 0.9133\n",
      "val Loss: 0.6434 Acc: 0.8960\n",
      "test Loss: 0.6577 Acc: 0.8960\n",
      "Epoch 830/1499\n",
      "----------\n",
      "train Loss: 0.6409 Acc: 0.9120\n",
      "val Loss: 0.6514 Acc: 0.8920\n",
      "test Loss: 0.6542 Acc: 0.8960\n",
      "Epoch 831/1499\n",
      "----------\n",
      "train Loss: 0.6413 Acc: 0.9107\n",
      "val Loss: 0.6438 Acc: 0.9000\n",
      "test Loss: 0.6554 Acc: 0.8960\n",
      "Epoch 832/1499\n",
      "----------\n",
      "train Loss: 0.6399 Acc: 0.9133\n",
      "val Loss: 0.6449 Acc: 0.9000\n",
      "test Loss: 0.6548 Acc: 0.8920\n",
      "Epoch 833/1499\n",
      "----------\n",
      "train Loss: 0.6389 Acc: 0.9144\n",
      "val Loss: 0.6475 Acc: 0.8920\n",
      "test Loss: 0.6562 Acc: 0.8920\n",
      "Epoch 834/1499\n",
      "----------\n",
      "train Loss: 0.6393 Acc: 0.9122\n",
      "val Loss: 0.6397 Acc: 0.9040\n",
      "test Loss: 0.6597 Acc: 0.8960\n",
      "Epoch 835/1499\n",
      "----------\n",
      "train Loss: 0.6409 Acc: 0.9127\n",
      "val Loss: 0.6428 Acc: 0.9080\n",
      "test Loss: 0.6568 Acc: 0.8920\n",
      "Epoch 836/1499\n",
      "----------\n",
      "train Loss: 0.6387 Acc: 0.9127\n",
      "val Loss: 0.6465 Acc: 0.8960\n",
      "test Loss: 0.6527 Acc: 0.8920\n",
      "Epoch 837/1499\n",
      "----------\n",
      "train Loss: 0.6395 Acc: 0.9118\n",
      "val Loss: 0.6460 Acc: 0.8920\n",
      "test Loss: 0.6563 Acc: 0.9000\n",
      "Epoch 838/1499\n",
      "----------\n",
      "train Loss: 0.6411 Acc: 0.9131\n",
      "val Loss: 0.6440 Acc: 0.9000\n",
      "test Loss: 0.6532 Acc: 0.9000\n",
      "Epoch 839/1499\n",
      "----------\n",
      "train Loss: 0.6397 Acc: 0.9113\n",
      "val Loss: 0.6489 Acc: 0.8920\n",
      "test Loss: 0.6542 Acc: 0.9000\n",
      "Epoch 840/1499\n",
      "----------\n",
      "train Loss: 0.6403 Acc: 0.9111\n",
      "val Loss: 0.6436 Acc: 0.8920\n",
      "test Loss: 0.6539 Acc: 0.8960\n",
      "Epoch 841/1499\n",
      "----------\n",
      "train Loss: 0.6394 Acc: 0.9124\n",
      "val Loss: 0.6442 Acc: 0.8920\n",
      "test Loss: 0.6538 Acc: 0.8960\n",
      "Epoch 842/1499\n",
      "----------\n",
      "train Loss: 0.6402 Acc: 0.9136\n",
      "val Loss: 0.6443 Acc: 0.8960\n",
      "test Loss: 0.6565 Acc: 0.8960\n",
      "Epoch 843/1499\n",
      "----------\n",
      "train Loss: 0.6401 Acc: 0.9120\n",
      "val Loss: 0.6428 Acc: 0.9000\n",
      "test Loss: 0.6513 Acc: 0.9000\n",
      "Epoch 844/1499\n",
      "----------\n",
      "train Loss: 0.6389 Acc: 0.9129\n",
      "val Loss: 0.6455 Acc: 0.9000\n",
      "test Loss: 0.6491 Acc: 0.9040\n",
      "Epoch 845/1499\n",
      "----------\n",
      "train Loss: 0.6387 Acc: 0.9133\n",
      "val Loss: 0.6465 Acc: 0.8920\n",
      "test Loss: 0.6576 Acc: 0.8960\n",
      "Epoch 846/1499\n",
      "----------\n",
      "train Loss: 0.6397 Acc: 0.9104\n",
      "val Loss: 0.6463 Acc: 0.9000\n",
      "test Loss: 0.6573 Acc: 0.9000\n",
      "Epoch 847/1499\n",
      "----------\n",
      "train Loss: 0.6393 Acc: 0.9122\n",
      "val Loss: 0.6500 Acc: 0.8960\n",
      "test Loss: 0.6563 Acc: 0.8960\n",
      "Epoch 848/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6400 Acc: 0.9127\n",
      "val Loss: 0.6432 Acc: 0.8960\n",
      "test Loss: 0.6531 Acc: 0.8960\n",
      "Epoch 849/1499\n",
      "----------\n",
      "train Loss: 0.6394 Acc: 0.9120\n",
      "val Loss: 0.6462 Acc: 0.9000\n",
      "test Loss: 0.6532 Acc: 0.8920\n",
      "Epoch 850/1499\n",
      "----------\n",
      "train Loss: 0.6402 Acc: 0.9133\n",
      "val Loss: 0.6458 Acc: 0.9000\n",
      "test Loss: 0.6517 Acc: 0.9040\n",
      "Epoch 851/1499\n",
      "----------\n",
      "train Loss: 0.6401 Acc: 0.9109\n",
      "val Loss: 0.6491 Acc: 0.8880\n",
      "test Loss: 0.6555 Acc: 0.8960\n",
      "Epoch 852/1499\n",
      "----------\n",
      "train Loss: 0.6395 Acc: 0.9120\n",
      "val Loss: 0.6476 Acc: 0.8920\n",
      "test Loss: 0.6576 Acc: 0.8960\n",
      "Epoch 853/1499\n",
      "----------\n",
      "train Loss: 0.6392 Acc: 0.9116\n",
      "val Loss: 0.6500 Acc: 0.9040\n",
      "test Loss: 0.6585 Acc: 0.8960\n",
      "Epoch 854/1499\n",
      "----------\n",
      "train Loss: 0.6397 Acc: 0.9131\n",
      "val Loss: 0.6479 Acc: 0.9000\n",
      "test Loss: 0.6514 Acc: 0.9000\n",
      "Epoch 855/1499\n",
      "----------\n",
      "train Loss: 0.6378 Acc: 0.9127\n",
      "val Loss: 0.6437 Acc: 0.9000\n",
      "test Loss: 0.6554 Acc: 0.8960\n",
      "Epoch 856/1499\n",
      "----------\n",
      "train Loss: 0.6399 Acc: 0.9113\n",
      "val Loss: 0.6474 Acc: 0.9000\n",
      "test Loss: 0.6551 Acc: 0.8920\n",
      "Epoch 857/1499\n",
      "----------\n",
      "train Loss: 0.6378 Acc: 0.9133\n",
      "val Loss: 0.6476 Acc: 0.9000\n",
      "test Loss: 0.6529 Acc: 0.9000\n",
      "Epoch 858/1499\n",
      "----------\n",
      "train Loss: 0.6389 Acc: 0.9131\n",
      "val Loss: 0.6470 Acc: 0.8920\n",
      "test Loss: 0.6557 Acc: 0.8960\n",
      "Epoch 859/1499\n",
      "----------\n",
      "train Loss: 0.6387 Acc: 0.9156\n",
      "val Loss: 0.6393 Acc: 0.9080\n",
      "test Loss: 0.6533 Acc: 0.9040\n",
      "Epoch 860/1499\n",
      "----------\n",
      "train Loss: 0.6393 Acc: 0.9138\n",
      "val Loss: 0.6458 Acc: 0.8960\n",
      "test Loss: 0.6567 Acc: 0.9000\n",
      "Epoch 861/1499\n",
      "----------\n",
      "train Loss: 0.6394 Acc: 0.9127\n",
      "val Loss: 0.6466 Acc: 0.8960\n",
      "test Loss: 0.6558 Acc: 0.8920\n",
      "Epoch 862/1499\n",
      "----------\n",
      "train Loss: 0.6395 Acc: 0.9133\n",
      "val Loss: 0.6534 Acc: 0.8880\n",
      "test Loss: 0.6544 Acc: 0.8960\n",
      "Epoch 863/1499\n",
      "----------\n",
      "train Loss: 0.6385 Acc: 0.9138\n",
      "val Loss: 0.6472 Acc: 0.9000\n",
      "test Loss: 0.6550 Acc: 0.8960\n",
      "Epoch 864/1499\n",
      "----------\n",
      "train Loss: 0.6388 Acc: 0.9116\n",
      "val Loss: 0.6507 Acc: 0.8960\n",
      "test Loss: 0.6543 Acc: 0.8960\n",
      "Epoch 865/1499\n",
      "----------\n",
      "train Loss: 0.6397 Acc: 0.9124\n",
      "val Loss: 0.6488 Acc: 0.8920\n",
      "test Loss: 0.6477 Acc: 0.9040\n",
      "Epoch 866/1499\n",
      "----------\n",
      "train Loss: 0.6382 Acc: 0.9142\n",
      "val Loss: 0.6474 Acc: 0.8960\n",
      "test Loss: 0.6505 Acc: 0.9000\n",
      "Epoch 867/1499\n",
      "----------\n",
      "train Loss: 0.6397 Acc: 0.9098\n",
      "val Loss: 0.6445 Acc: 0.9040\n",
      "test Loss: 0.6530 Acc: 0.8960\n",
      "Epoch 868/1499\n",
      "----------\n",
      "train Loss: 0.6403 Acc: 0.9107\n",
      "val Loss: 0.6420 Acc: 0.9040\n",
      "test Loss: 0.6540 Acc: 0.9000\n",
      "Epoch 869/1499\n",
      "----------\n",
      "train Loss: 0.6410 Acc: 0.9111\n",
      "val Loss: 0.6491 Acc: 0.8960\n",
      "test Loss: 0.6524 Acc: 0.8920\n",
      "Epoch 870/1499\n",
      "----------\n",
      "train Loss: 0.6387 Acc: 0.9116\n",
      "val Loss: 0.6507 Acc: 0.8960\n",
      "test Loss: 0.6539 Acc: 0.9000\n",
      "Epoch 871/1499\n",
      "----------\n",
      "train Loss: 0.6393 Acc: 0.9113\n",
      "val Loss: 0.6440 Acc: 0.8920\n",
      "test Loss: 0.6520 Acc: 0.8920\n",
      "Epoch 872/1499\n",
      "----------\n",
      "train Loss: 0.6391 Acc: 0.9147\n",
      "val Loss: 0.6453 Acc: 0.9040\n",
      "test Loss: 0.6480 Acc: 0.9080\n",
      "Epoch 873/1499\n",
      "----------\n",
      "train Loss: 0.6379 Acc: 0.9151\n",
      "val Loss: 0.6490 Acc: 0.8920\n",
      "test Loss: 0.6511 Acc: 0.9000\n",
      "Epoch 874/1499\n",
      "----------\n",
      "train Loss: 0.6379 Acc: 0.9140\n",
      "val Loss: 0.6484 Acc: 0.8960\n",
      "test Loss: 0.6556 Acc: 0.8920\n",
      "Epoch 875/1499\n",
      "----------\n",
      "train Loss: 0.6376 Acc: 0.9140\n",
      "val Loss: 0.6445 Acc: 0.8960\n",
      "test Loss: 0.6546 Acc: 0.9000\n",
      "Epoch 876/1499\n",
      "----------\n",
      "train Loss: 0.6381 Acc: 0.9140\n",
      "val Loss: 0.6430 Acc: 0.9040\n",
      "test Loss: 0.6525 Acc: 0.9000\n",
      "Epoch 877/1499\n",
      "----------\n",
      "train Loss: 0.6406 Acc: 0.9116\n",
      "val Loss: 0.6474 Acc: 0.9000\n",
      "test Loss: 0.6483 Acc: 0.9040\n",
      "Epoch 878/1499\n",
      "----------\n",
      "train Loss: 0.6389 Acc: 0.9138\n",
      "val Loss: 0.6471 Acc: 0.8920\n",
      "test Loss: 0.6521 Acc: 0.9040\n",
      "Epoch 879/1499\n",
      "----------\n",
      "train Loss: 0.6382 Acc: 0.9138\n",
      "val Loss: 0.6444 Acc: 0.9080\n",
      "test Loss: 0.6500 Acc: 0.9000\n",
      "Epoch 880/1499\n",
      "----------\n",
      "train Loss: 0.6376 Acc: 0.9153\n",
      "val Loss: 0.6461 Acc: 0.8960\n",
      "test Loss: 0.6542 Acc: 0.9040\n",
      "Epoch 881/1499\n",
      "----------\n",
      "train Loss: 0.6387 Acc: 0.9142\n",
      "val Loss: 0.6482 Acc: 0.9000\n",
      "test Loss: 0.6557 Acc: 0.9000\n",
      "Epoch 882/1499\n",
      "----------\n",
      "train Loss: 0.6391 Acc: 0.9133\n",
      "val Loss: 0.6473 Acc: 0.8920\n",
      "test Loss: 0.6523 Acc: 0.9000\n",
      "Epoch 883/1499\n",
      "----------\n",
      "train Loss: 0.6375 Acc: 0.9149\n",
      "val Loss: 0.6513 Acc: 0.9000\n",
      "test Loss: 0.6578 Acc: 0.8960\n",
      "Epoch 884/1499\n",
      "----------\n",
      "train Loss: 0.6374 Acc: 0.9156\n",
      "val Loss: 0.6428 Acc: 0.8920\n",
      "test Loss: 0.6542 Acc: 0.8920\n",
      "Epoch 885/1499\n",
      "----------\n",
      "train Loss: 0.6380 Acc: 0.9142\n",
      "val Loss: 0.6453 Acc: 0.9040\n",
      "test Loss: 0.6528 Acc: 0.8960\n",
      "Epoch 886/1499\n",
      "----------\n",
      "train Loss: 0.6397 Acc: 0.9147\n",
      "val Loss: 0.6458 Acc: 0.9000\n",
      "test Loss: 0.6572 Acc: 0.8920\n",
      "Epoch 887/1499\n",
      "----------\n",
      "train Loss: 0.6392 Acc: 0.9136\n",
      "val Loss: 0.6457 Acc: 0.9040\n",
      "test Loss: 0.6537 Acc: 0.8960\n",
      "Epoch 888/1499\n",
      "----------\n",
      "train Loss: 0.6371 Acc: 0.9144\n",
      "val Loss: 0.6412 Acc: 0.9080\n",
      "test Loss: 0.6516 Acc: 0.9040\n",
      "Epoch 889/1499\n",
      "----------\n",
      "train Loss: 0.6388 Acc: 0.9122\n",
      "val Loss: 0.6473 Acc: 0.8960\n",
      "test Loss: 0.6501 Acc: 0.9000\n",
      "Epoch 890/1499\n",
      "----------\n",
      "train Loss: 0.6379 Acc: 0.9138\n",
      "val Loss: 0.6419 Acc: 0.9080\n",
      "test Loss: 0.6492 Acc: 0.8960\n",
      "Epoch 891/1499\n",
      "----------\n",
      "train Loss: 0.6389 Acc: 0.9127\n",
      "val Loss: 0.6476 Acc: 0.9040\n",
      "test Loss: 0.6503 Acc: 0.8960\n",
      "Epoch 892/1499\n",
      "----------\n",
      "train Loss: 0.6381 Acc: 0.9142\n",
      "val Loss: 0.6446 Acc: 0.9080\n",
      "test Loss: 0.6508 Acc: 0.9000\n",
      "Epoch 893/1499\n",
      "----------\n",
      "train Loss: 0.6382 Acc: 0.9120\n",
      "val Loss: 0.6425 Acc: 0.9040\n",
      "test Loss: 0.6544 Acc: 0.8880\n",
      "Epoch 894/1499\n",
      "----------\n",
      "train Loss: 0.6388 Acc: 0.9147\n",
      "val Loss: 0.6452 Acc: 0.9080\n",
      "test Loss: 0.6513 Acc: 0.9040\n",
      "Epoch 895/1499\n",
      "----------\n",
      "train Loss: 0.6374 Acc: 0.9138\n",
      "val Loss: 0.6419 Acc: 0.9040\n",
      "test Loss: 0.6511 Acc: 0.8960\n",
      "Epoch 896/1499\n",
      "----------\n",
      "train Loss: 0.6390 Acc: 0.9144\n",
      "val Loss: 0.6417 Acc: 0.8960\n",
      "test Loss: 0.6542 Acc: 0.9000\n",
      "Epoch 897/1499\n",
      "----------\n",
      "train Loss: 0.6378 Acc: 0.9160\n",
      "val Loss: 0.6480 Acc: 0.8960\n",
      "test Loss: 0.6514 Acc: 0.8960\n",
      "Epoch 898/1499\n",
      "----------\n",
      "train Loss: 0.6379 Acc: 0.9144\n",
      "val Loss: 0.6464 Acc: 0.9000\n",
      "test Loss: 0.6525 Acc: 0.8960\n",
      "Epoch 899/1499\n",
      "----------\n",
      "train Loss: 0.6374 Acc: 0.9140\n",
      "val Loss: 0.6464 Acc: 0.9000\n",
      "test Loss: 0.6547 Acc: 0.9040\n",
      "Epoch 900/1499\n",
      "----------\n",
      "train Loss: 0.6382 Acc: 0.9133\n",
      "val Loss: 0.6404 Acc: 0.9040\n",
      "test Loss: 0.6532 Acc: 0.9000\n",
      "Epoch 901/1499\n",
      "----------\n",
      "train Loss: 0.6373 Acc: 0.9138\n",
      "val Loss: 0.6443 Acc: 0.9080\n",
      "test Loss: 0.6534 Acc: 0.8960\n",
      "Epoch 902/1499\n",
      "----------\n",
      "train Loss: 0.6386 Acc: 0.9129\n",
      "val Loss: 0.6432 Acc: 0.9000\n",
      "test Loss: 0.6534 Acc: 0.8960\n",
      "Epoch 903/1499\n",
      "----------\n",
      "train Loss: 0.6381 Acc: 0.9127\n",
      "val Loss: 0.6406 Acc: 0.9000\n",
      "test Loss: 0.6535 Acc: 0.9040\n",
      "Epoch 904/1499\n",
      "----------\n",
      "train Loss: 0.6384 Acc: 0.9129\n",
      "val Loss: 0.6443 Acc: 0.8960\n",
      "test Loss: 0.6537 Acc: 0.8960\n",
      "Epoch 905/1499\n",
      "----------\n",
      "train Loss: 0.6374 Acc: 0.9144\n",
      "val Loss: 0.6380 Acc: 0.9040\n",
      "test Loss: 0.6525 Acc: 0.8960\n",
      "Epoch 906/1499\n",
      "----------\n",
      "train Loss: 0.6379 Acc: 0.9129\n",
      "val Loss: 0.6459 Acc: 0.9000\n",
      "test Loss: 0.6548 Acc: 0.8960\n",
      "Epoch 907/1499\n",
      "----------\n",
      "train Loss: 0.6382 Acc: 0.9144\n",
      "val Loss: 0.6419 Acc: 0.9000\n",
      "test Loss: 0.6527 Acc: 0.8960\n",
      "Epoch 908/1499\n",
      "----------\n",
      "train Loss: 0.6385 Acc: 0.9151\n",
      "val Loss: 0.6437 Acc: 0.9040\n",
      "test Loss: 0.6511 Acc: 0.8960\n",
      "Epoch 909/1499\n",
      "----------\n",
      "train Loss: 0.6378 Acc: 0.9133\n",
      "val Loss: 0.6442 Acc: 0.9080\n",
      "test Loss: 0.6512 Acc: 0.9000\n",
      "Epoch 910/1499\n",
      "----------\n",
      "train Loss: 0.6381 Acc: 0.9124\n",
      "val Loss: 0.6431 Acc: 0.9120\n",
      "test Loss: 0.6490 Acc: 0.9000\n",
      "Epoch 911/1499\n",
      "----------\n",
      "train Loss: 0.6379 Acc: 0.9133\n",
      "val Loss: 0.6416 Acc: 0.9120\n",
      "test Loss: 0.6519 Acc: 0.9000\n",
      "Epoch 912/1499\n",
      "----------\n",
      "train Loss: 0.6377 Acc: 0.9142\n",
      "val Loss: 0.6446 Acc: 0.9080\n",
      "test Loss: 0.6531 Acc: 0.8920\n",
      "Epoch 913/1499\n",
      "----------\n",
      "train Loss: 0.6384 Acc: 0.9147\n",
      "val Loss: 0.6419 Acc: 0.9080\n",
      "test Loss: 0.6538 Acc: 0.8960\n",
      "Epoch 914/1499\n",
      "----------\n",
      "train Loss: 0.6377 Acc: 0.9116\n",
      "val Loss: 0.6444 Acc: 0.9080\n",
      "test Loss: 0.6563 Acc: 0.8960\n",
      "Epoch 915/1499\n",
      "----------\n",
      "train Loss: 0.6376 Acc: 0.9131\n",
      "val Loss: 0.6482 Acc: 0.9000\n",
      "test Loss: 0.6565 Acc: 0.9000\n",
      "Epoch 916/1499\n",
      "----------\n",
      "train Loss: 0.6386 Acc: 0.9136\n",
      "val Loss: 0.6428 Acc: 0.9080\n",
      "test Loss: 0.6573 Acc: 0.9000\n",
      "Epoch 917/1499\n",
      "----------\n",
      "train Loss: 0.6380 Acc: 0.9147\n",
      "val Loss: 0.6457 Acc: 0.9040\n",
      "test Loss: 0.6543 Acc: 0.8960\n",
      "Epoch 918/1499\n",
      "----------\n",
      "train Loss: 0.6381 Acc: 0.9140\n",
      "val Loss: 0.6411 Acc: 0.9080\n",
      "test Loss: 0.6503 Acc: 0.9000\n",
      "Epoch 919/1499\n",
      "----------\n",
      "train Loss: 0.6377 Acc: 0.9140\n",
      "val Loss: 0.6455 Acc: 0.9080\n",
      "test Loss: 0.6556 Acc: 0.8960\n",
      "Epoch 920/1499\n",
      "----------\n",
      "train Loss: 0.6379 Acc: 0.9142\n",
      "val Loss: 0.6432 Acc: 0.9080\n",
      "test Loss: 0.6487 Acc: 0.9040\n",
      "Epoch 921/1499\n",
      "----------\n",
      "train Loss: 0.6365 Acc: 0.9156\n",
      "val Loss: 0.6395 Acc: 0.9120\n",
      "test Loss: 0.6530 Acc: 0.8960\n",
      "Epoch 922/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6375 Acc: 0.9127\n",
      "val Loss: 0.6512 Acc: 0.8960\n",
      "test Loss: 0.6486 Acc: 0.9000\n",
      "Epoch 923/1499\n",
      "----------\n",
      "train Loss: 0.6381 Acc: 0.9127\n",
      "val Loss: 0.6451 Acc: 0.8960\n",
      "test Loss: 0.6512 Acc: 0.9000\n",
      "Epoch 924/1499\n",
      "----------\n",
      "train Loss: 0.6375 Acc: 0.9133\n",
      "val Loss: 0.6443 Acc: 0.9080\n",
      "test Loss: 0.6526 Acc: 0.8920\n",
      "Epoch 925/1499\n",
      "----------\n",
      "train Loss: 0.6371 Acc: 0.9144\n",
      "val Loss: 0.6477 Acc: 0.9000\n",
      "test Loss: 0.6523 Acc: 0.8960\n",
      "Epoch 926/1499\n",
      "----------\n",
      "train Loss: 0.6364 Acc: 0.9149\n",
      "val Loss: 0.6405 Acc: 0.9080\n",
      "test Loss: 0.6541 Acc: 0.9000\n",
      "Epoch 927/1499\n",
      "----------\n",
      "train Loss: 0.6367 Acc: 0.9156\n",
      "val Loss: 0.6373 Acc: 0.9080\n",
      "test Loss: 0.6518 Acc: 0.9000\n",
      "Epoch 928/1499\n",
      "----------\n",
      "train Loss: 0.6356 Acc: 0.9167\n",
      "val Loss: 0.6484 Acc: 0.9000\n",
      "test Loss: 0.6523 Acc: 0.8960\n",
      "Epoch 929/1499\n",
      "----------\n",
      "train Loss: 0.6385 Acc: 0.9118\n",
      "val Loss: 0.6455 Acc: 0.8920\n",
      "test Loss: 0.6460 Acc: 0.9000\n",
      "Epoch 930/1499\n",
      "----------\n",
      "train Loss: 0.6366 Acc: 0.9149\n",
      "val Loss: 0.6462 Acc: 0.9080\n",
      "test Loss: 0.6529 Acc: 0.9000\n",
      "Epoch 931/1499\n",
      "----------\n",
      "train Loss: 0.6363 Acc: 0.9144\n",
      "val Loss: 0.6456 Acc: 0.9080\n",
      "test Loss: 0.6529 Acc: 0.8960\n",
      "Epoch 932/1499\n",
      "----------\n",
      "train Loss: 0.6364 Acc: 0.9156\n",
      "val Loss: 0.6498 Acc: 0.9000\n",
      "test Loss: 0.6530 Acc: 0.8920\n",
      "Epoch 933/1499\n",
      "----------\n",
      "train Loss: 0.6371 Acc: 0.9133\n",
      "val Loss: 0.6445 Acc: 0.8960\n",
      "test Loss: 0.6547 Acc: 0.9000\n",
      "Epoch 934/1499\n",
      "----------\n",
      "train Loss: 0.6366 Acc: 0.9147\n",
      "val Loss: 0.6452 Acc: 0.9000\n",
      "test Loss: 0.6545 Acc: 0.8920\n",
      "Epoch 935/1499\n",
      "----------\n",
      "train Loss: 0.6361 Acc: 0.9171\n",
      "val Loss: 0.6437 Acc: 0.9040\n",
      "test Loss: 0.6580 Acc: 0.8920\n",
      "Epoch 936/1499\n",
      "----------\n",
      "train Loss: 0.6364 Acc: 0.9151\n",
      "val Loss: 0.6435 Acc: 0.9120\n",
      "test Loss: 0.6526 Acc: 0.9000\n",
      "Epoch 937/1499\n",
      "----------\n",
      "train Loss: 0.6362 Acc: 0.9160\n",
      "val Loss: 0.6430 Acc: 0.9120\n",
      "test Loss: 0.6527 Acc: 0.9000\n",
      "Epoch 938/1499\n",
      "----------\n",
      "train Loss: 0.6367 Acc: 0.9164\n",
      "val Loss: 0.6476 Acc: 0.8960\n",
      "test Loss: 0.6514 Acc: 0.9040\n",
      "Epoch 939/1499\n",
      "----------\n",
      "train Loss: 0.6369 Acc: 0.9140\n",
      "val Loss: 0.6442 Acc: 0.9040\n",
      "test Loss: 0.6565 Acc: 0.9000\n",
      "Epoch 940/1499\n",
      "----------\n",
      "train Loss: 0.6367 Acc: 0.9147\n",
      "val Loss: 0.6383 Acc: 0.9040\n",
      "test Loss: 0.6504 Acc: 0.8920\n",
      "Epoch 941/1499\n",
      "----------\n",
      "train Loss: 0.6361 Acc: 0.9153\n",
      "val Loss: 0.6399 Acc: 0.9040\n",
      "test Loss: 0.6508 Acc: 0.8960\n",
      "Epoch 942/1499\n",
      "----------\n",
      "train Loss: 0.6365 Acc: 0.9162\n",
      "val Loss: 0.6432 Acc: 0.9040\n",
      "test Loss: 0.6537 Acc: 0.8960\n",
      "Epoch 943/1499\n",
      "----------\n",
      "train Loss: 0.6353 Acc: 0.9171\n",
      "val Loss: 0.6411 Acc: 0.9080\n",
      "test Loss: 0.6526 Acc: 0.8960\n",
      "Epoch 944/1499\n",
      "----------\n",
      "train Loss: 0.6359 Acc: 0.9140\n",
      "val Loss: 0.6469 Acc: 0.9000\n",
      "test Loss: 0.6537 Acc: 0.9040\n",
      "Epoch 945/1499\n",
      "----------\n",
      "train Loss: 0.6365 Acc: 0.9173\n",
      "val Loss: 0.6495 Acc: 0.8920\n",
      "test Loss: 0.6539 Acc: 0.9000\n",
      "Epoch 946/1499\n",
      "----------\n",
      "train Loss: 0.6349 Acc: 0.9147\n",
      "val Loss: 0.6418 Acc: 0.9080\n",
      "test Loss: 0.6487 Acc: 0.8960\n",
      "Epoch 947/1499\n",
      "----------\n",
      "train Loss: 0.6359 Acc: 0.9169\n",
      "val Loss: 0.6448 Acc: 0.8960\n",
      "test Loss: 0.6511 Acc: 0.9000\n",
      "Epoch 948/1499\n",
      "----------\n",
      "train Loss: 0.6358 Acc: 0.9158\n",
      "val Loss: 0.6433 Acc: 0.9080\n",
      "test Loss: 0.6530 Acc: 0.9000\n",
      "Epoch 949/1499\n",
      "----------\n",
      "train Loss: 0.6375 Acc: 0.9162\n",
      "val Loss: 0.6439 Acc: 0.9040\n",
      "test Loss: 0.6543 Acc: 0.8960\n",
      "Epoch 950/1499\n",
      "----------\n",
      "train Loss: 0.6364 Acc: 0.9147\n",
      "val Loss: 0.6404 Acc: 0.9080\n",
      "test Loss: 0.6570 Acc: 0.8920\n",
      "Epoch 951/1499\n",
      "----------\n",
      "train Loss: 0.6364 Acc: 0.9149\n",
      "val Loss: 0.6448 Acc: 0.9040\n",
      "test Loss: 0.6478 Acc: 0.9040\n",
      "Epoch 952/1499\n",
      "----------\n",
      "train Loss: 0.6360 Acc: 0.9169\n",
      "val Loss: 0.6433 Acc: 0.9080\n",
      "test Loss: 0.6469 Acc: 0.9040\n",
      "Epoch 953/1499\n",
      "----------\n",
      "train Loss: 0.6358 Acc: 0.9169\n",
      "val Loss: 0.6445 Acc: 0.9040\n",
      "test Loss: 0.6551 Acc: 0.8960\n",
      "Epoch 954/1499\n",
      "----------\n",
      "train Loss: 0.6355 Acc: 0.9180\n",
      "val Loss: 0.6428 Acc: 0.9040\n",
      "test Loss: 0.6526 Acc: 0.8960\n",
      "Epoch 955/1499\n",
      "----------\n",
      "train Loss: 0.6373 Acc: 0.9138\n",
      "val Loss: 0.6431 Acc: 0.9080\n",
      "test Loss: 0.6483 Acc: 0.9000\n",
      "Epoch 956/1499\n",
      "----------\n",
      "train Loss: 0.6361 Acc: 0.9169\n",
      "val Loss: 0.6412 Acc: 0.9040\n",
      "test Loss: 0.6530 Acc: 0.9000\n",
      "Epoch 957/1499\n",
      "----------\n",
      "train Loss: 0.6354 Acc: 0.9171\n",
      "val Loss: 0.6447 Acc: 0.9040\n",
      "test Loss: 0.6515 Acc: 0.9040\n",
      "Epoch 958/1499\n",
      "----------\n",
      "train Loss: 0.6369 Acc: 0.9156\n",
      "val Loss: 0.6352 Acc: 0.9160\n",
      "test Loss: 0.6557 Acc: 0.9000\n",
      "Epoch 959/1499\n",
      "----------\n",
      "train Loss: 0.6362 Acc: 0.9156\n",
      "val Loss: 0.6462 Acc: 0.9040\n",
      "test Loss: 0.6514 Acc: 0.8960\n",
      "Epoch 960/1499\n",
      "----------\n",
      "train Loss: 0.6355 Acc: 0.9160\n",
      "val Loss: 0.6453 Acc: 0.9000\n",
      "test Loss: 0.6495 Acc: 0.9000\n",
      "Epoch 961/1499\n",
      "----------\n",
      "train Loss: 0.6361 Acc: 0.9153\n",
      "val Loss: 0.6434 Acc: 0.9080\n",
      "test Loss: 0.6549 Acc: 0.8960\n",
      "Epoch 962/1499\n",
      "----------\n",
      "train Loss: 0.6358 Acc: 0.9173\n",
      "val Loss: 0.6468 Acc: 0.8960\n",
      "test Loss: 0.6536 Acc: 0.9000\n",
      "Epoch 963/1499\n",
      "----------\n",
      "train Loss: 0.6357 Acc: 0.9176\n",
      "val Loss: 0.6453 Acc: 0.9040\n",
      "test Loss: 0.6494 Acc: 0.8960\n",
      "Epoch 964/1499\n",
      "----------\n",
      "train Loss: 0.6359 Acc: 0.9160\n",
      "val Loss: 0.6433 Acc: 0.9080\n",
      "test Loss: 0.6524 Acc: 0.8960\n",
      "Epoch 965/1499\n",
      "----------\n",
      "train Loss: 0.6359 Acc: 0.9140\n",
      "val Loss: 0.6417 Acc: 0.9040\n",
      "test Loss: 0.6497 Acc: 0.9000\n",
      "Epoch 966/1499\n",
      "----------\n",
      "train Loss: 0.6349 Acc: 0.9178\n",
      "val Loss: 0.6444 Acc: 0.9040\n",
      "test Loss: 0.6518 Acc: 0.8960\n",
      "Epoch 967/1499\n",
      "----------\n",
      "train Loss: 0.6354 Acc: 0.9178\n",
      "val Loss: 0.6435 Acc: 0.9040\n",
      "test Loss: 0.6506 Acc: 0.8960\n",
      "Epoch 968/1499\n",
      "----------\n",
      "train Loss: 0.6366 Acc: 0.9160\n",
      "val Loss: 0.6455 Acc: 0.9000\n",
      "test Loss: 0.6474 Acc: 0.8960\n",
      "Epoch 969/1499\n",
      "----------\n",
      "train Loss: 0.6355 Acc: 0.9153\n",
      "val Loss: 0.6427 Acc: 0.9080\n",
      "test Loss: 0.6506 Acc: 0.9000\n",
      "Epoch 970/1499\n",
      "----------\n",
      "train Loss: 0.6363 Acc: 0.9162\n",
      "val Loss: 0.6462 Acc: 0.9040\n",
      "test Loss: 0.6521 Acc: 0.8960\n",
      "Epoch 971/1499\n",
      "----------\n",
      "train Loss: 0.6347 Acc: 0.9180\n",
      "val Loss: 0.6431 Acc: 0.9040\n",
      "test Loss: 0.6558 Acc: 0.8920\n",
      "Epoch 972/1499\n",
      "----------\n",
      "train Loss: 0.6362 Acc: 0.9142\n",
      "val Loss: 0.6433 Acc: 0.9080\n",
      "test Loss: 0.6505 Acc: 0.9000\n",
      "Epoch 973/1499\n",
      "----------\n",
      "train Loss: 0.6356 Acc: 0.9156\n",
      "val Loss: 0.6436 Acc: 0.9000\n",
      "test Loss: 0.6504 Acc: 0.9040\n",
      "Epoch 974/1499\n",
      "----------\n",
      "train Loss: 0.6341 Acc: 0.9178\n",
      "val Loss: 0.6423 Acc: 0.9080\n",
      "test Loss: 0.6451 Acc: 0.9040\n",
      "Epoch 975/1499\n",
      "----------\n",
      "train Loss: 0.6360 Acc: 0.9178\n",
      "val Loss: 0.6389 Acc: 0.9160\n",
      "test Loss: 0.6513 Acc: 0.9000\n",
      "Epoch 976/1499\n",
      "----------\n",
      "train Loss: 0.6357 Acc: 0.9169\n",
      "val Loss: 0.6434 Acc: 0.8960\n",
      "test Loss: 0.6502 Acc: 0.9000\n",
      "Epoch 977/1499\n",
      "----------\n",
      "train Loss: 0.6357 Acc: 0.9164\n",
      "val Loss: 0.6392 Acc: 0.9080\n",
      "test Loss: 0.6500 Acc: 0.9000\n",
      "Epoch 978/1499\n",
      "----------\n",
      "train Loss: 0.6359 Acc: 0.9147\n",
      "val Loss: 0.6435 Acc: 0.9040\n",
      "test Loss: 0.6510 Acc: 0.9040\n",
      "Epoch 979/1499\n",
      "----------\n",
      "train Loss: 0.6358 Acc: 0.9182\n",
      "val Loss: 0.6418 Acc: 0.9120\n",
      "test Loss: 0.6555 Acc: 0.8920\n",
      "Epoch 980/1499\n",
      "----------\n",
      "train Loss: 0.6352 Acc: 0.9169\n",
      "val Loss: 0.6417 Acc: 0.9080\n",
      "test Loss: 0.6498 Acc: 0.9080\n",
      "Epoch 981/1499\n",
      "----------\n",
      "train Loss: 0.6341 Acc: 0.9178\n",
      "val Loss: 0.6368 Acc: 0.9080\n",
      "test Loss: 0.6464 Acc: 0.9000\n",
      "Epoch 982/1499\n",
      "----------\n",
      "train Loss: 0.6356 Acc: 0.9173\n",
      "val Loss: 0.6413 Acc: 0.9040\n",
      "test Loss: 0.6480 Acc: 0.9040\n",
      "Epoch 983/1499\n",
      "----------\n",
      "train Loss: 0.6363 Acc: 0.9156\n",
      "val Loss: 0.6432 Acc: 0.9000\n",
      "test Loss: 0.6476 Acc: 0.9000\n",
      "Epoch 984/1499\n",
      "----------\n",
      "train Loss: 0.6357 Acc: 0.9176\n",
      "val Loss: 0.6384 Acc: 0.9080\n",
      "test Loss: 0.6524 Acc: 0.8960\n",
      "Epoch 985/1499\n",
      "----------\n",
      "train Loss: 0.6358 Acc: 0.9140\n",
      "val Loss: 0.6418 Acc: 0.9040\n",
      "test Loss: 0.6507 Acc: 0.9000\n",
      "Epoch 986/1499\n",
      "----------\n",
      "train Loss: 0.6361 Acc: 0.9162\n",
      "val Loss: 0.6485 Acc: 0.8960\n",
      "test Loss: 0.6503 Acc: 0.8960\n",
      "Epoch 987/1499\n",
      "----------\n",
      "train Loss: 0.6362 Acc: 0.9149\n",
      "val Loss: 0.6415 Acc: 0.9120\n",
      "test Loss: 0.6471 Acc: 0.9040\n",
      "Epoch 988/1499\n",
      "----------\n",
      "train Loss: 0.6349 Acc: 0.9158\n",
      "val Loss: 0.6429 Acc: 0.9040\n",
      "test Loss: 0.6501 Acc: 0.9000\n",
      "Epoch 989/1499\n",
      "----------\n",
      "train Loss: 0.6344 Acc: 0.9167\n",
      "val Loss: 0.6438 Acc: 0.9080\n",
      "test Loss: 0.6509 Acc: 0.8960\n",
      "Epoch 990/1499\n",
      "----------\n",
      "train Loss: 0.6358 Acc: 0.9151\n",
      "val Loss: 0.6453 Acc: 0.9000\n",
      "test Loss: 0.6478 Acc: 0.9160\n",
      "Epoch 991/1499\n",
      "----------\n",
      "train Loss: 0.6360 Acc: 0.9164\n",
      "val Loss: 0.6440 Acc: 0.9040\n",
      "test Loss: 0.6494 Acc: 0.8960\n",
      "Epoch 992/1499\n",
      "----------\n",
      "train Loss: 0.6345 Acc: 0.9176\n",
      "val Loss: 0.6455 Acc: 0.9000\n",
      "test Loss: 0.6510 Acc: 0.8920\n",
      "Epoch 993/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6342 Acc: 0.9180\n",
      "val Loss: 0.6434 Acc: 0.9160\n",
      "test Loss: 0.6516 Acc: 0.8920\n",
      "Epoch 994/1499\n",
      "----------\n",
      "train Loss: 0.6350 Acc: 0.9184\n",
      "val Loss: 0.6410 Acc: 0.9040\n",
      "test Loss: 0.6449 Acc: 0.9040\n",
      "Epoch 995/1499\n",
      "----------\n",
      "train Loss: 0.6347 Acc: 0.9182\n",
      "val Loss: 0.6419 Acc: 0.9080\n",
      "test Loss: 0.6502 Acc: 0.8960\n",
      "Epoch 996/1499\n",
      "----------\n",
      "train Loss: 0.6341 Acc: 0.9171\n",
      "val Loss: 0.6471 Acc: 0.9000\n",
      "test Loss: 0.6495 Acc: 0.9000\n",
      "Epoch 997/1499\n",
      "----------\n",
      "train Loss: 0.6343 Acc: 0.9173\n",
      "val Loss: 0.6396 Acc: 0.9160\n",
      "test Loss: 0.6507 Acc: 0.9000\n",
      "Epoch 998/1499\n",
      "----------\n",
      "train Loss: 0.6362 Acc: 0.9180\n",
      "val Loss: 0.6419 Acc: 0.9040\n",
      "test Loss: 0.6528 Acc: 0.9000\n",
      "Epoch 999/1499\n",
      "----------\n",
      "train Loss: 0.6342 Acc: 0.9178\n",
      "val Loss: 0.6421 Acc: 0.9080\n",
      "test Loss: 0.6471 Acc: 0.9040\n",
      "Epoch 1000/1499\n",
      "----------\n",
      "train Loss: 0.6352 Acc: 0.9182\n",
      "val Loss: 0.6480 Acc: 0.9000\n",
      "test Loss: 0.6490 Acc: 0.9000\n",
      "Epoch 1001/1499\n",
      "----------\n",
      "train Loss: 0.6344 Acc: 0.9167\n",
      "val Loss: 0.6459 Acc: 0.9080\n",
      "test Loss: 0.6485 Acc: 0.9040\n",
      "Epoch 1002/1499\n",
      "----------\n",
      "train Loss: 0.6347 Acc: 0.9164\n",
      "val Loss: 0.6399 Acc: 0.9080\n",
      "test Loss: 0.6501 Acc: 0.8920\n",
      "Epoch 1003/1499\n",
      "----------\n",
      "train Loss: 0.6340 Acc: 0.9180\n",
      "val Loss: 0.6421 Acc: 0.9080\n",
      "test Loss: 0.6531 Acc: 0.8920\n",
      "Epoch 1004/1499\n",
      "----------\n",
      "train Loss: 0.6347 Acc: 0.9173\n",
      "val Loss: 0.6417 Acc: 0.9040\n",
      "test Loss: 0.6507 Acc: 0.8880\n",
      "Epoch 1005/1499\n",
      "----------\n",
      "train Loss: 0.6351 Acc: 0.9187\n",
      "val Loss: 0.6414 Acc: 0.9080\n",
      "test Loss: 0.6494 Acc: 0.9000\n",
      "Epoch 1006/1499\n",
      "----------\n",
      "train Loss: 0.6353 Acc: 0.9176\n",
      "val Loss: 0.6467 Acc: 0.8960\n",
      "test Loss: 0.6491 Acc: 0.8960\n",
      "Epoch 1007/1499\n",
      "----------\n",
      "train Loss: 0.6353 Acc: 0.9182\n",
      "val Loss: 0.6416 Acc: 0.9080\n",
      "test Loss: 0.6480 Acc: 0.8960\n",
      "Epoch 1008/1499\n",
      "----------\n",
      "train Loss: 0.6347 Acc: 0.9182\n",
      "val Loss: 0.6442 Acc: 0.9040\n",
      "test Loss: 0.6499 Acc: 0.8880\n",
      "Epoch 1009/1499\n",
      "----------\n",
      "train Loss: 0.6334 Acc: 0.9202\n",
      "val Loss: 0.6478 Acc: 0.9040\n",
      "test Loss: 0.6532 Acc: 0.8920\n",
      "Epoch 1010/1499\n",
      "----------\n",
      "train Loss: 0.6351 Acc: 0.9189\n",
      "val Loss: 0.6507 Acc: 0.9080\n",
      "test Loss: 0.6464 Acc: 0.9080\n",
      "Epoch 1011/1499\n",
      "----------\n",
      "train Loss: 0.6339 Acc: 0.9171\n",
      "val Loss: 0.6425 Acc: 0.9080\n",
      "test Loss: 0.6476 Acc: 0.8960\n",
      "Epoch 1012/1499\n",
      "----------\n",
      "train Loss: 0.6339 Acc: 0.9182\n",
      "val Loss: 0.6454 Acc: 0.9080\n",
      "test Loss: 0.6473 Acc: 0.9040\n",
      "Epoch 1013/1499\n",
      "----------\n",
      "train Loss: 0.6346 Acc: 0.9178\n",
      "val Loss: 0.6453 Acc: 0.8960\n",
      "test Loss: 0.6485 Acc: 0.9000\n",
      "Epoch 1014/1499\n",
      "----------\n",
      "train Loss: 0.6352 Acc: 0.9189\n",
      "val Loss: 0.6443 Acc: 0.9040\n",
      "test Loss: 0.6490 Acc: 0.9000\n",
      "Epoch 1015/1499\n",
      "----------\n",
      "train Loss: 0.6346 Acc: 0.9176\n",
      "val Loss: 0.6478 Acc: 0.9000\n",
      "test Loss: 0.6505 Acc: 0.8840\n",
      "Epoch 1016/1499\n",
      "----------\n",
      "train Loss: 0.6350 Acc: 0.9189\n",
      "val Loss: 0.6434 Acc: 0.9000\n",
      "test Loss: 0.6499 Acc: 0.8920\n",
      "Epoch 1017/1499\n",
      "----------\n",
      "train Loss: 0.6343 Acc: 0.9182\n",
      "val Loss: 0.6434 Acc: 0.9080\n",
      "test Loss: 0.6471 Acc: 0.9000\n",
      "Epoch 1018/1499\n",
      "----------\n",
      "train Loss: 0.6347 Acc: 0.9173\n",
      "val Loss: 0.6490 Acc: 0.8880\n",
      "test Loss: 0.6496 Acc: 0.9000\n",
      "Epoch 1019/1499\n",
      "----------\n",
      "train Loss: 0.6347 Acc: 0.9171\n",
      "val Loss: 0.6479 Acc: 0.9040\n",
      "test Loss: 0.6498 Acc: 0.8960\n",
      "Epoch 1020/1499\n",
      "----------\n",
      "train Loss: 0.6345 Acc: 0.9196\n",
      "val Loss: 0.6421 Acc: 0.9080\n",
      "test Loss: 0.6491 Acc: 0.8960\n",
      "Epoch 1021/1499\n",
      "----------\n",
      "train Loss: 0.6332 Acc: 0.9176\n",
      "val Loss: 0.6408 Acc: 0.9080\n",
      "test Loss: 0.6533 Acc: 0.9000\n",
      "Epoch 1022/1499\n",
      "----------\n",
      "train Loss: 0.6345 Acc: 0.9173\n",
      "val Loss: 0.6420 Acc: 0.9080\n",
      "test Loss: 0.6543 Acc: 0.9000\n",
      "Epoch 1023/1499\n",
      "----------\n",
      "train Loss: 0.6345 Acc: 0.9176\n",
      "val Loss: 0.6442 Acc: 0.9080\n",
      "test Loss: 0.6472 Acc: 0.8920\n",
      "Epoch 1024/1499\n",
      "----------\n",
      "train Loss: 0.6344 Acc: 0.9182\n",
      "val Loss: 0.6445 Acc: 0.9120\n",
      "test Loss: 0.6457 Acc: 0.9040\n",
      "Epoch 1025/1499\n",
      "----------\n",
      "train Loss: 0.6340 Acc: 0.9176\n",
      "val Loss: 0.6426 Acc: 0.9040\n",
      "test Loss: 0.6467 Acc: 0.9040\n",
      "Epoch 1026/1499\n",
      "----------\n",
      "train Loss: 0.6349 Acc: 0.9173\n",
      "val Loss: 0.6430 Acc: 0.9080\n",
      "test Loss: 0.6462 Acc: 0.9080\n",
      "Epoch 1027/1499\n",
      "----------\n",
      "train Loss: 0.6332 Acc: 0.9182\n",
      "val Loss: 0.6443 Acc: 0.9040\n",
      "test Loss: 0.6452 Acc: 0.9040\n",
      "Epoch 1028/1499\n",
      "----------\n",
      "train Loss: 0.6334 Acc: 0.9187\n",
      "val Loss: 0.6454 Acc: 0.9040\n",
      "test Loss: 0.6491 Acc: 0.9040\n",
      "Epoch 1029/1499\n",
      "----------\n",
      "train Loss: 0.6339 Acc: 0.9189\n",
      "val Loss: 0.6405 Acc: 0.9040\n",
      "test Loss: 0.6491 Acc: 0.8960\n",
      "Epoch 1030/1499\n",
      "----------\n",
      "train Loss: 0.6336 Acc: 0.9169\n",
      "val Loss: 0.6436 Acc: 0.9040\n",
      "test Loss: 0.6464 Acc: 0.9080\n",
      "Epoch 1031/1499\n",
      "----------\n",
      "train Loss: 0.6337 Acc: 0.9184\n",
      "val Loss: 0.6418 Acc: 0.9120\n",
      "test Loss: 0.6456 Acc: 0.8960\n",
      "Epoch 1032/1499\n",
      "----------\n",
      "train Loss: 0.6339 Acc: 0.9182\n",
      "val Loss: 0.6418 Acc: 0.9040\n",
      "test Loss: 0.6460 Acc: 0.9000\n",
      "Epoch 1033/1499\n",
      "----------\n",
      "train Loss: 0.6335 Acc: 0.9173\n",
      "val Loss: 0.6463 Acc: 0.9080\n",
      "test Loss: 0.6452 Acc: 0.8960\n",
      "Epoch 1034/1499\n",
      "----------\n",
      "train Loss: 0.6335 Acc: 0.9173\n",
      "val Loss: 0.6434 Acc: 0.9040\n",
      "test Loss: 0.6442 Acc: 0.9040\n",
      "Epoch 1035/1499\n",
      "----------\n",
      "train Loss: 0.6343 Acc: 0.9187\n",
      "val Loss: 0.6454 Acc: 0.9040\n",
      "test Loss: 0.6455 Acc: 0.9000\n",
      "Epoch 1036/1499\n",
      "----------\n",
      "train Loss: 0.6348 Acc: 0.9187\n",
      "val Loss: 0.6460 Acc: 0.9040\n",
      "test Loss: 0.6446 Acc: 0.9160\n",
      "Epoch 1037/1499\n",
      "----------\n",
      "train Loss: 0.6336 Acc: 0.9191\n",
      "val Loss: 0.6406 Acc: 0.9120\n",
      "test Loss: 0.6509 Acc: 0.8960\n",
      "Epoch 1038/1499\n",
      "----------\n",
      "train Loss: 0.6336 Acc: 0.9191\n",
      "val Loss: 0.6435 Acc: 0.9040\n",
      "test Loss: 0.6495 Acc: 0.8920\n",
      "Epoch 1039/1499\n",
      "----------\n",
      "train Loss: 0.6348 Acc: 0.9169\n",
      "val Loss: 0.6417 Acc: 0.9040\n",
      "test Loss: 0.6448 Acc: 0.9040\n",
      "Epoch 1040/1499\n",
      "----------\n",
      "train Loss: 0.6340 Acc: 0.9173\n",
      "val Loss: 0.6487 Acc: 0.9080\n",
      "test Loss: 0.6445 Acc: 0.9120\n",
      "Epoch 1041/1499\n",
      "----------\n",
      "train Loss: 0.6342 Acc: 0.9180\n",
      "val Loss: 0.6434 Acc: 0.9120\n",
      "test Loss: 0.6474 Acc: 0.9080\n",
      "Epoch 1042/1499\n",
      "----------\n",
      "train Loss: 0.6332 Acc: 0.9193\n",
      "val Loss: 0.6432 Acc: 0.9080\n",
      "test Loss: 0.6462 Acc: 0.9040\n",
      "Epoch 1043/1499\n",
      "----------\n",
      "train Loss: 0.6338 Acc: 0.9193\n",
      "val Loss: 0.6410 Acc: 0.9120\n",
      "test Loss: 0.6460 Acc: 0.9080\n",
      "Epoch 1044/1499\n",
      "----------\n",
      "train Loss: 0.6339 Acc: 0.9184\n",
      "val Loss: 0.6402 Acc: 0.9120\n",
      "test Loss: 0.6464 Acc: 0.8960\n",
      "Epoch 1045/1499\n",
      "----------\n",
      "train Loss: 0.6344 Acc: 0.9176\n",
      "val Loss: 0.6425 Acc: 0.9120\n",
      "test Loss: 0.6474 Acc: 0.9080\n",
      "Epoch 1046/1499\n",
      "----------\n",
      "train Loss: 0.6332 Acc: 0.9180\n",
      "val Loss: 0.6447 Acc: 0.9080\n",
      "test Loss: 0.6438 Acc: 0.9000\n",
      "Epoch 1047/1499\n",
      "----------\n",
      "train Loss: 0.6330 Acc: 0.9200\n",
      "val Loss: 0.6418 Acc: 0.9080\n",
      "test Loss: 0.6467 Acc: 0.8920\n",
      "Epoch 1048/1499\n",
      "----------\n",
      "train Loss: 0.6352 Acc: 0.9153\n",
      "val Loss: 0.6407 Acc: 0.9080\n",
      "test Loss: 0.6513 Acc: 0.8920\n",
      "Epoch 1049/1499\n",
      "----------\n",
      "train Loss: 0.6337 Acc: 0.9182\n",
      "val Loss: 0.6447 Acc: 0.9040\n",
      "test Loss: 0.6457 Acc: 0.9000\n",
      "Epoch 1050/1499\n",
      "----------\n",
      "train Loss: 0.6336 Acc: 0.9167\n",
      "val Loss: 0.6479 Acc: 0.9040\n",
      "test Loss: 0.6484 Acc: 0.9000\n",
      "Epoch 1051/1499\n",
      "----------\n",
      "train Loss: 0.6328 Acc: 0.9180\n",
      "val Loss: 0.6429 Acc: 0.9040\n",
      "test Loss: 0.6482 Acc: 0.9040\n",
      "Epoch 1052/1499\n",
      "----------\n",
      "train Loss: 0.6329 Acc: 0.9200\n",
      "val Loss: 0.6464 Acc: 0.9040\n",
      "test Loss: 0.6483 Acc: 0.8960\n",
      "Epoch 1053/1499\n",
      "----------\n",
      "train Loss: 0.6327 Acc: 0.9198\n",
      "val Loss: 0.6477 Acc: 0.9040\n",
      "test Loss: 0.6427 Acc: 0.9040\n",
      "Epoch 1054/1499\n",
      "----------\n",
      "train Loss: 0.6340 Acc: 0.9184\n",
      "val Loss: 0.6476 Acc: 0.8920\n",
      "test Loss: 0.6509 Acc: 0.8960\n",
      "Epoch 1055/1499\n",
      "----------\n",
      "train Loss: 0.6342 Acc: 0.9202\n",
      "val Loss: 0.6424 Acc: 0.9040\n",
      "test Loss: 0.6476 Acc: 0.8880\n",
      "Epoch 1056/1499\n",
      "----------\n",
      "train Loss: 0.6333 Acc: 0.9191\n",
      "val Loss: 0.6425 Acc: 0.9080\n",
      "test Loss: 0.6472 Acc: 0.8960\n",
      "Epoch 1057/1499\n",
      "----------\n",
      "train Loss: 0.6333 Acc: 0.9184\n",
      "val Loss: 0.6437 Acc: 0.9080\n",
      "test Loss: 0.6509 Acc: 0.8960\n",
      "Epoch 1058/1499\n",
      "----------\n",
      "train Loss: 0.6327 Acc: 0.9198\n",
      "val Loss: 0.6429 Acc: 0.9040\n",
      "test Loss: 0.6444 Acc: 0.9040\n",
      "Epoch 1059/1499\n",
      "----------\n",
      "train Loss: 0.6337 Acc: 0.9187\n",
      "val Loss: 0.6421 Acc: 0.9080\n",
      "test Loss: 0.6425 Acc: 0.9000\n",
      "Epoch 1060/1499\n",
      "----------\n",
      "train Loss: 0.6327 Acc: 0.9176\n",
      "val Loss: 0.6477 Acc: 0.9040\n",
      "test Loss: 0.6488 Acc: 0.8960\n",
      "Epoch 1061/1499\n",
      "----------\n",
      "train Loss: 0.6345 Acc: 0.9169\n",
      "val Loss: 0.6435 Acc: 0.9080\n",
      "test Loss: 0.6440 Acc: 0.9080\n",
      "Epoch 1062/1499\n",
      "----------\n",
      "train Loss: 0.6347 Acc: 0.9169\n",
      "val Loss: 0.6419 Acc: 0.9040\n",
      "test Loss: 0.6435 Acc: 0.8920\n",
      "Epoch 1063/1499\n",
      "----------\n",
      "train Loss: 0.6332 Acc: 0.9189\n",
      "val Loss: 0.6412 Acc: 0.9120\n",
      "test Loss: 0.6474 Acc: 0.9080\n",
      "Epoch 1064/1499\n",
      "----------\n",
      "train Loss: 0.6330 Acc: 0.9184\n",
      "val Loss: 0.6400 Acc: 0.9080\n",
      "test Loss: 0.6470 Acc: 0.9000\n",
      "Epoch 1065/1499\n",
      "----------\n",
      "train Loss: 0.6347 Acc: 0.9164\n",
      "val Loss: 0.6445 Acc: 0.8960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6454 Acc: 0.9080\n",
      "Epoch 1066/1499\n",
      "----------\n",
      "train Loss: 0.6340 Acc: 0.9153\n",
      "val Loss: 0.6390 Acc: 0.9080\n",
      "test Loss: 0.6487 Acc: 0.8920\n",
      "Epoch 1067/1499\n",
      "----------\n",
      "train Loss: 0.6320 Acc: 0.9176\n",
      "val Loss: 0.6539 Acc: 0.8960\n",
      "test Loss: 0.6447 Acc: 0.9080\n",
      "Epoch 1068/1499\n",
      "----------\n",
      "train Loss: 0.6326 Acc: 0.9184\n",
      "val Loss: 0.6476 Acc: 0.9080\n",
      "test Loss: 0.6487 Acc: 0.9080\n",
      "Epoch 1069/1499\n",
      "----------\n",
      "train Loss: 0.6338 Acc: 0.9178\n",
      "val Loss: 0.6492 Acc: 0.9080\n",
      "test Loss: 0.6456 Acc: 0.9040\n",
      "Epoch 1070/1499\n",
      "----------\n",
      "train Loss: 0.6330 Acc: 0.9184\n",
      "val Loss: 0.6459 Acc: 0.9040\n",
      "test Loss: 0.6431 Acc: 0.9040\n",
      "Epoch 1071/1499\n",
      "----------\n",
      "train Loss: 0.6317 Acc: 0.9200\n",
      "val Loss: 0.6418 Acc: 0.9080\n",
      "test Loss: 0.6473 Acc: 0.9000\n",
      "Epoch 1072/1499\n",
      "----------\n",
      "train Loss: 0.6329 Acc: 0.9193\n",
      "val Loss: 0.6427 Acc: 0.9040\n",
      "test Loss: 0.6463 Acc: 0.9160\n",
      "Epoch 1073/1499\n",
      "----------\n",
      "train Loss: 0.6327 Acc: 0.9189\n",
      "val Loss: 0.6394 Acc: 0.9040\n",
      "test Loss: 0.6473 Acc: 0.9040\n",
      "Epoch 1074/1499\n",
      "----------\n",
      "train Loss: 0.6343 Acc: 0.9178\n",
      "val Loss: 0.6455 Acc: 0.9120\n",
      "test Loss: 0.6445 Acc: 0.9080\n",
      "Epoch 1075/1499\n",
      "----------\n",
      "train Loss: 0.6327 Acc: 0.9182\n",
      "val Loss: 0.6392 Acc: 0.9120\n",
      "test Loss: 0.6472 Acc: 0.9080\n",
      "Epoch 1076/1499\n",
      "----------\n",
      "train Loss: 0.6321 Acc: 0.9196\n",
      "val Loss: 0.6436 Acc: 0.9040\n",
      "test Loss: 0.6418 Acc: 0.9080\n",
      "Epoch 1077/1499\n",
      "----------\n",
      "train Loss: 0.6335 Acc: 0.9176\n",
      "val Loss: 0.6416 Acc: 0.9120\n",
      "test Loss: 0.6446 Acc: 0.9080\n",
      "Epoch 1078/1499\n",
      "----------\n",
      "train Loss: 0.6322 Acc: 0.9200\n",
      "val Loss: 0.6439 Acc: 0.9080\n",
      "test Loss: 0.6480 Acc: 0.9040\n",
      "Epoch 1079/1499\n",
      "----------\n",
      "train Loss: 0.6326 Acc: 0.9193\n",
      "val Loss: 0.6408 Acc: 0.9080\n",
      "test Loss: 0.6509 Acc: 0.8960\n",
      "Epoch 1080/1499\n",
      "----------\n",
      "train Loss: 0.6323 Acc: 0.9191\n",
      "val Loss: 0.6453 Acc: 0.9040\n",
      "test Loss: 0.6498 Acc: 0.9000\n",
      "Epoch 1081/1499\n",
      "----------\n",
      "train Loss: 0.6332 Acc: 0.9184\n",
      "val Loss: 0.6405 Acc: 0.9120\n",
      "test Loss: 0.6464 Acc: 0.9000\n",
      "Epoch 1082/1499\n",
      "----------\n",
      "train Loss: 0.6325 Acc: 0.9167\n",
      "val Loss: 0.6412 Acc: 0.9080\n",
      "test Loss: 0.6427 Acc: 0.9120\n",
      "Epoch 1083/1499\n",
      "----------\n",
      "train Loss: 0.6327 Acc: 0.9202\n",
      "val Loss: 0.6431 Acc: 0.9040\n",
      "test Loss: 0.6456 Acc: 0.9000\n",
      "Epoch 1084/1499\n",
      "----------\n",
      "train Loss: 0.6329 Acc: 0.9196\n",
      "val Loss: 0.6431 Acc: 0.9040\n",
      "test Loss: 0.6461 Acc: 0.8960\n",
      "Epoch 1085/1499\n",
      "----------\n",
      "train Loss: 0.6341 Acc: 0.9193\n",
      "val Loss: 0.6417 Acc: 0.9080\n",
      "test Loss: 0.6448 Acc: 0.9040\n",
      "Epoch 1086/1499\n",
      "----------\n",
      "train Loss: 0.6332 Acc: 0.9187\n",
      "val Loss: 0.6419 Acc: 0.9080\n",
      "test Loss: 0.6430 Acc: 0.9160\n",
      "Epoch 1087/1499\n",
      "----------\n",
      "train Loss: 0.6334 Acc: 0.9207\n",
      "val Loss: 0.6425 Acc: 0.9080\n",
      "test Loss: 0.6454 Acc: 0.9000\n",
      "Epoch 1088/1499\n",
      "----------\n",
      "train Loss: 0.6327 Acc: 0.9187\n",
      "val Loss: 0.6420 Acc: 0.9120\n",
      "test Loss: 0.6422 Acc: 0.9040\n",
      "Epoch 1089/1499\n",
      "----------\n",
      "train Loss: 0.6329 Acc: 0.9182\n",
      "val Loss: 0.6423 Acc: 0.9080\n",
      "test Loss: 0.6455 Acc: 0.9000\n",
      "Epoch 1090/1499\n",
      "----------\n",
      "train Loss: 0.6339 Acc: 0.9178\n",
      "val Loss: 0.6428 Acc: 0.9040\n",
      "test Loss: 0.6481 Acc: 0.9040\n",
      "Epoch 1091/1499\n",
      "----------\n",
      "train Loss: 0.6329 Acc: 0.9198\n",
      "val Loss: 0.6484 Acc: 0.8960\n",
      "test Loss: 0.6497 Acc: 0.9000\n",
      "Epoch 1092/1499\n",
      "----------\n",
      "train Loss: 0.6341 Acc: 0.9180\n",
      "val Loss: 0.6458 Acc: 0.9080\n",
      "test Loss: 0.6478 Acc: 0.9000\n",
      "Epoch 1093/1499\n",
      "----------\n",
      "train Loss: 0.6329 Acc: 0.9184\n",
      "val Loss: 0.6427 Acc: 0.9040\n",
      "test Loss: 0.6428 Acc: 0.9120\n",
      "Epoch 1094/1499\n",
      "----------\n",
      "train Loss: 0.6329 Acc: 0.9189\n",
      "val Loss: 0.6441 Acc: 0.9040\n",
      "test Loss: 0.6436 Acc: 0.9040\n",
      "Epoch 1095/1499\n",
      "----------\n",
      "train Loss: 0.6335 Acc: 0.9178\n",
      "val Loss: 0.6425 Acc: 0.9000\n",
      "test Loss: 0.6519 Acc: 0.9000\n",
      "Epoch 1096/1499\n",
      "----------\n",
      "train Loss: 0.6316 Acc: 0.9196\n",
      "val Loss: 0.6396 Acc: 0.9000\n",
      "test Loss: 0.6432 Acc: 0.9000\n",
      "Epoch 1097/1499\n",
      "----------\n",
      "train Loss: 0.6324 Acc: 0.9189\n",
      "val Loss: 0.6469 Acc: 0.9000\n",
      "test Loss: 0.6475 Acc: 0.8960\n",
      "Epoch 1098/1499\n",
      "----------\n",
      "train Loss: 0.6330 Acc: 0.9191\n",
      "val Loss: 0.6376 Acc: 0.9120\n",
      "test Loss: 0.6435 Acc: 0.9080\n",
      "Epoch 1099/1499\n",
      "----------\n",
      "train Loss: 0.6325 Acc: 0.9180\n",
      "val Loss: 0.6433 Acc: 0.9080\n",
      "test Loss: 0.6420 Acc: 0.9080\n",
      "Epoch 1100/1499\n",
      "----------\n",
      "train Loss: 0.6334 Acc: 0.9184\n",
      "val Loss: 0.6440 Acc: 0.9040\n",
      "test Loss: 0.6430 Acc: 0.9040\n",
      "Epoch 1101/1499\n",
      "----------\n",
      "train Loss: 0.6329 Acc: 0.9202\n",
      "val Loss: 0.6456 Acc: 0.9080\n",
      "test Loss: 0.6454 Acc: 0.9040\n",
      "Epoch 1102/1499\n",
      "----------\n",
      "train Loss: 0.6330 Acc: 0.9196\n",
      "val Loss: 0.6418 Acc: 0.9040\n",
      "test Loss: 0.6433 Acc: 0.9000\n",
      "Epoch 1103/1499\n",
      "----------\n",
      "train Loss: 0.6332 Acc: 0.9176\n",
      "val Loss: 0.6427 Acc: 0.9160\n",
      "test Loss: 0.6441 Acc: 0.9040\n",
      "Epoch 1104/1499\n",
      "----------\n",
      "train Loss: 0.6334 Acc: 0.9187\n",
      "val Loss: 0.6406 Acc: 0.9080\n",
      "test Loss: 0.6468 Acc: 0.8960\n",
      "Epoch 1105/1499\n",
      "----------\n",
      "train Loss: 0.6324 Acc: 0.9187\n",
      "val Loss: 0.6467 Acc: 0.9040\n",
      "test Loss: 0.6423 Acc: 0.9040\n",
      "Epoch 1106/1499\n",
      "----------\n",
      "train Loss: 0.6328 Acc: 0.9180\n",
      "val Loss: 0.6413 Acc: 0.9080\n",
      "test Loss: 0.6425 Acc: 0.9080\n",
      "Epoch 1107/1499\n",
      "----------\n",
      "train Loss: 0.6333 Acc: 0.9171\n",
      "val Loss: 0.6429 Acc: 0.9000\n",
      "test Loss: 0.6503 Acc: 0.9000\n",
      "Epoch 1108/1499\n",
      "----------\n",
      "train Loss: 0.6326 Acc: 0.9200\n",
      "val Loss: 0.6435 Acc: 0.9040\n",
      "test Loss: 0.6444 Acc: 0.9040\n",
      "Epoch 1109/1499\n",
      "----------\n",
      "train Loss: 0.6328 Acc: 0.9187\n",
      "val Loss: 0.6394 Acc: 0.9120\n",
      "test Loss: 0.6451 Acc: 0.9000\n",
      "Epoch 1110/1499\n",
      "----------\n",
      "train Loss: 0.6331 Acc: 0.9169\n",
      "val Loss: 0.6400 Acc: 0.9000\n",
      "test Loss: 0.6429 Acc: 0.9040\n",
      "Epoch 1111/1499\n",
      "----------\n",
      "train Loss: 0.6329 Acc: 0.9184\n",
      "val Loss: 0.6409 Acc: 0.9080\n",
      "test Loss: 0.6445 Acc: 0.9040\n",
      "Epoch 1112/1499\n",
      "----------\n",
      "train Loss: 0.6321 Acc: 0.9200\n",
      "val Loss: 0.6419 Acc: 0.9080\n",
      "test Loss: 0.6486 Acc: 0.9000\n",
      "Epoch 1113/1499\n",
      "----------\n",
      "train Loss: 0.6317 Acc: 0.9209\n",
      "val Loss: 0.6443 Acc: 0.9000\n",
      "test Loss: 0.6476 Acc: 0.9000\n",
      "Epoch 1114/1499\n",
      "----------\n",
      "train Loss: 0.6315 Acc: 0.9198\n",
      "val Loss: 0.6465 Acc: 0.8960\n",
      "test Loss: 0.6392 Acc: 0.9120\n",
      "Epoch 1115/1499\n",
      "----------\n",
      "train Loss: 0.6323 Acc: 0.9204\n",
      "val Loss: 0.6431 Acc: 0.9040\n",
      "test Loss: 0.6481 Acc: 0.9040\n",
      "Epoch 1116/1499\n",
      "----------\n",
      "train Loss: 0.6321 Acc: 0.9204\n",
      "val Loss: 0.6424 Acc: 0.9080\n",
      "test Loss: 0.6426 Acc: 0.9080\n",
      "Epoch 1117/1499\n",
      "----------\n",
      "train Loss: 0.6326 Acc: 0.9184\n",
      "val Loss: 0.6425 Acc: 0.9080\n",
      "test Loss: 0.6454 Acc: 0.9080\n",
      "Epoch 1118/1499\n",
      "----------\n",
      "train Loss: 0.6315 Acc: 0.9204\n",
      "val Loss: 0.6413 Acc: 0.9040\n",
      "test Loss: 0.6455 Acc: 0.9000\n",
      "Epoch 1119/1499\n",
      "----------\n",
      "train Loss: 0.6319 Acc: 0.9218\n",
      "val Loss: 0.6423 Acc: 0.9000\n",
      "test Loss: 0.6456 Acc: 0.9000\n",
      "Epoch 1120/1499\n",
      "----------\n",
      "train Loss: 0.6321 Acc: 0.9202\n",
      "val Loss: 0.6409 Acc: 0.9120\n",
      "test Loss: 0.6465 Acc: 0.9080\n",
      "Epoch 1121/1499\n",
      "----------\n",
      "train Loss: 0.6316 Acc: 0.9207\n",
      "val Loss: 0.6392 Acc: 0.9160\n",
      "test Loss: 0.6467 Acc: 0.9000\n",
      "Epoch 1122/1499\n",
      "----------\n",
      "train Loss: 0.6324 Acc: 0.9200\n",
      "val Loss: 0.6406 Acc: 0.9080\n",
      "test Loss: 0.6443 Acc: 0.9000\n",
      "Epoch 1123/1499\n",
      "----------\n",
      "train Loss: 0.6328 Acc: 0.9187\n",
      "val Loss: 0.6381 Acc: 0.9160\n",
      "test Loss: 0.6406 Acc: 0.9080\n",
      "Epoch 1124/1499\n",
      "----------\n",
      "train Loss: 0.6322 Acc: 0.9198\n",
      "val Loss: 0.6468 Acc: 0.9000\n",
      "test Loss: 0.6432 Acc: 0.9080\n",
      "Epoch 1125/1499\n",
      "----------\n",
      "train Loss: 0.6324 Acc: 0.9218\n",
      "val Loss: 0.6418 Acc: 0.9080\n",
      "test Loss: 0.6435 Acc: 0.9080\n",
      "Epoch 1126/1499\n",
      "----------\n",
      "train Loss: 0.6324 Acc: 0.9191\n",
      "val Loss: 0.6421 Acc: 0.8960\n",
      "test Loss: 0.6455 Acc: 0.9080\n",
      "Epoch 1127/1499\n",
      "----------\n",
      "train Loss: 0.6322 Acc: 0.9182\n",
      "val Loss: 0.6416 Acc: 0.9080\n",
      "test Loss: 0.6421 Acc: 0.9160\n",
      "Epoch 1128/1499\n",
      "----------\n",
      "train Loss: 0.6324 Acc: 0.9173\n",
      "val Loss: 0.6433 Acc: 0.8960\n",
      "test Loss: 0.6496 Acc: 0.8960\n",
      "Epoch 1129/1499\n",
      "----------\n",
      "train Loss: 0.6321 Acc: 0.9198\n",
      "val Loss: 0.6419 Acc: 0.9120\n",
      "test Loss: 0.6432 Acc: 0.9040\n",
      "Epoch 1130/1499\n",
      "----------\n",
      "train Loss: 0.6327 Acc: 0.9182\n",
      "val Loss: 0.6436 Acc: 0.9080\n",
      "test Loss: 0.6503 Acc: 0.9040\n",
      "Epoch 1131/1499\n",
      "----------\n",
      "train Loss: 0.6328 Acc: 0.9209\n",
      "val Loss: 0.6461 Acc: 0.9000\n",
      "test Loss: 0.6469 Acc: 0.9080\n",
      "Epoch 1132/1499\n",
      "----------\n",
      "train Loss: 0.6330 Acc: 0.9176\n",
      "val Loss: 0.6436 Acc: 0.9080\n",
      "test Loss: 0.6442 Acc: 0.9080\n",
      "Epoch 1133/1499\n",
      "----------\n",
      "train Loss: 0.6320 Acc: 0.9189\n",
      "val Loss: 0.6426 Acc: 0.9120\n",
      "test Loss: 0.6440 Acc: 0.9000\n",
      "Epoch 1134/1499\n",
      "----------\n",
      "train Loss: 0.6316 Acc: 0.9200\n",
      "val Loss: 0.6456 Acc: 0.9080\n",
      "test Loss: 0.6431 Acc: 0.9080\n",
      "Epoch 1135/1499\n",
      "----------\n",
      "train Loss: 0.6324 Acc: 0.9209\n",
      "val Loss: 0.6449 Acc: 0.9040\n",
      "test Loss: 0.6497 Acc: 0.9000\n",
      "Epoch 1136/1499\n",
      "----------\n",
      "train Loss: 0.6331 Acc: 0.9169\n",
      "val Loss: 0.6387 Acc: 0.9120\n",
      "test Loss: 0.6461 Acc: 0.9040\n",
      "Epoch 1137/1499\n",
      "----------\n",
      "train Loss: 0.6320 Acc: 0.9209\n",
      "val Loss: 0.6416 Acc: 0.9040\n",
      "test Loss: 0.6462 Acc: 0.9040\n",
      "Epoch 1138/1499\n",
      "----------\n",
      "train Loss: 0.6317 Acc: 0.9202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.6428 Acc: 0.9040\n",
      "test Loss: 0.6459 Acc: 0.9040\n",
      "Epoch 1139/1499\n",
      "----------\n",
      "train Loss: 0.6318 Acc: 0.9209\n",
      "val Loss: 0.6413 Acc: 0.9080\n",
      "test Loss: 0.6449 Acc: 0.8960\n",
      "Epoch 1140/1499\n",
      "----------\n",
      "train Loss: 0.6328 Acc: 0.9211\n",
      "val Loss: 0.6450 Acc: 0.9000\n",
      "test Loss: 0.6432 Acc: 0.9080\n",
      "Epoch 1141/1499\n",
      "----------\n",
      "train Loss: 0.6315 Acc: 0.9193\n",
      "val Loss: 0.6425 Acc: 0.9040\n",
      "test Loss: 0.6470 Acc: 0.9080\n",
      "Epoch 1142/1499\n",
      "----------\n",
      "train Loss: 0.6320 Acc: 0.9196\n",
      "val Loss: 0.6424 Acc: 0.9120\n",
      "test Loss: 0.6420 Acc: 0.9160\n",
      "Epoch 1143/1499\n",
      "----------\n",
      "train Loss: 0.6320 Acc: 0.9193\n",
      "val Loss: 0.6424 Acc: 0.9080\n",
      "test Loss: 0.6454 Acc: 0.9120\n",
      "Epoch 1144/1499\n",
      "----------\n",
      "train Loss: 0.6323 Acc: 0.9211\n",
      "val Loss: 0.6429 Acc: 0.9040\n",
      "test Loss: 0.6476 Acc: 0.9080\n",
      "Epoch 1145/1499\n",
      "----------\n",
      "train Loss: 0.6323 Acc: 0.9189\n",
      "val Loss: 0.6445 Acc: 0.9040\n",
      "test Loss: 0.6453 Acc: 0.9080\n",
      "Epoch 1146/1499\n",
      "----------\n",
      "train Loss: 0.6320 Acc: 0.9191\n",
      "val Loss: 0.6417 Acc: 0.9040\n",
      "test Loss: 0.6442 Acc: 0.9080\n",
      "Epoch 1147/1499\n",
      "----------\n",
      "train Loss: 0.6313 Acc: 0.9200\n",
      "val Loss: 0.6435 Acc: 0.9080\n",
      "test Loss: 0.6428 Acc: 0.9120\n",
      "Epoch 1148/1499\n",
      "----------\n",
      "train Loss: 0.6322 Acc: 0.9182\n",
      "val Loss: 0.6458 Acc: 0.8960\n",
      "test Loss: 0.6460 Acc: 0.9080\n",
      "Epoch 1149/1499\n",
      "----------\n",
      "train Loss: 0.6309 Acc: 0.9216\n",
      "val Loss: 0.6450 Acc: 0.9040\n",
      "test Loss: 0.6446 Acc: 0.9080\n",
      "Epoch 1150/1499\n",
      "----------\n",
      "train Loss: 0.6313 Acc: 0.9216\n",
      "val Loss: 0.6464 Acc: 0.8920\n",
      "test Loss: 0.6436 Acc: 0.9040\n",
      "Epoch 1151/1499\n",
      "----------\n",
      "train Loss: 0.6307 Acc: 0.9211\n",
      "val Loss: 0.6454 Acc: 0.9000\n",
      "test Loss: 0.6449 Acc: 0.9080\n",
      "Epoch 1152/1499\n",
      "----------\n",
      "train Loss: 0.6322 Acc: 0.9216\n",
      "val Loss: 0.6409 Acc: 0.9080\n",
      "test Loss: 0.6421 Acc: 0.9160\n",
      "Epoch 1153/1499\n",
      "----------\n",
      "train Loss: 0.6324 Acc: 0.9198\n",
      "val Loss: 0.6408 Acc: 0.9160\n",
      "test Loss: 0.6450 Acc: 0.9000\n",
      "Epoch 1154/1499\n",
      "----------\n",
      "train Loss: 0.6320 Acc: 0.9207\n",
      "val Loss: 0.6435 Acc: 0.9000\n",
      "test Loss: 0.6401 Acc: 0.9080\n",
      "Epoch 1155/1499\n",
      "----------\n",
      "train Loss: 0.6324 Acc: 0.9202\n",
      "val Loss: 0.6441 Acc: 0.9080\n",
      "test Loss: 0.6404 Acc: 0.9120\n",
      "Epoch 1156/1499\n",
      "----------\n",
      "train Loss: 0.6321 Acc: 0.9200\n",
      "val Loss: 0.6424 Acc: 0.9040\n",
      "test Loss: 0.6472 Acc: 0.8960\n",
      "Epoch 1157/1499\n",
      "----------\n",
      "train Loss: 0.6327 Acc: 0.9200\n",
      "val Loss: 0.6414 Acc: 0.9040\n",
      "test Loss: 0.6445 Acc: 0.9000\n",
      "Epoch 1158/1499\n",
      "----------\n",
      "train Loss: 0.6310 Acc: 0.9216\n",
      "val Loss: 0.6450 Acc: 0.9040\n",
      "test Loss: 0.6445 Acc: 0.9040\n",
      "Epoch 1159/1499\n",
      "----------\n",
      "train Loss: 0.6317 Acc: 0.9196\n",
      "val Loss: 0.6458 Acc: 0.9040\n",
      "test Loss: 0.6436 Acc: 0.9040\n",
      "Epoch 1160/1499\n",
      "----------\n",
      "train Loss: 0.6315 Acc: 0.9202\n",
      "val Loss: 0.6428 Acc: 0.8960\n",
      "test Loss: 0.6470 Acc: 0.8960\n",
      "Epoch 1161/1499\n",
      "----------\n",
      "train Loss: 0.6315 Acc: 0.9209\n",
      "val Loss: 0.6443 Acc: 0.9040\n",
      "test Loss: 0.6437 Acc: 0.9040\n",
      "Epoch 1162/1499\n",
      "----------\n",
      "train Loss: 0.6325 Acc: 0.9216\n",
      "val Loss: 0.6437 Acc: 0.9080\n",
      "test Loss: 0.6448 Acc: 0.9080\n",
      "Epoch 1163/1499\n",
      "----------\n",
      "train Loss: 0.6310 Acc: 0.9193\n",
      "val Loss: 0.6432 Acc: 0.9040\n",
      "test Loss: 0.6419 Acc: 0.9080\n",
      "Epoch 1164/1499\n",
      "----------\n",
      "train Loss: 0.6334 Acc: 0.9173\n",
      "val Loss: 0.6399 Acc: 0.9080\n",
      "test Loss: 0.6378 Acc: 0.9120\n",
      "Epoch 1165/1499\n",
      "----------\n",
      "train Loss: 0.6322 Acc: 0.9196\n",
      "val Loss: 0.6480 Acc: 0.9000\n",
      "test Loss: 0.6405 Acc: 0.9080\n",
      "Epoch 1166/1499\n",
      "----------\n",
      "train Loss: 0.6318 Acc: 0.9196\n",
      "val Loss: 0.6468 Acc: 0.8880\n",
      "test Loss: 0.6428 Acc: 0.9080\n",
      "Epoch 1167/1499\n",
      "----------\n",
      "train Loss: 0.6313 Acc: 0.9200\n",
      "val Loss: 0.6470 Acc: 0.8920\n",
      "test Loss: 0.6424 Acc: 0.9000\n",
      "Epoch 1168/1499\n",
      "----------\n",
      "train Loss: 0.6326 Acc: 0.9178\n",
      "val Loss: 0.6406 Acc: 0.9080\n",
      "test Loss: 0.6452 Acc: 0.9040\n",
      "Epoch 1169/1499\n",
      "----------\n",
      "train Loss: 0.6312 Acc: 0.9209\n",
      "val Loss: 0.6400 Acc: 0.9080\n",
      "test Loss: 0.6448 Acc: 0.9080\n",
      "Epoch 1170/1499\n",
      "----------\n",
      "train Loss: 0.6327 Acc: 0.9207\n",
      "val Loss: 0.6417 Acc: 0.9120\n",
      "test Loss: 0.6445 Acc: 0.9000\n",
      "Epoch 1171/1499\n",
      "----------\n",
      "train Loss: 0.6312 Acc: 0.9216\n",
      "val Loss: 0.6409 Acc: 0.9040\n",
      "test Loss: 0.6454 Acc: 0.9080\n",
      "Epoch 1172/1499\n",
      "----------\n",
      "train Loss: 0.6308 Acc: 0.9207\n",
      "val Loss: 0.6400 Acc: 0.9120\n",
      "test Loss: 0.6422 Acc: 0.9120\n",
      "Epoch 1173/1499\n",
      "----------\n",
      "train Loss: 0.6319 Acc: 0.9204\n",
      "val Loss: 0.6460 Acc: 0.9000\n",
      "test Loss: 0.6401 Acc: 0.9080\n",
      "Epoch 1174/1499\n",
      "----------\n",
      "train Loss: 0.6315 Acc: 0.9202\n",
      "val Loss: 0.6461 Acc: 0.9080\n",
      "test Loss: 0.6425 Acc: 0.9040\n",
      "Epoch 1175/1499\n",
      "----------\n",
      "train Loss: 0.6309 Acc: 0.9196\n",
      "val Loss: 0.6438 Acc: 0.9080\n",
      "test Loss: 0.6493 Acc: 0.9000\n",
      "Epoch 1176/1499\n",
      "----------\n",
      "train Loss: 0.6312 Acc: 0.9204\n",
      "val Loss: 0.6424 Acc: 0.9120\n",
      "test Loss: 0.6435 Acc: 0.9080\n",
      "Epoch 1177/1499\n",
      "----------\n",
      "train Loss: 0.6315 Acc: 0.9204\n",
      "val Loss: 0.6424 Acc: 0.9040\n",
      "test Loss: 0.6472 Acc: 0.8960\n",
      "Epoch 1178/1499\n",
      "----------\n",
      "train Loss: 0.6317 Acc: 0.9196\n",
      "val Loss: 0.6405 Acc: 0.9080\n",
      "test Loss: 0.6416 Acc: 0.9120\n",
      "Epoch 1179/1499\n",
      "----------\n",
      "train Loss: 0.6311 Acc: 0.9200\n",
      "val Loss: 0.6392 Acc: 0.9080\n",
      "test Loss: 0.6461 Acc: 0.9080\n",
      "Epoch 1180/1499\n",
      "----------\n",
      "train Loss: 0.6318 Acc: 0.9191\n",
      "val Loss: 0.6455 Acc: 0.9000\n",
      "test Loss: 0.6421 Acc: 0.9040\n",
      "Epoch 1181/1499\n",
      "----------\n",
      "train Loss: 0.6318 Acc: 0.9207\n",
      "val Loss: 0.6430 Acc: 0.9080\n",
      "test Loss: 0.6392 Acc: 0.9200\n",
      "Epoch 1182/1499\n",
      "----------\n",
      "train Loss: 0.6318 Acc: 0.9207\n",
      "val Loss: 0.6394 Acc: 0.9120\n",
      "test Loss: 0.6435 Acc: 0.9080\n",
      "Epoch 1183/1499\n",
      "----------\n",
      "train Loss: 0.6315 Acc: 0.9200\n",
      "val Loss: 0.6459 Acc: 0.8960\n",
      "test Loss: 0.6433 Acc: 0.9040\n",
      "Epoch 1184/1499\n",
      "----------\n",
      "train Loss: 0.6316 Acc: 0.9209\n",
      "val Loss: 0.6407 Acc: 0.9080\n",
      "test Loss: 0.6424 Acc: 0.9120\n",
      "Epoch 1185/1499\n",
      "----------\n",
      "train Loss: 0.6311 Acc: 0.9211\n",
      "val Loss: 0.6444 Acc: 0.9040\n",
      "test Loss: 0.6467 Acc: 0.9080\n",
      "Epoch 1186/1499\n",
      "----------\n",
      "train Loss: 0.6319 Acc: 0.9198\n",
      "val Loss: 0.6407 Acc: 0.9120\n",
      "test Loss: 0.6453 Acc: 0.9000\n",
      "Epoch 1187/1499\n",
      "----------\n",
      "train Loss: 0.6308 Acc: 0.9207\n",
      "val Loss: 0.6413 Acc: 0.9040\n",
      "test Loss: 0.6408 Acc: 0.9080\n",
      "Epoch 1188/1499\n",
      "----------\n",
      "train Loss: 0.6312 Acc: 0.9200\n",
      "val Loss: 0.6448 Acc: 0.9080\n",
      "test Loss: 0.6452 Acc: 0.9080\n",
      "Epoch 1189/1499\n",
      "----------\n",
      "train Loss: 0.6319 Acc: 0.9184\n",
      "val Loss: 0.6450 Acc: 0.9000\n",
      "test Loss: 0.6445 Acc: 0.9040\n",
      "Epoch 1190/1499\n",
      "----------\n",
      "train Loss: 0.6313 Acc: 0.9196\n",
      "val Loss: 0.6453 Acc: 0.9040\n",
      "test Loss: 0.6434 Acc: 0.9080\n",
      "Epoch 1191/1499\n",
      "----------\n",
      "train Loss: 0.6324 Acc: 0.9184\n",
      "val Loss: 0.6418 Acc: 0.9040\n",
      "test Loss: 0.6445 Acc: 0.9040\n",
      "Epoch 1192/1499\n",
      "----------\n",
      "train Loss: 0.6323 Acc: 0.9184\n",
      "val Loss: 0.6422 Acc: 0.9000\n",
      "test Loss: 0.6445 Acc: 0.9080\n",
      "Epoch 1193/1499\n",
      "----------\n",
      "train Loss: 0.6317 Acc: 0.9204\n",
      "val Loss: 0.6385 Acc: 0.9120\n",
      "test Loss: 0.6429 Acc: 0.9080\n",
      "Epoch 1194/1499\n",
      "----------\n",
      "train Loss: 0.6318 Acc: 0.9189\n",
      "val Loss: 0.6349 Acc: 0.9160\n",
      "test Loss: 0.6416 Acc: 0.9080\n",
      "Epoch 1195/1499\n",
      "----------\n",
      "train Loss: 0.6318 Acc: 0.9204\n",
      "val Loss: 0.6415 Acc: 0.9120\n",
      "test Loss: 0.6468 Acc: 0.9080\n",
      "Epoch 1196/1499\n",
      "----------\n",
      "train Loss: 0.6310 Acc: 0.9209\n",
      "val Loss: 0.6407 Acc: 0.9080\n",
      "test Loss: 0.6421 Acc: 0.9000\n",
      "Epoch 1197/1499\n",
      "----------\n",
      "train Loss: 0.6312 Acc: 0.9220\n",
      "val Loss: 0.6440 Acc: 0.9120\n",
      "test Loss: 0.6430 Acc: 0.9080\n",
      "Epoch 1198/1499\n",
      "----------\n",
      "train Loss: 0.6323 Acc: 0.9173\n",
      "val Loss: 0.6395 Acc: 0.9160\n",
      "test Loss: 0.6418 Acc: 0.9080\n",
      "Epoch 1199/1499\n",
      "----------\n",
      "train Loss: 0.6297 Acc: 0.9207\n",
      "val Loss: 0.6443 Acc: 0.9040\n",
      "test Loss: 0.6438 Acc: 0.9080\n",
      "Epoch 1200/1499\n",
      "----------\n",
      "train Loss: 0.6312 Acc: 0.9204\n",
      "val Loss: 0.6421 Acc: 0.9080\n",
      "test Loss: 0.6446 Acc: 0.9080\n",
      "Epoch 1201/1499\n",
      "----------\n",
      "train Loss: 0.6310 Acc: 0.9207\n",
      "val Loss: 0.6395 Acc: 0.9160\n",
      "test Loss: 0.6439 Acc: 0.9080\n",
      "Epoch 1202/1499\n",
      "----------\n",
      "train Loss: 0.6315 Acc: 0.9193\n",
      "val Loss: 0.6425 Acc: 0.9080\n",
      "test Loss: 0.6405 Acc: 0.9120\n",
      "Epoch 1203/1499\n",
      "----------\n",
      "train Loss: 0.6310 Acc: 0.9211\n",
      "val Loss: 0.6454 Acc: 0.9040\n",
      "test Loss: 0.6466 Acc: 0.9000\n",
      "Epoch 1204/1499\n",
      "----------\n",
      "train Loss: 0.6314 Acc: 0.9196\n",
      "val Loss: 0.6433 Acc: 0.9000\n",
      "test Loss: 0.6445 Acc: 0.9080\n",
      "Epoch 1205/1499\n",
      "----------\n",
      "train Loss: 0.6312 Acc: 0.9193\n",
      "val Loss: 0.6450 Acc: 0.9000\n",
      "test Loss: 0.6427 Acc: 0.9040\n",
      "Epoch 1206/1499\n",
      "----------\n",
      "train Loss: 0.6312 Acc: 0.9213\n",
      "val Loss: 0.6418 Acc: 0.9080\n",
      "test Loss: 0.6474 Acc: 0.9000\n",
      "Epoch 1207/1499\n",
      "----------\n",
      "train Loss: 0.6311 Acc: 0.9204\n",
      "val Loss: 0.6465 Acc: 0.9040\n",
      "test Loss: 0.6410 Acc: 0.9120\n",
      "Epoch 1208/1499\n",
      "----------\n",
      "train Loss: 0.6317 Acc: 0.9202\n",
      "val Loss: 0.6411 Acc: 0.9080\n",
      "test Loss: 0.6432 Acc: 0.9120\n",
      "Epoch 1209/1499\n",
      "----------\n",
      "train Loss: 0.6308 Acc: 0.9202\n",
      "val Loss: 0.6487 Acc: 0.8920\n",
      "test Loss: 0.6440 Acc: 0.9040\n",
      "Epoch 1210/1499\n",
      "----------\n",
      "train Loss: 0.6319 Acc: 0.9200\n",
      "val Loss: 0.6411 Acc: 0.9040\n",
      "test Loss: 0.6442 Acc: 0.9000\n",
      "Epoch 1211/1499\n",
      "----------\n",
      "train Loss: 0.6308 Acc: 0.9200\n",
      "val Loss: 0.6393 Acc: 0.9080\n",
      "test Loss: 0.6415 Acc: 0.9120\n",
      "Epoch 1212/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6309 Acc: 0.9220\n",
      "val Loss: 0.6431 Acc: 0.9000\n",
      "test Loss: 0.6456 Acc: 0.9040\n",
      "Epoch 1213/1499\n",
      "----------\n",
      "train Loss: 0.6303 Acc: 0.9222\n",
      "val Loss: 0.6435 Acc: 0.9000\n",
      "test Loss: 0.6415 Acc: 0.9080\n",
      "Epoch 1214/1499\n",
      "----------\n",
      "train Loss: 0.6309 Acc: 0.9189\n",
      "val Loss: 0.6453 Acc: 0.9000\n",
      "test Loss: 0.6422 Acc: 0.9120\n",
      "Epoch 1215/1499\n",
      "----------\n",
      "train Loss: 0.6302 Acc: 0.9211\n",
      "val Loss: 0.6427 Acc: 0.9080\n",
      "test Loss: 0.6438 Acc: 0.9000\n",
      "Epoch 1216/1499\n",
      "----------\n",
      "train Loss: 0.6319 Acc: 0.9193\n",
      "val Loss: 0.6428 Acc: 0.9120\n",
      "test Loss: 0.6449 Acc: 0.9000\n",
      "Epoch 1217/1499\n",
      "----------\n",
      "train Loss: 0.6318 Acc: 0.9187\n",
      "val Loss: 0.6403 Acc: 0.9120\n",
      "test Loss: 0.6457 Acc: 0.9080\n",
      "Epoch 1218/1499\n",
      "----------\n",
      "train Loss: 0.6305 Acc: 0.9191\n",
      "val Loss: 0.6426 Acc: 0.9080\n",
      "test Loss: 0.6420 Acc: 0.9080\n",
      "Epoch 1219/1499\n",
      "----------\n",
      "train Loss: 0.6308 Acc: 0.9204\n",
      "val Loss: 0.6453 Acc: 0.9080\n",
      "test Loss: 0.6457 Acc: 0.9080\n",
      "Epoch 1220/1499\n",
      "----------\n",
      "train Loss: 0.6314 Acc: 0.9207\n",
      "val Loss: 0.6450 Acc: 0.9080\n",
      "test Loss: 0.6429 Acc: 0.9080\n",
      "Epoch 1221/1499\n",
      "----------\n",
      "train Loss: 0.6303 Acc: 0.9216\n",
      "val Loss: 0.6446 Acc: 0.9040\n",
      "test Loss: 0.6436 Acc: 0.9080\n",
      "Epoch 1222/1499\n",
      "----------\n",
      "train Loss: 0.6312 Acc: 0.9189\n",
      "val Loss: 0.6407 Acc: 0.9080\n",
      "test Loss: 0.6482 Acc: 0.9040\n",
      "Epoch 1223/1499\n",
      "----------\n",
      "train Loss: 0.6310 Acc: 0.9211\n",
      "val Loss: 0.6414 Acc: 0.9000\n",
      "test Loss: 0.6413 Acc: 0.9120\n",
      "Epoch 1224/1499\n",
      "----------\n",
      "train Loss: 0.6314 Acc: 0.9218\n",
      "val Loss: 0.6391 Acc: 0.9120\n",
      "test Loss: 0.6437 Acc: 0.9080\n",
      "Epoch 1225/1499\n",
      "----------\n",
      "train Loss: 0.6311 Acc: 0.9202\n",
      "val Loss: 0.6417 Acc: 0.9040\n",
      "test Loss: 0.6489 Acc: 0.8960\n",
      "Epoch 1226/1499\n",
      "----------\n",
      "train Loss: 0.6321 Acc: 0.9191\n",
      "val Loss: 0.6392 Acc: 0.9080\n",
      "test Loss: 0.6449 Acc: 0.9120\n",
      "Epoch 1227/1499\n",
      "----------\n",
      "train Loss: 0.6304 Acc: 0.9211\n",
      "val Loss: 0.6427 Acc: 0.9040\n",
      "test Loss: 0.6461 Acc: 0.9080\n",
      "Epoch 1228/1499\n",
      "----------\n",
      "train Loss: 0.6312 Acc: 0.9207\n",
      "val Loss: 0.6402 Acc: 0.9040\n",
      "test Loss: 0.6427 Acc: 0.9120\n",
      "Epoch 1229/1499\n",
      "----------\n",
      "train Loss: 0.6306 Acc: 0.9218\n",
      "val Loss: 0.6442 Acc: 0.9080\n",
      "test Loss: 0.6429 Acc: 0.9040\n",
      "Epoch 1230/1499\n",
      "----------\n",
      "train Loss: 0.6320 Acc: 0.9204\n",
      "val Loss: 0.6434 Acc: 0.9040\n",
      "test Loss: 0.6450 Acc: 0.9000\n",
      "Epoch 1231/1499\n",
      "----------\n",
      "train Loss: 0.6309 Acc: 0.9196\n",
      "val Loss: 0.6451 Acc: 0.9000\n",
      "test Loss: 0.6410 Acc: 0.9080\n",
      "Epoch 1232/1499\n",
      "----------\n",
      "train Loss: 0.6305 Acc: 0.9200\n",
      "val Loss: 0.6458 Acc: 0.9040\n",
      "test Loss: 0.6436 Acc: 0.9080\n",
      "Epoch 1233/1499\n",
      "----------\n",
      "train Loss: 0.6307 Acc: 0.9200\n",
      "val Loss: 0.6465 Acc: 0.9000\n",
      "test Loss: 0.6437 Acc: 0.9040\n",
      "Epoch 1234/1499\n",
      "----------\n",
      "train Loss: 0.6313 Acc: 0.9189\n",
      "val Loss: 0.6446 Acc: 0.9120\n",
      "test Loss: 0.6417 Acc: 0.9080\n",
      "Epoch 1235/1499\n",
      "----------\n",
      "train Loss: 0.6309 Acc: 0.9198\n",
      "val Loss: 0.6475 Acc: 0.9040\n",
      "test Loss: 0.6393 Acc: 0.9120\n",
      "Epoch 1236/1499\n",
      "----------\n",
      "train Loss: 0.6327 Acc: 0.9178\n",
      "val Loss: 0.6417 Acc: 0.9000\n",
      "test Loss: 0.6472 Acc: 0.9040\n",
      "Epoch 1237/1499\n",
      "----------\n",
      "train Loss: 0.6303 Acc: 0.9198\n",
      "val Loss: 0.6450 Acc: 0.9000\n",
      "test Loss: 0.6424 Acc: 0.9040\n",
      "Epoch 1238/1499\n",
      "----------\n",
      "train Loss: 0.6306 Acc: 0.9202\n",
      "val Loss: 0.6400 Acc: 0.9040\n",
      "test Loss: 0.6411 Acc: 0.9160\n",
      "Epoch 1239/1499\n",
      "----------\n",
      "train Loss: 0.6312 Acc: 0.9202\n",
      "val Loss: 0.6443 Acc: 0.9040\n",
      "test Loss: 0.6438 Acc: 0.9080\n",
      "Epoch 1240/1499\n",
      "----------\n",
      "train Loss: 0.6309 Acc: 0.9200\n",
      "val Loss: 0.6433 Acc: 0.9080\n",
      "test Loss: 0.6419 Acc: 0.9080\n",
      "Epoch 1241/1499\n",
      "----------\n",
      "train Loss: 0.6308 Acc: 0.9216\n",
      "val Loss: 0.6419 Acc: 0.9120\n",
      "test Loss: 0.6445 Acc: 0.9000\n",
      "Epoch 1242/1499\n",
      "----------\n",
      "train Loss: 0.6323 Acc: 0.9182\n",
      "val Loss: 0.6424 Acc: 0.9120\n",
      "test Loss: 0.6478 Acc: 0.9040\n",
      "Epoch 1243/1499\n",
      "----------\n",
      "train Loss: 0.6312 Acc: 0.9193\n",
      "val Loss: 0.6419 Acc: 0.9080\n",
      "test Loss: 0.6496 Acc: 0.9000\n",
      "Epoch 1244/1499\n",
      "----------\n",
      "train Loss: 0.6318 Acc: 0.9184\n",
      "val Loss: 0.6418 Acc: 0.9120\n",
      "test Loss: 0.6429 Acc: 0.9160\n",
      "Epoch 1245/1499\n",
      "----------\n",
      "train Loss: 0.6311 Acc: 0.9196\n",
      "val Loss: 0.6372 Acc: 0.9040\n",
      "test Loss: 0.6455 Acc: 0.9040\n",
      "Epoch 1246/1499\n",
      "----------\n",
      "train Loss: 0.6304 Acc: 0.9204\n",
      "val Loss: 0.6400 Acc: 0.9120\n",
      "test Loss: 0.6436 Acc: 0.9040\n",
      "Epoch 1247/1499\n",
      "----------\n",
      "train Loss: 0.6315 Acc: 0.9218\n",
      "val Loss: 0.6395 Acc: 0.9080\n",
      "test Loss: 0.6433 Acc: 0.9080\n",
      "Epoch 1248/1499\n",
      "----------\n",
      "train Loss: 0.6301 Acc: 0.9211\n",
      "val Loss: 0.6434 Acc: 0.9080\n",
      "test Loss: 0.6466 Acc: 0.9000\n",
      "Epoch 1249/1499\n",
      "----------\n",
      "train Loss: 0.6311 Acc: 0.9211\n",
      "val Loss: 0.6457 Acc: 0.9000\n",
      "test Loss: 0.6453 Acc: 0.9120\n",
      "Epoch 1250/1499\n",
      "----------\n",
      "train Loss: 0.6304 Acc: 0.9213\n",
      "val Loss: 0.6432 Acc: 0.9080\n",
      "test Loss: 0.6424 Acc: 0.9000\n",
      "Epoch 1251/1499\n",
      "----------\n",
      "train Loss: 0.6310 Acc: 0.9200\n",
      "val Loss: 0.6403 Acc: 0.9080\n",
      "test Loss: 0.6451 Acc: 0.9040\n",
      "Epoch 1252/1499\n",
      "----------\n",
      "train Loss: 0.6306 Acc: 0.9216\n",
      "val Loss: 0.6432 Acc: 0.9080\n",
      "test Loss: 0.6446 Acc: 0.9000\n",
      "Epoch 1253/1499\n",
      "----------\n",
      "train Loss: 0.6307 Acc: 0.9191\n",
      "val Loss: 0.6438 Acc: 0.9120\n",
      "test Loss: 0.6423 Acc: 0.9120\n",
      "Epoch 1254/1499\n",
      "----------\n",
      "train Loss: 0.6312 Acc: 0.9189\n",
      "val Loss: 0.6412 Acc: 0.9080\n",
      "test Loss: 0.6434 Acc: 0.9040\n",
      "Epoch 1255/1499\n",
      "----------\n",
      "train Loss: 0.6311 Acc: 0.9180\n",
      "val Loss: 0.6413 Acc: 0.9120\n",
      "test Loss: 0.6464 Acc: 0.9040\n",
      "Epoch 1256/1499\n",
      "----------\n",
      "train Loss: 0.6303 Acc: 0.9204\n",
      "val Loss: 0.6430 Acc: 0.9040\n",
      "test Loss: 0.6427 Acc: 0.9080\n",
      "Epoch 1257/1499\n",
      "----------\n",
      "train Loss: 0.6309 Acc: 0.9209\n",
      "val Loss: 0.6507 Acc: 0.8960\n",
      "test Loss: 0.6450 Acc: 0.9000\n",
      "Epoch 1258/1499\n",
      "----------\n",
      "train Loss: 0.6303 Acc: 0.9220\n",
      "val Loss: 0.6461 Acc: 0.9000\n",
      "test Loss: 0.6430 Acc: 0.9040\n",
      "Epoch 1259/1499\n",
      "----------\n",
      "train Loss: 0.6309 Acc: 0.9211\n",
      "val Loss: 0.6405 Acc: 0.9040\n",
      "test Loss: 0.6433 Acc: 0.9000\n",
      "Epoch 1260/1499\n",
      "----------\n",
      "train Loss: 0.6320 Acc: 0.9182\n",
      "val Loss: 0.6427 Acc: 0.9000\n",
      "test Loss: 0.6413 Acc: 0.9080\n",
      "Epoch 1261/1499\n",
      "----------\n",
      "train Loss: 0.6303 Acc: 0.9211\n",
      "val Loss: 0.6458 Acc: 0.9040\n",
      "test Loss: 0.6471 Acc: 0.9000\n",
      "Epoch 1262/1499\n",
      "----------\n",
      "train Loss: 0.6303 Acc: 0.9196\n",
      "val Loss: 0.6474 Acc: 0.8960\n",
      "test Loss: 0.6445 Acc: 0.9000\n",
      "Epoch 1263/1499\n",
      "----------\n",
      "train Loss: 0.6297 Acc: 0.9200\n",
      "val Loss: 0.6437 Acc: 0.9040\n",
      "test Loss: 0.6398 Acc: 0.9000\n",
      "Epoch 1264/1499\n",
      "----------\n",
      "train Loss: 0.6292 Acc: 0.9204\n",
      "val Loss: 0.6407 Acc: 0.9120\n",
      "test Loss: 0.6456 Acc: 0.9000\n",
      "Epoch 1265/1499\n",
      "----------\n",
      "train Loss: 0.6301 Acc: 0.9218\n",
      "val Loss: 0.6426 Acc: 0.9080\n",
      "test Loss: 0.6450 Acc: 0.9000\n",
      "Epoch 1266/1499\n",
      "----------\n",
      "train Loss: 0.6305 Acc: 0.9209\n",
      "val Loss: 0.6392 Acc: 0.9120\n",
      "test Loss: 0.6506 Acc: 0.9000\n",
      "Epoch 1267/1499\n",
      "----------\n",
      "train Loss: 0.6299 Acc: 0.9220\n",
      "val Loss: 0.6428 Acc: 0.9080\n",
      "test Loss: 0.6456 Acc: 0.9000\n",
      "Epoch 1268/1499\n",
      "----------\n",
      "train Loss: 0.6306 Acc: 0.9198\n",
      "val Loss: 0.6422 Acc: 0.9080\n",
      "test Loss: 0.6451 Acc: 0.9040\n",
      "Epoch 1269/1499\n",
      "----------\n",
      "train Loss: 0.6304 Acc: 0.9213\n",
      "val Loss: 0.6442 Acc: 0.9080\n",
      "test Loss: 0.6400 Acc: 0.9040\n",
      "Epoch 1270/1499\n",
      "----------\n",
      "train Loss: 0.6305 Acc: 0.9198\n",
      "val Loss: 0.6417 Acc: 0.9080\n",
      "test Loss: 0.6434 Acc: 0.9120\n",
      "Epoch 1271/1499\n",
      "----------\n",
      "train Loss: 0.6306 Acc: 0.9207\n",
      "val Loss: 0.6421 Acc: 0.9040\n",
      "test Loss: 0.6465 Acc: 0.9000\n",
      "Epoch 1272/1499\n",
      "----------\n",
      "train Loss: 0.6308 Acc: 0.9222\n",
      "val Loss: 0.6402 Acc: 0.9120\n",
      "test Loss: 0.6461 Acc: 0.8960\n",
      "Epoch 1273/1499\n",
      "----------\n",
      "train Loss: 0.6308 Acc: 0.9218\n",
      "val Loss: 0.6423 Acc: 0.9080\n",
      "test Loss: 0.6397 Acc: 0.9040\n",
      "Epoch 1274/1499\n",
      "----------\n",
      "train Loss: 0.6302 Acc: 0.9204\n",
      "val Loss: 0.6444 Acc: 0.8960\n",
      "test Loss: 0.6446 Acc: 0.9000\n",
      "Epoch 1275/1499\n",
      "----------\n",
      "train Loss: 0.6306 Acc: 0.9218\n",
      "val Loss: 0.6437 Acc: 0.9040\n",
      "test Loss: 0.6451 Acc: 0.9000\n",
      "Epoch 1276/1499\n",
      "----------\n",
      "train Loss: 0.6303 Acc: 0.9213\n",
      "val Loss: 0.6425 Acc: 0.9040\n",
      "test Loss: 0.6434 Acc: 0.9040\n",
      "Epoch 1277/1499\n",
      "----------\n",
      "train Loss: 0.6308 Acc: 0.9213\n",
      "val Loss: 0.6410 Acc: 0.9080\n",
      "test Loss: 0.6442 Acc: 0.9080\n",
      "Epoch 1278/1499\n",
      "----------\n",
      "train Loss: 0.6305 Acc: 0.9196\n",
      "val Loss: 0.6376 Acc: 0.9160\n",
      "test Loss: 0.6452 Acc: 0.9080\n",
      "Epoch 1279/1499\n",
      "----------\n",
      "train Loss: 0.6308 Acc: 0.9209\n",
      "val Loss: 0.6404 Acc: 0.9040\n",
      "test Loss: 0.6414 Acc: 0.9160\n",
      "Epoch 1280/1499\n",
      "----------\n",
      "train Loss: 0.6303 Acc: 0.9224\n",
      "val Loss: 0.6418 Acc: 0.9040\n",
      "test Loss: 0.6419 Acc: 0.9160\n",
      "Epoch 1281/1499\n",
      "----------\n",
      "train Loss: 0.6301 Acc: 0.9209\n",
      "val Loss: 0.6423 Acc: 0.9040\n",
      "test Loss: 0.6419 Acc: 0.9080\n",
      "Epoch 1282/1499\n",
      "----------\n",
      "train Loss: 0.6292 Acc: 0.9222\n",
      "val Loss: 0.6428 Acc: 0.9040\n",
      "test Loss: 0.6423 Acc: 0.9080\n",
      "Epoch 1283/1499\n",
      "----------\n",
      "train Loss: 0.6293 Acc: 0.9229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.6387 Acc: 0.9080\n",
      "test Loss: 0.6465 Acc: 0.9040\n",
      "Epoch 1284/1499\n",
      "----------\n",
      "train Loss: 0.6303 Acc: 0.9211\n",
      "val Loss: 0.6382 Acc: 0.9120\n",
      "test Loss: 0.6462 Acc: 0.8960\n",
      "Epoch 1285/1499\n",
      "----------\n",
      "train Loss: 0.6316 Acc: 0.9216\n",
      "val Loss: 0.6445 Acc: 0.8960\n",
      "test Loss: 0.6413 Acc: 0.9080\n",
      "Epoch 1286/1499\n",
      "----------\n",
      "train Loss: 0.6312 Acc: 0.9202\n",
      "val Loss: 0.6395 Acc: 0.9120\n",
      "test Loss: 0.6430 Acc: 0.9040\n",
      "Epoch 1287/1499\n",
      "----------\n",
      "train Loss: 0.6313 Acc: 0.9189\n",
      "val Loss: 0.6369 Acc: 0.9160\n",
      "test Loss: 0.6456 Acc: 0.9080\n",
      "Epoch 1288/1499\n",
      "----------\n",
      "train Loss: 0.6302 Acc: 0.9209\n",
      "val Loss: 0.6410 Acc: 0.9040\n",
      "test Loss: 0.6439 Acc: 0.9000\n",
      "Epoch 1289/1499\n",
      "----------\n",
      "train Loss: 0.6316 Acc: 0.9191\n",
      "val Loss: 0.6453 Acc: 0.9040\n",
      "test Loss: 0.6427 Acc: 0.9160\n",
      "Epoch 1290/1499\n",
      "----------\n",
      "train Loss: 0.6304 Acc: 0.9202\n",
      "val Loss: 0.6450 Acc: 0.9040\n",
      "test Loss: 0.6449 Acc: 0.9000\n",
      "Epoch 1291/1499\n",
      "----------\n",
      "train Loss: 0.6310 Acc: 0.9191\n",
      "val Loss: 0.6389 Acc: 0.9080\n",
      "test Loss: 0.6441 Acc: 0.9000\n",
      "Epoch 1292/1499\n",
      "----------\n",
      "train Loss: 0.6308 Acc: 0.9196\n",
      "val Loss: 0.6463 Acc: 0.9000\n",
      "test Loss: 0.6446 Acc: 0.9040\n",
      "Epoch 1293/1499\n",
      "----------\n",
      "train Loss: 0.6301 Acc: 0.9207\n",
      "val Loss: 0.6386 Acc: 0.9120\n",
      "test Loss: 0.6461 Acc: 0.9000\n",
      "Epoch 1294/1499\n",
      "----------\n",
      "train Loss: 0.6303 Acc: 0.9193\n",
      "val Loss: 0.6444 Acc: 0.9080\n",
      "test Loss: 0.6438 Acc: 0.9000\n",
      "Epoch 1295/1499\n",
      "----------\n",
      "train Loss: 0.6293 Acc: 0.9233\n",
      "val Loss: 0.6435 Acc: 0.9120\n",
      "test Loss: 0.6444 Acc: 0.8960\n",
      "Epoch 1296/1499\n",
      "----------\n",
      "train Loss: 0.6301 Acc: 0.9222\n",
      "val Loss: 0.6436 Acc: 0.9040\n",
      "test Loss: 0.6421 Acc: 0.9080\n",
      "Epoch 1297/1499\n",
      "----------\n",
      "train Loss: 0.6306 Acc: 0.9204\n",
      "val Loss: 0.6434 Acc: 0.9040\n",
      "test Loss: 0.6442 Acc: 0.9080\n",
      "Epoch 1298/1499\n",
      "----------\n",
      "train Loss: 0.6307 Acc: 0.9209\n",
      "val Loss: 0.6406 Acc: 0.9080\n",
      "test Loss: 0.6416 Acc: 0.9120\n",
      "Epoch 1299/1499\n",
      "----------\n",
      "train Loss: 0.6300 Acc: 0.9231\n",
      "val Loss: 0.6399 Acc: 0.9040\n",
      "test Loss: 0.6417 Acc: 0.9080\n",
      "Epoch 1300/1499\n",
      "----------\n",
      "train Loss: 0.6304 Acc: 0.9211\n",
      "val Loss: 0.6436 Acc: 0.9000\n",
      "test Loss: 0.6456 Acc: 0.9080\n",
      "Epoch 1301/1499\n",
      "----------\n",
      "train Loss: 0.6310 Acc: 0.9202\n",
      "val Loss: 0.6360 Acc: 0.9160\n",
      "test Loss: 0.6387 Acc: 0.9080\n",
      "Epoch 1302/1499\n",
      "----------\n",
      "train Loss: 0.6294 Acc: 0.9236\n",
      "val Loss: 0.6438 Acc: 0.9120\n",
      "test Loss: 0.6443 Acc: 0.9080\n",
      "Epoch 1303/1499\n",
      "----------\n",
      "train Loss: 0.6296 Acc: 0.9198\n",
      "val Loss: 0.6398 Acc: 0.9080\n",
      "test Loss: 0.6437 Acc: 0.9040\n",
      "Epoch 1304/1499\n",
      "----------\n",
      "train Loss: 0.6283 Acc: 0.9244\n",
      "val Loss: 0.6413 Acc: 0.9120\n",
      "test Loss: 0.6434 Acc: 0.9040\n",
      "Epoch 1305/1499\n",
      "----------\n",
      "train Loss: 0.6310 Acc: 0.9224\n",
      "val Loss: 0.6473 Acc: 0.9000\n",
      "test Loss: 0.6404 Acc: 0.9120\n",
      "Epoch 1306/1499\n",
      "----------\n",
      "train Loss: 0.6298 Acc: 0.9216\n",
      "val Loss: 0.6423 Acc: 0.9000\n",
      "test Loss: 0.6442 Acc: 0.9160\n",
      "Epoch 1307/1499\n",
      "----------\n",
      "train Loss: 0.6306 Acc: 0.9202\n",
      "val Loss: 0.6442 Acc: 0.9120\n",
      "test Loss: 0.6416 Acc: 0.9080\n",
      "Epoch 1308/1499\n",
      "----------\n",
      "train Loss: 0.6296 Acc: 0.9218\n",
      "val Loss: 0.6441 Acc: 0.9040\n",
      "test Loss: 0.6425 Acc: 0.9120\n",
      "Epoch 1309/1499\n",
      "----------\n",
      "train Loss: 0.6302 Acc: 0.9222\n",
      "val Loss: 0.6438 Acc: 0.9040\n",
      "test Loss: 0.6444 Acc: 0.9120\n",
      "Epoch 1310/1499\n",
      "----------\n",
      "train Loss: 0.6317 Acc: 0.9196\n",
      "val Loss: 0.6443 Acc: 0.9080\n",
      "test Loss: 0.6440 Acc: 0.9080\n",
      "Epoch 1311/1499\n",
      "----------\n",
      "train Loss: 0.6295 Acc: 0.9220\n",
      "val Loss: 0.6409 Acc: 0.9000\n",
      "test Loss: 0.6451 Acc: 0.9040\n",
      "Epoch 1312/1499\n",
      "----------\n",
      "train Loss: 0.6307 Acc: 0.9200\n",
      "val Loss: 0.6423 Acc: 0.9080\n",
      "test Loss: 0.6426 Acc: 0.9040\n",
      "Epoch 1313/1499\n",
      "----------\n",
      "train Loss: 0.6298 Acc: 0.9220\n",
      "val Loss: 0.6462 Acc: 0.9120\n",
      "test Loss: 0.6409 Acc: 0.9120\n",
      "Epoch 1314/1499\n",
      "----------\n",
      "train Loss: 0.6296 Acc: 0.9198\n",
      "val Loss: 0.6411 Acc: 0.9080\n",
      "test Loss: 0.6467 Acc: 0.9120\n",
      "Epoch 1315/1499\n",
      "----------\n",
      "train Loss: 0.6304 Acc: 0.9218\n",
      "val Loss: 0.6482 Acc: 0.9000\n",
      "test Loss: 0.6427 Acc: 0.9160\n",
      "Epoch 1316/1499\n",
      "----------\n",
      "train Loss: 0.6300 Acc: 0.9220\n",
      "val Loss: 0.6436 Acc: 0.9040\n",
      "test Loss: 0.6459 Acc: 0.9040\n",
      "Epoch 1317/1499\n",
      "----------\n",
      "train Loss: 0.6301 Acc: 0.9231\n",
      "val Loss: 0.6431 Acc: 0.9040\n",
      "test Loss: 0.6442 Acc: 0.9080\n",
      "Epoch 1318/1499\n",
      "----------\n",
      "train Loss: 0.6303 Acc: 0.9222\n",
      "val Loss: 0.6411 Acc: 0.9080\n",
      "test Loss: 0.6470 Acc: 0.9040\n",
      "Epoch 1319/1499\n",
      "----------\n",
      "train Loss: 0.6303 Acc: 0.9202\n",
      "val Loss: 0.6421 Acc: 0.9120\n",
      "test Loss: 0.6496 Acc: 0.9000\n",
      "Epoch 1320/1499\n",
      "----------\n",
      "train Loss: 0.6308 Acc: 0.9200\n",
      "val Loss: 0.6430 Acc: 0.9040\n",
      "test Loss: 0.6481 Acc: 0.9000\n",
      "Epoch 1321/1499\n",
      "----------\n",
      "train Loss: 0.6301 Acc: 0.9222\n",
      "val Loss: 0.6397 Acc: 0.9120\n",
      "test Loss: 0.6436 Acc: 0.9040\n",
      "Epoch 1322/1499\n",
      "----------\n",
      "train Loss: 0.6311 Acc: 0.9204\n",
      "val Loss: 0.6424 Acc: 0.9000\n",
      "test Loss: 0.6456 Acc: 0.9040\n",
      "Epoch 1323/1499\n",
      "----------\n",
      "train Loss: 0.6305 Acc: 0.9222\n",
      "val Loss: 0.6404 Acc: 0.9160\n",
      "test Loss: 0.6408 Acc: 0.9080\n",
      "Epoch 1324/1499\n",
      "----------\n",
      "train Loss: 0.6295 Acc: 0.9207\n",
      "val Loss: 0.6481 Acc: 0.9040\n",
      "test Loss: 0.6419 Acc: 0.9080\n",
      "Epoch 1325/1499\n",
      "----------\n",
      "train Loss: 0.6309 Acc: 0.9216\n",
      "val Loss: 0.6444 Acc: 0.9080\n",
      "test Loss: 0.6433 Acc: 0.9080\n",
      "Epoch 1326/1499\n",
      "----------\n",
      "train Loss: 0.6291 Acc: 0.9213\n",
      "val Loss: 0.6449 Acc: 0.9080\n",
      "test Loss: 0.6377 Acc: 0.9200\n",
      "Epoch 1327/1499\n",
      "----------\n",
      "train Loss: 0.6308 Acc: 0.9204\n",
      "val Loss: 0.6405 Acc: 0.9080\n",
      "test Loss: 0.6453 Acc: 0.9080\n",
      "Epoch 1328/1499\n",
      "----------\n",
      "train Loss: 0.6307 Acc: 0.9204\n",
      "val Loss: 0.6418 Acc: 0.9080\n",
      "test Loss: 0.6450 Acc: 0.9080\n",
      "Epoch 1329/1499\n",
      "----------\n",
      "train Loss: 0.6305 Acc: 0.9187\n",
      "val Loss: 0.6410 Acc: 0.9080\n",
      "test Loss: 0.6410 Acc: 0.9040\n",
      "Epoch 1330/1499\n",
      "----------\n",
      "train Loss: 0.6297 Acc: 0.9193\n",
      "val Loss: 0.6402 Acc: 0.9120\n",
      "test Loss: 0.6425 Acc: 0.9040\n",
      "Epoch 1331/1499\n",
      "----------\n",
      "train Loss: 0.6292 Acc: 0.9207\n",
      "val Loss: 0.6409 Acc: 0.9080\n",
      "test Loss: 0.6464 Acc: 0.9000\n",
      "Epoch 1332/1499\n",
      "----------\n",
      "train Loss: 0.6307 Acc: 0.9200\n",
      "val Loss: 0.6404 Acc: 0.9080\n",
      "test Loss: 0.6475 Acc: 0.9000\n",
      "Epoch 1333/1499\n",
      "----------\n",
      "train Loss: 0.6304 Acc: 0.9213\n",
      "val Loss: 0.6402 Acc: 0.9120\n",
      "test Loss: 0.6399 Acc: 0.9080\n",
      "Epoch 1334/1499\n",
      "----------\n",
      "train Loss: 0.6300 Acc: 0.9202\n",
      "val Loss: 0.6460 Acc: 0.9080\n",
      "test Loss: 0.6399 Acc: 0.9120\n",
      "Epoch 1335/1499\n",
      "----------\n",
      "train Loss: 0.6298 Acc: 0.9209\n",
      "val Loss: 0.6442 Acc: 0.9000\n",
      "test Loss: 0.6416 Acc: 0.9120\n",
      "Epoch 1336/1499\n",
      "----------\n",
      "train Loss: 0.6302 Acc: 0.9202\n",
      "val Loss: 0.6419 Acc: 0.9040\n",
      "test Loss: 0.6417 Acc: 0.9080\n",
      "Epoch 1337/1499\n",
      "----------\n",
      "train Loss: 0.6293 Acc: 0.9218\n",
      "val Loss: 0.6425 Acc: 0.9080\n",
      "test Loss: 0.6458 Acc: 0.9080\n",
      "Epoch 1338/1499\n",
      "----------\n",
      "train Loss: 0.6302 Acc: 0.9198\n",
      "val Loss: 0.6368 Acc: 0.9120\n",
      "test Loss: 0.6432 Acc: 0.9080\n",
      "Epoch 1339/1499\n",
      "----------\n",
      "train Loss: 0.6311 Acc: 0.9173\n",
      "val Loss: 0.6470 Acc: 0.9080\n",
      "test Loss: 0.6458 Acc: 0.9040\n",
      "Epoch 1340/1499\n",
      "----------\n",
      "train Loss: 0.6300 Acc: 0.9218\n",
      "val Loss: 0.6441 Acc: 0.9040\n",
      "test Loss: 0.6447 Acc: 0.9080\n",
      "Epoch 1341/1499\n",
      "----------\n",
      "train Loss: 0.6305 Acc: 0.9193\n",
      "val Loss: 0.6402 Acc: 0.9040\n",
      "test Loss: 0.6419 Acc: 0.9120\n",
      "Epoch 1342/1499\n",
      "----------\n",
      "train Loss: 0.6310 Acc: 0.9209\n",
      "val Loss: 0.6461 Acc: 0.9040\n",
      "test Loss: 0.6451 Acc: 0.9000\n",
      "Epoch 1343/1499\n",
      "----------\n",
      "train Loss: 0.6298 Acc: 0.9233\n",
      "val Loss: 0.6440 Acc: 0.9080\n",
      "test Loss: 0.6433 Acc: 0.9120\n",
      "Epoch 1344/1499\n",
      "----------\n",
      "train Loss: 0.6293 Acc: 0.9224\n",
      "val Loss: 0.6393 Acc: 0.9160\n",
      "test Loss: 0.6462 Acc: 0.9080\n",
      "Epoch 1345/1499\n",
      "----------\n",
      "train Loss: 0.6314 Acc: 0.9198\n",
      "val Loss: 0.6416 Acc: 0.9040\n",
      "test Loss: 0.6458 Acc: 0.9040\n",
      "Epoch 1346/1499\n",
      "----------\n",
      "train Loss: 0.6293 Acc: 0.9200\n",
      "val Loss: 0.6419 Acc: 0.9160\n",
      "test Loss: 0.6456 Acc: 0.9080\n",
      "Epoch 1347/1499\n",
      "----------\n",
      "train Loss: 0.6307 Acc: 0.9184\n",
      "val Loss: 0.6404 Acc: 0.9080\n",
      "test Loss: 0.6460 Acc: 0.9080\n",
      "Epoch 1348/1499\n",
      "----------\n",
      "train Loss: 0.6306 Acc: 0.9198\n",
      "val Loss: 0.6401 Acc: 0.9120\n",
      "test Loss: 0.6469 Acc: 0.9040\n",
      "Epoch 1349/1499\n",
      "----------\n",
      "train Loss: 0.6298 Acc: 0.9207\n",
      "val Loss: 0.6405 Acc: 0.9040\n",
      "test Loss: 0.6459 Acc: 0.9040\n",
      "Epoch 1350/1499\n",
      "----------\n",
      "train Loss: 0.6302 Acc: 0.9218\n",
      "val Loss: 0.6480 Acc: 0.9040\n",
      "test Loss: 0.6462 Acc: 0.9000\n",
      "Epoch 1351/1499\n",
      "----------\n",
      "train Loss: 0.6285 Acc: 0.9227\n",
      "val Loss: 0.6434 Acc: 0.9000\n",
      "test Loss: 0.6415 Acc: 0.9080\n",
      "Epoch 1352/1499\n",
      "----------\n",
      "train Loss: 0.6307 Acc: 0.9207\n",
      "val Loss: 0.6410 Acc: 0.9040\n",
      "test Loss: 0.6406 Acc: 0.9040\n",
      "Epoch 1353/1499\n",
      "----------\n",
      "train Loss: 0.6305 Acc: 0.9222\n",
      "val Loss: 0.6397 Acc: 0.9200\n",
      "test Loss: 0.6456 Acc: 0.9000\n",
      "Epoch 1354/1499\n",
      "----------\n",
      "train Loss: 0.6294 Acc: 0.9218\n",
      "val Loss: 0.6428 Acc: 0.9000\n",
      "test Loss: 0.6471 Acc: 0.9000\n",
      "Epoch 1355/1499\n",
      "----------\n",
      "train Loss: 0.6294 Acc: 0.9207\n",
      "val Loss: 0.6431 Acc: 0.9040\n",
      "test Loss: 0.6445 Acc: 0.9040\n",
      "Epoch 1356/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6306 Acc: 0.9193\n",
      "val Loss: 0.6408 Acc: 0.9080\n",
      "test Loss: 0.6418 Acc: 0.9080\n",
      "Epoch 1357/1499\n",
      "----------\n",
      "train Loss: 0.6299 Acc: 0.9204\n",
      "val Loss: 0.6407 Acc: 0.9120\n",
      "test Loss: 0.6398 Acc: 0.9080\n",
      "Epoch 1358/1499\n",
      "----------\n",
      "train Loss: 0.6304 Acc: 0.9216\n",
      "val Loss: 0.6403 Acc: 0.9080\n",
      "test Loss: 0.6442 Acc: 0.9080\n",
      "Epoch 1359/1499\n",
      "----------\n",
      "train Loss: 0.6300 Acc: 0.9200\n",
      "val Loss: 0.6434 Acc: 0.9080\n",
      "test Loss: 0.6435 Acc: 0.9120\n",
      "Epoch 1360/1499\n",
      "----------\n",
      "train Loss: 0.6295 Acc: 0.9222\n",
      "val Loss: 0.6438 Acc: 0.9080\n",
      "test Loss: 0.6482 Acc: 0.9040\n",
      "Epoch 1361/1499\n",
      "----------\n",
      "train Loss: 0.6303 Acc: 0.9202\n",
      "val Loss: 0.6420 Acc: 0.9080\n",
      "test Loss: 0.6436 Acc: 0.9080\n",
      "Epoch 1362/1499\n",
      "----------\n",
      "train Loss: 0.6293 Acc: 0.9209\n",
      "val Loss: 0.6382 Acc: 0.9160\n",
      "test Loss: 0.6422 Acc: 0.9120\n",
      "Epoch 1363/1499\n",
      "----------\n",
      "train Loss: 0.6299 Acc: 0.9198\n",
      "val Loss: 0.6395 Acc: 0.9160\n",
      "test Loss: 0.6431 Acc: 0.9160\n",
      "Epoch 1364/1499\n",
      "----------\n",
      "train Loss: 0.6297 Acc: 0.9184\n",
      "val Loss: 0.6425 Acc: 0.9040\n",
      "test Loss: 0.6423 Acc: 0.9120\n",
      "Epoch 1365/1499\n",
      "----------\n",
      "train Loss: 0.6297 Acc: 0.9204\n",
      "val Loss: 0.6436 Acc: 0.9040\n",
      "test Loss: 0.6474 Acc: 0.9080\n",
      "Epoch 1366/1499\n",
      "----------\n",
      "train Loss: 0.6303 Acc: 0.9198\n",
      "val Loss: 0.6411 Acc: 0.9080\n",
      "test Loss: 0.6421 Acc: 0.9080\n",
      "Epoch 1367/1499\n",
      "----------\n",
      "train Loss: 0.6295 Acc: 0.9218\n",
      "val Loss: 0.6423 Acc: 0.9080\n",
      "test Loss: 0.6421 Acc: 0.9040\n",
      "Epoch 1368/1499\n",
      "----------\n",
      "train Loss: 0.6284 Acc: 0.9224\n",
      "val Loss: 0.6429 Acc: 0.9080\n",
      "test Loss: 0.6428 Acc: 0.9040\n",
      "Epoch 1369/1499\n",
      "----------\n",
      "train Loss: 0.6289 Acc: 0.9218\n",
      "val Loss: 0.6387 Acc: 0.9120\n",
      "test Loss: 0.6419 Acc: 0.9120\n",
      "Epoch 1370/1499\n",
      "----------\n",
      "train Loss: 0.6301 Acc: 0.9213\n",
      "val Loss: 0.6419 Acc: 0.9040\n",
      "test Loss: 0.6438 Acc: 0.9040\n",
      "Epoch 1371/1499\n",
      "----------\n",
      "train Loss: 0.6300 Acc: 0.9222\n",
      "val Loss: 0.6416 Acc: 0.9040\n",
      "test Loss: 0.6384 Acc: 0.9120\n",
      "Epoch 1372/1499\n",
      "----------\n",
      "train Loss: 0.6300 Acc: 0.9209\n",
      "val Loss: 0.6420 Acc: 0.9080\n",
      "test Loss: 0.6413 Acc: 0.9120\n",
      "Epoch 1373/1499\n",
      "----------\n",
      "train Loss: 0.6296 Acc: 0.9216\n",
      "val Loss: 0.6407 Acc: 0.9120\n",
      "test Loss: 0.6460 Acc: 0.9000\n",
      "Epoch 1374/1499\n",
      "----------\n",
      "train Loss: 0.6287 Acc: 0.9240\n",
      "val Loss: 0.6408 Acc: 0.9120\n",
      "test Loss: 0.6438 Acc: 0.9080\n",
      "Epoch 1375/1499\n",
      "----------\n",
      "train Loss: 0.6296 Acc: 0.9216\n",
      "val Loss: 0.6419 Acc: 0.8960\n",
      "test Loss: 0.6448 Acc: 0.9040\n",
      "Epoch 1376/1499\n",
      "----------\n",
      "train Loss: 0.6308 Acc: 0.9202\n",
      "val Loss: 0.6415 Acc: 0.9160\n",
      "test Loss: 0.6449 Acc: 0.8960\n",
      "Epoch 1377/1499\n",
      "----------\n",
      "train Loss: 0.6296 Acc: 0.9204\n",
      "val Loss: 0.6479 Acc: 0.9040\n",
      "test Loss: 0.6442 Acc: 0.9040\n",
      "Epoch 1378/1499\n",
      "----------\n",
      "train Loss: 0.6293 Acc: 0.9227\n",
      "val Loss: 0.6411 Acc: 0.9120\n",
      "test Loss: 0.6417 Acc: 0.9040\n",
      "Epoch 1379/1499\n",
      "----------\n",
      "train Loss: 0.6295 Acc: 0.9213\n",
      "val Loss: 0.6397 Acc: 0.9160\n",
      "test Loss: 0.6494 Acc: 0.8960\n",
      "Epoch 1380/1499\n",
      "----------\n",
      "train Loss: 0.6291 Acc: 0.9216\n",
      "val Loss: 0.6417 Acc: 0.9120\n",
      "test Loss: 0.6477 Acc: 0.9040\n",
      "Epoch 1381/1499\n",
      "----------\n",
      "train Loss: 0.6283 Acc: 0.9229\n",
      "val Loss: 0.6425 Acc: 0.9120\n",
      "test Loss: 0.6415 Acc: 0.9040\n",
      "Epoch 1382/1499\n",
      "----------\n",
      "train Loss: 0.6304 Acc: 0.9207\n",
      "val Loss: 0.6427 Acc: 0.9040\n",
      "test Loss: 0.6379 Acc: 0.9160\n",
      "Epoch 1383/1499\n",
      "----------\n",
      "train Loss: 0.6321 Acc: 0.9213\n",
      "val Loss: 0.6450 Acc: 0.9120\n",
      "test Loss: 0.6435 Acc: 0.9080\n",
      "Epoch 1384/1499\n",
      "----------\n",
      "train Loss: 0.6299 Acc: 0.9218\n",
      "val Loss: 0.6445 Acc: 0.9080\n",
      "test Loss: 0.6436 Acc: 0.9080\n",
      "Epoch 1385/1499\n",
      "----------\n",
      "train Loss: 0.6294 Acc: 0.9202\n",
      "val Loss: 0.6419 Acc: 0.9080\n",
      "test Loss: 0.6425 Acc: 0.9080\n",
      "Epoch 1386/1499\n",
      "----------\n",
      "train Loss: 0.6289 Acc: 0.9218\n",
      "val Loss: 0.6423 Acc: 0.9080\n",
      "test Loss: 0.6426 Acc: 0.9040\n",
      "Epoch 1387/1499\n",
      "----------\n",
      "train Loss: 0.6297 Acc: 0.9213\n",
      "val Loss: 0.6407 Acc: 0.9040\n",
      "test Loss: 0.6431 Acc: 0.9080\n",
      "Epoch 1388/1499\n",
      "----------\n",
      "train Loss: 0.6289 Acc: 0.9209\n",
      "val Loss: 0.6385 Acc: 0.9120\n",
      "test Loss: 0.6410 Acc: 0.9080\n",
      "Epoch 1389/1499\n",
      "----------\n",
      "train Loss: 0.6299 Acc: 0.9224\n",
      "val Loss: 0.6359 Acc: 0.9160\n",
      "test Loss: 0.6395 Acc: 0.9160\n",
      "Epoch 1390/1499\n",
      "----------\n",
      "train Loss: 0.6302 Acc: 0.9224\n",
      "val Loss: 0.6452 Acc: 0.9080\n",
      "test Loss: 0.6411 Acc: 0.9120\n",
      "Epoch 1391/1499\n",
      "----------\n",
      "train Loss: 0.6294 Acc: 0.9216\n",
      "val Loss: 0.6421 Acc: 0.9120\n",
      "test Loss: 0.6423 Acc: 0.9080\n",
      "Epoch 1392/1499\n",
      "----------\n",
      "train Loss: 0.6302 Acc: 0.9220\n",
      "val Loss: 0.6414 Acc: 0.9120\n",
      "test Loss: 0.6457 Acc: 0.9080\n",
      "Epoch 1393/1499\n",
      "----------\n",
      "train Loss: 0.6299 Acc: 0.9207\n",
      "val Loss: 0.6399 Acc: 0.9120\n",
      "test Loss: 0.6473 Acc: 0.9000\n",
      "Epoch 1394/1499\n",
      "----------\n",
      "train Loss: 0.6299 Acc: 0.9202\n",
      "val Loss: 0.6442 Acc: 0.9080\n",
      "test Loss: 0.6448 Acc: 0.9000\n",
      "Epoch 1395/1499\n",
      "----------\n",
      "train Loss: 0.6296 Acc: 0.9224\n",
      "val Loss: 0.6428 Acc: 0.9000\n",
      "test Loss: 0.6439 Acc: 0.9080\n",
      "Epoch 1396/1499\n",
      "----------\n",
      "train Loss: 0.6290 Acc: 0.9213\n",
      "val Loss: 0.6442 Acc: 0.9080\n",
      "test Loss: 0.6430 Acc: 0.9080\n",
      "Epoch 1397/1499\n",
      "----------\n",
      "train Loss: 0.6296 Acc: 0.9224\n",
      "val Loss: 0.6443 Acc: 0.9080\n",
      "test Loss: 0.6387 Acc: 0.9080\n",
      "Epoch 1398/1499\n",
      "----------\n",
      "train Loss: 0.6285 Acc: 0.9242\n",
      "val Loss: 0.6425 Acc: 0.9080\n",
      "test Loss: 0.6400 Acc: 0.9160\n",
      "Epoch 1399/1499\n",
      "----------\n",
      "train Loss: 0.6292 Acc: 0.9216\n",
      "val Loss: 0.6391 Acc: 0.9120\n",
      "test Loss: 0.6423 Acc: 0.9040\n",
      "Epoch 1400/1499\n",
      "----------\n",
      "train Loss: 0.6289 Acc: 0.9220\n",
      "val Loss: 0.6445 Acc: 0.9080\n",
      "test Loss: 0.6433 Acc: 0.9040\n",
      "Epoch 1401/1499\n",
      "----------\n",
      "train Loss: 0.6295 Acc: 0.9198\n",
      "val Loss: 0.6421 Acc: 0.9120\n",
      "test Loss: 0.6479 Acc: 0.9000\n",
      "Epoch 1402/1499\n",
      "----------\n",
      "train Loss: 0.6305 Acc: 0.9216\n",
      "val Loss: 0.6407 Acc: 0.9160\n",
      "test Loss: 0.6432 Acc: 0.9040\n",
      "Epoch 1403/1499\n",
      "----------\n",
      "train Loss: 0.6292 Acc: 0.9231\n",
      "val Loss: 0.6441 Acc: 0.9000\n",
      "test Loss: 0.6426 Acc: 0.9080\n",
      "Epoch 1404/1499\n",
      "----------\n",
      "train Loss: 0.6307 Acc: 0.9213\n",
      "val Loss: 0.6403 Acc: 0.9120\n",
      "test Loss: 0.6467 Acc: 0.9000\n",
      "Epoch 1405/1499\n",
      "----------\n",
      "train Loss: 0.6294 Acc: 0.9220\n",
      "val Loss: 0.6429 Acc: 0.9040\n",
      "test Loss: 0.6464 Acc: 0.9040\n",
      "Epoch 1406/1499\n",
      "----------\n",
      "train Loss: 0.6301 Acc: 0.9196\n",
      "val Loss: 0.6389 Acc: 0.9120\n",
      "test Loss: 0.6496 Acc: 0.8960\n",
      "Epoch 1407/1499\n",
      "----------\n",
      "train Loss: 0.6290 Acc: 0.9224\n",
      "val Loss: 0.6445 Acc: 0.9080\n",
      "test Loss: 0.6431 Acc: 0.9040\n",
      "Epoch 1408/1499\n",
      "----------\n",
      "train Loss: 0.6292 Acc: 0.9209\n",
      "val Loss: 0.6452 Acc: 0.9040\n",
      "test Loss: 0.6397 Acc: 0.9160\n",
      "Epoch 1409/1499\n",
      "----------\n",
      "train Loss: 0.6299 Acc: 0.9220\n",
      "val Loss: 0.6418 Acc: 0.9120\n",
      "test Loss: 0.6471 Acc: 0.9080\n",
      "Epoch 1410/1499\n",
      "----------\n",
      "train Loss: 0.6297 Acc: 0.9213\n",
      "val Loss: 0.6454 Acc: 0.9120\n",
      "test Loss: 0.6390 Acc: 0.9160\n",
      "Epoch 1411/1499\n",
      "----------\n",
      "train Loss: 0.6287 Acc: 0.9224\n",
      "val Loss: 0.6393 Acc: 0.9080\n",
      "test Loss: 0.6443 Acc: 0.9080\n",
      "Epoch 1412/1499\n",
      "----------\n",
      "train Loss: 0.6296 Acc: 0.9224\n",
      "val Loss: 0.6416 Acc: 0.9040\n",
      "test Loss: 0.6430 Acc: 0.9080\n",
      "Epoch 1413/1499\n",
      "----------\n",
      "train Loss: 0.6305 Acc: 0.9200\n",
      "val Loss: 0.6402 Acc: 0.9120\n",
      "test Loss: 0.6419 Acc: 0.9040\n",
      "Epoch 1414/1499\n",
      "----------\n",
      "train Loss: 0.6289 Acc: 0.9227\n",
      "val Loss: 0.6408 Acc: 0.9120\n",
      "test Loss: 0.6412 Acc: 0.9080\n",
      "Epoch 1415/1499\n",
      "----------\n",
      "train Loss: 0.6296 Acc: 0.9229\n",
      "val Loss: 0.6435 Acc: 0.9080\n",
      "test Loss: 0.6417 Acc: 0.9080\n",
      "Epoch 1416/1499\n",
      "----------\n",
      "train Loss: 0.6300 Acc: 0.9222\n",
      "val Loss: 0.6403 Acc: 0.9120\n",
      "test Loss: 0.6461 Acc: 0.9000\n",
      "Epoch 1417/1499\n",
      "----------\n",
      "train Loss: 0.6297 Acc: 0.9196\n",
      "val Loss: 0.6430 Acc: 0.9120\n",
      "test Loss: 0.6391 Acc: 0.9120\n",
      "Epoch 1418/1499\n",
      "----------\n",
      "train Loss: 0.6300 Acc: 0.9216\n",
      "val Loss: 0.6402 Acc: 0.9120\n",
      "test Loss: 0.6399 Acc: 0.9120\n",
      "Epoch 1419/1499\n",
      "----------\n",
      "train Loss: 0.6299 Acc: 0.9218\n",
      "val Loss: 0.6429 Acc: 0.9120\n",
      "test Loss: 0.6438 Acc: 0.9080\n",
      "Epoch 1420/1499\n",
      "----------\n",
      "train Loss: 0.6298 Acc: 0.9211\n",
      "val Loss: 0.6366 Acc: 0.9160\n",
      "test Loss: 0.6416 Acc: 0.9040\n",
      "Epoch 1421/1499\n",
      "----------\n",
      "train Loss: 0.6294 Acc: 0.9216\n",
      "val Loss: 0.6398 Acc: 0.9120\n",
      "test Loss: 0.6460 Acc: 0.9040\n",
      "Epoch 1422/1499\n",
      "----------\n",
      "train Loss: 0.6298 Acc: 0.9224\n",
      "val Loss: 0.6403 Acc: 0.9120\n",
      "test Loss: 0.6490 Acc: 0.9000\n",
      "Epoch 1423/1499\n",
      "----------\n",
      "train Loss: 0.6302 Acc: 0.9211\n",
      "val Loss: 0.6383 Acc: 0.9080\n",
      "test Loss: 0.6409 Acc: 0.9040\n",
      "Epoch 1424/1499\n",
      "----------\n",
      "train Loss: 0.6299 Acc: 0.9196\n",
      "val Loss: 0.6404 Acc: 0.9080\n",
      "test Loss: 0.6415 Acc: 0.9080\n",
      "Epoch 1425/1499\n",
      "----------\n",
      "train Loss: 0.6296 Acc: 0.9220\n",
      "val Loss: 0.6421 Acc: 0.9120\n",
      "test Loss: 0.6461 Acc: 0.9080\n",
      "Epoch 1426/1499\n",
      "----------\n",
      "train Loss: 0.6306 Acc: 0.9204\n",
      "val Loss: 0.6424 Acc: 0.9120\n",
      "test Loss: 0.6433 Acc: 0.9040\n",
      "Epoch 1427/1499\n",
      "----------\n",
      "train Loss: 0.6288 Acc: 0.9222\n",
      "val Loss: 0.6443 Acc: 0.9040\n",
      "test Loss: 0.6432 Acc: 0.9040\n",
      "Epoch 1428/1499\n",
      "----------\n",
      "train Loss: 0.6282 Acc: 0.9231\n",
      "val Loss: 0.6407 Acc: 0.9080\n",
      "test Loss: 0.6464 Acc: 0.8960\n",
      "Epoch 1429/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6284 Acc: 0.9229\n",
      "val Loss: 0.6433 Acc: 0.9120\n",
      "test Loss: 0.6444 Acc: 0.9040\n",
      "Epoch 1430/1499\n",
      "----------\n",
      "train Loss: 0.6284 Acc: 0.9222\n",
      "val Loss: 0.6397 Acc: 0.9080\n",
      "test Loss: 0.6450 Acc: 0.9080\n",
      "Epoch 1431/1499\n",
      "----------\n",
      "train Loss: 0.6296 Acc: 0.9220\n",
      "val Loss: 0.6432 Acc: 0.9080\n",
      "test Loss: 0.6459 Acc: 0.9040\n",
      "Epoch 1432/1499\n",
      "----------\n",
      "train Loss: 0.6295 Acc: 0.9209\n",
      "val Loss: 0.6435 Acc: 0.9000\n",
      "test Loss: 0.6437 Acc: 0.9040\n",
      "Epoch 1433/1499\n",
      "----------\n",
      "train Loss: 0.6287 Acc: 0.9229\n",
      "val Loss: 0.6490 Acc: 0.9040\n",
      "test Loss: 0.6454 Acc: 0.9120\n",
      "Epoch 1434/1499\n",
      "----------\n",
      "train Loss: 0.6293 Acc: 0.9220\n",
      "val Loss: 0.6460 Acc: 0.9040\n",
      "test Loss: 0.6488 Acc: 0.8960\n",
      "Epoch 1435/1499\n",
      "----------\n",
      "train Loss: 0.6287 Acc: 0.9224\n",
      "val Loss: 0.6440 Acc: 0.9080\n",
      "test Loss: 0.6428 Acc: 0.9080\n",
      "Epoch 1436/1499\n",
      "----------\n",
      "train Loss: 0.6291 Acc: 0.9222\n",
      "val Loss: 0.6458 Acc: 0.9000\n",
      "test Loss: 0.6450 Acc: 0.9040\n",
      "Epoch 1437/1499\n",
      "----------\n",
      "train Loss: 0.6302 Acc: 0.9218\n",
      "val Loss: 0.6371 Acc: 0.9120\n",
      "test Loss: 0.6425 Acc: 0.9120\n",
      "Epoch 1438/1499\n",
      "----------\n",
      "train Loss: 0.6292 Acc: 0.9213\n",
      "val Loss: 0.6411 Acc: 0.9120\n",
      "test Loss: 0.6426 Acc: 0.9040\n",
      "Epoch 1439/1499\n",
      "----------\n",
      "train Loss: 0.6296 Acc: 0.9218\n",
      "val Loss: 0.6414 Acc: 0.9120\n",
      "test Loss: 0.6453 Acc: 0.9000\n",
      "Epoch 1440/1499\n",
      "----------\n",
      "train Loss: 0.6298 Acc: 0.9222\n",
      "val Loss: 0.6372 Acc: 0.9160\n",
      "test Loss: 0.6464 Acc: 0.9040\n",
      "Epoch 1441/1499\n",
      "----------\n",
      "train Loss: 0.6299 Acc: 0.9213\n",
      "val Loss: 0.6409 Acc: 0.9120\n",
      "test Loss: 0.6455 Acc: 0.9080\n",
      "Epoch 1442/1499\n",
      "----------\n",
      "train Loss: 0.6297 Acc: 0.9211\n",
      "val Loss: 0.6437 Acc: 0.9080\n",
      "test Loss: 0.6486 Acc: 0.8960\n",
      "Epoch 1443/1499\n",
      "----------\n",
      "train Loss: 0.6289 Acc: 0.9220\n",
      "val Loss: 0.6399 Acc: 0.9160\n",
      "test Loss: 0.6422 Acc: 0.9080\n",
      "Epoch 1444/1499\n",
      "----------\n",
      "train Loss: 0.6286 Acc: 0.9240\n",
      "val Loss: 0.6406 Acc: 0.9120\n",
      "test Loss: 0.6443 Acc: 0.9040\n",
      "Epoch 1445/1499\n",
      "----------\n",
      "train Loss: 0.6286 Acc: 0.9224\n",
      "val Loss: 0.6380 Acc: 0.9160\n",
      "test Loss: 0.6432 Acc: 0.9040\n",
      "Epoch 1446/1499\n",
      "----------\n",
      "train Loss: 0.6289 Acc: 0.9227\n",
      "val Loss: 0.6392 Acc: 0.9120\n",
      "test Loss: 0.6438 Acc: 0.9000\n",
      "Epoch 1447/1499\n",
      "----------\n",
      "train Loss: 0.6280 Acc: 0.9227\n",
      "val Loss: 0.6393 Acc: 0.9120\n",
      "test Loss: 0.6422 Acc: 0.9040\n",
      "Epoch 1448/1499\n",
      "----------\n",
      "train Loss: 0.6288 Acc: 0.9224\n",
      "val Loss: 0.6390 Acc: 0.9120\n",
      "test Loss: 0.6481 Acc: 0.9040\n",
      "Epoch 1449/1499\n",
      "----------\n",
      "train Loss: 0.6282 Acc: 0.9213\n",
      "val Loss: 0.6444 Acc: 0.9040\n",
      "test Loss: 0.6437 Acc: 0.9000\n",
      "Epoch 1450/1499\n",
      "----------\n",
      "train Loss: 0.6302 Acc: 0.9204\n",
      "val Loss: 0.6390 Acc: 0.9120\n",
      "test Loss: 0.6459 Acc: 0.9080\n",
      "Epoch 1451/1499\n",
      "----------\n",
      "train Loss: 0.6288 Acc: 0.9231\n",
      "val Loss: 0.6345 Acc: 0.9160\n",
      "test Loss: 0.6421 Acc: 0.9080\n",
      "Epoch 1452/1499\n",
      "----------\n",
      "train Loss: 0.6289 Acc: 0.9213\n",
      "val Loss: 0.6392 Acc: 0.9040\n",
      "test Loss: 0.6439 Acc: 0.9040\n",
      "Epoch 1453/1499\n",
      "----------\n",
      "train Loss: 0.6293 Acc: 0.9209\n",
      "val Loss: 0.6423 Acc: 0.9080\n",
      "test Loss: 0.6383 Acc: 0.9120\n",
      "Epoch 1454/1499\n",
      "----------\n",
      "train Loss: 0.6291 Acc: 0.9218\n",
      "val Loss: 0.6422 Acc: 0.9120\n",
      "test Loss: 0.6482 Acc: 0.8960\n",
      "Epoch 1455/1499\n",
      "----------\n",
      "train Loss: 0.6291 Acc: 0.9207\n",
      "val Loss: 0.6398 Acc: 0.9120\n",
      "test Loss: 0.6445 Acc: 0.9040\n",
      "Epoch 1456/1499\n",
      "----------\n",
      "train Loss: 0.6299 Acc: 0.9222\n",
      "val Loss: 0.6384 Acc: 0.9160\n",
      "test Loss: 0.6423 Acc: 0.9040\n",
      "Epoch 1457/1499\n",
      "----------\n",
      "train Loss: 0.6287 Acc: 0.9236\n",
      "val Loss: 0.6423 Acc: 0.9160\n",
      "test Loss: 0.6450 Acc: 0.9040\n",
      "Epoch 1458/1499\n",
      "----------\n",
      "train Loss: 0.6283 Acc: 0.9222\n",
      "val Loss: 0.6406 Acc: 0.9120\n",
      "test Loss: 0.6417 Acc: 0.9080\n",
      "Epoch 1459/1499\n",
      "----------\n",
      "train Loss: 0.6294 Acc: 0.9227\n",
      "val Loss: 0.6441 Acc: 0.9080\n",
      "test Loss: 0.6458 Acc: 0.9040\n",
      "Epoch 1460/1499\n",
      "----------\n",
      "train Loss: 0.6289 Acc: 0.9207\n",
      "val Loss: 0.6414 Acc: 0.9080\n",
      "test Loss: 0.6442 Acc: 0.9080\n",
      "Epoch 1461/1499\n",
      "----------\n",
      "train Loss: 0.6300 Acc: 0.9202\n",
      "val Loss: 0.6417 Acc: 0.9080\n",
      "test Loss: 0.6445 Acc: 0.9080\n",
      "Epoch 1462/1499\n",
      "----------\n",
      "train Loss: 0.6280 Acc: 0.9224\n",
      "val Loss: 0.6386 Acc: 0.9120\n",
      "test Loss: 0.6439 Acc: 0.9080\n",
      "Epoch 1463/1499\n",
      "----------\n",
      "train Loss: 0.6292 Acc: 0.9240\n",
      "val Loss: 0.6400 Acc: 0.9080\n",
      "test Loss: 0.6449 Acc: 0.9040\n",
      "Epoch 1464/1499\n",
      "----------\n",
      "train Loss: 0.6284 Acc: 0.9211\n",
      "val Loss: 0.6410 Acc: 0.9040\n",
      "test Loss: 0.6453 Acc: 0.9000\n",
      "Epoch 1465/1499\n",
      "----------\n",
      "train Loss: 0.6295 Acc: 0.9204\n",
      "val Loss: 0.6405 Acc: 0.9080\n",
      "test Loss: 0.6490 Acc: 0.9000\n",
      "Epoch 1466/1499\n",
      "----------\n",
      "train Loss: 0.6298 Acc: 0.9200\n",
      "val Loss: 0.6410 Acc: 0.9120\n",
      "test Loss: 0.6488 Acc: 0.8960\n",
      "Epoch 1467/1499\n",
      "----------\n",
      "train Loss: 0.6294 Acc: 0.9198\n",
      "val Loss: 0.6420 Acc: 0.9120\n",
      "test Loss: 0.6444 Acc: 0.9000\n",
      "Epoch 1468/1499\n",
      "----------\n",
      "train Loss: 0.6300 Acc: 0.9216\n",
      "val Loss: 0.6432 Acc: 0.9120\n",
      "test Loss: 0.6409 Acc: 0.9080\n",
      "Epoch 1469/1499\n",
      "----------\n",
      "train Loss: 0.6284 Acc: 0.9209\n",
      "val Loss: 0.6464 Acc: 0.9080\n",
      "test Loss: 0.6449 Acc: 0.9040\n",
      "Epoch 1470/1499\n",
      "----------\n",
      "train Loss: 0.6289 Acc: 0.9224\n",
      "val Loss: 0.6416 Acc: 0.9080\n",
      "test Loss: 0.6448 Acc: 0.9000\n",
      "Epoch 1471/1499\n",
      "----------\n",
      "train Loss: 0.6286 Acc: 0.9238\n",
      "val Loss: 0.6416 Acc: 0.9120\n",
      "test Loss: 0.6437 Acc: 0.9080\n",
      "Epoch 1472/1499\n",
      "----------\n",
      "train Loss: 0.6303 Acc: 0.9184\n",
      "val Loss: 0.6407 Acc: 0.9120\n",
      "test Loss: 0.6465 Acc: 0.9000\n",
      "Epoch 1473/1499\n",
      "----------\n",
      "train Loss: 0.6288 Acc: 0.9216\n",
      "val Loss: 0.6450 Acc: 0.9040\n",
      "test Loss: 0.6481 Acc: 0.8960\n",
      "Epoch 1474/1499\n",
      "----------\n",
      "train Loss: 0.6295 Acc: 0.9211\n",
      "val Loss: 0.6399 Acc: 0.9120\n",
      "test Loss: 0.6461 Acc: 0.9000\n",
      "Epoch 1475/1499\n",
      "----------\n",
      "train Loss: 0.6292 Acc: 0.9238\n",
      "val Loss: 0.6407 Acc: 0.9120\n",
      "test Loss: 0.6476 Acc: 0.9000\n",
      "Epoch 1476/1499\n",
      "----------\n",
      "train Loss: 0.6298 Acc: 0.9233\n",
      "val Loss: 0.6429 Acc: 0.9080\n",
      "test Loss: 0.6418 Acc: 0.9080\n",
      "Epoch 1477/1499\n",
      "----------\n",
      "train Loss: 0.6292 Acc: 0.9227\n",
      "val Loss: 0.6454 Acc: 0.9120\n",
      "test Loss: 0.6439 Acc: 0.9080\n",
      "Epoch 1478/1499\n",
      "----------\n",
      "train Loss: 0.6298 Acc: 0.9220\n",
      "val Loss: 0.6401 Acc: 0.9120\n",
      "test Loss: 0.6440 Acc: 0.9040\n",
      "Epoch 1479/1499\n",
      "----------\n",
      "train Loss: 0.6290 Acc: 0.9213\n",
      "val Loss: 0.6406 Acc: 0.9120\n",
      "test Loss: 0.6455 Acc: 0.9040\n",
      "Epoch 1480/1499\n",
      "----------\n",
      "train Loss: 0.6289 Acc: 0.9229\n",
      "val Loss: 0.6396 Acc: 0.9120\n",
      "test Loss: 0.6466 Acc: 0.9080\n",
      "Epoch 1481/1499\n",
      "----------\n",
      "train Loss: 0.6290 Acc: 0.9236\n",
      "val Loss: 0.6443 Acc: 0.9120\n",
      "test Loss: 0.6424 Acc: 0.9040\n",
      "Epoch 1482/1499\n",
      "----------\n",
      "train Loss: 0.6287 Acc: 0.9220\n",
      "val Loss: 0.6422 Acc: 0.9120\n",
      "test Loss: 0.6410 Acc: 0.9080\n",
      "Epoch 1483/1499\n",
      "----------\n",
      "train Loss: 0.6296 Acc: 0.9207\n",
      "val Loss: 0.6452 Acc: 0.9120\n",
      "test Loss: 0.6502 Acc: 0.8880\n",
      "Epoch 1484/1499\n",
      "----------\n",
      "train Loss: 0.6289 Acc: 0.9216\n",
      "val Loss: 0.6359 Acc: 0.9200\n",
      "test Loss: 0.6465 Acc: 0.8960\n",
      "Epoch 1485/1499\n",
      "----------\n",
      "train Loss: 0.6290 Acc: 0.9231\n",
      "val Loss: 0.6429 Acc: 0.9080\n",
      "test Loss: 0.6494 Acc: 0.8960\n",
      "Epoch 1486/1499\n",
      "----------\n",
      "train Loss: 0.6301 Acc: 0.9202\n",
      "val Loss: 0.6445 Acc: 0.9040\n",
      "test Loss: 0.6421 Acc: 0.9080\n",
      "Epoch 1487/1499\n",
      "----------\n",
      "train Loss: 0.6290 Acc: 0.9222\n",
      "val Loss: 0.6386 Acc: 0.9160\n",
      "test Loss: 0.6481 Acc: 0.9000\n",
      "Epoch 1488/1499\n",
      "----------\n",
      "train Loss: 0.6293 Acc: 0.9218\n",
      "val Loss: 0.6399 Acc: 0.9120\n",
      "test Loss: 0.6456 Acc: 0.9040\n",
      "Epoch 1489/1499\n",
      "----------\n",
      "train Loss: 0.6296 Acc: 0.9213\n",
      "val Loss: 0.6420 Acc: 0.9120\n",
      "test Loss: 0.6454 Acc: 0.9040\n",
      "Epoch 1490/1499\n",
      "----------\n",
      "train Loss: 0.6289 Acc: 0.9236\n",
      "val Loss: 0.6445 Acc: 0.9040\n",
      "test Loss: 0.6447 Acc: 0.9040\n",
      "Epoch 1491/1499\n",
      "----------\n",
      "train Loss: 0.6290 Acc: 0.9236\n",
      "val Loss: 0.6423 Acc: 0.9080\n",
      "test Loss: 0.6408 Acc: 0.9120\n",
      "Epoch 1492/1499\n",
      "----------\n",
      "train Loss: 0.6289 Acc: 0.9233\n",
      "val Loss: 0.6427 Acc: 0.9040\n",
      "test Loss: 0.6492 Acc: 0.9040\n",
      "Epoch 1493/1499\n",
      "----------\n",
      "train Loss: 0.6292 Acc: 0.9222\n",
      "val Loss: 0.6422 Acc: 0.9120\n",
      "test Loss: 0.6432 Acc: 0.9000\n",
      "Epoch 1494/1499\n",
      "----------\n",
      "train Loss: 0.6291 Acc: 0.9227\n",
      "val Loss: 0.6427 Acc: 0.9040\n",
      "test Loss: 0.6453 Acc: 0.8960\n",
      "Epoch 1495/1499\n",
      "----------\n",
      "train Loss: 0.6287 Acc: 0.9227\n",
      "val Loss: 0.6387 Acc: 0.9160\n",
      "test Loss: 0.6489 Acc: 0.8960\n",
      "Epoch 1496/1499\n",
      "----------\n",
      "train Loss: 0.6291 Acc: 0.9224\n",
      "val Loss: 0.6393 Acc: 0.9120\n",
      "test Loss: 0.6464 Acc: 0.9040\n",
      "Epoch 1497/1499\n",
      "----------\n",
      "train Loss: 0.6309 Acc: 0.9220\n",
      "val Loss: 0.6402 Acc: 0.9160\n",
      "test Loss: 0.6513 Acc: 0.9000\n",
      "Epoch 1498/1499\n",
      "----------\n",
      "train Loss: 0.6294 Acc: 0.9224\n",
      "val Loss: 0.6386 Acc: 0.9120\n",
      "test Loss: 0.6445 Acc: 0.9080\n",
      "Epoch 1499/1499\n",
      "----------\n",
      "train Loss: 0.6288 Acc: 0.9227\n",
      "val Loss: 0.6386 Acc: 0.9160\n",
      "test Loss: 0.6434 Acc: 0.9080\n",
      "Training complete in 1m 26s\n",
      "Best test Acc: 0.920000\n",
      "Epoch 0/1499\n",
      "----------\n",
      "train Loss: 1.1016 Acc: 0.3304\n",
      "val Loss: 1.0972 Acc: 0.3720\n",
      "test Loss: 1.0996 Acc: 0.3280\n",
      "Epoch 1/1499\n",
      "----------\n",
      "train Loss: 1.1014 Acc: 0.3289\n",
      "val Loss: 1.0973 Acc: 0.3680\n",
      "test Loss: 1.1000 Acc: 0.3160\n",
      "Epoch 2/1499\n",
      "----------\n",
      "train Loss: 1.1011 Acc: 0.3347\n",
      "val Loss: 1.0971 Acc: 0.3760\n",
      "test Loss: 1.0996 Acc: 0.3240\n",
      "Epoch 3/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.1011 Acc: 0.3349\n",
      "val Loss: 1.0971 Acc: 0.3680\n",
      "test Loss: 1.0991 Acc: 0.3160\n",
      "Epoch 4/1499\n",
      "----------\n",
      "train Loss: 1.1007 Acc: 0.3347\n",
      "val Loss: 1.0967 Acc: 0.3720\n",
      "test Loss: 1.0989 Acc: 0.3440\n",
      "Epoch 5/1499\n",
      "----------\n",
      "train Loss: 1.1006 Acc: 0.3369\n",
      "val Loss: 1.0961 Acc: 0.3600\n",
      "test Loss: 1.0991 Acc: 0.3280\n",
      "Epoch 6/1499\n",
      "----------\n",
      "train Loss: 1.1004 Acc: 0.3333\n",
      "val Loss: 1.0967 Acc: 0.3680\n",
      "test Loss: 1.0990 Acc: 0.3320\n",
      "Epoch 7/1499\n",
      "----------\n",
      "train Loss: 1.1002 Acc: 0.3362\n",
      "val Loss: 1.0956 Acc: 0.3760\n",
      "test Loss: 1.0987 Acc: 0.3160\n",
      "Epoch 8/1499\n",
      "----------\n",
      "train Loss: 1.1001 Acc: 0.3349\n",
      "val Loss: 1.0957 Acc: 0.3800\n",
      "test Loss: 1.0980 Acc: 0.3320\n",
      "Epoch 9/1499\n",
      "----------\n",
      "train Loss: 1.0999 Acc: 0.3376\n",
      "val Loss: 1.0957 Acc: 0.3760\n",
      "test Loss: 1.0982 Acc: 0.3320\n",
      "Epoch 10/1499\n",
      "----------\n",
      "train Loss: 1.0995 Acc: 0.3393\n",
      "val Loss: 1.0959 Acc: 0.3640\n",
      "test Loss: 1.0979 Acc: 0.3280\n",
      "Epoch 11/1499\n",
      "----------\n",
      "train Loss: 1.0994 Acc: 0.3400\n",
      "val Loss: 1.0957 Acc: 0.3960\n",
      "test Loss: 1.0976 Acc: 0.3400\n",
      "Epoch 12/1499\n",
      "----------\n",
      "train Loss: 1.0992 Acc: 0.3369\n",
      "val Loss: 1.0950 Acc: 0.3720\n",
      "test Loss: 1.0970 Acc: 0.3360\n",
      "Epoch 13/1499\n",
      "----------\n",
      "train Loss: 1.0991 Acc: 0.3356\n",
      "val Loss: 1.0951 Acc: 0.3640\n",
      "test Loss: 1.0976 Acc: 0.3240\n",
      "Epoch 14/1499\n",
      "----------\n",
      "train Loss: 1.0990 Acc: 0.3371\n",
      "val Loss: 1.0943 Acc: 0.3840\n",
      "test Loss: 1.0977 Acc: 0.3240\n",
      "Epoch 15/1499\n",
      "----------\n",
      "train Loss: 1.0988 Acc: 0.3431\n",
      "val Loss: 1.0945 Acc: 0.3800\n",
      "test Loss: 1.0975 Acc: 0.3280\n",
      "Epoch 16/1499\n",
      "----------\n",
      "train Loss: 1.0987 Acc: 0.3393\n",
      "val Loss: 1.0951 Acc: 0.3760\n",
      "test Loss: 1.0972 Acc: 0.3560\n",
      "Epoch 17/1499\n",
      "----------\n",
      "train Loss: 1.0986 Acc: 0.3384\n",
      "val Loss: 1.0948 Acc: 0.3760\n",
      "test Loss: 1.0967 Acc: 0.3280\n",
      "Epoch 18/1499\n",
      "----------\n",
      "train Loss: 1.0982 Acc: 0.3442\n",
      "val Loss: 1.0945 Acc: 0.3760\n",
      "test Loss: 1.0966 Acc: 0.3240\n",
      "Epoch 19/1499\n",
      "----------\n",
      "train Loss: 1.0980 Acc: 0.3384\n",
      "val Loss: 1.0936 Acc: 0.3920\n",
      "test Loss: 1.0963 Acc: 0.3400\n",
      "Epoch 20/1499\n",
      "----------\n",
      "train Loss: 1.0980 Acc: 0.3416\n",
      "val Loss: 1.0938 Acc: 0.3720\n",
      "test Loss: 1.0961 Acc: 0.3280\n",
      "Epoch 21/1499\n",
      "----------\n",
      "train Loss: 1.0978 Acc: 0.3464\n",
      "val Loss: 1.0936 Acc: 0.3800\n",
      "test Loss: 1.0959 Acc: 0.3720\n",
      "Epoch 22/1499\n",
      "----------\n",
      "train Loss: 1.0975 Acc: 0.3438\n",
      "val Loss: 1.0939 Acc: 0.3840\n",
      "test Loss: 1.0961 Acc: 0.3600\n",
      "Epoch 23/1499\n",
      "----------\n",
      "train Loss: 1.0972 Acc: 0.3487\n",
      "val Loss: 1.0929 Acc: 0.3880\n",
      "test Loss: 1.0959 Acc: 0.3520\n",
      "Epoch 24/1499\n",
      "----------\n",
      "train Loss: 1.0972 Acc: 0.3511\n",
      "val Loss: 1.0929 Acc: 0.3920\n",
      "test Loss: 1.0953 Acc: 0.3480\n",
      "Epoch 25/1499\n",
      "----------\n",
      "train Loss: 1.0972 Acc: 0.3440\n",
      "val Loss: 1.0930 Acc: 0.4000\n",
      "test Loss: 1.0950 Acc: 0.3480\n",
      "Epoch 26/1499\n",
      "----------\n",
      "train Loss: 1.0969 Acc: 0.3516\n",
      "val Loss: 1.0932 Acc: 0.3800\n",
      "test Loss: 1.0958 Acc: 0.3320\n",
      "Epoch 27/1499\n",
      "----------\n",
      "train Loss: 1.0966 Acc: 0.3544\n",
      "val Loss: 1.0930 Acc: 0.4000\n",
      "test Loss: 1.0948 Acc: 0.3520\n",
      "Epoch 28/1499\n",
      "----------\n",
      "train Loss: 1.0965 Acc: 0.3529\n",
      "val Loss: 1.0930 Acc: 0.3760\n",
      "test Loss: 1.0941 Acc: 0.3520\n",
      "Epoch 29/1499\n",
      "----------\n",
      "train Loss: 1.0963 Acc: 0.3576\n",
      "val Loss: 1.0921 Acc: 0.3920\n",
      "test Loss: 1.0946 Acc: 0.3800\n",
      "Epoch 30/1499\n",
      "----------\n",
      "train Loss: 1.0962 Acc: 0.3556\n",
      "val Loss: 1.0915 Acc: 0.4000\n",
      "test Loss: 1.0943 Acc: 0.3680\n",
      "Epoch 31/1499\n",
      "----------\n",
      "train Loss: 1.0958 Acc: 0.3629\n",
      "val Loss: 1.0915 Acc: 0.4040\n",
      "test Loss: 1.0947 Acc: 0.3640\n",
      "Epoch 32/1499\n",
      "----------\n",
      "train Loss: 1.0956 Acc: 0.3631\n",
      "val Loss: 1.0919 Acc: 0.4160\n",
      "test Loss: 1.0941 Acc: 0.3680\n",
      "Epoch 33/1499\n",
      "----------\n",
      "train Loss: 1.0955 Acc: 0.3618\n",
      "val Loss: 1.0913 Acc: 0.4080\n",
      "test Loss: 1.0944 Acc: 0.3600\n",
      "Epoch 34/1499\n",
      "----------\n",
      "train Loss: 1.0952 Acc: 0.3680\n",
      "val Loss: 1.0906 Acc: 0.4160\n",
      "test Loss: 1.0933 Acc: 0.3680\n",
      "Epoch 35/1499\n",
      "----------\n",
      "train Loss: 1.0951 Acc: 0.3700\n",
      "val Loss: 1.0912 Acc: 0.3960\n",
      "test Loss: 1.0936 Acc: 0.3640\n",
      "Epoch 36/1499\n",
      "----------\n",
      "train Loss: 1.0949 Acc: 0.3696\n",
      "val Loss: 1.0905 Acc: 0.4120\n",
      "test Loss: 1.0935 Acc: 0.3640\n",
      "Epoch 37/1499\n",
      "----------\n",
      "train Loss: 1.0946 Acc: 0.3684\n",
      "val Loss: 1.0907 Acc: 0.4040\n",
      "test Loss: 1.0924 Acc: 0.3800\n",
      "Epoch 38/1499\n",
      "----------\n",
      "train Loss: 1.0944 Acc: 0.3807\n",
      "val Loss: 1.0912 Acc: 0.4040\n",
      "test Loss: 1.0930 Acc: 0.3720\n",
      "Epoch 39/1499\n",
      "----------\n",
      "train Loss: 1.0945 Acc: 0.3773\n",
      "val Loss: 1.0906 Acc: 0.3960\n",
      "test Loss: 1.0931 Acc: 0.3680\n",
      "Epoch 40/1499\n",
      "----------\n",
      "train Loss: 1.0939 Acc: 0.3849\n",
      "val Loss: 1.0894 Acc: 0.4320\n",
      "test Loss: 1.0925 Acc: 0.3960\n",
      "Epoch 41/1499\n",
      "----------\n",
      "train Loss: 1.0938 Acc: 0.3876\n",
      "val Loss: 1.0893 Acc: 0.4160\n",
      "test Loss: 1.0929 Acc: 0.3720\n",
      "Epoch 42/1499\n",
      "----------\n",
      "train Loss: 1.0935 Acc: 0.3891\n",
      "val Loss: 1.0879 Acc: 0.4560\n",
      "test Loss: 1.0910 Acc: 0.3760\n",
      "Epoch 43/1499\n",
      "----------\n",
      "train Loss: 1.0934 Acc: 0.3856\n",
      "val Loss: 1.0893 Acc: 0.4120\n",
      "test Loss: 1.0921 Acc: 0.3920\n",
      "Epoch 44/1499\n",
      "----------\n",
      "train Loss: 1.0933 Acc: 0.3893\n",
      "val Loss: 1.0891 Acc: 0.4160\n",
      "test Loss: 1.0922 Acc: 0.3800\n",
      "Epoch 45/1499\n",
      "----------\n",
      "train Loss: 1.0929 Acc: 0.3953\n",
      "val Loss: 1.0890 Acc: 0.4440\n",
      "test Loss: 1.0914 Acc: 0.4200\n",
      "Epoch 46/1499\n",
      "----------\n",
      "train Loss: 1.0929 Acc: 0.3940\n",
      "val Loss: 1.0884 Acc: 0.4280\n",
      "test Loss: 1.0920 Acc: 0.3840\n",
      "Epoch 47/1499\n",
      "----------\n",
      "train Loss: 1.0926 Acc: 0.3987\n",
      "val Loss: 1.0879 Acc: 0.4520\n",
      "test Loss: 1.0906 Acc: 0.4000\n",
      "Epoch 48/1499\n",
      "----------\n",
      "train Loss: 1.0922 Acc: 0.4002\n",
      "val Loss: 1.0884 Acc: 0.4360\n",
      "test Loss: 1.0918 Acc: 0.3800\n",
      "Epoch 49/1499\n",
      "----------\n",
      "train Loss: 1.0919 Acc: 0.4004\n",
      "val Loss: 1.0880 Acc: 0.4480\n",
      "test Loss: 1.0913 Acc: 0.3880\n",
      "Epoch 50/1499\n",
      "----------\n",
      "train Loss: 1.0919 Acc: 0.4064\n",
      "val Loss: 1.0871 Acc: 0.4480\n",
      "test Loss: 1.0896 Acc: 0.4160\n",
      "Epoch 51/1499\n",
      "----------\n",
      "train Loss: 1.0918 Acc: 0.4076\n",
      "val Loss: 1.0865 Acc: 0.4680\n",
      "test Loss: 1.0901 Acc: 0.4000\n",
      "Epoch 52/1499\n",
      "----------\n",
      "train Loss: 1.0914 Acc: 0.4082\n",
      "val Loss: 1.0861 Acc: 0.4680\n",
      "test Loss: 1.0910 Acc: 0.4080\n",
      "Epoch 53/1499\n",
      "----------\n",
      "train Loss: 1.0915 Acc: 0.4060\n",
      "val Loss: 1.0862 Acc: 0.4560\n",
      "test Loss: 1.0900 Acc: 0.4160\n",
      "Epoch 54/1499\n",
      "----------\n",
      "train Loss: 1.0910 Acc: 0.4109\n",
      "val Loss: 1.0867 Acc: 0.4560\n",
      "test Loss: 1.0897 Acc: 0.4160\n",
      "Epoch 55/1499\n",
      "----------\n",
      "train Loss: 1.0907 Acc: 0.4153\n",
      "val Loss: 1.0859 Acc: 0.4680\n",
      "test Loss: 1.0886 Acc: 0.4280\n",
      "Epoch 56/1499\n",
      "----------\n",
      "train Loss: 1.0906 Acc: 0.4156\n",
      "val Loss: 1.0848 Acc: 0.4680\n",
      "test Loss: 1.0884 Acc: 0.4160\n",
      "Epoch 57/1499\n",
      "----------\n",
      "train Loss: 1.0903 Acc: 0.4191\n",
      "val Loss: 1.0850 Acc: 0.4600\n",
      "test Loss: 1.0881 Acc: 0.4360\n",
      "Epoch 58/1499\n",
      "----------\n",
      "train Loss: 1.0899 Acc: 0.4249\n",
      "val Loss: 1.0861 Acc: 0.4840\n",
      "test Loss: 1.0882 Acc: 0.4280\n",
      "Epoch 59/1499\n",
      "----------\n",
      "train Loss: 1.0894 Acc: 0.4291\n",
      "val Loss: 1.0848 Acc: 0.4760\n",
      "test Loss: 1.0883 Acc: 0.4280\n",
      "Epoch 60/1499\n",
      "----------\n",
      "train Loss: 1.0896 Acc: 0.4271\n",
      "val Loss: 1.0838 Acc: 0.4760\n",
      "test Loss: 1.0880 Acc: 0.4400\n",
      "Epoch 61/1499\n",
      "----------\n",
      "train Loss: 1.0890 Acc: 0.4304\n",
      "val Loss: 1.0842 Acc: 0.4920\n",
      "test Loss: 1.0881 Acc: 0.4280\n",
      "Epoch 62/1499\n",
      "----------\n",
      "train Loss: 1.0888 Acc: 0.4340\n",
      "val Loss: 1.0834 Acc: 0.4840\n",
      "test Loss: 1.0867 Acc: 0.4360\n",
      "Epoch 63/1499\n",
      "----------\n",
      "train Loss: 1.0887 Acc: 0.4371\n",
      "val Loss: 1.0836 Acc: 0.4920\n",
      "test Loss: 1.0868 Acc: 0.4440\n",
      "Epoch 64/1499\n",
      "----------\n",
      "train Loss: 1.0884 Acc: 0.4376\n",
      "val Loss: 1.0832 Acc: 0.4880\n",
      "test Loss: 1.0879 Acc: 0.4280\n",
      "Epoch 65/1499\n",
      "----------\n",
      "train Loss: 1.0878 Acc: 0.4427\n",
      "val Loss: 1.0821 Acc: 0.4920\n",
      "test Loss: 1.0870 Acc: 0.4280\n",
      "Epoch 66/1499\n",
      "----------\n",
      "train Loss: 1.0877 Acc: 0.4451\n",
      "val Loss: 1.0825 Acc: 0.5000\n",
      "test Loss: 1.0860 Acc: 0.4440\n",
      "Epoch 67/1499\n",
      "----------\n",
      "train Loss: 1.0872 Acc: 0.4451\n",
      "val Loss: 1.0833 Acc: 0.4680\n",
      "test Loss: 1.0851 Acc: 0.4480\n",
      "Epoch 68/1499\n",
      "----------\n",
      "train Loss: 1.0875 Acc: 0.4411\n",
      "val Loss: 1.0812 Acc: 0.4960\n",
      "test Loss: 1.0868 Acc: 0.4320\n",
      "Epoch 69/1499\n",
      "----------\n",
      "train Loss: 1.0867 Acc: 0.4489\n",
      "val Loss: 1.0821 Acc: 0.4960\n",
      "test Loss: 1.0852 Acc: 0.4480\n",
      "Epoch 70/1499\n",
      "----------\n",
      "train Loss: 1.0866 Acc: 0.4487\n",
      "val Loss: 1.0818 Acc: 0.4680\n",
      "test Loss: 1.0844 Acc: 0.4360\n",
      "Epoch 71/1499\n",
      "----------\n",
      "train Loss: 1.0863 Acc: 0.4529\n",
      "val Loss: 1.0799 Acc: 0.5120\n",
      "test Loss: 1.0846 Acc: 0.4400\n",
      "Epoch 72/1499\n",
      "----------\n",
      "train Loss: 1.0859 Acc: 0.4560\n",
      "val Loss: 1.0808 Acc: 0.5040\n",
      "test Loss: 1.0846 Acc: 0.4560\n",
      "Epoch 73/1499\n",
      "----------\n",
      "train Loss: 1.0853 Acc: 0.4584\n",
      "val Loss: 1.0803 Acc: 0.5000\n",
      "test Loss: 1.0831 Acc: 0.4520\n",
      "Epoch 74/1499\n",
      "----------\n",
      "train Loss: 1.0850 Acc: 0.4582\n",
      "val Loss: 1.0795 Acc: 0.5200\n",
      "test Loss: 1.0828 Acc: 0.4440\n",
      "Epoch 75/1499\n",
      "----------\n",
      "train Loss: 1.0845 Acc: 0.4631\n",
      "val Loss: 1.0790 Acc: 0.5200\n",
      "test Loss: 1.0826 Acc: 0.4520\n",
      "Epoch 76/1499\n",
      "----------\n",
      "train Loss: 1.0846 Acc: 0.4560\n",
      "val Loss: 1.0780 Acc: 0.5000\n",
      "test Loss: 1.0830 Acc: 0.4440\n",
      "Epoch 77/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.0839 Acc: 0.4631\n",
      "val Loss: 1.0792 Acc: 0.5080\n",
      "test Loss: 1.0835 Acc: 0.4360\n",
      "Epoch 78/1499\n",
      "----------\n",
      "train Loss: 1.0836 Acc: 0.4620\n",
      "val Loss: 1.0775 Acc: 0.5200\n",
      "test Loss: 1.0822 Acc: 0.4600\n",
      "Epoch 79/1499\n",
      "----------\n",
      "train Loss: 1.0833 Acc: 0.4640\n",
      "val Loss: 1.0754 Acc: 0.5360\n",
      "test Loss: 1.0824 Acc: 0.4680\n",
      "Epoch 80/1499\n",
      "----------\n",
      "train Loss: 1.0829 Acc: 0.4631\n",
      "val Loss: 1.0777 Acc: 0.5160\n",
      "test Loss: 1.0816 Acc: 0.4440\n",
      "Epoch 81/1499\n",
      "----------\n",
      "train Loss: 1.0827 Acc: 0.4660\n",
      "val Loss: 1.0760 Acc: 0.5160\n",
      "test Loss: 1.0815 Acc: 0.4600\n",
      "Epoch 82/1499\n",
      "----------\n",
      "train Loss: 1.0821 Acc: 0.4707\n",
      "val Loss: 1.0750 Acc: 0.5400\n",
      "test Loss: 1.0811 Acc: 0.4480\n",
      "Epoch 83/1499\n",
      "----------\n",
      "train Loss: 1.0816 Acc: 0.4704\n",
      "val Loss: 1.0751 Acc: 0.5520\n",
      "test Loss: 1.0794 Acc: 0.4800\n",
      "Epoch 84/1499\n",
      "----------\n",
      "train Loss: 1.0814 Acc: 0.4693\n",
      "val Loss: 1.0740 Acc: 0.5320\n",
      "test Loss: 1.0822 Acc: 0.4520\n",
      "Epoch 85/1499\n",
      "----------\n",
      "train Loss: 1.0809 Acc: 0.4707\n",
      "val Loss: 1.0747 Acc: 0.5360\n",
      "test Loss: 1.0805 Acc: 0.4720\n",
      "Epoch 86/1499\n",
      "----------\n",
      "train Loss: 1.0803 Acc: 0.4729\n",
      "val Loss: 1.0737 Acc: 0.5320\n",
      "test Loss: 1.0799 Acc: 0.4680\n",
      "Epoch 87/1499\n",
      "----------\n",
      "train Loss: 1.0801 Acc: 0.4700\n",
      "val Loss: 1.0738 Acc: 0.5440\n",
      "test Loss: 1.0782 Acc: 0.4840\n",
      "Epoch 88/1499\n",
      "----------\n",
      "train Loss: 1.0797 Acc: 0.4711\n",
      "val Loss: 1.0724 Acc: 0.5480\n",
      "test Loss: 1.0796 Acc: 0.4560\n",
      "Epoch 89/1499\n",
      "----------\n",
      "train Loss: 1.0789 Acc: 0.4751\n",
      "val Loss: 1.0729 Acc: 0.5320\n",
      "test Loss: 1.0778 Acc: 0.4600\n",
      "Epoch 90/1499\n",
      "----------\n",
      "train Loss: 1.0788 Acc: 0.4762\n",
      "val Loss: 1.0701 Acc: 0.5520\n",
      "test Loss: 1.0771 Acc: 0.4800\n",
      "Epoch 91/1499\n",
      "----------\n",
      "train Loss: 1.0782 Acc: 0.4776\n",
      "val Loss: 1.0702 Acc: 0.5360\n",
      "test Loss: 1.0761 Acc: 0.4840\n",
      "Epoch 92/1499\n",
      "----------\n",
      "train Loss: 1.0776 Acc: 0.4816\n",
      "val Loss: 1.0712 Acc: 0.5360\n",
      "test Loss: 1.0758 Acc: 0.4880\n",
      "Epoch 93/1499\n",
      "----------\n",
      "train Loss: 1.0770 Acc: 0.4804\n",
      "val Loss: 1.0695 Acc: 0.5480\n",
      "test Loss: 1.0752 Acc: 0.4880\n",
      "Epoch 94/1499\n",
      "----------\n",
      "train Loss: 1.0766 Acc: 0.4822\n",
      "val Loss: 1.0699 Acc: 0.5280\n",
      "test Loss: 1.0749 Acc: 0.4840\n",
      "Epoch 95/1499\n",
      "----------\n",
      "train Loss: 1.0759 Acc: 0.4856\n",
      "val Loss: 1.0701 Acc: 0.5440\n",
      "test Loss: 1.0754 Acc: 0.4880\n",
      "Epoch 96/1499\n",
      "----------\n",
      "train Loss: 1.0751 Acc: 0.4858\n",
      "val Loss: 1.0704 Acc: 0.5240\n",
      "test Loss: 1.0732 Acc: 0.4920\n",
      "Epoch 97/1499\n",
      "----------\n",
      "train Loss: 1.0747 Acc: 0.4864\n",
      "val Loss: 1.0689 Acc: 0.5360\n",
      "test Loss: 1.0730 Acc: 0.4880\n",
      "Epoch 98/1499\n",
      "----------\n",
      "train Loss: 1.0750 Acc: 0.4844\n",
      "val Loss: 1.0673 Acc: 0.5240\n",
      "test Loss: 1.0737 Acc: 0.4880\n",
      "Epoch 99/1499\n",
      "----------\n",
      "train Loss: 1.0737 Acc: 0.4900\n",
      "val Loss: 1.0681 Acc: 0.5560\n",
      "test Loss: 1.0716 Acc: 0.4920\n",
      "Epoch 100/1499\n",
      "----------\n",
      "train Loss: 1.0736 Acc: 0.4864\n",
      "val Loss: 1.0647 Acc: 0.5560\n",
      "test Loss: 1.0713 Acc: 0.5040\n",
      "Epoch 101/1499\n",
      "----------\n",
      "train Loss: 1.0724 Acc: 0.4956\n",
      "val Loss: 1.0675 Acc: 0.5360\n",
      "test Loss: 1.0706 Acc: 0.4920\n",
      "Epoch 102/1499\n",
      "----------\n",
      "train Loss: 1.0725 Acc: 0.4920\n",
      "val Loss: 1.0640 Acc: 0.5520\n",
      "test Loss: 1.0698 Acc: 0.5080\n",
      "Epoch 103/1499\n",
      "----------\n",
      "train Loss: 1.0714 Acc: 0.4929\n",
      "val Loss: 1.0637 Acc: 0.5440\n",
      "test Loss: 1.0696 Acc: 0.5000\n",
      "Epoch 104/1499\n",
      "----------\n",
      "train Loss: 1.0711 Acc: 0.4924\n",
      "val Loss: 1.0653 Acc: 0.5440\n",
      "test Loss: 1.0697 Acc: 0.5000\n",
      "Epoch 105/1499\n",
      "----------\n",
      "train Loss: 1.0702 Acc: 0.4951\n",
      "val Loss: 1.0622 Acc: 0.5560\n",
      "test Loss: 1.0704 Acc: 0.4880\n",
      "Epoch 106/1499\n",
      "----------\n",
      "train Loss: 1.0700 Acc: 0.4962\n",
      "val Loss: 1.0634 Acc: 0.5400\n",
      "test Loss: 1.0675 Acc: 0.5040\n",
      "Epoch 107/1499\n",
      "----------\n",
      "train Loss: 1.0694 Acc: 0.4942\n",
      "val Loss: 1.0615 Acc: 0.5280\n",
      "test Loss: 1.0683 Acc: 0.4920\n",
      "Epoch 108/1499\n",
      "----------\n",
      "train Loss: 1.0682 Acc: 0.5002\n",
      "val Loss: 1.0636 Acc: 0.5400\n",
      "test Loss: 1.0693 Acc: 0.4840\n",
      "Epoch 109/1499\n",
      "----------\n",
      "train Loss: 1.0676 Acc: 0.4980\n",
      "val Loss: 1.0588 Acc: 0.5560\n",
      "test Loss: 1.0642 Acc: 0.5080\n",
      "Epoch 110/1499\n",
      "----------\n",
      "train Loss: 1.0679 Acc: 0.4947\n",
      "val Loss: 1.0598 Acc: 0.5400\n",
      "test Loss: 1.0650 Acc: 0.5040\n",
      "Epoch 111/1499\n",
      "----------\n",
      "train Loss: 1.0671 Acc: 0.4984\n",
      "val Loss: 1.0593 Acc: 0.5560\n",
      "test Loss: 1.0657 Acc: 0.4960\n",
      "Epoch 112/1499\n",
      "----------\n",
      "train Loss: 1.0659 Acc: 0.5007\n",
      "val Loss: 1.0588 Acc: 0.5480\n",
      "test Loss: 1.0646 Acc: 0.5160\n",
      "Epoch 113/1499\n",
      "----------\n",
      "train Loss: 1.0656 Acc: 0.5024\n",
      "val Loss: 1.0563 Acc: 0.5600\n",
      "test Loss: 1.0620 Acc: 0.5160\n",
      "Epoch 114/1499\n",
      "----------\n",
      "train Loss: 1.0640 Acc: 0.5031\n",
      "val Loss: 1.0557 Acc: 0.5480\n",
      "test Loss: 1.0662 Acc: 0.4720\n",
      "Epoch 115/1499\n",
      "----------\n",
      "train Loss: 1.0638 Acc: 0.5007\n",
      "val Loss: 1.0555 Acc: 0.5640\n",
      "test Loss: 1.0633 Acc: 0.5040\n",
      "Epoch 116/1499\n",
      "----------\n",
      "train Loss: 1.0631 Acc: 0.5069\n",
      "val Loss: 1.0553 Acc: 0.5520\n",
      "test Loss: 1.0616 Acc: 0.5120\n",
      "Epoch 117/1499\n",
      "----------\n",
      "train Loss: 1.0629 Acc: 0.5020\n",
      "val Loss: 1.0533 Acc: 0.5520\n",
      "test Loss: 1.0605 Acc: 0.4920\n",
      "Epoch 118/1499\n",
      "----------\n",
      "train Loss: 1.0613 Acc: 0.5062\n",
      "val Loss: 1.0573 Acc: 0.5080\n",
      "test Loss: 1.0581 Acc: 0.5240\n",
      "Epoch 119/1499\n",
      "----------\n",
      "train Loss: 1.0609 Acc: 0.5053\n",
      "val Loss: 1.0518 Acc: 0.5640\n",
      "test Loss: 1.0584 Acc: 0.5000\n",
      "Epoch 120/1499\n",
      "----------\n",
      "train Loss: 1.0598 Acc: 0.5076\n",
      "val Loss: 1.0538 Acc: 0.5360\n",
      "test Loss: 1.0554 Acc: 0.5160\n",
      "Epoch 121/1499\n",
      "----------\n",
      "train Loss: 1.0593 Acc: 0.5084\n",
      "val Loss: 1.0518 Acc: 0.5600\n",
      "test Loss: 1.0580 Acc: 0.5120\n",
      "Epoch 122/1499\n",
      "----------\n",
      "train Loss: 1.0590 Acc: 0.5104\n",
      "val Loss: 1.0507 Acc: 0.5560\n",
      "test Loss: 1.0545 Acc: 0.5120\n",
      "Epoch 123/1499\n",
      "----------\n",
      "train Loss: 1.0575 Acc: 0.5104\n",
      "val Loss: 1.0492 Acc: 0.5520\n",
      "test Loss: 1.0533 Acc: 0.5120\n",
      "Epoch 124/1499\n",
      "----------\n",
      "train Loss: 1.0565 Acc: 0.5129\n",
      "val Loss: 1.0474 Acc: 0.5600\n",
      "test Loss: 1.0537 Acc: 0.5200\n",
      "Epoch 125/1499\n",
      "----------\n",
      "train Loss: 1.0564 Acc: 0.5127\n",
      "val Loss: 1.0469 Acc: 0.5480\n",
      "test Loss: 1.0542 Acc: 0.5160\n",
      "Epoch 126/1499\n",
      "----------\n",
      "train Loss: 1.0542 Acc: 0.5200\n",
      "val Loss: 1.0455 Acc: 0.5560\n",
      "test Loss: 1.0548 Acc: 0.5120\n",
      "Epoch 127/1499\n",
      "----------\n",
      "train Loss: 1.0541 Acc: 0.5189\n",
      "val Loss: 1.0454 Acc: 0.5560\n",
      "test Loss: 1.0508 Acc: 0.5120\n",
      "Epoch 128/1499\n",
      "----------\n",
      "train Loss: 1.0545 Acc: 0.5124\n",
      "val Loss: 1.0454 Acc: 0.5680\n",
      "test Loss: 1.0520 Acc: 0.5120\n",
      "Epoch 129/1499\n",
      "----------\n",
      "train Loss: 1.0528 Acc: 0.5180\n",
      "val Loss: 1.0453 Acc: 0.5440\n",
      "test Loss: 1.0512 Acc: 0.5360\n",
      "Epoch 130/1499\n",
      "----------\n",
      "train Loss: 1.0518 Acc: 0.5209\n",
      "val Loss: 1.0426 Acc: 0.5400\n",
      "test Loss: 1.0467 Acc: 0.5320\n",
      "Epoch 131/1499\n",
      "----------\n",
      "train Loss: 1.0512 Acc: 0.5171\n",
      "val Loss: 1.0420 Acc: 0.5440\n",
      "test Loss: 1.0531 Acc: 0.5240\n",
      "Epoch 132/1499\n",
      "----------\n",
      "train Loss: 1.0500 Acc: 0.5151\n",
      "val Loss: 1.0389 Acc: 0.5600\n",
      "test Loss: 1.0494 Acc: 0.5160\n",
      "Epoch 133/1499\n",
      "----------\n",
      "train Loss: 1.0493 Acc: 0.5184\n",
      "val Loss: 1.0395 Acc: 0.5520\n",
      "test Loss: 1.0478 Acc: 0.5280\n",
      "Epoch 134/1499\n",
      "----------\n",
      "train Loss: 1.0479 Acc: 0.5171\n",
      "val Loss: 1.0416 Acc: 0.5600\n",
      "test Loss: 1.0457 Acc: 0.5240\n",
      "Epoch 135/1499\n",
      "----------\n",
      "train Loss: 1.0477 Acc: 0.5178\n",
      "val Loss: 1.0388 Acc: 0.5680\n",
      "test Loss: 1.0439 Acc: 0.5400\n",
      "Epoch 136/1499\n",
      "----------\n",
      "train Loss: 1.0470 Acc: 0.5202\n",
      "val Loss: 1.0355 Acc: 0.5600\n",
      "test Loss: 1.0438 Acc: 0.5440\n",
      "Epoch 137/1499\n",
      "----------\n",
      "train Loss: 1.0459 Acc: 0.5191\n",
      "val Loss: 1.0360 Acc: 0.5720\n",
      "test Loss: 1.0421 Acc: 0.5400\n",
      "Epoch 138/1499\n",
      "----------\n",
      "train Loss: 1.0448 Acc: 0.5209\n",
      "val Loss: 1.0343 Acc: 0.5600\n",
      "test Loss: 1.0406 Acc: 0.5280\n",
      "Epoch 139/1499\n",
      "----------\n",
      "train Loss: 1.0435 Acc: 0.5236\n",
      "val Loss: 1.0362 Acc: 0.5600\n",
      "test Loss: 1.0407 Acc: 0.5160\n",
      "Epoch 140/1499\n",
      "----------\n",
      "train Loss: 1.0427 Acc: 0.5220\n",
      "val Loss: 1.0359 Acc: 0.5640\n",
      "test Loss: 1.0358 Acc: 0.5480\n",
      "Epoch 141/1499\n",
      "----------\n",
      "train Loss: 1.0412 Acc: 0.5269\n",
      "val Loss: 1.0295 Acc: 0.5760\n",
      "test Loss: 1.0372 Acc: 0.5440\n",
      "Epoch 142/1499\n",
      "----------\n",
      "train Loss: 1.0406 Acc: 0.5278\n",
      "val Loss: 1.0297 Acc: 0.5640\n",
      "test Loss: 1.0356 Acc: 0.5280\n",
      "Epoch 143/1499\n",
      "----------\n",
      "train Loss: 1.0395 Acc: 0.5260\n",
      "val Loss: 1.0253 Acc: 0.5880\n",
      "test Loss: 1.0354 Acc: 0.5360\n",
      "Epoch 144/1499\n",
      "----------\n",
      "train Loss: 1.0386 Acc: 0.5333\n",
      "val Loss: 1.0321 Acc: 0.5560\n",
      "test Loss: 1.0355 Acc: 0.5360\n",
      "Epoch 145/1499\n",
      "----------\n",
      "train Loss: 1.0371 Acc: 0.5322\n",
      "val Loss: 1.0237 Acc: 0.5800\n",
      "test Loss: 1.0343 Acc: 0.5160\n",
      "Epoch 146/1499\n",
      "----------\n",
      "train Loss: 1.0360 Acc: 0.5333\n",
      "val Loss: 1.0285 Acc: 0.5720\n",
      "test Loss: 1.0341 Acc: 0.5400\n",
      "Epoch 147/1499\n",
      "----------\n",
      "train Loss: 1.0356 Acc: 0.5351\n",
      "val Loss: 1.0294 Acc: 0.5640\n",
      "test Loss: 1.0312 Acc: 0.5240\n",
      "Epoch 148/1499\n",
      "----------\n",
      "train Loss: 1.0345 Acc: 0.5371\n",
      "val Loss: 1.0261 Acc: 0.5800\n",
      "test Loss: 1.0300 Acc: 0.5320\n",
      "Epoch 149/1499\n",
      "----------\n",
      "train Loss: 1.0330 Acc: 0.5364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0181 Acc: 0.5840\n",
      "test Loss: 1.0278 Acc: 0.5440\n",
      "Epoch 150/1499\n",
      "----------\n",
      "train Loss: 1.0321 Acc: 0.5373\n",
      "val Loss: 1.0252 Acc: 0.5880\n",
      "test Loss: 1.0284 Acc: 0.5400\n",
      "Epoch 151/1499\n",
      "----------\n",
      "train Loss: 1.0316 Acc: 0.5369\n",
      "val Loss: 1.0206 Acc: 0.5800\n",
      "test Loss: 1.0352 Acc: 0.5400\n",
      "Epoch 152/1499\n",
      "----------\n",
      "train Loss: 1.0306 Acc: 0.5364\n",
      "val Loss: 1.0222 Acc: 0.5840\n",
      "test Loss: 1.0327 Acc: 0.5320\n",
      "Epoch 153/1499\n",
      "----------\n",
      "train Loss: 1.0298 Acc: 0.5387\n",
      "val Loss: 1.0196 Acc: 0.5760\n",
      "test Loss: 1.0300 Acc: 0.5400\n",
      "Epoch 154/1499\n",
      "----------\n",
      "train Loss: 1.0289 Acc: 0.5396\n",
      "val Loss: 1.0116 Acc: 0.5920\n",
      "test Loss: 1.0272 Acc: 0.5400\n",
      "Epoch 155/1499\n",
      "----------\n",
      "train Loss: 1.0276 Acc: 0.5378\n",
      "val Loss: 1.0114 Acc: 0.5840\n",
      "test Loss: 1.0260 Acc: 0.5240\n",
      "Epoch 156/1499\n",
      "----------\n",
      "train Loss: 1.0245 Acc: 0.5427\n",
      "val Loss: 1.0177 Acc: 0.5800\n",
      "test Loss: 1.0222 Acc: 0.5520\n",
      "Epoch 157/1499\n",
      "----------\n",
      "train Loss: 1.0245 Acc: 0.5407\n",
      "val Loss: 1.0133 Acc: 0.5920\n",
      "test Loss: 1.0283 Acc: 0.5480\n",
      "Epoch 158/1499\n",
      "----------\n",
      "train Loss: 1.0233 Acc: 0.5418\n",
      "val Loss: 1.0130 Acc: 0.5840\n",
      "test Loss: 1.0202 Acc: 0.5520\n",
      "Epoch 159/1499\n",
      "----------\n",
      "train Loss: 1.0235 Acc: 0.5424\n",
      "val Loss: 1.0151 Acc: 0.5840\n",
      "test Loss: 1.0232 Acc: 0.5480\n",
      "Epoch 160/1499\n",
      "----------\n",
      "train Loss: 1.0228 Acc: 0.5429\n",
      "val Loss: 1.0139 Acc: 0.5880\n",
      "test Loss: 1.0158 Acc: 0.5440\n",
      "Epoch 161/1499\n",
      "----------\n",
      "train Loss: 1.0213 Acc: 0.5427\n",
      "val Loss: 1.0116 Acc: 0.5760\n",
      "test Loss: 1.0177 Acc: 0.5440\n",
      "Epoch 162/1499\n",
      "----------\n",
      "train Loss: 1.0203 Acc: 0.5462\n",
      "val Loss: 1.0070 Acc: 0.5720\n",
      "test Loss: 1.0184 Acc: 0.5440\n",
      "Epoch 163/1499\n",
      "----------\n",
      "train Loss: 1.0177 Acc: 0.5473\n",
      "val Loss: 1.0070 Acc: 0.5720\n",
      "test Loss: 1.0124 Acc: 0.5360\n",
      "Epoch 164/1499\n",
      "----------\n",
      "train Loss: 1.0181 Acc: 0.5442\n",
      "val Loss: 1.0047 Acc: 0.5960\n",
      "test Loss: 1.0117 Acc: 0.5600\n",
      "Epoch 165/1499\n",
      "----------\n",
      "train Loss: 1.0173 Acc: 0.5453\n",
      "val Loss: 1.0063 Acc: 0.5960\n",
      "test Loss: 1.0197 Acc: 0.5280\n",
      "Epoch 166/1499\n",
      "----------\n",
      "train Loss: 1.0158 Acc: 0.5431\n",
      "val Loss: 1.0087 Acc: 0.5920\n",
      "test Loss: 1.0147 Acc: 0.5480\n",
      "Epoch 167/1499\n",
      "----------\n",
      "train Loss: 1.0147 Acc: 0.5440\n",
      "val Loss: 1.0060 Acc: 0.5880\n",
      "test Loss: 1.0110 Acc: 0.5600\n",
      "Epoch 168/1499\n",
      "----------\n",
      "train Loss: 1.0136 Acc: 0.5498\n",
      "val Loss: 1.0002 Acc: 0.5920\n",
      "test Loss: 1.0106 Acc: 0.5600\n",
      "Epoch 169/1499\n",
      "----------\n",
      "train Loss: 1.0121 Acc: 0.5478\n",
      "val Loss: 1.0042 Acc: 0.5800\n",
      "test Loss: 1.0091 Acc: 0.5360\n",
      "Epoch 170/1499\n",
      "----------\n",
      "train Loss: 1.0110 Acc: 0.5524\n",
      "val Loss: 1.0061 Acc: 0.5800\n",
      "test Loss: 1.0092 Acc: 0.5440\n",
      "Epoch 171/1499\n",
      "----------\n",
      "train Loss: 1.0097 Acc: 0.5533\n",
      "val Loss: 0.9995 Acc: 0.5840\n",
      "test Loss: 1.0069 Acc: 0.5360\n",
      "Epoch 172/1499\n",
      "----------\n",
      "train Loss: 1.0092 Acc: 0.5522\n",
      "val Loss: 1.0062 Acc: 0.5760\n",
      "test Loss: 1.0118 Acc: 0.5520\n",
      "Epoch 173/1499\n",
      "----------\n",
      "train Loss: 1.0090 Acc: 0.5493\n",
      "val Loss: 0.9995 Acc: 0.5760\n",
      "test Loss: 1.0044 Acc: 0.5520\n",
      "Epoch 174/1499\n",
      "----------\n",
      "train Loss: 1.0074 Acc: 0.5536\n",
      "val Loss: 1.0018 Acc: 0.5680\n",
      "test Loss: 1.0012 Acc: 0.5520\n",
      "Epoch 175/1499\n",
      "----------\n",
      "train Loss: 1.0052 Acc: 0.5547\n",
      "val Loss: 0.9918 Acc: 0.5920\n",
      "test Loss: 0.9993 Acc: 0.5680\n",
      "Epoch 176/1499\n",
      "----------\n",
      "train Loss: 1.0056 Acc: 0.5500\n",
      "val Loss: 0.9963 Acc: 0.5920\n",
      "test Loss: 0.9992 Acc: 0.5480\n",
      "Epoch 177/1499\n",
      "----------\n",
      "train Loss: 1.0044 Acc: 0.5527\n",
      "val Loss: 0.9933 Acc: 0.5760\n",
      "test Loss: 1.0049 Acc: 0.5320\n",
      "Epoch 178/1499\n",
      "----------\n",
      "train Loss: 1.0025 Acc: 0.5509\n",
      "val Loss: 0.9915 Acc: 0.5960\n",
      "test Loss: 1.0015 Acc: 0.5400\n",
      "Epoch 179/1499\n",
      "----------\n",
      "train Loss: 1.0016 Acc: 0.5473\n",
      "val Loss: 0.9886 Acc: 0.5800\n",
      "test Loss: 1.0008 Acc: 0.5440\n",
      "Epoch 180/1499\n",
      "----------\n",
      "train Loss: 1.0000 Acc: 0.5509\n",
      "val Loss: 0.9923 Acc: 0.5840\n",
      "test Loss: 0.9964 Acc: 0.5480\n",
      "Epoch 181/1499\n",
      "----------\n",
      "train Loss: 0.9982 Acc: 0.5551\n",
      "val Loss: 0.9871 Acc: 0.5840\n",
      "test Loss: 0.9979 Acc: 0.5480\n",
      "Epoch 182/1499\n",
      "----------\n",
      "train Loss: 0.9986 Acc: 0.5498\n",
      "val Loss: 0.9831 Acc: 0.5760\n",
      "test Loss: 0.9923 Acc: 0.5640\n",
      "Epoch 183/1499\n",
      "----------\n",
      "train Loss: 0.9972 Acc: 0.5540\n",
      "val Loss: 0.9770 Acc: 0.5960\n",
      "test Loss: 0.9973 Acc: 0.5720\n",
      "Epoch 184/1499\n",
      "----------\n",
      "train Loss: 0.9956 Acc: 0.5549\n",
      "val Loss: 0.9824 Acc: 0.6000\n",
      "test Loss: 0.9923 Acc: 0.5520\n",
      "Epoch 185/1499\n",
      "----------\n",
      "train Loss: 0.9947 Acc: 0.5589\n",
      "val Loss: 0.9816 Acc: 0.5880\n",
      "test Loss: 0.9868 Acc: 0.5480\n",
      "Epoch 186/1499\n",
      "----------\n",
      "train Loss: 0.9939 Acc: 0.5560\n",
      "val Loss: 0.9784 Acc: 0.5840\n",
      "test Loss: 0.9910 Acc: 0.5520\n",
      "Epoch 187/1499\n",
      "----------\n",
      "train Loss: 0.9928 Acc: 0.5556\n",
      "val Loss: 0.9794 Acc: 0.5960\n",
      "test Loss: 0.9830 Acc: 0.5640\n",
      "Epoch 188/1499\n",
      "----------\n",
      "train Loss: 0.9923 Acc: 0.5564\n",
      "val Loss: 0.9866 Acc: 0.5960\n",
      "test Loss: 0.9851 Acc: 0.5440\n",
      "Epoch 189/1499\n",
      "----------\n",
      "train Loss: 0.9906 Acc: 0.5589\n",
      "val Loss: 0.9749 Acc: 0.6000\n",
      "test Loss: 0.9922 Acc: 0.5440\n",
      "Epoch 190/1499\n",
      "----------\n",
      "train Loss: 0.9904 Acc: 0.5567\n",
      "val Loss: 0.9771 Acc: 0.5920\n",
      "test Loss: 0.9858 Acc: 0.5600\n",
      "Epoch 191/1499\n",
      "----------\n",
      "train Loss: 0.9894 Acc: 0.5609\n",
      "val Loss: 0.9746 Acc: 0.5920\n",
      "test Loss: 0.9817 Acc: 0.5600\n",
      "Epoch 192/1499\n",
      "----------\n",
      "train Loss: 0.9891 Acc: 0.5618\n",
      "val Loss: 0.9745 Acc: 0.5960\n",
      "test Loss: 0.9905 Acc: 0.5440\n",
      "Epoch 193/1499\n",
      "----------\n",
      "train Loss: 0.9878 Acc: 0.5609\n",
      "val Loss: 0.9740 Acc: 0.5920\n",
      "test Loss: 0.9829 Acc: 0.5680\n",
      "Epoch 194/1499\n",
      "----------\n",
      "train Loss: 0.9851 Acc: 0.5596\n",
      "val Loss: 0.9704 Acc: 0.6040\n",
      "test Loss: 0.9845 Acc: 0.5440\n",
      "Epoch 195/1499\n",
      "----------\n",
      "train Loss: 0.9848 Acc: 0.5620\n",
      "val Loss: 0.9766 Acc: 0.5840\n",
      "test Loss: 0.9848 Acc: 0.5440\n",
      "Epoch 196/1499\n",
      "----------\n",
      "train Loss: 0.9856 Acc: 0.5587\n",
      "val Loss: 0.9668 Acc: 0.5920\n",
      "test Loss: 0.9801 Acc: 0.5600\n",
      "Epoch 197/1499\n",
      "----------\n",
      "train Loss: 0.9842 Acc: 0.5611\n",
      "val Loss: 0.9709 Acc: 0.6000\n",
      "test Loss: 0.9729 Acc: 0.5720\n",
      "Epoch 198/1499\n",
      "----------\n",
      "train Loss: 0.9830 Acc: 0.5604\n",
      "val Loss: 0.9653 Acc: 0.5920\n",
      "test Loss: 0.9767 Acc: 0.5600\n",
      "Epoch 199/1499\n",
      "----------\n",
      "train Loss: 0.9799 Acc: 0.5667\n",
      "val Loss: 0.9613 Acc: 0.6040\n",
      "test Loss: 0.9749 Acc: 0.5600\n",
      "Epoch 200/1499\n",
      "----------\n",
      "train Loss: 0.9803 Acc: 0.5640\n",
      "val Loss: 0.9652 Acc: 0.6040\n",
      "test Loss: 0.9777 Acc: 0.5560\n",
      "Epoch 201/1499\n",
      "----------\n",
      "train Loss: 0.9790 Acc: 0.5627\n",
      "val Loss: 0.9675 Acc: 0.5960\n",
      "test Loss: 0.9795 Acc: 0.5600\n",
      "Epoch 202/1499\n",
      "----------\n",
      "train Loss: 0.9781 Acc: 0.5629\n",
      "val Loss: 0.9652 Acc: 0.5960\n",
      "test Loss: 0.9800 Acc: 0.5720\n",
      "Epoch 203/1499\n",
      "----------\n",
      "train Loss: 0.9771 Acc: 0.5609\n",
      "val Loss: 0.9693 Acc: 0.5880\n",
      "test Loss: 0.9682 Acc: 0.5720\n",
      "Epoch 204/1499\n",
      "----------\n",
      "train Loss: 0.9757 Acc: 0.5649\n",
      "val Loss: 0.9650 Acc: 0.5920\n",
      "test Loss: 0.9696 Acc: 0.5640\n",
      "Epoch 205/1499\n",
      "----------\n",
      "train Loss: 0.9749 Acc: 0.5631\n",
      "val Loss: 0.9695 Acc: 0.5840\n",
      "test Loss: 0.9712 Acc: 0.5600\n",
      "Epoch 206/1499\n",
      "----------\n",
      "train Loss: 0.9753 Acc: 0.5622\n",
      "val Loss: 0.9630 Acc: 0.5840\n",
      "test Loss: 0.9719 Acc: 0.5600\n",
      "Epoch 207/1499\n",
      "----------\n",
      "train Loss: 0.9744 Acc: 0.5640\n",
      "val Loss: 0.9535 Acc: 0.5920\n",
      "test Loss: 0.9724 Acc: 0.5640\n",
      "Epoch 208/1499\n",
      "----------\n",
      "train Loss: 0.9722 Acc: 0.5667\n",
      "val Loss: 0.9535 Acc: 0.5920\n",
      "test Loss: 0.9785 Acc: 0.5720\n",
      "Epoch 209/1499\n",
      "----------\n",
      "train Loss: 0.9727 Acc: 0.5611\n",
      "val Loss: 0.9537 Acc: 0.6000\n",
      "test Loss: 0.9609 Acc: 0.5680\n",
      "Epoch 210/1499\n",
      "----------\n",
      "train Loss: 0.9710 Acc: 0.5649\n",
      "val Loss: 0.9574 Acc: 0.5880\n",
      "test Loss: 0.9623 Acc: 0.5680\n",
      "Epoch 211/1499\n",
      "----------\n",
      "train Loss: 0.9696 Acc: 0.5664\n",
      "val Loss: 0.9565 Acc: 0.5920\n",
      "test Loss: 0.9644 Acc: 0.5840\n",
      "Epoch 212/1499\n",
      "----------\n",
      "train Loss: 0.9698 Acc: 0.5682\n",
      "val Loss: 0.9551 Acc: 0.6040\n",
      "test Loss: 0.9628 Acc: 0.5760\n",
      "Epoch 213/1499\n",
      "----------\n",
      "train Loss: 0.9691 Acc: 0.5660\n",
      "val Loss: 0.9494 Acc: 0.6000\n",
      "test Loss: 0.9738 Acc: 0.5760\n",
      "Epoch 214/1499\n",
      "----------\n",
      "train Loss: 0.9676 Acc: 0.5667\n",
      "val Loss: 0.9481 Acc: 0.5920\n",
      "test Loss: 0.9638 Acc: 0.5640\n",
      "Epoch 215/1499\n",
      "----------\n",
      "train Loss: 0.9668 Acc: 0.5644\n",
      "val Loss: 0.9552 Acc: 0.5960\n",
      "test Loss: 0.9622 Acc: 0.5840\n",
      "Epoch 216/1499\n",
      "----------\n",
      "train Loss: 0.9660 Acc: 0.5696\n",
      "val Loss: 0.9501 Acc: 0.5920\n",
      "test Loss: 0.9588 Acc: 0.5840\n",
      "Epoch 217/1499\n",
      "----------\n",
      "train Loss: 0.9660 Acc: 0.5700\n",
      "val Loss: 0.9506 Acc: 0.5760\n",
      "test Loss: 0.9616 Acc: 0.5680\n",
      "Epoch 218/1499\n",
      "----------\n",
      "train Loss: 0.9636 Acc: 0.5671\n",
      "val Loss: 0.9567 Acc: 0.5960\n",
      "test Loss: 0.9647 Acc: 0.5720\n",
      "Epoch 219/1499\n",
      "----------\n",
      "train Loss: 0.9618 Acc: 0.5704\n",
      "val Loss: 0.9502 Acc: 0.5920\n",
      "test Loss: 0.9599 Acc: 0.5760\n",
      "Epoch 220/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.9613 Acc: 0.5700\n",
      "val Loss: 0.9522 Acc: 0.5960\n",
      "test Loss: 0.9650 Acc: 0.5800\n",
      "Epoch 221/1499\n",
      "----------\n",
      "train Loss: 0.9621 Acc: 0.5711\n",
      "val Loss: 0.9522 Acc: 0.6080\n",
      "test Loss: 0.9515 Acc: 0.6000\n",
      "Epoch 222/1499\n",
      "----------\n",
      "train Loss: 0.9609 Acc: 0.5769\n",
      "val Loss: 0.9470 Acc: 0.5920\n",
      "test Loss: 0.9597 Acc: 0.5680\n",
      "Epoch 223/1499\n",
      "----------\n",
      "train Loss: 0.9599 Acc: 0.5773\n",
      "val Loss: 0.9465 Acc: 0.6200\n",
      "test Loss: 0.9618 Acc: 0.5840\n",
      "Epoch 224/1499\n",
      "----------\n",
      "train Loss: 0.9597 Acc: 0.5729\n",
      "val Loss: 0.9450 Acc: 0.5960\n",
      "test Loss: 0.9581 Acc: 0.5760\n",
      "Epoch 225/1499\n",
      "----------\n",
      "train Loss: 0.9591 Acc: 0.5720\n",
      "val Loss: 0.9411 Acc: 0.6160\n",
      "test Loss: 0.9550 Acc: 0.5920\n",
      "Epoch 226/1499\n",
      "----------\n",
      "train Loss: 0.9580 Acc: 0.5787\n",
      "val Loss: 0.9512 Acc: 0.6120\n",
      "test Loss: 0.9513 Acc: 0.5880\n",
      "Epoch 227/1499\n",
      "----------\n",
      "train Loss: 0.9553 Acc: 0.5836\n",
      "val Loss: 0.9440 Acc: 0.6000\n",
      "test Loss: 0.9556 Acc: 0.5800\n",
      "Epoch 228/1499\n",
      "----------\n",
      "train Loss: 0.9566 Acc: 0.5796\n",
      "val Loss: 0.9432 Acc: 0.6200\n",
      "test Loss: 0.9627 Acc: 0.5880\n",
      "Epoch 229/1499\n",
      "----------\n",
      "train Loss: 0.9543 Acc: 0.5780\n",
      "val Loss: 0.9394 Acc: 0.6000\n",
      "test Loss: 0.9554 Acc: 0.5920\n",
      "Epoch 230/1499\n",
      "----------\n",
      "train Loss: 0.9537 Acc: 0.5842\n",
      "val Loss: 0.9458 Acc: 0.5920\n",
      "test Loss: 0.9342 Acc: 0.6040\n",
      "Epoch 231/1499\n",
      "----------\n",
      "train Loss: 0.9535 Acc: 0.5818\n",
      "val Loss: 0.9291 Acc: 0.6200\n",
      "test Loss: 0.9517 Acc: 0.5840\n",
      "Epoch 232/1499\n",
      "----------\n",
      "train Loss: 0.9532 Acc: 0.5802\n",
      "val Loss: 0.9426 Acc: 0.6040\n",
      "test Loss: 0.9515 Acc: 0.5920\n",
      "Epoch 233/1499\n",
      "----------\n",
      "train Loss: 0.9517 Acc: 0.5820\n",
      "val Loss: 0.9467 Acc: 0.5880\n",
      "test Loss: 0.9501 Acc: 0.5920\n",
      "Epoch 234/1499\n",
      "----------\n",
      "train Loss: 0.9506 Acc: 0.5816\n",
      "val Loss: 0.9466 Acc: 0.5960\n",
      "test Loss: 0.9450 Acc: 0.5960\n",
      "Epoch 235/1499\n",
      "----------\n",
      "train Loss: 0.9482 Acc: 0.5827\n",
      "val Loss: 0.9302 Acc: 0.6040\n",
      "test Loss: 0.9376 Acc: 0.6280\n",
      "Epoch 236/1499\n",
      "----------\n",
      "train Loss: 0.9493 Acc: 0.5876\n",
      "val Loss: 0.9375 Acc: 0.6040\n",
      "test Loss: 0.9514 Acc: 0.5840\n",
      "Epoch 237/1499\n",
      "----------\n",
      "train Loss: 0.9469 Acc: 0.5860\n",
      "val Loss: 0.9388 Acc: 0.6000\n",
      "test Loss: 0.9498 Acc: 0.5680\n",
      "Epoch 238/1499\n",
      "----------\n",
      "train Loss: 0.9463 Acc: 0.5771\n",
      "val Loss: 0.9391 Acc: 0.5840\n",
      "test Loss: 0.9474 Acc: 0.5800\n",
      "Epoch 239/1499\n",
      "----------\n",
      "train Loss: 0.9456 Acc: 0.5711\n",
      "val Loss: 0.9361 Acc: 0.5920\n",
      "test Loss: 0.9417 Acc: 0.5840\n",
      "Epoch 240/1499\n",
      "----------\n",
      "train Loss: 0.9465 Acc: 0.5676\n",
      "val Loss: 0.9295 Acc: 0.5960\n",
      "test Loss: 0.9443 Acc: 0.5840\n",
      "Epoch 241/1499\n",
      "----------\n",
      "train Loss: 0.9460 Acc: 0.5682\n",
      "val Loss: 0.9320 Acc: 0.5960\n",
      "test Loss: 0.9416 Acc: 0.5840\n",
      "Epoch 242/1499\n",
      "----------\n",
      "train Loss: 0.9442 Acc: 0.5696\n",
      "val Loss: 0.9414 Acc: 0.5800\n",
      "test Loss: 0.9369 Acc: 0.5960\n",
      "Epoch 243/1499\n",
      "----------\n",
      "train Loss: 0.9437 Acc: 0.5742\n",
      "val Loss: 0.9327 Acc: 0.6080\n",
      "test Loss: 0.9419 Acc: 0.5760\n",
      "Epoch 244/1499\n",
      "----------\n",
      "train Loss: 0.9413 Acc: 0.5753\n",
      "val Loss: 0.9286 Acc: 0.5840\n",
      "test Loss: 0.9317 Acc: 0.6000\n",
      "Epoch 245/1499\n",
      "----------\n",
      "train Loss: 0.9426 Acc: 0.5744\n",
      "val Loss: 0.9295 Acc: 0.5760\n",
      "test Loss: 0.9331 Acc: 0.6000\n",
      "Epoch 246/1499\n",
      "----------\n",
      "train Loss: 0.9419 Acc: 0.5704\n",
      "val Loss: 0.9250 Acc: 0.6120\n",
      "test Loss: 0.9382 Acc: 0.5880\n",
      "Epoch 247/1499\n",
      "----------\n",
      "train Loss: 0.9403 Acc: 0.5760\n",
      "val Loss: 0.9279 Acc: 0.6040\n",
      "test Loss: 0.9347 Acc: 0.6000\n",
      "Epoch 248/1499\n",
      "----------\n",
      "train Loss: 0.9395 Acc: 0.5727\n",
      "val Loss: 0.9232 Acc: 0.6240\n",
      "test Loss: 0.9325 Acc: 0.5880\n",
      "Epoch 249/1499\n",
      "----------\n",
      "train Loss: 0.9377 Acc: 0.5764\n",
      "val Loss: 0.9238 Acc: 0.5880\n",
      "test Loss: 0.9265 Acc: 0.6240\n",
      "Epoch 250/1499\n",
      "----------\n",
      "train Loss: 0.9386 Acc: 0.5787\n",
      "val Loss: 0.9193 Acc: 0.6000\n",
      "test Loss: 0.9347 Acc: 0.6040\n",
      "Epoch 251/1499\n",
      "----------\n",
      "train Loss: 0.9374 Acc: 0.5780\n",
      "val Loss: 0.9343 Acc: 0.6040\n",
      "test Loss: 0.9357 Acc: 0.6160\n",
      "Epoch 252/1499\n",
      "----------\n",
      "train Loss: 0.9379 Acc: 0.5780\n",
      "val Loss: 0.9241 Acc: 0.5800\n",
      "test Loss: 0.9296 Acc: 0.5960\n",
      "Epoch 253/1499\n",
      "----------\n",
      "train Loss: 0.9354 Acc: 0.5800\n",
      "val Loss: 0.9131 Acc: 0.6280\n",
      "test Loss: 0.9214 Acc: 0.6320\n",
      "Epoch 254/1499\n",
      "----------\n",
      "train Loss: 0.9358 Acc: 0.5789\n",
      "val Loss: 0.9230 Acc: 0.6040\n",
      "test Loss: 0.9276 Acc: 0.6160\n",
      "Epoch 255/1499\n",
      "----------\n",
      "train Loss: 0.9361 Acc: 0.5787\n",
      "val Loss: 0.9207 Acc: 0.5960\n",
      "test Loss: 0.9330 Acc: 0.6040\n",
      "Epoch 256/1499\n",
      "----------\n",
      "train Loss: 0.9333 Acc: 0.5856\n",
      "val Loss: 0.9189 Acc: 0.6080\n",
      "test Loss: 0.9291 Acc: 0.6040\n",
      "Epoch 257/1499\n",
      "----------\n",
      "train Loss: 0.9335 Acc: 0.5804\n",
      "val Loss: 0.9211 Acc: 0.6000\n",
      "test Loss: 0.9373 Acc: 0.5840\n",
      "Epoch 258/1499\n",
      "----------\n",
      "train Loss: 0.9335 Acc: 0.5800\n",
      "val Loss: 0.9194 Acc: 0.6200\n",
      "test Loss: 0.9274 Acc: 0.6240\n",
      "Epoch 259/1499\n",
      "----------\n",
      "train Loss: 0.9301 Acc: 0.5822\n",
      "val Loss: 0.9102 Acc: 0.6120\n",
      "test Loss: 0.9259 Acc: 0.6160\n",
      "Epoch 260/1499\n",
      "----------\n",
      "train Loss: 0.9332 Acc: 0.5849\n",
      "val Loss: 0.9126 Acc: 0.6360\n",
      "test Loss: 0.9319 Acc: 0.6200\n",
      "Epoch 261/1499\n",
      "----------\n",
      "train Loss: 0.9330 Acc: 0.5831\n",
      "val Loss: 0.9233 Acc: 0.6200\n",
      "test Loss: 0.9295 Acc: 0.6080\n",
      "Epoch 262/1499\n",
      "----------\n",
      "train Loss: 0.9313 Acc: 0.5836\n",
      "val Loss: 0.9232 Acc: 0.6080\n",
      "test Loss: 0.9325 Acc: 0.6120\n",
      "Epoch 263/1499\n",
      "----------\n",
      "train Loss: 0.9288 Acc: 0.5860\n",
      "val Loss: 0.9125 Acc: 0.6280\n",
      "test Loss: 0.9231 Acc: 0.6200\n",
      "Epoch 264/1499\n",
      "----------\n",
      "train Loss: 0.9287 Acc: 0.5833\n",
      "val Loss: 0.9175 Acc: 0.6000\n",
      "test Loss: 0.9291 Acc: 0.6080\n",
      "Epoch 265/1499\n",
      "----------\n",
      "train Loss: 0.9283 Acc: 0.5867\n",
      "val Loss: 0.9164 Acc: 0.5920\n",
      "test Loss: 0.9231 Acc: 0.6200\n",
      "Epoch 266/1499\n",
      "----------\n",
      "train Loss: 0.9270 Acc: 0.5902\n",
      "val Loss: 0.9120 Acc: 0.6120\n",
      "test Loss: 0.9199 Acc: 0.6160\n",
      "Epoch 267/1499\n",
      "----------\n",
      "train Loss: 0.9251 Acc: 0.5916\n",
      "val Loss: 0.9126 Acc: 0.6280\n",
      "test Loss: 0.9123 Acc: 0.6320\n",
      "Epoch 268/1499\n",
      "----------\n",
      "train Loss: 0.9241 Acc: 0.5909\n",
      "val Loss: 0.9234 Acc: 0.5800\n",
      "test Loss: 0.9285 Acc: 0.6120\n",
      "Epoch 269/1499\n",
      "----------\n",
      "train Loss: 0.9259 Acc: 0.5902\n",
      "val Loss: 0.9150 Acc: 0.6080\n",
      "test Loss: 0.9149 Acc: 0.6160\n",
      "Epoch 270/1499\n",
      "----------\n",
      "train Loss: 0.9251 Acc: 0.5851\n",
      "val Loss: 0.9190 Acc: 0.6040\n",
      "test Loss: 0.9161 Acc: 0.6280\n",
      "Epoch 271/1499\n",
      "----------\n",
      "train Loss: 0.9228 Acc: 0.5889\n",
      "val Loss: 0.9163 Acc: 0.6040\n",
      "test Loss: 0.9241 Acc: 0.5960\n",
      "Epoch 272/1499\n",
      "----------\n",
      "train Loss: 0.9226 Acc: 0.5971\n",
      "val Loss: 0.9088 Acc: 0.6160\n",
      "test Loss: 0.9069 Acc: 0.6400\n",
      "Epoch 273/1499\n",
      "----------\n",
      "train Loss: 0.9209 Acc: 0.5942\n",
      "val Loss: 0.9196 Acc: 0.6040\n",
      "test Loss: 0.9193 Acc: 0.6160\n",
      "Epoch 274/1499\n",
      "----------\n",
      "train Loss: 0.9232 Acc: 0.5949\n",
      "val Loss: 0.9120 Acc: 0.5880\n",
      "test Loss: 0.9184 Acc: 0.6160\n",
      "Epoch 275/1499\n",
      "----------\n",
      "train Loss: 0.9212 Acc: 0.5898\n",
      "val Loss: 0.8973 Acc: 0.6280\n",
      "test Loss: 0.9176 Acc: 0.6200\n",
      "Epoch 276/1499\n",
      "----------\n",
      "train Loss: 0.9209 Acc: 0.5929\n",
      "val Loss: 0.9062 Acc: 0.6040\n",
      "test Loss: 0.9257 Acc: 0.6120\n",
      "Epoch 277/1499\n",
      "----------\n",
      "train Loss: 0.9226 Acc: 0.5880\n",
      "val Loss: 0.9158 Acc: 0.6080\n",
      "test Loss: 0.9166 Acc: 0.6120\n",
      "Epoch 278/1499\n",
      "----------\n",
      "train Loss: 0.9195 Acc: 0.5938\n",
      "val Loss: 0.8963 Acc: 0.6240\n",
      "test Loss: 0.9076 Acc: 0.6240\n",
      "Epoch 279/1499\n",
      "----------\n",
      "train Loss: 0.9169 Acc: 0.5971\n",
      "val Loss: 0.9051 Acc: 0.6360\n",
      "test Loss: 0.9116 Acc: 0.6280\n",
      "Epoch 280/1499\n",
      "----------\n",
      "train Loss: 0.9193 Acc: 0.5962\n",
      "val Loss: 0.8961 Acc: 0.6320\n",
      "test Loss: 0.9133 Acc: 0.6200\n",
      "Epoch 281/1499\n",
      "----------\n",
      "train Loss: 0.9196 Acc: 0.5929\n",
      "val Loss: 0.9101 Acc: 0.6200\n",
      "test Loss: 0.9043 Acc: 0.6520\n",
      "Epoch 282/1499\n",
      "----------\n",
      "train Loss: 0.9160 Acc: 0.6031\n",
      "val Loss: 0.9043 Acc: 0.6120\n",
      "test Loss: 0.9079 Acc: 0.6400\n",
      "Epoch 283/1499\n",
      "----------\n",
      "train Loss: 0.9160 Acc: 0.6002\n",
      "val Loss: 0.9048 Acc: 0.6200\n",
      "test Loss: 0.9199 Acc: 0.6160\n",
      "Epoch 284/1499\n",
      "----------\n",
      "train Loss: 0.9162 Acc: 0.5964\n",
      "val Loss: 0.9183 Acc: 0.6040\n",
      "test Loss: 0.9066 Acc: 0.6320\n",
      "Epoch 285/1499\n",
      "----------\n",
      "train Loss: 0.9142 Acc: 0.6022\n",
      "val Loss: 0.9042 Acc: 0.6280\n",
      "test Loss: 0.8997 Acc: 0.6520\n",
      "Epoch 286/1499\n",
      "----------\n",
      "train Loss: 0.9123 Acc: 0.6058\n",
      "val Loss: 0.8994 Acc: 0.6280\n",
      "test Loss: 0.9222 Acc: 0.6480\n",
      "Epoch 287/1499\n",
      "----------\n",
      "train Loss: 0.9141 Acc: 0.6018\n",
      "val Loss: 0.9006 Acc: 0.6320\n",
      "test Loss: 0.9213 Acc: 0.6080\n",
      "Epoch 288/1499\n",
      "----------\n",
      "train Loss: 0.9138 Acc: 0.6000\n",
      "val Loss: 0.9065 Acc: 0.6160\n",
      "test Loss: 0.9038 Acc: 0.6520\n",
      "Epoch 289/1499\n",
      "----------\n",
      "train Loss: 0.9142 Acc: 0.5973\n",
      "val Loss: 0.9041 Acc: 0.6160\n",
      "test Loss: 0.9148 Acc: 0.6040\n",
      "Epoch 290/1499\n",
      "----------\n",
      "train Loss: 0.9149 Acc: 0.6058\n",
      "val Loss: 0.9077 Acc: 0.6160\n",
      "test Loss: 0.9055 Acc: 0.6320\n",
      "Epoch 291/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.9100 Acc: 0.6064\n",
      "val Loss: 0.9041 Acc: 0.6280\n",
      "test Loss: 0.9067 Acc: 0.6320\n",
      "Epoch 292/1499\n",
      "----------\n",
      "train Loss: 0.9106 Acc: 0.6056\n",
      "val Loss: 0.9012 Acc: 0.6320\n",
      "test Loss: 0.9054 Acc: 0.6120\n",
      "Epoch 293/1499\n",
      "----------\n",
      "train Loss: 0.9108 Acc: 0.6060\n",
      "val Loss: 0.8982 Acc: 0.6440\n",
      "test Loss: 0.9043 Acc: 0.6600\n",
      "Epoch 294/1499\n",
      "----------\n",
      "train Loss: 0.9080 Acc: 0.6118\n",
      "val Loss: 0.9008 Acc: 0.6320\n",
      "test Loss: 0.8964 Acc: 0.6480\n",
      "Epoch 295/1499\n",
      "----------\n",
      "train Loss: 0.9081 Acc: 0.6118\n",
      "val Loss: 0.9003 Acc: 0.6360\n",
      "test Loss: 0.8958 Acc: 0.6640\n",
      "Epoch 296/1499\n",
      "----------\n",
      "train Loss: 0.9079 Acc: 0.6116\n",
      "val Loss: 0.8986 Acc: 0.6200\n",
      "test Loss: 0.8971 Acc: 0.6440\n",
      "Epoch 297/1499\n",
      "----------\n",
      "train Loss: 0.9081 Acc: 0.6162\n",
      "val Loss: 0.8868 Acc: 0.6640\n",
      "test Loss: 0.9029 Acc: 0.6400\n",
      "Epoch 298/1499\n",
      "----------\n",
      "train Loss: 0.9078 Acc: 0.6162\n",
      "val Loss: 0.8951 Acc: 0.6640\n",
      "test Loss: 0.9087 Acc: 0.6200\n",
      "Epoch 299/1499\n",
      "----------\n",
      "train Loss: 0.9049 Acc: 0.6169\n",
      "val Loss: 0.8989 Acc: 0.6360\n",
      "test Loss: 0.8942 Acc: 0.6680\n",
      "Epoch 300/1499\n",
      "----------\n",
      "train Loss: 0.9061 Acc: 0.6153\n",
      "val Loss: 0.8944 Acc: 0.6520\n",
      "test Loss: 0.8925 Acc: 0.6720\n",
      "Epoch 301/1499\n",
      "----------\n",
      "train Loss: 0.9053 Acc: 0.6149\n",
      "val Loss: 0.8827 Acc: 0.6600\n",
      "test Loss: 0.8977 Acc: 0.6720\n",
      "Epoch 302/1499\n",
      "----------\n",
      "train Loss: 0.9059 Acc: 0.6169\n",
      "val Loss: 0.8970 Acc: 0.6520\n",
      "test Loss: 0.8889 Acc: 0.7000\n",
      "Epoch 303/1499\n",
      "----------\n",
      "train Loss: 0.9053 Acc: 0.6213\n",
      "val Loss: 0.8892 Acc: 0.6520\n",
      "test Loss: 0.9018 Acc: 0.6680\n",
      "Epoch 304/1499\n",
      "----------\n",
      "train Loss: 0.9020 Acc: 0.6242\n",
      "val Loss: 0.9031 Acc: 0.6320\n",
      "test Loss: 0.9133 Acc: 0.6240\n",
      "Epoch 305/1499\n",
      "----------\n",
      "train Loss: 0.9031 Acc: 0.6213\n",
      "val Loss: 0.8862 Acc: 0.6440\n",
      "test Loss: 0.8967 Acc: 0.6640\n",
      "Epoch 306/1499\n",
      "----------\n",
      "train Loss: 0.9017 Acc: 0.6280\n",
      "val Loss: 0.8910 Acc: 0.6640\n",
      "test Loss: 0.8957 Acc: 0.6760\n",
      "Epoch 307/1499\n",
      "----------\n",
      "train Loss: 0.9032 Acc: 0.6229\n",
      "val Loss: 0.8905 Acc: 0.6560\n",
      "test Loss: 0.8978 Acc: 0.6800\n",
      "Epoch 308/1499\n",
      "----------\n",
      "train Loss: 0.8999 Acc: 0.6309\n",
      "val Loss: 0.8874 Acc: 0.6640\n",
      "test Loss: 0.8973 Acc: 0.6640\n",
      "Epoch 309/1499\n",
      "----------\n",
      "train Loss: 0.9001 Acc: 0.6318\n",
      "val Loss: 0.8870 Acc: 0.6760\n",
      "test Loss: 0.8914 Acc: 0.6720\n",
      "Epoch 310/1499\n",
      "----------\n",
      "train Loss: 0.8999 Acc: 0.6302\n",
      "val Loss: 0.8846 Acc: 0.6760\n",
      "test Loss: 0.8935 Acc: 0.6760\n",
      "Epoch 311/1499\n",
      "----------\n",
      "train Loss: 0.8988 Acc: 0.6329\n",
      "val Loss: 0.9053 Acc: 0.6560\n",
      "test Loss: 0.9025 Acc: 0.6480\n",
      "Epoch 312/1499\n",
      "----------\n",
      "train Loss: 0.9000 Acc: 0.6340\n",
      "val Loss: 0.8932 Acc: 0.6520\n",
      "test Loss: 0.9107 Acc: 0.6720\n",
      "Epoch 313/1499\n",
      "----------\n",
      "train Loss: 0.8975 Acc: 0.6342\n",
      "val Loss: 0.8910 Acc: 0.6600\n",
      "test Loss: 0.8880 Acc: 0.6800\n",
      "Epoch 314/1499\n",
      "----------\n",
      "train Loss: 0.8985 Acc: 0.6360\n",
      "val Loss: 0.8838 Acc: 0.6680\n",
      "test Loss: 0.8885 Acc: 0.6840\n",
      "Epoch 315/1499\n",
      "----------\n",
      "train Loss: 0.8967 Acc: 0.6438\n",
      "val Loss: 0.8877 Acc: 0.6720\n",
      "test Loss: 0.8913 Acc: 0.7040\n",
      "Epoch 316/1499\n",
      "----------\n",
      "train Loss: 0.8946 Acc: 0.6473\n",
      "val Loss: 0.8901 Acc: 0.6600\n",
      "test Loss: 0.8877 Acc: 0.6840\n",
      "Epoch 317/1499\n",
      "----------\n",
      "train Loss: 0.8951 Acc: 0.6453\n",
      "val Loss: 0.8854 Acc: 0.6920\n",
      "test Loss: 0.8859 Acc: 0.6960\n",
      "Epoch 318/1499\n",
      "----------\n",
      "train Loss: 0.8964 Acc: 0.6436\n",
      "val Loss: 0.8806 Acc: 0.6760\n",
      "test Loss: 0.8907 Acc: 0.6840\n",
      "Epoch 319/1499\n",
      "----------\n",
      "train Loss: 0.8937 Acc: 0.6493\n",
      "val Loss: 0.8815 Acc: 0.6800\n",
      "test Loss: 0.8885 Acc: 0.6920\n",
      "Epoch 320/1499\n",
      "----------\n",
      "train Loss: 0.8938 Acc: 0.6473\n",
      "val Loss: 0.8872 Acc: 0.6640\n",
      "test Loss: 0.8978 Acc: 0.6920\n",
      "Epoch 321/1499\n",
      "----------\n",
      "train Loss: 0.8911 Acc: 0.6524\n",
      "val Loss: 0.8850 Acc: 0.6720\n",
      "test Loss: 0.8771 Acc: 0.7280\n",
      "Epoch 322/1499\n",
      "----------\n",
      "train Loss: 0.8942 Acc: 0.6484\n",
      "val Loss: 0.8870 Acc: 0.6800\n",
      "test Loss: 0.8843 Acc: 0.7080\n",
      "Epoch 323/1499\n",
      "----------\n",
      "train Loss: 0.8917 Acc: 0.6549\n",
      "val Loss: 0.8803 Acc: 0.6760\n",
      "test Loss: 0.8923 Acc: 0.7000\n",
      "Epoch 324/1499\n",
      "----------\n",
      "train Loss: 0.8929 Acc: 0.6564\n",
      "val Loss: 0.8713 Acc: 0.6880\n",
      "test Loss: 0.8833 Acc: 0.7080\n",
      "Epoch 325/1499\n",
      "----------\n",
      "train Loss: 0.8933 Acc: 0.6498\n",
      "val Loss: 0.8771 Acc: 0.6880\n",
      "test Loss: 0.8790 Acc: 0.6800\n",
      "Epoch 326/1499\n",
      "----------\n",
      "train Loss: 0.8930 Acc: 0.6498\n",
      "val Loss: 0.8854 Acc: 0.6640\n",
      "test Loss: 0.8779 Acc: 0.7160\n",
      "Epoch 327/1499\n",
      "----------\n",
      "train Loss: 0.8924 Acc: 0.6484\n",
      "val Loss: 0.8741 Acc: 0.6960\n",
      "test Loss: 0.8790 Acc: 0.7040\n",
      "Epoch 328/1499\n",
      "----------\n",
      "train Loss: 0.8905 Acc: 0.6589\n",
      "val Loss: 0.8851 Acc: 0.6480\n",
      "test Loss: 0.8824 Acc: 0.7080\n",
      "Epoch 329/1499\n",
      "----------\n",
      "train Loss: 0.8912 Acc: 0.6522\n",
      "val Loss: 0.8773 Acc: 0.6760\n",
      "test Loss: 0.8853 Acc: 0.7040\n",
      "Epoch 330/1499\n",
      "----------\n",
      "train Loss: 0.8887 Acc: 0.6596\n",
      "val Loss: 0.8816 Acc: 0.6960\n",
      "test Loss: 0.8815 Acc: 0.7000\n",
      "Epoch 331/1499\n",
      "----------\n",
      "train Loss: 0.8875 Acc: 0.6622\n",
      "val Loss: 0.8721 Acc: 0.6880\n",
      "test Loss: 0.8799 Acc: 0.7080\n",
      "Epoch 332/1499\n",
      "----------\n",
      "train Loss: 0.8892 Acc: 0.6596\n",
      "val Loss: 0.8832 Acc: 0.6600\n",
      "test Loss: 0.8763 Acc: 0.7320\n",
      "Epoch 333/1499\n",
      "----------\n",
      "train Loss: 0.8869 Acc: 0.6678\n",
      "val Loss: 0.8818 Acc: 0.7040\n",
      "test Loss: 0.8850 Acc: 0.7080\n",
      "Epoch 334/1499\n",
      "----------\n",
      "train Loss: 0.8875 Acc: 0.6620\n",
      "val Loss: 0.8833 Acc: 0.6800\n",
      "test Loss: 0.8825 Acc: 0.7160\n",
      "Epoch 335/1499\n",
      "----------\n",
      "train Loss: 0.8861 Acc: 0.6693\n",
      "val Loss: 0.8685 Acc: 0.7000\n",
      "test Loss: 0.8715 Acc: 0.7240\n",
      "Epoch 336/1499\n",
      "----------\n",
      "train Loss: 0.8870 Acc: 0.6689\n",
      "val Loss: 0.8728 Acc: 0.6880\n",
      "test Loss: 0.8767 Acc: 0.7120\n",
      "Epoch 337/1499\n",
      "----------\n",
      "train Loss: 0.8846 Acc: 0.6742\n",
      "val Loss: 0.8706 Acc: 0.7040\n",
      "test Loss: 0.8756 Acc: 0.7200\n",
      "Epoch 338/1499\n",
      "----------\n",
      "train Loss: 0.8823 Acc: 0.6784\n",
      "val Loss: 0.8727 Acc: 0.6920\n",
      "test Loss: 0.8792 Acc: 0.7080\n",
      "Epoch 339/1499\n",
      "----------\n",
      "train Loss: 0.8848 Acc: 0.6760\n",
      "val Loss: 0.8765 Acc: 0.7120\n",
      "test Loss: 0.8750 Acc: 0.7240\n",
      "Epoch 340/1499\n",
      "----------\n",
      "train Loss: 0.8824 Acc: 0.6844\n",
      "val Loss: 0.8741 Acc: 0.6880\n",
      "test Loss: 0.8807 Acc: 0.7240\n",
      "Epoch 341/1499\n",
      "----------\n",
      "train Loss: 0.8829 Acc: 0.6811\n",
      "val Loss: 0.8822 Acc: 0.6600\n",
      "test Loss: 0.8714 Acc: 0.7200\n",
      "Epoch 342/1499\n",
      "----------\n",
      "train Loss: 0.8833 Acc: 0.6760\n",
      "val Loss: 0.8798 Acc: 0.6560\n",
      "test Loss: 0.8651 Acc: 0.7440\n",
      "Epoch 343/1499\n",
      "----------\n",
      "train Loss: 0.8846 Acc: 0.6816\n",
      "val Loss: 0.8781 Acc: 0.6760\n",
      "test Loss: 0.8651 Acc: 0.7440\n",
      "Epoch 344/1499\n",
      "----------\n",
      "train Loss: 0.8813 Acc: 0.6831\n",
      "val Loss: 0.8809 Acc: 0.6600\n",
      "test Loss: 0.8774 Acc: 0.7240\n",
      "Epoch 345/1499\n",
      "----------\n",
      "train Loss: 0.8846 Acc: 0.6782\n",
      "val Loss: 0.8740 Acc: 0.6760\n",
      "test Loss: 0.8700 Acc: 0.7280\n",
      "Epoch 346/1499\n",
      "----------\n",
      "train Loss: 0.8815 Acc: 0.6800\n",
      "val Loss: 0.8664 Acc: 0.6880\n",
      "test Loss: 0.8751 Acc: 0.7200\n",
      "Epoch 347/1499\n",
      "----------\n",
      "train Loss: 0.8775 Acc: 0.6942\n",
      "val Loss: 0.8647 Acc: 0.6920\n",
      "test Loss: 0.8780 Acc: 0.7280\n",
      "Epoch 348/1499\n",
      "----------\n",
      "train Loss: 0.8765 Acc: 0.6913\n",
      "val Loss: 0.8713 Acc: 0.6880\n",
      "test Loss: 0.8714 Acc: 0.7240\n",
      "Epoch 349/1499\n",
      "----------\n",
      "train Loss: 0.8793 Acc: 0.6893\n",
      "val Loss: 0.8836 Acc: 0.6560\n",
      "test Loss: 0.8739 Acc: 0.7320\n",
      "Epoch 350/1499\n",
      "----------\n",
      "train Loss: 0.8783 Acc: 0.6878\n",
      "val Loss: 0.8861 Acc: 0.6600\n",
      "test Loss: 0.8701 Acc: 0.7280\n",
      "Epoch 351/1499\n",
      "----------\n",
      "train Loss: 0.8775 Acc: 0.6924\n",
      "val Loss: 0.8691 Acc: 0.6960\n",
      "test Loss: 0.8757 Acc: 0.7200\n",
      "Epoch 352/1499\n",
      "----------\n",
      "train Loss: 0.8777 Acc: 0.6929\n",
      "val Loss: 0.8689 Acc: 0.6800\n",
      "test Loss: 0.8616 Acc: 0.7440\n",
      "Epoch 353/1499\n",
      "----------\n",
      "train Loss: 0.8782 Acc: 0.6953\n",
      "val Loss: 0.8756 Acc: 0.6760\n",
      "test Loss: 0.8661 Acc: 0.7560\n",
      "Epoch 354/1499\n",
      "----------\n",
      "train Loss: 0.8758 Acc: 0.7022\n",
      "val Loss: 0.8684 Acc: 0.6920\n",
      "test Loss: 0.8656 Acc: 0.7480\n",
      "Epoch 355/1499\n",
      "----------\n",
      "train Loss: 0.8739 Acc: 0.7049\n",
      "val Loss: 0.8642 Acc: 0.7000\n",
      "test Loss: 0.8612 Acc: 0.7440\n",
      "Epoch 356/1499\n",
      "----------\n",
      "train Loss: 0.8717 Acc: 0.7087\n",
      "val Loss: 0.8667 Acc: 0.6920\n",
      "test Loss: 0.8688 Acc: 0.7400\n",
      "Epoch 357/1499\n",
      "----------\n",
      "train Loss: 0.8713 Acc: 0.7082\n",
      "val Loss: 0.8705 Acc: 0.6840\n",
      "test Loss: 0.8769 Acc: 0.7120\n",
      "Epoch 358/1499\n",
      "----------\n",
      "train Loss: 0.8741 Acc: 0.7011\n",
      "val Loss: 0.8635 Acc: 0.7080\n",
      "test Loss: 0.8550 Acc: 0.7640\n",
      "Epoch 359/1499\n",
      "----------\n",
      "train Loss: 0.8759 Acc: 0.6984\n",
      "val Loss: 0.8568 Acc: 0.6920\n",
      "test Loss: 0.8720 Acc: 0.7240\n",
      "Epoch 360/1499\n",
      "----------\n",
      "train Loss: 0.8726 Acc: 0.7071\n",
      "val Loss: 0.8654 Acc: 0.6800\n",
      "test Loss: 0.8752 Acc: 0.7120\n",
      "Epoch 361/1499\n",
      "----------\n",
      "train Loss: 0.8695 Acc: 0.7060\n",
      "val Loss: 0.8636 Acc: 0.7000\n",
      "test Loss: 0.8656 Acc: 0.7320\n",
      "Epoch 362/1499\n",
      "----------\n",
      "train Loss: 0.8701 Acc: 0.7084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.8682 Acc: 0.6840\n",
      "test Loss: 0.8651 Acc: 0.7280\n",
      "Epoch 363/1499\n",
      "----------\n",
      "train Loss: 0.8692 Acc: 0.7058\n",
      "val Loss: 0.8650 Acc: 0.7040\n",
      "test Loss: 0.8681 Acc: 0.7200\n",
      "Epoch 364/1499\n",
      "----------\n",
      "train Loss: 0.8681 Acc: 0.7140\n",
      "val Loss: 0.8614 Acc: 0.7040\n",
      "test Loss: 0.8545 Acc: 0.7600\n",
      "Epoch 365/1499\n",
      "----------\n",
      "train Loss: 0.8718 Acc: 0.7082\n",
      "val Loss: 0.8665 Acc: 0.7000\n",
      "test Loss: 0.8691 Acc: 0.7200\n",
      "Epoch 366/1499\n",
      "----------\n",
      "train Loss: 0.8696 Acc: 0.7093\n",
      "val Loss: 0.8662 Acc: 0.6880\n",
      "test Loss: 0.8612 Acc: 0.7400\n",
      "Epoch 367/1499\n",
      "----------\n",
      "train Loss: 0.8684 Acc: 0.7167\n",
      "val Loss: 0.8557 Acc: 0.7120\n",
      "test Loss: 0.8820 Acc: 0.6960\n",
      "Epoch 368/1499\n",
      "----------\n",
      "train Loss: 0.8680 Acc: 0.7129\n",
      "val Loss: 0.8688 Acc: 0.6920\n",
      "test Loss: 0.8647 Acc: 0.7640\n",
      "Epoch 369/1499\n",
      "----------\n",
      "train Loss: 0.8705 Acc: 0.7109\n",
      "val Loss: 0.8733 Acc: 0.6760\n",
      "test Loss: 0.8560 Acc: 0.7440\n",
      "Epoch 370/1499\n",
      "----------\n",
      "train Loss: 0.8685 Acc: 0.7156\n",
      "val Loss: 0.8664 Acc: 0.6840\n",
      "test Loss: 0.8582 Acc: 0.7600\n",
      "Epoch 371/1499\n",
      "----------\n",
      "train Loss: 0.8702 Acc: 0.7158\n",
      "val Loss: 0.8610 Acc: 0.7040\n",
      "test Loss: 0.8594 Acc: 0.7520\n",
      "Epoch 372/1499\n",
      "----------\n",
      "train Loss: 0.8660 Acc: 0.7213\n",
      "val Loss: 0.8521 Acc: 0.7320\n",
      "test Loss: 0.8633 Acc: 0.7280\n",
      "Epoch 373/1499\n",
      "----------\n",
      "train Loss: 0.8657 Acc: 0.7164\n",
      "val Loss: 0.8639 Acc: 0.6960\n",
      "test Loss: 0.8587 Acc: 0.7680\n",
      "Epoch 374/1499\n",
      "----------\n",
      "train Loss: 0.8646 Acc: 0.7209\n",
      "val Loss: 0.8541 Acc: 0.7200\n",
      "test Loss: 0.8573 Acc: 0.7480\n",
      "Epoch 375/1499\n",
      "----------\n",
      "train Loss: 0.8705 Acc: 0.7131\n",
      "val Loss: 0.8484 Acc: 0.7280\n",
      "test Loss: 0.8531 Acc: 0.7600\n",
      "Epoch 376/1499\n",
      "----------\n",
      "train Loss: 0.8673 Acc: 0.7191\n",
      "val Loss: 0.8570 Acc: 0.7160\n",
      "test Loss: 0.8542 Acc: 0.7600\n",
      "Epoch 377/1499\n",
      "----------\n",
      "train Loss: 0.8626 Acc: 0.7296\n",
      "val Loss: 0.8580 Acc: 0.7120\n",
      "test Loss: 0.8663 Acc: 0.7280\n",
      "Epoch 378/1499\n",
      "----------\n",
      "train Loss: 0.8637 Acc: 0.7276\n",
      "val Loss: 0.8552 Acc: 0.7240\n",
      "test Loss: 0.8526 Acc: 0.7640\n",
      "Epoch 379/1499\n",
      "----------\n",
      "train Loss: 0.8634 Acc: 0.7262\n",
      "val Loss: 0.8557 Acc: 0.7200\n",
      "test Loss: 0.8508 Acc: 0.7480\n",
      "Epoch 380/1499\n",
      "----------\n",
      "train Loss: 0.8620 Acc: 0.7264\n",
      "val Loss: 0.8512 Acc: 0.7200\n",
      "test Loss: 0.8617 Acc: 0.7360\n",
      "Epoch 381/1499\n",
      "----------\n",
      "train Loss: 0.8649 Acc: 0.7236\n",
      "val Loss: 0.8563 Acc: 0.7080\n",
      "test Loss: 0.8450 Acc: 0.7720\n",
      "Epoch 382/1499\n",
      "----------\n",
      "train Loss: 0.8611 Acc: 0.7282\n",
      "val Loss: 0.8588 Acc: 0.7120\n",
      "test Loss: 0.8431 Acc: 0.8040\n",
      "Epoch 383/1499\n",
      "----------\n",
      "train Loss: 0.8612 Acc: 0.7302\n",
      "val Loss: 0.8525 Acc: 0.7240\n",
      "test Loss: 0.8569 Acc: 0.7600\n",
      "Epoch 384/1499\n",
      "----------\n",
      "train Loss: 0.8577 Acc: 0.7422\n",
      "val Loss: 0.8604 Acc: 0.6960\n",
      "test Loss: 0.8650 Acc: 0.7480\n",
      "Epoch 385/1499\n",
      "----------\n",
      "train Loss: 0.8605 Acc: 0.7333\n",
      "val Loss: 0.8506 Acc: 0.7280\n",
      "test Loss: 0.8709 Acc: 0.7280\n",
      "Epoch 386/1499\n",
      "----------\n",
      "train Loss: 0.8603 Acc: 0.7369\n",
      "val Loss: 0.8493 Acc: 0.7360\n",
      "test Loss: 0.8466 Acc: 0.7880\n",
      "Epoch 387/1499\n",
      "----------\n",
      "train Loss: 0.8597 Acc: 0.7340\n",
      "val Loss: 0.8512 Acc: 0.7240\n",
      "test Loss: 0.8590 Acc: 0.7480\n",
      "Epoch 388/1499\n",
      "----------\n",
      "train Loss: 0.8605 Acc: 0.7387\n",
      "val Loss: 0.8514 Acc: 0.7280\n",
      "test Loss: 0.8500 Acc: 0.7880\n",
      "Epoch 389/1499\n",
      "----------\n",
      "train Loss: 0.8542 Acc: 0.7451\n",
      "val Loss: 0.8508 Acc: 0.7240\n",
      "test Loss: 0.8417 Acc: 0.7800\n",
      "Epoch 390/1499\n",
      "----------\n",
      "train Loss: 0.8572 Acc: 0.7458\n",
      "val Loss: 0.8503 Acc: 0.7240\n",
      "test Loss: 0.8436 Acc: 0.7880\n",
      "Epoch 391/1499\n",
      "----------\n",
      "train Loss: 0.8566 Acc: 0.7411\n",
      "val Loss: 0.8490 Acc: 0.7200\n",
      "test Loss: 0.8578 Acc: 0.7440\n",
      "Epoch 392/1499\n",
      "----------\n",
      "train Loss: 0.8577 Acc: 0.7418\n",
      "val Loss: 0.8516 Acc: 0.7320\n",
      "test Loss: 0.8455 Acc: 0.7720\n",
      "Epoch 393/1499\n",
      "----------\n",
      "train Loss: 0.8555 Acc: 0.7442\n",
      "val Loss: 0.8498 Acc: 0.7280\n",
      "test Loss: 0.8434 Acc: 0.7800\n",
      "Epoch 394/1499\n",
      "----------\n",
      "train Loss: 0.8565 Acc: 0.7422\n",
      "val Loss: 0.8586 Acc: 0.6960\n",
      "test Loss: 0.8602 Acc: 0.7600\n",
      "Epoch 395/1499\n",
      "----------\n",
      "train Loss: 0.8560 Acc: 0.7424\n",
      "val Loss: 0.8515 Acc: 0.7240\n",
      "test Loss: 0.8634 Acc: 0.7480\n",
      "Epoch 396/1499\n",
      "----------\n",
      "train Loss: 0.8561 Acc: 0.7398\n",
      "val Loss: 0.8540 Acc: 0.7280\n",
      "test Loss: 0.8353 Acc: 0.7840\n",
      "Epoch 397/1499\n",
      "----------\n",
      "train Loss: 0.8557 Acc: 0.7458\n",
      "val Loss: 0.8396 Acc: 0.7400\n",
      "test Loss: 0.8484 Acc: 0.7800\n",
      "Epoch 398/1499\n",
      "----------\n",
      "train Loss: 0.8526 Acc: 0.7467\n",
      "val Loss: 0.8497 Acc: 0.7080\n",
      "test Loss: 0.8406 Acc: 0.7840\n",
      "Epoch 399/1499\n",
      "----------\n",
      "train Loss: 0.8506 Acc: 0.7540\n",
      "val Loss: 0.8548 Acc: 0.7160\n",
      "test Loss: 0.8406 Acc: 0.7880\n",
      "Epoch 400/1499\n",
      "----------\n",
      "train Loss: 0.8527 Acc: 0.7458\n",
      "val Loss: 0.8536 Acc: 0.7280\n",
      "test Loss: 0.8491 Acc: 0.7800\n",
      "Epoch 401/1499\n",
      "----------\n",
      "train Loss: 0.8517 Acc: 0.7507\n",
      "val Loss: 0.8656 Acc: 0.6960\n",
      "test Loss: 0.8560 Acc: 0.7640\n",
      "Epoch 402/1499\n",
      "----------\n",
      "train Loss: 0.8485 Acc: 0.7540\n",
      "val Loss: 0.8519 Acc: 0.7280\n",
      "test Loss: 0.8459 Acc: 0.7920\n",
      "Epoch 403/1499\n",
      "----------\n",
      "train Loss: 0.8492 Acc: 0.7524\n",
      "val Loss: 0.8471 Acc: 0.7240\n",
      "test Loss: 0.8391 Acc: 0.7920\n",
      "Epoch 404/1499\n",
      "----------\n",
      "train Loss: 0.8513 Acc: 0.7507\n",
      "val Loss: 0.8562 Acc: 0.7040\n",
      "test Loss: 0.8506 Acc: 0.7640\n",
      "Epoch 405/1499\n",
      "----------\n",
      "train Loss: 0.8494 Acc: 0.7576\n",
      "val Loss: 0.8411 Acc: 0.7360\n",
      "test Loss: 0.8526 Acc: 0.7680\n",
      "Epoch 406/1499\n",
      "----------\n",
      "train Loss: 0.8504 Acc: 0.7500\n",
      "val Loss: 0.8305 Acc: 0.7560\n",
      "test Loss: 0.8350 Acc: 0.7960\n",
      "Epoch 407/1499\n",
      "----------\n",
      "train Loss: 0.8455 Acc: 0.7622\n",
      "val Loss: 0.8429 Acc: 0.7160\n",
      "test Loss: 0.8500 Acc: 0.7880\n",
      "Epoch 408/1499\n",
      "----------\n",
      "train Loss: 0.8471 Acc: 0.7576\n",
      "val Loss: 0.8378 Acc: 0.7320\n",
      "test Loss: 0.8416 Acc: 0.7920\n",
      "Epoch 409/1499\n",
      "----------\n",
      "train Loss: 0.8457 Acc: 0.7613\n",
      "val Loss: 0.8451 Acc: 0.7280\n",
      "test Loss: 0.8439 Acc: 0.7840\n",
      "Epoch 410/1499\n",
      "----------\n",
      "train Loss: 0.8500 Acc: 0.7551\n",
      "val Loss: 0.8604 Acc: 0.7080\n",
      "test Loss: 0.8410 Acc: 0.8000\n",
      "Epoch 411/1499\n",
      "----------\n",
      "train Loss: 0.8472 Acc: 0.7591\n",
      "val Loss: 0.8448 Acc: 0.7240\n",
      "test Loss: 0.8392 Acc: 0.7960\n",
      "Epoch 412/1499\n",
      "----------\n",
      "train Loss: 0.8462 Acc: 0.7560\n",
      "val Loss: 0.8428 Acc: 0.7440\n",
      "test Loss: 0.8487 Acc: 0.7720\n",
      "Epoch 413/1499\n",
      "----------\n",
      "train Loss: 0.8470 Acc: 0.7600\n",
      "val Loss: 0.8389 Acc: 0.7440\n",
      "test Loss: 0.8395 Acc: 0.8040\n",
      "Epoch 414/1499\n",
      "----------\n",
      "train Loss: 0.8470 Acc: 0.7591\n",
      "val Loss: 0.8459 Acc: 0.7480\n",
      "test Loss: 0.8272 Acc: 0.8240\n",
      "Epoch 415/1499\n",
      "----------\n",
      "train Loss: 0.8455 Acc: 0.7607\n",
      "val Loss: 0.8400 Acc: 0.7400\n",
      "test Loss: 0.8522 Acc: 0.7600\n",
      "Epoch 416/1499\n",
      "----------\n",
      "train Loss: 0.8427 Acc: 0.7649\n",
      "val Loss: 0.8446 Acc: 0.7240\n",
      "test Loss: 0.8369 Acc: 0.8000\n",
      "Epoch 417/1499\n",
      "----------\n",
      "train Loss: 0.8462 Acc: 0.7598\n",
      "val Loss: 0.8381 Acc: 0.7320\n",
      "test Loss: 0.8402 Acc: 0.7960\n",
      "Epoch 418/1499\n",
      "----------\n",
      "train Loss: 0.8428 Acc: 0.7653\n",
      "val Loss: 0.8304 Acc: 0.7600\n",
      "test Loss: 0.8393 Acc: 0.8000\n",
      "Epoch 419/1499\n",
      "----------\n",
      "train Loss: 0.8414 Acc: 0.7680\n",
      "val Loss: 0.8459 Acc: 0.7360\n",
      "test Loss: 0.8434 Acc: 0.7920\n",
      "Epoch 420/1499\n",
      "----------\n",
      "train Loss: 0.8427 Acc: 0.7673\n",
      "val Loss: 0.8393 Acc: 0.7240\n",
      "test Loss: 0.8316 Acc: 0.8200\n",
      "Epoch 421/1499\n",
      "----------\n",
      "train Loss: 0.8421 Acc: 0.7733\n",
      "val Loss: 0.8536 Acc: 0.7160\n",
      "test Loss: 0.8356 Acc: 0.8280\n",
      "Epoch 422/1499\n",
      "----------\n",
      "train Loss: 0.8440 Acc: 0.7647\n",
      "val Loss: 0.8428 Acc: 0.7280\n",
      "test Loss: 0.8412 Acc: 0.7840\n",
      "Epoch 423/1499\n",
      "----------\n",
      "train Loss: 0.8418 Acc: 0.7671\n",
      "val Loss: 0.8301 Acc: 0.7560\n",
      "test Loss: 0.8416 Acc: 0.7960\n",
      "Epoch 424/1499\n",
      "----------\n",
      "train Loss: 0.8409 Acc: 0.7678\n",
      "val Loss: 0.8346 Acc: 0.7360\n",
      "test Loss: 0.8347 Acc: 0.7880\n",
      "Epoch 425/1499\n",
      "----------\n",
      "train Loss: 0.8383 Acc: 0.7744\n",
      "val Loss: 0.8293 Acc: 0.7520\n",
      "test Loss: 0.8382 Acc: 0.8160\n",
      "Epoch 426/1499\n",
      "----------\n",
      "train Loss: 0.8415 Acc: 0.7671\n",
      "val Loss: 0.8400 Acc: 0.7320\n",
      "test Loss: 0.8327 Acc: 0.8080\n",
      "Epoch 427/1499\n",
      "----------\n",
      "train Loss: 0.8393 Acc: 0.7700\n",
      "val Loss: 0.8341 Acc: 0.7360\n",
      "test Loss: 0.8427 Acc: 0.8080\n",
      "Epoch 428/1499\n",
      "----------\n",
      "train Loss: 0.8415 Acc: 0.7687\n",
      "val Loss: 0.8441 Acc: 0.7520\n",
      "test Loss: 0.8358 Acc: 0.8080\n",
      "Epoch 429/1499\n",
      "----------\n",
      "train Loss: 0.8376 Acc: 0.7738\n",
      "val Loss: 0.8467 Acc: 0.7320\n",
      "test Loss: 0.8326 Acc: 0.8160\n",
      "Epoch 430/1499\n",
      "----------\n",
      "train Loss: 0.8395 Acc: 0.7742\n",
      "val Loss: 0.8278 Acc: 0.7640\n",
      "test Loss: 0.8292 Acc: 0.8160\n",
      "Epoch 431/1499\n",
      "----------\n",
      "train Loss: 0.8385 Acc: 0.7753\n",
      "val Loss: 0.8425 Acc: 0.7400\n",
      "test Loss: 0.8338 Acc: 0.8080\n",
      "Epoch 432/1499\n",
      "----------\n",
      "train Loss: 0.8378 Acc: 0.7756\n",
      "val Loss: 0.8393 Acc: 0.7560\n",
      "test Loss: 0.8310 Acc: 0.8120\n",
      "Epoch 433/1499\n",
      "----------\n",
      "train Loss: 0.8379 Acc: 0.7782\n",
      "val Loss: 0.8323 Acc: 0.7560\n",
      "test Loss: 0.8296 Acc: 0.8320\n",
      "Epoch 434/1499\n",
      "----------\n",
      "train Loss: 0.8385 Acc: 0.7767\n",
      "val Loss: 0.8287 Acc: 0.7680\n",
      "test Loss: 0.8236 Acc: 0.8280\n",
      "Epoch 435/1499\n",
      "----------\n",
      "train Loss: 0.8364 Acc: 0.7813\n",
      "val Loss: 0.8385 Acc: 0.7280\n",
      "test Loss: 0.8304 Acc: 0.8200\n",
      "Epoch 436/1499\n",
      "----------\n",
      "train Loss: 0.8348 Acc: 0.7751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.8376 Acc: 0.7360\n",
      "test Loss: 0.8328 Acc: 0.8160\n",
      "Epoch 437/1499\n",
      "----------\n",
      "train Loss: 0.8352 Acc: 0.7816\n",
      "val Loss: 0.8253 Acc: 0.7640\n",
      "test Loss: 0.8386 Acc: 0.7960\n",
      "Epoch 438/1499\n",
      "----------\n",
      "train Loss: 0.8347 Acc: 0.7809\n",
      "val Loss: 0.8234 Acc: 0.7680\n",
      "test Loss: 0.8298 Acc: 0.8360\n",
      "Epoch 439/1499\n",
      "----------\n",
      "train Loss: 0.8347 Acc: 0.7798\n",
      "val Loss: 0.8487 Acc: 0.7360\n",
      "test Loss: 0.8373 Acc: 0.7960\n",
      "Epoch 440/1499\n",
      "----------\n",
      "train Loss: 0.8349 Acc: 0.7811\n",
      "val Loss: 0.8262 Acc: 0.7720\n",
      "test Loss: 0.8331 Acc: 0.8160\n",
      "Epoch 441/1499\n",
      "----------\n",
      "train Loss: 0.8330 Acc: 0.7791\n",
      "val Loss: 0.8340 Acc: 0.7640\n",
      "test Loss: 0.8312 Acc: 0.8120\n",
      "Epoch 442/1499\n",
      "----------\n",
      "train Loss: 0.8348 Acc: 0.7793\n",
      "val Loss: 0.8319 Acc: 0.7640\n",
      "test Loss: 0.8231 Acc: 0.8280\n",
      "Epoch 443/1499\n",
      "----------\n",
      "train Loss: 0.8296 Acc: 0.7904\n",
      "val Loss: 0.8314 Acc: 0.7600\n",
      "test Loss: 0.8260 Acc: 0.8200\n",
      "Epoch 444/1499\n",
      "----------\n",
      "train Loss: 0.8313 Acc: 0.7827\n",
      "val Loss: 0.8275 Acc: 0.7600\n",
      "test Loss: 0.8227 Acc: 0.8200\n",
      "Epoch 445/1499\n",
      "----------\n",
      "train Loss: 0.8327 Acc: 0.7818\n",
      "val Loss: 0.8261 Acc: 0.7800\n",
      "test Loss: 0.8319 Acc: 0.8120\n",
      "Epoch 446/1499\n",
      "----------\n",
      "train Loss: 0.8302 Acc: 0.7849\n",
      "val Loss: 0.8439 Acc: 0.7360\n",
      "test Loss: 0.8319 Acc: 0.8080\n",
      "Epoch 447/1499\n",
      "----------\n",
      "train Loss: 0.8298 Acc: 0.7891\n",
      "val Loss: 0.8372 Acc: 0.7480\n",
      "test Loss: 0.8221 Acc: 0.8200\n",
      "Epoch 448/1499\n",
      "----------\n",
      "train Loss: 0.8292 Acc: 0.7907\n",
      "val Loss: 0.8192 Acc: 0.7680\n",
      "test Loss: 0.8377 Acc: 0.7960\n",
      "Epoch 449/1499\n",
      "----------\n",
      "train Loss: 0.8296 Acc: 0.7856\n",
      "val Loss: 0.8381 Acc: 0.7440\n",
      "test Loss: 0.8199 Acc: 0.8360\n",
      "Epoch 450/1499\n",
      "----------\n",
      "train Loss: 0.8315 Acc: 0.7831\n",
      "val Loss: 0.8309 Acc: 0.7680\n",
      "test Loss: 0.8310 Acc: 0.8000\n",
      "Epoch 451/1499\n",
      "----------\n",
      "train Loss: 0.8291 Acc: 0.7858\n",
      "val Loss: 0.8277 Acc: 0.7600\n",
      "test Loss: 0.8259 Acc: 0.8240\n",
      "Epoch 452/1499\n",
      "----------\n",
      "train Loss: 0.8267 Acc: 0.7927\n",
      "val Loss: 0.8214 Acc: 0.7720\n",
      "test Loss: 0.8261 Acc: 0.8200\n",
      "Epoch 453/1499\n",
      "----------\n",
      "train Loss: 0.8272 Acc: 0.7864\n",
      "val Loss: 0.8345 Acc: 0.7640\n",
      "test Loss: 0.8278 Acc: 0.8080\n",
      "Epoch 454/1499\n",
      "----------\n",
      "train Loss: 0.8297 Acc: 0.7867\n",
      "val Loss: 0.8276 Acc: 0.7600\n",
      "test Loss: 0.8160 Acc: 0.8160\n",
      "Epoch 455/1499\n",
      "----------\n",
      "train Loss: 0.8263 Acc: 0.7900\n",
      "val Loss: 0.8201 Acc: 0.7760\n",
      "test Loss: 0.8287 Acc: 0.8000\n",
      "Epoch 456/1499\n",
      "----------\n",
      "train Loss: 0.8251 Acc: 0.7907\n",
      "val Loss: 0.8150 Acc: 0.7680\n",
      "test Loss: 0.8294 Acc: 0.8000\n",
      "Epoch 457/1499\n",
      "----------\n",
      "train Loss: 0.8280 Acc: 0.7884\n",
      "val Loss: 0.8144 Acc: 0.8000\n",
      "test Loss: 0.8207 Acc: 0.8160\n",
      "Epoch 458/1499\n",
      "----------\n",
      "train Loss: 0.8269 Acc: 0.7909\n",
      "val Loss: 0.8130 Acc: 0.8000\n",
      "test Loss: 0.8181 Acc: 0.8080\n",
      "Epoch 459/1499\n",
      "----------\n",
      "train Loss: 0.8261 Acc: 0.7916\n",
      "val Loss: 0.8317 Acc: 0.7600\n",
      "test Loss: 0.8235 Acc: 0.8160\n",
      "Epoch 460/1499\n",
      "----------\n",
      "train Loss: 0.8216 Acc: 0.7980\n",
      "val Loss: 0.8284 Acc: 0.7480\n",
      "test Loss: 0.8149 Acc: 0.8080\n",
      "Epoch 461/1499\n",
      "----------\n",
      "train Loss: 0.8249 Acc: 0.7916\n",
      "val Loss: 0.8209 Acc: 0.7600\n",
      "test Loss: 0.8166 Acc: 0.8120\n",
      "Epoch 462/1499\n",
      "----------\n",
      "train Loss: 0.8260 Acc: 0.7933\n",
      "val Loss: 0.8340 Acc: 0.7520\n",
      "test Loss: 0.8294 Acc: 0.8040\n",
      "Epoch 463/1499\n",
      "----------\n",
      "train Loss: 0.8217 Acc: 0.7962\n",
      "val Loss: 0.8216 Acc: 0.7880\n",
      "test Loss: 0.8223 Acc: 0.8120\n",
      "Epoch 464/1499\n",
      "----------\n",
      "train Loss: 0.8241 Acc: 0.7933\n",
      "val Loss: 0.8182 Acc: 0.7840\n",
      "test Loss: 0.8227 Acc: 0.8200\n",
      "Epoch 465/1499\n",
      "----------\n",
      "train Loss: 0.8242 Acc: 0.7907\n",
      "val Loss: 0.8087 Acc: 0.7920\n",
      "test Loss: 0.8313 Acc: 0.8040\n",
      "Epoch 466/1499\n",
      "----------\n",
      "train Loss: 0.8186 Acc: 0.7989\n",
      "val Loss: 0.8146 Acc: 0.7800\n",
      "test Loss: 0.8197 Acc: 0.8080\n",
      "Epoch 467/1499\n",
      "----------\n",
      "train Loss: 0.8219 Acc: 0.7933\n",
      "val Loss: 0.8166 Acc: 0.7800\n",
      "test Loss: 0.8050 Acc: 0.8320\n",
      "Epoch 468/1499\n",
      "----------\n",
      "train Loss: 0.8231 Acc: 0.7922\n",
      "val Loss: 0.8275 Acc: 0.7560\n",
      "test Loss: 0.8132 Acc: 0.8240\n",
      "Epoch 469/1499\n",
      "----------\n",
      "train Loss: 0.8208 Acc: 0.8009\n",
      "val Loss: 0.8187 Acc: 0.7800\n",
      "test Loss: 0.8041 Acc: 0.8320\n",
      "Epoch 470/1499\n",
      "----------\n",
      "train Loss: 0.8220 Acc: 0.7940\n",
      "val Loss: 0.8236 Acc: 0.7680\n",
      "test Loss: 0.8140 Acc: 0.8360\n",
      "Epoch 471/1499\n",
      "----------\n",
      "train Loss: 0.8208 Acc: 0.7936\n",
      "val Loss: 0.8265 Acc: 0.7720\n",
      "test Loss: 0.8185 Acc: 0.8240\n",
      "Epoch 472/1499\n",
      "----------\n",
      "train Loss: 0.8212 Acc: 0.7922\n",
      "val Loss: 0.8127 Acc: 0.7880\n",
      "test Loss: 0.8092 Acc: 0.8320\n",
      "Epoch 473/1499\n",
      "----------\n",
      "train Loss: 0.8195 Acc: 0.7971\n",
      "val Loss: 0.8239 Acc: 0.7680\n",
      "test Loss: 0.8180 Acc: 0.8240\n",
      "Epoch 474/1499\n",
      "----------\n",
      "train Loss: 0.8224 Acc: 0.7920\n",
      "val Loss: 0.8159 Acc: 0.7880\n",
      "test Loss: 0.8171 Acc: 0.8240\n",
      "Epoch 475/1499\n",
      "----------\n",
      "train Loss: 0.8188 Acc: 0.7956\n",
      "val Loss: 0.8250 Acc: 0.7720\n",
      "test Loss: 0.8169 Acc: 0.8280\n",
      "Epoch 476/1499\n",
      "----------\n",
      "train Loss: 0.8164 Acc: 0.8049\n",
      "val Loss: 0.8152 Acc: 0.7800\n",
      "test Loss: 0.8180 Acc: 0.8240\n",
      "Epoch 477/1499\n",
      "----------\n",
      "train Loss: 0.8176 Acc: 0.7998\n",
      "val Loss: 0.8206 Acc: 0.7800\n",
      "test Loss: 0.8085 Acc: 0.8400\n",
      "Epoch 478/1499\n",
      "----------\n",
      "train Loss: 0.8156 Acc: 0.8020\n",
      "val Loss: 0.8162 Acc: 0.7760\n",
      "test Loss: 0.8140 Acc: 0.8200\n",
      "Epoch 479/1499\n",
      "----------\n",
      "train Loss: 0.8156 Acc: 0.8040\n",
      "val Loss: 0.8062 Acc: 0.7960\n",
      "test Loss: 0.8106 Acc: 0.8320\n",
      "Epoch 480/1499\n",
      "----------\n",
      "train Loss: 0.8201 Acc: 0.7967\n",
      "val Loss: 0.8241 Acc: 0.7760\n",
      "test Loss: 0.8028 Acc: 0.8480\n",
      "Epoch 481/1499\n",
      "----------\n",
      "train Loss: 0.8141 Acc: 0.8038\n",
      "val Loss: 0.8043 Acc: 0.8080\n",
      "test Loss: 0.8027 Acc: 0.8360\n",
      "Epoch 482/1499\n",
      "----------\n",
      "train Loss: 0.8161 Acc: 0.8053\n",
      "val Loss: 0.8270 Acc: 0.7600\n",
      "test Loss: 0.8127 Acc: 0.8200\n",
      "Epoch 483/1499\n",
      "----------\n",
      "train Loss: 0.8162 Acc: 0.7973\n",
      "val Loss: 0.8033 Acc: 0.7960\n",
      "test Loss: 0.8060 Acc: 0.8320\n",
      "Epoch 484/1499\n",
      "----------\n",
      "train Loss: 0.8165 Acc: 0.7989\n",
      "val Loss: 0.8127 Acc: 0.7760\n",
      "test Loss: 0.8129 Acc: 0.8280\n",
      "Epoch 485/1499\n",
      "----------\n",
      "train Loss: 0.8124 Acc: 0.8064\n",
      "val Loss: 0.8167 Acc: 0.7880\n",
      "test Loss: 0.8074 Acc: 0.8280\n",
      "Epoch 486/1499\n",
      "----------\n",
      "train Loss: 0.8142 Acc: 0.8031\n",
      "val Loss: 0.8062 Acc: 0.8000\n",
      "test Loss: 0.8253 Acc: 0.8000\n",
      "Epoch 487/1499\n",
      "----------\n",
      "train Loss: 0.8133 Acc: 0.8038\n",
      "val Loss: 0.8238 Acc: 0.7880\n",
      "test Loss: 0.7997 Acc: 0.8360\n",
      "Epoch 488/1499\n",
      "----------\n",
      "train Loss: 0.8146 Acc: 0.8000\n",
      "val Loss: 0.8182 Acc: 0.7840\n",
      "test Loss: 0.8141 Acc: 0.8200\n",
      "Epoch 489/1499\n",
      "----------\n",
      "train Loss: 0.8121 Acc: 0.8042\n",
      "val Loss: 0.8132 Acc: 0.7920\n",
      "test Loss: 0.7954 Acc: 0.8440\n",
      "Epoch 490/1499\n",
      "----------\n",
      "train Loss: 0.8133 Acc: 0.8029\n",
      "val Loss: 0.8016 Acc: 0.7960\n",
      "test Loss: 0.8016 Acc: 0.8400\n",
      "Epoch 491/1499\n",
      "----------\n",
      "train Loss: 0.8140 Acc: 0.8024\n",
      "val Loss: 0.8090 Acc: 0.7920\n",
      "test Loss: 0.8020 Acc: 0.8360\n",
      "Epoch 492/1499\n",
      "----------\n",
      "train Loss: 0.8126 Acc: 0.8024\n",
      "val Loss: 0.8084 Acc: 0.7920\n",
      "test Loss: 0.8055 Acc: 0.8320\n",
      "Epoch 493/1499\n",
      "----------\n",
      "train Loss: 0.8127 Acc: 0.8022\n",
      "val Loss: 0.8167 Acc: 0.7920\n",
      "test Loss: 0.8138 Acc: 0.8200\n",
      "Epoch 494/1499\n",
      "----------\n",
      "train Loss: 0.8080 Acc: 0.8071\n",
      "val Loss: 0.8126 Acc: 0.8000\n",
      "test Loss: 0.8223 Acc: 0.8080\n",
      "Epoch 495/1499\n",
      "----------\n",
      "train Loss: 0.8095 Acc: 0.8076\n",
      "val Loss: 0.8141 Acc: 0.7840\n",
      "test Loss: 0.8164 Acc: 0.8120\n",
      "Epoch 496/1499\n",
      "----------\n",
      "train Loss: 0.8107 Acc: 0.8031\n",
      "val Loss: 0.8098 Acc: 0.7880\n",
      "test Loss: 0.8050 Acc: 0.8240\n",
      "Epoch 497/1499\n",
      "----------\n",
      "train Loss: 0.8133 Acc: 0.8002\n",
      "val Loss: 0.8118 Acc: 0.7920\n",
      "test Loss: 0.7982 Acc: 0.8440\n",
      "Epoch 498/1499\n",
      "----------\n",
      "train Loss: 0.8093 Acc: 0.8033\n",
      "val Loss: 0.8132 Acc: 0.7800\n",
      "test Loss: 0.7976 Acc: 0.8400\n",
      "Epoch 499/1499\n",
      "----------\n",
      "train Loss: 0.8086 Acc: 0.8036\n",
      "val Loss: 0.8033 Acc: 0.7960\n",
      "test Loss: 0.8126 Acc: 0.8160\n",
      "Epoch 500/1499\n",
      "----------\n",
      "train Loss: 0.8111 Acc: 0.8020\n",
      "val Loss: 0.8192 Acc: 0.7760\n",
      "test Loss: 0.7988 Acc: 0.8280\n",
      "Epoch 501/1499\n",
      "----------\n",
      "train Loss: 0.8090 Acc: 0.8033\n",
      "val Loss: 0.8111 Acc: 0.7760\n",
      "test Loss: 0.7987 Acc: 0.8240\n",
      "Epoch 502/1499\n",
      "----------\n",
      "train Loss: 0.8059 Acc: 0.8107\n",
      "val Loss: 0.8165 Acc: 0.7920\n",
      "test Loss: 0.8071 Acc: 0.8080\n",
      "Epoch 503/1499\n",
      "----------\n",
      "train Loss: 0.8099 Acc: 0.8047\n",
      "val Loss: 0.8087 Acc: 0.7920\n",
      "test Loss: 0.7999 Acc: 0.8440\n",
      "Epoch 504/1499\n",
      "----------\n",
      "train Loss: 0.8080 Acc: 0.8067\n",
      "val Loss: 0.8078 Acc: 0.7960\n",
      "test Loss: 0.7860 Acc: 0.8560\n",
      "Epoch 505/1499\n",
      "----------\n",
      "train Loss: 0.8085 Acc: 0.8047\n",
      "val Loss: 0.7996 Acc: 0.8040\n",
      "test Loss: 0.8044 Acc: 0.8160\n",
      "Epoch 506/1499\n",
      "----------\n",
      "train Loss: 0.8048 Acc: 0.8096\n",
      "val Loss: 0.7978 Acc: 0.8160\n",
      "test Loss: 0.8136 Acc: 0.8120\n",
      "Epoch 507/1499\n",
      "----------\n",
      "train Loss: 0.8084 Acc: 0.8064\n",
      "val Loss: 0.8036 Acc: 0.8040\n",
      "test Loss: 0.8086 Acc: 0.8280\n",
      "Epoch 508/1499\n",
      "----------\n",
      "train Loss: 0.8046 Acc: 0.8111\n",
      "val Loss: 0.8134 Acc: 0.7720\n",
      "test Loss: 0.7940 Acc: 0.8440\n",
      "Epoch 509/1499\n",
      "----------\n",
      "train Loss: 0.8085 Acc: 0.8033\n",
      "val Loss: 0.8011 Acc: 0.8160\n",
      "test Loss: 0.8115 Acc: 0.8160\n",
      "Epoch 510/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.8076 Acc: 0.8058\n",
      "val Loss: 0.8013 Acc: 0.8000\n",
      "test Loss: 0.7941 Acc: 0.8480\n",
      "Epoch 511/1499\n",
      "----------\n",
      "train Loss: 0.8043 Acc: 0.8062\n",
      "val Loss: 0.8117 Acc: 0.7760\n",
      "test Loss: 0.8121 Acc: 0.8120\n",
      "Epoch 512/1499\n",
      "----------\n",
      "train Loss: 0.8054 Acc: 0.8060\n",
      "val Loss: 0.8152 Acc: 0.7840\n",
      "test Loss: 0.8070 Acc: 0.8200\n",
      "Epoch 513/1499\n",
      "----------\n",
      "train Loss: 0.8025 Acc: 0.8089\n",
      "val Loss: 0.8100 Acc: 0.7960\n",
      "test Loss: 0.7908 Acc: 0.8480\n",
      "Epoch 514/1499\n",
      "----------\n",
      "train Loss: 0.8011 Acc: 0.8096\n",
      "val Loss: 0.8018 Acc: 0.7960\n",
      "test Loss: 0.8201 Acc: 0.7920\n",
      "Epoch 515/1499\n",
      "----------\n",
      "train Loss: 0.8026 Acc: 0.8089\n",
      "val Loss: 0.8139 Acc: 0.7720\n",
      "test Loss: 0.7922 Acc: 0.8320\n",
      "Epoch 516/1499\n",
      "----------\n",
      "train Loss: 0.8055 Acc: 0.8047\n",
      "val Loss: 0.8008 Acc: 0.8080\n",
      "test Loss: 0.8127 Acc: 0.7960\n",
      "Epoch 517/1499\n",
      "----------\n",
      "train Loss: 0.8029 Acc: 0.8080\n",
      "val Loss: 0.7966 Acc: 0.8120\n",
      "test Loss: 0.8004 Acc: 0.8120\n",
      "Epoch 518/1499\n",
      "----------\n",
      "train Loss: 0.8020 Acc: 0.8133\n",
      "val Loss: 0.8136 Acc: 0.7800\n",
      "test Loss: 0.7979 Acc: 0.8240\n",
      "Epoch 519/1499\n",
      "----------\n",
      "train Loss: 0.7998 Acc: 0.8138\n",
      "val Loss: 0.8010 Acc: 0.8040\n",
      "test Loss: 0.7915 Acc: 0.8400\n",
      "Epoch 520/1499\n",
      "----------\n",
      "train Loss: 0.8007 Acc: 0.8111\n",
      "val Loss: 0.8065 Acc: 0.7760\n",
      "test Loss: 0.7889 Acc: 0.8440\n",
      "Epoch 521/1499\n",
      "----------\n",
      "train Loss: 0.7989 Acc: 0.8118\n",
      "val Loss: 0.7990 Acc: 0.8000\n",
      "test Loss: 0.8009 Acc: 0.8240\n",
      "Epoch 522/1499\n",
      "----------\n",
      "train Loss: 0.8014 Acc: 0.8084\n",
      "val Loss: 0.8035 Acc: 0.7920\n",
      "test Loss: 0.7968 Acc: 0.8200\n",
      "Epoch 523/1499\n",
      "----------\n",
      "train Loss: 0.7998 Acc: 0.8127\n",
      "val Loss: 0.7999 Acc: 0.7960\n",
      "test Loss: 0.7815 Acc: 0.8640\n",
      "Epoch 524/1499\n",
      "----------\n",
      "train Loss: 0.7984 Acc: 0.8151\n",
      "val Loss: 0.7943 Acc: 0.8200\n",
      "test Loss: 0.7895 Acc: 0.8440\n",
      "Epoch 525/1499\n",
      "----------\n",
      "train Loss: 0.8009 Acc: 0.8129\n",
      "val Loss: 0.8021 Acc: 0.7920\n",
      "test Loss: 0.7994 Acc: 0.8200\n",
      "Epoch 526/1499\n",
      "----------\n",
      "train Loss: 0.7985 Acc: 0.8147\n",
      "val Loss: 0.7957 Acc: 0.8000\n",
      "test Loss: 0.7882 Acc: 0.8480\n",
      "Epoch 527/1499\n",
      "----------\n",
      "train Loss: 0.7990 Acc: 0.8144\n",
      "val Loss: 0.7960 Acc: 0.8040\n",
      "test Loss: 0.7902 Acc: 0.8360\n",
      "Epoch 528/1499\n",
      "----------\n",
      "train Loss: 0.7982 Acc: 0.8122\n",
      "val Loss: 0.7993 Acc: 0.7920\n",
      "test Loss: 0.8016 Acc: 0.8240\n",
      "Epoch 529/1499\n",
      "----------\n",
      "train Loss: 0.7967 Acc: 0.8169\n",
      "val Loss: 0.7877 Acc: 0.8240\n",
      "test Loss: 0.8018 Acc: 0.8240\n",
      "Epoch 530/1499\n",
      "----------\n",
      "train Loss: 0.8031 Acc: 0.8060\n",
      "val Loss: 0.7885 Acc: 0.8200\n",
      "test Loss: 0.7911 Acc: 0.8360\n",
      "Epoch 531/1499\n",
      "----------\n",
      "train Loss: 0.7983 Acc: 0.8129\n",
      "val Loss: 0.7866 Acc: 0.8200\n",
      "test Loss: 0.7841 Acc: 0.8360\n",
      "Epoch 532/1499\n",
      "----------\n",
      "train Loss: 0.7976 Acc: 0.8147\n",
      "val Loss: 0.8117 Acc: 0.7760\n",
      "test Loss: 0.7851 Acc: 0.8320\n",
      "Epoch 533/1499\n",
      "----------\n",
      "train Loss: 0.7951 Acc: 0.8189\n",
      "val Loss: 0.8034 Acc: 0.7840\n",
      "test Loss: 0.7789 Acc: 0.8640\n",
      "Epoch 534/1499\n",
      "----------\n",
      "train Loss: 0.7934 Acc: 0.8178\n",
      "val Loss: 0.7924 Acc: 0.8120\n",
      "test Loss: 0.8014 Acc: 0.8320\n",
      "Epoch 535/1499\n",
      "----------\n",
      "train Loss: 0.7993 Acc: 0.8102\n",
      "val Loss: 0.8024 Acc: 0.8000\n",
      "test Loss: 0.7944 Acc: 0.8320\n",
      "Epoch 536/1499\n",
      "----------\n",
      "train Loss: 0.7959 Acc: 0.8144\n",
      "val Loss: 0.7999 Acc: 0.7960\n",
      "test Loss: 0.7969 Acc: 0.8200\n",
      "Epoch 537/1499\n",
      "----------\n",
      "train Loss: 0.7950 Acc: 0.8164\n",
      "val Loss: 0.8072 Acc: 0.7920\n",
      "test Loss: 0.7964 Acc: 0.8240\n",
      "Epoch 538/1499\n",
      "----------\n",
      "train Loss: 0.7947 Acc: 0.8151\n",
      "val Loss: 0.8024 Acc: 0.7800\n",
      "test Loss: 0.7824 Acc: 0.8440\n",
      "Epoch 539/1499\n",
      "----------\n",
      "train Loss: 0.7936 Acc: 0.8151\n",
      "val Loss: 0.7891 Acc: 0.8120\n",
      "test Loss: 0.7857 Acc: 0.8320\n",
      "Epoch 540/1499\n",
      "----------\n",
      "train Loss: 0.7945 Acc: 0.8151\n",
      "val Loss: 0.7947 Acc: 0.8000\n",
      "test Loss: 0.7779 Acc: 0.8560\n",
      "Epoch 541/1499\n",
      "----------\n",
      "train Loss: 0.7933 Acc: 0.8173\n",
      "val Loss: 0.7838 Acc: 0.8200\n",
      "test Loss: 0.7891 Acc: 0.8360\n",
      "Epoch 542/1499\n",
      "----------\n",
      "train Loss: 0.7931 Acc: 0.8162\n",
      "val Loss: 0.7924 Acc: 0.8000\n",
      "test Loss: 0.7844 Acc: 0.8440\n",
      "Epoch 543/1499\n",
      "----------\n",
      "train Loss: 0.7938 Acc: 0.8147\n",
      "val Loss: 0.8091 Acc: 0.7720\n",
      "test Loss: 0.7787 Acc: 0.8440\n",
      "Epoch 544/1499\n",
      "----------\n",
      "train Loss: 0.7949 Acc: 0.8127\n",
      "val Loss: 0.7968 Acc: 0.8000\n",
      "test Loss: 0.7794 Acc: 0.8520\n",
      "Epoch 545/1499\n",
      "----------\n",
      "train Loss: 0.7944 Acc: 0.8107\n",
      "val Loss: 0.7944 Acc: 0.7960\n",
      "test Loss: 0.7800 Acc: 0.8480\n",
      "Epoch 546/1499\n",
      "----------\n",
      "train Loss: 0.7928 Acc: 0.8147\n",
      "val Loss: 0.7911 Acc: 0.8040\n",
      "test Loss: 0.7835 Acc: 0.8320\n",
      "Epoch 547/1499\n",
      "----------\n",
      "train Loss: 0.7888 Acc: 0.8218\n",
      "val Loss: 0.7919 Acc: 0.8120\n",
      "test Loss: 0.7849 Acc: 0.8360\n",
      "Epoch 548/1499\n",
      "----------\n",
      "train Loss: 0.7918 Acc: 0.8162\n",
      "val Loss: 0.7949 Acc: 0.7960\n",
      "test Loss: 0.7922 Acc: 0.8240\n",
      "Epoch 549/1499\n",
      "----------\n",
      "train Loss: 0.7938 Acc: 0.8098\n",
      "val Loss: 0.7899 Acc: 0.8000\n",
      "test Loss: 0.7897 Acc: 0.8200\n",
      "Epoch 550/1499\n",
      "----------\n",
      "train Loss: 0.7966 Acc: 0.8098\n",
      "val Loss: 0.7892 Acc: 0.8040\n",
      "test Loss: 0.7843 Acc: 0.8360\n",
      "Epoch 551/1499\n",
      "----------\n",
      "train Loss: 0.7937 Acc: 0.8147\n",
      "val Loss: 0.7835 Acc: 0.8120\n",
      "test Loss: 0.7956 Acc: 0.8240\n",
      "Epoch 552/1499\n",
      "----------\n",
      "train Loss: 0.7911 Acc: 0.8144\n",
      "val Loss: 0.7960 Acc: 0.7960\n",
      "test Loss: 0.7867 Acc: 0.8480\n",
      "Epoch 553/1499\n",
      "----------\n",
      "train Loss: 0.7891 Acc: 0.8180\n",
      "val Loss: 0.7887 Acc: 0.8000\n",
      "test Loss: 0.7923 Acc: 0.8360\n",
      "Epoch 554/1499\n",
      "----------\n",
      "train Loss: 0.7924 Acc: 0.8104\n",
      "val Loss: 0.7957 Acc: 0.7920\n",
      "test Loss: 0.7849 Acc: 0.8400\n",
      "Epoch 555/1499\n",
      "----------\n",
      "train Loss: 0.7880 Acc: 0.8169\n",
      "val Loss: 0.7832 Acc: 0.8120\n",
      "test Loss: 0.7767 Acc: 0.8520\n",
      "Epoch 556/1499\n",
      "----------\n",
      "train Loss: 0.7927 Acc: 0.8082\n",
      "val Loss: 0.7804 Acc: 0.8200\n",
      "test Loss: 0.7849 Acc: 0.8400\n",
      "Epoch 557/1499\n",
      "----------\n",
      "train Loss: 0.7887 Acc: 0.8171\n",
      "val Loss: 0.7877 Acc: 0.8040\n",
      "test Loss: 0.7975 Acc: 0.8240\n",
      "Epoch 558/1499\n",
      "----------\n",
      "train Loss: 0.7885 Acc: 0.8202\n",
      "val Loss: 0.7862 Acc: 0.8000\n",
      "test Loss: 0.7801 Acc: 0.8480\n",
      "Epoch 559/1499\n",
      "----------\n",
      "train Loss: 0.7898 Acc: 0.8158\n",
      "val Loss: 0.7792 Acc: 0.8240\n",
      "test Loss: 0.7772 Acc: 0.8520\n",
      "Epoch 560/1499\n",
      "----------\n",
      "train Loss: 0.7907 Acc: 0.8133\n",
      "val Loss: 0.7810 Acc: 0.8160\n",
      "test Loss: 0.7703 Acc: 0.8600\n",
      "Epoch 561/1499\n",
      "----------\n",
      "train Loss: 0.7876 Acc: 0.8184\n",
      "val Loss: 0.7800 Acc: 0.8080\n",
      "test Loss: 0.7869 Acc: 0.8400\n",
      "Epoch 562/1499\n",
      "----------\n",
      "train Loss: 0.7857 Acc: 0.8213\n",
      "val Loss: 0.7918 Acc: 0.7960\n",
      "test Loss: 0.7780 Acc: 0.8240\n",
      "Epoch 563/1499\n",
      "----------\n",
      "train Loss: 0.7877 Acc: 0.8138\n",
      "val Loss: 0.7902 Acc: 0.8000\n",
      "test Loss: 0.7810 Acc: 0.8320\n",
      "Epoch 564/1499\n",
      "----------\n",
      "train Loss: 0.7889 Acc: 0.8160\n",
      "val Loss: 0.7824 Acc: 0.8040\n",
      "test Loss: 0.7833 Acc: 0.8240\n",
      "Epoch 565/1499\n",
      "----------\n",
      "train Loss: 0.7870 Acc: 0.8158\n",
      "val Loss: 0.7968 Acc: 0.7800\n",
      "test Loss: 0.7855 Acc: 0.8400\n",
      "Epoch 566/1499\n",
      "----------\n",
      "train Loss: 0.7849 Acc: 0.8191\n",
      "val Loss: 0.7831 Acc: 0.8080\n",
      "test Loss: 0.7858 Acc: 0.8440\n",
      "Epoch 567/1499\n",
      "----------\n",
      "train Loss: 0.7871 Acc: 0.8162\n",
      "val Loss: 0.7797 Acc: 0.8000\n",
      "test Loss: 0.7823 Acc: 0.8400\n",
      "Epoch 568/1499\n",
      "----------\n",
      "train Loss: 0.7875 Acc: 0.8169\n",
      "val Loss: 0.7897 Acc: 0.7920\n",
      "test Loss: 0.7717 Acc: 0.8560\n",
      "Epoch 569/1499\n",
      "----------\n",
      "train Loss: 0.7859 Acc: 0.8187\n",
      "val Loss: 0.7835 Acc: 0.8040\n",
      "test Loss: 0.7637 Acc: 0.8560\n",
      "Epoch 570/1499\n",
      "----------\n",
      "train Loss: 0.7856 Acc: 0.8189\n",
      "val Loss: 0.7730 Acc: 0.8160\n",
      "test Loss: 0.7724 Acc: 0.8520\n",
      "Epoch 571/1499\n",
      "----------\n",
      "train Loss: 0.7880 Acc: 0.8131\n",
      "val Loss: 0.7909 Acc: 0.7960\n",
      "test Loss: 0.7905 Acc: 0.8320\n",
      "Epoch 572/1499\n",
      "----------\n",
      "train Loss: 0.7864 Acc: 0.8164\n",
      "val Loss: 0.7920 Acc: 0.8040\n",
      "test Loss: 0.7739 Acc: 0.8440\n",
      "Epoch 573/1499\n",
      "----------\n",
      "train Loss: 0.7841 Acc: 0.8209\n",
      "val Loss: 0.7806 Acc: 0.8040\n",
      "test Loss: 0.7725 Acc: 0.8520\n",
      "Epoch 574/1499\n",
      "----------\n",
      "train Loss: 0.7853 Acc: 0.8156\n",
      "val Loss: 0.7774 Acc: 0.8080\n",
      "test Loss: 0.7879 Acc: 0.8280\n",
      "Epoch 575/1499\n",
      "----------\n",
      "train Loss: 0.7807 Acc: 0.8240\n",
      "val Loss: 0.7907 Acc: 0.8000\n",
      "test Loss: 0.7781 Acc: 0.8440\n",
      "Epoch 576/1499\n",
      "----------\n",
      "train Loss: 0.7812 Acc: 0.8218\n",
      "val Loss: 0.7827 Acc: 0.8120\n",
      "test Loss: 0.7720 Acc: 0.8440\n",
      "Epoch 577/1499\n",
      "----------\n",
      "train Loss: 0.7851 Acc: 0.8147\n",
      "val Loss: 0.7866 Acc: 0.8040\n",
      "test Loss: 0.7676 Acc: 0.8640\n",
      "Epoch 578/1499\n",
      "----------\n",
      "train Loss: 0.7856 Acc: 0.8131\n",
      "val Loss: 0.7981 Acc: 0.7880\n",
      "test Loss: 0.7748 Acc: 0.8480\n",
      "Epoch 579/1499\n",
      "----------\n",
      "train Loss: 0.7813 Acc: 0.8196\n",
      "val Loss: 0.7842 Acc: 0.8040\n",
      "test Loss: 0.7771 Acc: 0.8200\n",
      "Epoch 580/1499\n",
      "----------\n",
      "train Loss: 0.7832 Acc: 0.8204\n",
      "val Loss: 0.7907 Acc: 0.7960\n",
      "test Loss: 0.7734 Acc: 0.8400\n",
      "Epoch 581/1499\n",
      "----------\n",
      "train Loss: 0.7802 Acc: 0.8220\n",
      "val Loss: 0.7928 Acc: 0.7960\n",
      "test Loss: 0.7815 Acc: 0.8320\n",
      "Epoch 582/1499\n",
      "----------\n",
      "train Loss: 0.7819 Acc: 0.8211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.7889 Acc: 0.8080\n",
      "test Loss: 0.7694 Acc: 0.8480\n",
      "Epoch 583/1499\n",
      "----------\n",
      "train Loss: 0.7803 Acc: 0.8202\n",
      "val Loss: 0.7898 Acc: 0.7960\n",
      "test Loss: 0.7711 Acc: 0.8560\n",
      "Epoch 584/1499\n",
      "----------\n",
      "train Loss: 0.7796 Acc: 0.8209\n",
      "val Loss: 0.7820 Acc: 0.8160\n",
      "test Loss: 0.7733 Acc: 0.8520\n",
      "Epoch 585/1499\n",
      "----------\n",
      "train Loss: 0.7843 Acc: 0.8144\n",
      "val Loss: 0.7867 Acc: 0.7960\n",
      "test Loss: 0.7722 Acc: 0.8560\n",
      "Epoch 586/1499\n",
      "----------\n",
      "train Loss: 0.7799 Acc: 0.8220\n",
      "val Loss: 0.7832 Acc: 0.8000\n",
      "test Loss: 0.7732 Acc: 0.8360\n",
      "Epoch 587/1499\n",
      "----------\n",
      "train Loss: 0.7790 Acc: 0.8222\n",
      "val Loss: 0.7889 Acc: 0.8080\n",
      "test Loss: 0.7640 Acc: 0.8520\n",
      "Epoch 588/1499\n",
      "----------\n",
      "train Loss: 0.7835 Acc: 0.8149\n",
      "val Loss: 0.7862 Acc: 0.8080\n",
      "test Loss: 0.7734 Acc: 0.8520\n",
      "Epoch 589/1499\n",
      "----------\n",
      "train Loss: 0.7791 Acc: 0.8220\n",
      "val Loss: 0.7942 Acc: 0.7800\n",
      "test Loss: 0.7856 Acc: 0.8280\n",
      "Epoch 590/1499\n",
      "----------\n",
      "train Loss: 0.7818 Acc: 0.8180\n",
      "val Loss: 0.7788 Acc: 0.8120\n",
      "test Loss: 0.7732 Acc: 0.8480\n",
      "Epoch 591/1499\n",
      "----------\n",
      "train Loss: 0.7759 Acc: 0.8227\n",
      "val Loss: 0.7651 Acc: 0.8320\n",
      "test Loss: 0.7783 Acc: 0.8440\n",
      "Epoch 592/1499\n",
      "----------\n",
      "train Loss: 0.7782 Acc: 0.8227\n",
      "val Loss: 0.7805 Acc: 0.8080\n",
      "test Loss: 0.7739 Acc: 0.8560\n",
      "Epoch 593/1499\n",
      "----------\n",
      "train Loss: 0.7819 Acc: 0.8158\n",
      "val Loss: 0.7805 Acc: 0.8040\n",
      "test Loss: 0.7749 Acc: 0.8360\n",
      "Epoch 594/1499\n",
      "----------\n",
      "train Loss: 0.7779 Acc: 0.8229\n",
      "val Loss: 0.7845 Acc: 0.8040\n",
      "test Loss: 0.7615 Acc: 0.8560\n",
      "Epoch 595/1499\n",
      "----------\n",
      "train Loss: 0.7776 Acc: 0.8218\n",
      "val Loss: 0.7890 Acc: 0.7920\n",
      "test Loss: 0.7740 Acc: 0.8400\n",
      "Epoch 596/1499\n",
      "----------\n",
      "train Loss: 0.7804 Acc: 0.8158\n",
      "val Loss: 0.7771 Acc: 0.8120\n",
      "test Loss: 0.7652 Acc: 0.8520\n",
      "Epoch 597/1499\n",
      "----------\n",
      "train Loss: 0.7816 Acc: 0.8167\n",
      "val Loss: 0.7671 Acc: 0.8280\n",
      "test Loss: 0.7671 Acc: 0.8480\n",
      "Epoch 598/1499\n",
      "----------\n",
      "train Loss: 0.7780 Acc: 0.8260\n",
      "val Loss: 0.7847 Acc: 0.8080\n",
      "test Loss: 0.7756 Acc: 0.8440\n",
      "Epoch 599/1499\n",
      "----------\n",
      "train Loss: 0.7788 Acc: 0.8180\n",
      "val Loss: 0.7686 Acc: 0.8240\n",
      "test Loss: 0.7739 Acc: 0.8360\n",
      "Epoch 600/1499\n",
      "----------\n",
      "train Loss: 0.7780 Acc: 0.8196\n",
      "val Loss: 0.7771 Acc: 0.8040\n",
      "test Loss: 0.7755 Acc: 0.8440\n",
      "Epoch 601/1499\n",
      "----------\n",
      "train Loss: 0.7765 Acc: 0.8247\n",
      "val Loss: 0.7700 Acc: 0.8240\n",
      "test Loss: 0.7863 Acc: 0.8280\n",
      "Epoch 602/1499\n",
      "----------\n",
      "train Loss: 0.7782 Acc: 0.8224\n",
      "val Loss: 0.7822 Acc: 0.7960\n",
      "test Loss: 0.7629 Acc: 0.8640\n",
      "Epoch 603/1499\n",
      "----------\n",
      "train Loss: 0.7759 Acc: 0.8251\n",
      "val Loss: 0.7860 Acc: 0.7880\n",
      "test Loss: 0.7645 Acc: 0.8680\n",
      "Epoch 604/1499\n",
      "----------\n",
      "train Loss: 0.7740 Acc: 0.8262\n",
      "val Loss: 0.7764 Acc: 0.8080\n",
      "test Loss: 0.7640 Acc: 0.8600\n",
      "Epoch 605/1499\n",
      "----------\n",
      "train Loss: 0.7748 Acc: 0.8229\n",
      "val Loss: 0.7766 Acc: 0.8040\n",
      "test Loss: 0.7692 Acc: 0.8600\n",
      "Epoch 606/1499\n",
      "----------\n",
      "train Loss: 0.7715 Acc: 0.8269\n",
      "val Loss: 0.7724 Acc: 0.8120\n",
      "test Loss: 0.7622 Acc: 0.8600\n",
      "Epoch 607/1499\n",
      "----------\n",
      "train Loss: 0.7755 Acc: 0.8224\n",
      "val Loss: 0.7873 Acc: 0.7920\n",
      "test Loss: 0.7681 Acc: 0.8560\n",
      "Epoch 608/1499\n",
      "----------\n",
      "train Loss: 0.7766 Acc: 0.8164\n",
      "val Loss: 0.7827 Acc: 0.8000\n",
      "test Loss: 0.7706 Acc: 0.8480\n",
      "Epoch 609/1499\n",
      "----------\n",
      "train Loss: 0.7785 Acc: 0.8167\n",
      "val Loss: 0.7693 Acc: 0.8040\n",
      "test Loss: 0.7669 Acc: 0.8560\n",
      "Epoch 610/1499\n",
      "----------\n",
      "train Loss: 0.7751 Acc: 0.8229\n",
      "val Loss: 0.7827 Acc: 0.7960\n",
      "test Loss: 0.7627 Acc: 0.8640\n",
      "Epoch 611/1499\n",
      "----------\n",
      "train Loss: 0.7757 Acc: 0.8191\n",
      "val Loss: 0.7782 Acc: 0.8080\n",
      "test Loss: 0.7735 Acc: 0.8360\n",
      "Epoch 612/1499\n",
      "----------\n",
      "train Loss: 0.7739 Acc: 0.8238\n",
      "val Loss: 0.7798 Acc: 0.7920\n",
      "test Loss: 0.7689 Acc: 0.8640\n",
      "Epoch 613/1499\n",
      "----------\n",
      "train Loss: 0.7755 Acc: 0.8218\n",
      "val Loss: 0.7735 Acc: 0.8120\n",
      "test Loss: 0.7536 Acc: 0.8600\n",
      "Epoch 614/1499\n",
      "----------\n",
      "train Loss: 0.7757 Acc: 0.8193\n",
      "val Loss: 0.7830 Acc: 0.7960\n",
      "test Loss: 0.7694 Acc: 0.8480\n",
      "Epoch 615/1499\n",
      "----------\n",
      "train Loss: 0.7729 Acc: 0.8258\n",
      "val Loss: 0.7832 Acc: 0.7880\n",
      "test Loss: 0.7672 Acc: 0.8440\n",
      "Epoch 616/1499\n",
      "----------\n",
      "train Loss: 0.7729 Acc: 0.8238\n",
      "val Loss: 0.7729 Acc: 0.8040\n",
      "test Loss: 0.7658 Acc: 0.8520\n",
      "Epoch 617/1499\n",
      "----------\n",
      "train Loss: 0.7733 Acc: 0.8242\n",
      "val Loss: 0.7685 Acc: 0.8200\n",
      "test Loss: 0.7640 Acc: 0.8480\n",
      "Epoch 618/1499\n",
      "----------\n",
      "train Loss: 0.7724 Acc: 0.8253\n",
      "val Loss: 0.7735 Acc: 0.8080\n",
      "test Loss: 0.7612 Acc: 0.8640\n",
      "Epoch 619/1499\n",
      "----------\n",
      "train Loss: 0.7683 Acc: 0.8302\n",
      "val Loss: 0.7703 Acc: 0.8160\n",
      "test Loss: 0.7748 Acc: 0.8320\n",
      "Epoch 620/1499\n",
      "----------\n",
      "train Loss: 0.7731 Acc: 0.8253\n",
      "val Loss: 0.7612 Acc: 0.8280\n",
      "test Loss: 0.7640 Acc: 0.8400\n",
      "Epoch 621/1499\n",
      "----------\n",
      "train Loss: 0.7701 Acc: 0.8298\n",
      "val Loss: 0.7688 Acc: 0.8080\n",
      "test Loss: 0.7757 Acc: 0.8400\n",
      "Epoch 622/1499\n",
      "----------\n",
      "train Loss: 0.7696 Acc: 0.8258\n",
      "val Loss: 0.7691 Acc: 0.8120\n",
      "test Loss: 0.7677 Acc: 0.8400\n",
      "Epoch 623/1499\n",
      "----------\n",
      "train Loss: 0.7689 Acc: 0.8267\n",
      "val Loss: 0.7798 Acc: 0.8000\n",
      "test Loss: 0.7638 Acc: 0.8480\n",
      "Epoch 624/1499\n",
      "----------\n",
      "train Loss: 0.7700 Acc: 0.8256\n",
      "val Loss: 0.7603 Acc: 0.8320\n",
      "test Loss: 0.7700 Acc: 0.8400\n",
      "Epoch 625/1499\n",
      "----------\n",
      "train Loss: 0.7722 Acc: 0.8207\n",
      "val Loss: 0.7679 Acc: 0.8080\n",
      "test Loss: 0.7517 Acc: 0.8600\n",
      "Epoch 626/1499\n",
      "----------\n",
      "train Loss: 0.7702 Acc: 0.8267\n",
      "val Loss: 0.7656 Acc: 0.8240\n",
      "test Loss: 0.7673 Acc: 0.8440\n",
      "Epoch 627/1499\n",
      "----------\n",
      "train Loss: 0.7686 Acc: 0.8287\n",
      "val Loss: 0.7593 Acc: 0.8320\n",
      "test Loss: 0.7675 Acc: 0.8520\n",
      "Epoch 628/1499\n",
      "----------\n",
      "train Loss: 0.7712 Acc: 0.8258\n",
      "val Loss: 0.7755 Acc: 0.8040\n",
      "test Loss: 0.7782 Acc: 0.8320\n",
      "Epoch 629/1499\n",
      "----------\n",
      "train Loss: 0.7691 Acc: 0.8233\n",
      "val Loss: 0.7784 Acc: 0.8040\n",
      "test Loss: 0.7783 Acc: 0.8360\n",
      "Epoch 630/1499\n",
      "----------\n",
      "train Loss: 0.7718 Acc: 0.8224\n",
      "val Loss: 0.7709 Acc: 0.8160\n",
      "test Loss: 0.7618 Acc: 0.8680\n",
      "Epoch 631/1499\n",
      "----------\n",
      "train Loss: 0.7714 Acc: 0.8213\n",
      "val Loss: 0.7804 Acc: 0.7960\n",
      "test Loss: 0.7447 Acc: 0.8720\n",
      "Epoch 632/1499\n",
      "----------\n",
      "train Loss: 0.7698 Acc: 0.8213\n",
      "val Loss: 0.7709 Acc: 0.8000\n",
      "test Loss: 0.7644 Acc: 0.8320\n",
      "Epoch 633/1499\n",
      "----------\n",
      "train Loss: 0.7687 Acc: 0.8249\n",
      "val Loss: 0.7644 Acc: 0.8120\n",
      "test Loss: 0.7513 Acc: 0.8560\n",
      "Epoch 634/1499\n",
      "----------\n",
      "train Loss: 0.7672 Acc: 0.8244\n",
      "val Loss: 0.7759 Acc: 0.8200\n",
      "test Loss: 0.7752 Acc: 0.8400\n",
      "Epoch 635/1499\n",
      "----------\n",
      "train Loss: 0.7692 Acc: 0.8224\n",
      "val Loss: 0.7669 Acc: 0.8240\n",
      "test Loss: 0.7502 Acc: 0.8640\n",
      "Epoch 636/1499\n",
      "----------\n",
      "train Loss: 0.7675 Acc: 0.8260\n",
      "val Loss: 0.7722 Acc: 0.8120\n",
      "test Loss: 0.7472 Acc: 0.8760\n",
      "Epoch 637/1499\n",
      "----------\n",
      "train Loss: 0.7681 Acc: 0.8258\n",
      "val Loss: 0.7580 Acc: 0.8200\n",
      "test Loss: 0.7719 Acc: 0.8320\n",
      "Epoch 638/1499\n",
      "----------\n",
      "train Loss: 0.7693 Acc: 0.8229\n",
      "val Loss: 0.7761 Acc: 0.8040\n",
      "test Loss: 0.7687 Acc: 0.8440\n",
      "Epoch 639/1499\n",
      "----------\n",
      "train Loss: 0.7648 Acc: 0.8300\n",
      "val Loss: 0.7726 Acc: 0.8120\n",
      "test Loss: 0.7499 Acc: 0.8640\n",
      "Epoch 640/1499\n",
      "----------\n",
      "train Loss: 0.7670 Acc: 0.8238\n",
      "val Loss: 0.7706 Acc: 0.8160\n",
      "test Loss: 0.7489 Acc: 0.8680\n",
      "Epoch 641/1499\n",
      "----------\n",
      "train Loss: 0.7635 Acc: 0.8291\n",
      "val Loss: 0.7555 Acc: 0.8320\n",
      "test Loss: 0.7555 Acc: 0.8640\n",
      "Epoch 642/1499\n",
      "----------\n",
      "train Loss: 0.7658 Acc: 0.8267\n",
      "val Loss: 0.7817 Acc: 0.7920\n",
      "test Loss: 0.7637 Acc: 0.8480\n",
      "Epoch 643/1499\n",
      "----------\n",
      "train Loss: 0.7681 Acc: 0.8249\n",
      "val Loss: 0.7556 Acc: 0.8280\n",
      "test Loss: 0.7460 Acc: 0.8520\n",
      "Epoch 644/1499\n",
      "----------\n",
      "train Loss: 0.7632 Acc: 0.8302\n",
      "val Loss: 0.7656 Acc: 0.8280\n",
      "test Loss: 0.7672 Acc: 0.8320\n",
      "Epoch 645/1499\n",
      "----------\n",
      "train Loss: 0.7653 Acc: 0.8269\n",
      "val Loss: 0.7642 Acc: 0.8120\n",
      "test Loss: 0.7626 Acc: 0.8400\n",
      "Epoch 646/1499\n",
      "----------\n",
      "train Loss: 0.7645 Acc: 0.8269\n",
      "val Loss: 0.7651 Acc: 0.8160\n",
      "test Loss: 0.7590 Acc: 0.8400\n",
      "Epoch 647/1499\n",
      "----------\n",
      "train Loss: 0.7645 Acc: 0.8284\n",
      "val Loss: 0.7617 Acc: 0.8320\n",
      "test Loss: 0.7606 Acc: 0.8400\n",
      "Epoch 648/1499\n",
      "----------\n",
      "train Loss: 0.7642 Acc: 0.8280\n",
      "val Loss: 0.7692 Acc: 0.8200\n",
      "test Loss: 0.7774 Acc: 0.8280\n",
      "Epoch 649/1499\n",
      "----------\n",
      "train Loss: 0.7659 Acc: 0.8242\n",
      "val Loss: 0.7582 Acc: 0.8280\n",
      "test Loss: 0.7603 Acc: 0.8520\n",
      "Epoch 650/1499\n",
      "----------\n",
      "train Loss: 0.7630 Acc: 0.8273\n",
      "val Loss: 0.7646 Acc: 0.8200\n",
      "test Loss: 0.7605 Acc: 0.8400\n",
      "Epoch 651/1499\n",
      "----------\n",
      "train Loss: 0.7631 Acc: 0.8298\n",
      "val Loss: 0.7730 Acc: 0.8080\n",
      "test Loss: 0.7631 Acc: 0.8400\n",
      "Epoch 652/1499\n",
      "----------\n",
      "train Loss: 0.7647 Acc: 0.8302\n",
      "val Loss: 0.7563 Acc: 0.8400\n",
      "test Loss: 0.7668 Acc: 0.8400\n",
      "Epoch 653/1499\n",
      "----------\n",
      "train Loss: 0.7667 Acc: 0.8224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.7660 Acc: 0.8320\n",
      "test Loss: 0.7490 Acc: 0.8560\n",
      "Epoch 654/1499\n",
      "----------\n",
      "train Loss: 0.7665 Acc: 0.8236\n",
      "val Loss: 0.7598 Acc: 0.8200\n",
      "test Loss: 0.7483 Acc: 0.8600\n",
      "Epoch 655/1499\n",
      "----------\n",
      "train Loss: 0.7657 Acc: 0.8233\n",
      "val Loss: 0.7583 Acc: 0.8400\n",
      "test Loss: 0.7509 Acc: 0.8440\n",
      "Epoch 656/1499\n",
      "----------\n",
      "train Loss: 0.7625 Acc: 0.8298\n",
      "val Loss: 0.7531 Acc: 0.8400\n",
      "test Loss: 0.7523 Acc: 0.8560\n",
      "Epoch 657/1499\n",
      "----------\n",
      "train Loss: 0.7626 Acc: 0.8304\n",
      "val Loss: 0.7593 Acc: 0.8240\n",
      "test Loss: 0.7470 Acc: 0.8600\n",
      "Epoch 658/1499\n",
      "----------\n",
      "train Loss: 0.7641 Acc: 0.8256\n",
      "val Loss: 0.7536 Acc: 0.8280\n",
      "test Loss: 0.7568 Acc: 0.8600\n",
      "Epoch 659/1499\n",
      "----------\n",
      "train Loss: 0.7609 Acc: 0.8316\n",
      "val Loss: 0.7595 Acc: 0.8280\n",
      "test Loss: 0.7531 Acc: 0.8520\n",
      "Epoch 660/1499\n",
      "----------\n",
      "train Loss: 0.7637 Acc: 0.8293\n",
      "val Loss: 0.7536 Acc: 0.8480\n",
      "test Loss: 0.7528 Acc: 0.8520\n",
      "Epoch 661/1499\n",
      "----------\n",
      "train Loss: 0.7598 Acc: 0.8309\n",
      "val Loss: 0.7756 Acc: 0.8040\n",
      "test Loss: 0.7596 Acc: 0.8400\n",
      "Epoch 662/1499\n",
      "----------\n",
      "train Loss: 0.7616 Acc: 0.8282\n",
      "val Loss: 0.7490 Acc: 0.8360\n",
      "test Loss: 0.7523 Acc: 0.8600\n",
      "Epoch 663/1499\n",
      "----------\n",
      "train Loss: 0.7587 Acc: 0.8318\n",
      "val Loss: 0.7577 Acc: 0.8120\n",
      "test Loss: 0.7418 Acc: 0.8600\n",
      "Epoch 664/1499\n",
      "----------\n",
      "train Loss: 0.7630 Acc: 0.8278\n",
      "val Loss: 0.7552 Acc: 0.8400\n",
      "test Loss: 0.7587 Acc: 0.8440\n",
      "Epoch 665/1499\n",
      "----------\n",
      "train Loss: 0.7633 Acc: 0.8244\n",
      "val Loss: 0.7631 Acc: 0.8120\n",
      "test Loss: 0.7601 Acc: 0.8480\n",
      "Epoch 666/1499\n",
      "----------\n",
      "train Loss: 0.7620 Acc: 0.8276\n",
      "val Loss: 0.7727 Acc: 0.8080\n",
      "test Loss: 0.7471 Acc: 0.8640\n",
      "Epoch 667/1499\n",
      "----------\n",
      "train Loss: 0.7602 Acc: 0.8293\n",
      "val Loss: 0.7674 Acc: 0.8240\n",
      "test Loss: 0.7688 Acc: 0.8240\n",
      "Epoch 668/1499\n",
      "----------\n",
      "train Loss: 0.7564 Acc: 0.8338\n",
      "val Loss: 0.7567 Acc: 0.8280\n",
      "test Loss: 0.7531 Acc: 0.8440\n",
      "Epoch 669/1499\n",
      "----------\n",
      "train Loss: 0.7579 Acc: 0.8311\n",
      "val Loss: 0.7552 Acc: 0.8280\n",
      "test Loss: 0.7415 Acc: 0.8640\n",
      "Epoch 670/1499\n",
      "----------\n",
      "train Loss: 0.7603 Acc: 0.8309\n",
      "val Loss: 0.7694 Acc: 0.8120\n",
      "test Loss: 0.7676 Acc: 0.8200\n",
      "Epoch 671/1499\n",
      "----------\n",
      "train Loss: 0.7609 Acc: 0.8256\n",
      "val Loss: 0.7634 Acc: 0.8160\n",
      "test Loss: 0.7506 Acc: 0.8560\n",
      "Epoch 672/1499\n",
      "----------\n",
      "train Loss: 0.7610 Acc: 0.8267\n",
      "val Loss: 0.7523 Acc: 0.8360\n",
      "test Loss: 0.7566 Acc: 0.8440\n",
      "Epoch 673/1499\n",
      "----------\n",
      "train Loss: 0.7575 Acc: 0.8322\n",
      "val Loss: 0.7665 Acc: 0.8120\n",
      "test Loss: 0.7560 Acc: 0.8560\n",
      "Epoch 674/1499\n",
      "----------\n",
      "train Loss: 0.7579 Acc: 0.8282\n",
      "val Loss: 0.7634 Acc: 0.8160\n",
      "test Loss: 0.7483 Acc: 0.8600\n",
      "Epoch 675/1499\n",
      "----------\n",
      "train Loss: 0.7590 Acc: 0.8271\n",
      "val Loss: 0.7615 Acc: 0.8120\n",
      "test Loss: 0.7626 Acc: 0.8360\n",
      "Epoch 676/1499\n",
      "----------\n",
      "train Loss: 0.7609 Acc: 0.8227\n",
      "val Loss: 0.7673 Acc: 0.8200\n",
      "test Loss: 0.7463 Acc: 0.8600\n",
      "Epoch 677/1499\n",
      "----------\n",
      "train Loss: 0.7594 Acc: 0.8291\n",
      "val Loss: 0.7463 Acc: 0.8320\n",
      "test Loss: 0.7519 Acc: 0.8480\n",
      "Epoch 678/1499\n",
      "----------\n",
      "train Loss: 0.7607 Acc: 0.8260\n",
      "val Loss: 0.7554 Acc: 0.8360\n",
      "test Loss: 0.7576 Acc: 0.8400\n",
      "Epoch 679/1499\n",
      "----------\n",
      "train Loss: 0.7560 Acc: 0.8349\n",
      "val Loss: 0.7632 Acc: 0.8240\n",
      "test Loss: 0.7402 Acc: 0.8680\n",
      "Epoch 680/1499\n",
      "----------\n",
      "train Loss: 0.7608 Acc: 0.8253\n",
      "val Loss: 0.7606 Acc: 0.8200\n",
      "test Loss: 0.7585 Acc: 0.8440\n",
      "Epoch 681/1499\n",
      "----------\n",
      "train Loss: 0.7572 Acc: 0.8324\n",
      "val Loss: 0.7570 Acc: 0.8200\n",
      "test Loss: 0.7639 Acc: 0.8360\n",
      "Epoch 682/1499\n",
      "----------\n",
      "train Loss: 0.7611 Acc: 0.8262\n",
      "val Loss: 0.7569 Acc: 0.8320\n",
      "test Loss: 0.7438 Acc: 0.8640\n",
      "Epoch 683/1499\n",
      "----------\n",
      "train Loss: 0.7555 Acc: 0.8329\n",
      "val Loss: 0.7476 Acc: 0.8400\n",
      "test Loss: 0.7570 Acc: 0.8360\n",
      "Epoch 684/1499\n",
      "----------\n",
      "train Loss: 0.7569 Acc: 0.8278\n",
      "val Loss: 0.7445 Acc: 0.8280\n",
      "test Loss: 0.7396 Acc: 0.8600\n",
      "Epoch 685/1499\n",
      "----------\n",
      "train Loss: 0.7580 Acc: 0.8289\n",
      "val Loss: 0.7574 Acc: 0.8160\n",
      "test Loss: 0.7411 Acc: 0.8600\n",
      "Epoch 686/1499\n",
      "----------\n",
      "train Loss: 0.7556 Acc: 0.8320\n",
      "val Loss: 0.7624 Acc: 0.8040\n",
      "test Loss: 0.7449 Acc: 0.8720\n",
      "Epoch 687/1499\n",
      "----------\n",
      "train Loss: 0.7570 Acc: 0.8284\n",
      "val Loss: 0.7564 Acc: 0.8240\n",
      "test Loss: 0.7617 Acc: 0.8280\n",
      "Epoch 688/1499\n",
      "----------\n",
      "train Loss: 0.7577 Acc: 0.8298\n",
      "val Loss: 0.7556 Acc: 0.8200\n",
      "test Loss: 0.7493 Acc: 0.8400\n",
      "Epoch 689/1499\n",
      "----------\n",
      "train Loss: 0.7569 Acc: 0.8278\n",
      "val Loss: 0.7630 Acc: 0.8040\n",
      "test Loss: 0.7625 Acc: 0.8400\n",
      "Epoch 690/1499\n",
      "----------\n",
      "train Loss: 0.7542 Acc: 0.8333\n",
      "val Loss: 0.7667 Acc: 0.8120\n",
      "test Loss: 0.7612 Acc: 0.8280\n",
      "Epoch 691/1499\n",
      "----------\n",
      "train Loss: 0.7551 Acc: 0.8296\n",
      "val Loss: 0.7648 Acc: 0.8080\n",
      "test Loss: 0.7439 Acc: 0.8560\n",
      "Epoch 692/1499\n",
      "----------\n",
      "train Loss: 0.7589 Acc: 0.8280\n",
      "val Loss: 0.7530 Acc: 0.8240\n",
      "test Loss: 0.7376 Acc: 0.8680\n",
      "Epoch 693/1499\n",
      "----------\n",
      "train Loss: 0.7561 Acc: 0.8293\n",
      "val Loss: 0.7587 Acc: 0.8160\n",
      "test Loss: 0.7488 Acc: 0.8640\n",
      "Epoch 694/1499\n",
      "----------\n",
      "train Loss: 0.7525 Acc: 0.8331\n",
      "val Loss: 0.7707 Acc: 0.8160\n",
      "test Loss: 0.7439 Acc: 0.8520\n",
      "Epoch 695/1499\n",
      "----------\n",
      "train Loss: 0.7513 Acc: 0.8333\n",
      "val Loss: 0.7485 Acc: 0.8320\n",
      "test Loss: 0.7478 Acc: 0.8520\n",
      "Epoch 696/1499\n",
      "----------\n",
      "train Loss: 0.7543 Acc: 0.8340\n",
      "val Loss: 0.7461 Acc: 0.8360\n",
      "test Loss: 0.7529 Acc: 0.8440\n",
      "Epoch 697/1499\n",
      "----------\n",
      "train Loss: 0.7548 Acc: 0.8307\n",
      "val Loss: 0.7482 Acc: 0.8200\n",
      "test Loss: 0.7396 Acc: 0.8640\n",
      "Epoch 698/1499\n",
      "----------\n",
      "train Loss: 0.7544 Acc: 0.8309\n",
      "val Loss: 0.7544 Acc: 0.8200\n",
      "test Loss: 0.7483 Acc: 0.8560\n",
      "Epoch 699/1499\n",
      "----------\n",
      "train Loss: 0.7550 Acc: 0.8298\n",
      "val Loss: 0.7629 Acc: 0.8080\n",
      "test Loss: 0.7449 Acc: 0.8520\n",
      "Epoch 700/1499\n",
      "----------\n",
      "train Loss: 0.7549 Acc: 0.8282\n",
      "val Loss: 0.7529 Acc: 0.8160\n",
      "test Loss: 0.7402 Acc: 0.8640\n",
      "Epoch 701/1499\n",
      "----------\n",
      "train Loss: 0.7538 Acc: 0.8271\n",
      "val Loss: 0.7548 Acc: 0.8160\n",
      "test Loss: 0.7563 Acc: 0.8360\n",
      "Epoch 702/1499\n",
      "----------\n",
      "train Loss: 0.7559 Acc: 0.8278\n",
      "val Loss: 0.7406 Acc: 0.8360\n",
      "test Loss: 0.7439 Acc: 0.8520\n",
      "Epoch 703/1499\n",
      "----------\n",
      "train Loss: 0.7563 Acc: 0.8264\n",
      "val Loss: 0.7647 Acc: 0.8120\n",
      "test Loss: 0.7736 Acc: 0.8280\n",
      "Epoch 704/1499\n",
      "----------\n",
      "train Loss: 0.7528 Acc: 0.8296\n",
      "val Loss: 0.7529 Acc: 0.8120\n",
      "test Loss: 0.7299 Acc: 0.8720\n",
      "Epoch 705/1499\n",
      "----------\n",
      "train Loss: 0.7525 Acc: 0.8322\n",
      "val Loss: 0.7316 Acc: 0.8600\n",
      "test Loss: 0.7386 Acc: 0.8480\n",
      "Epoch 706/1499\n",
      "----------\n",
      "train Loss: 0.7511 Acc: 0.8360\n",
      "val Loss: 0.7529 Acc: 0.8200\n",
      "test Loss: 0.7537 Acc: 0.8440\n",
      "Epoch 707/1499\n",
      "----------\n",
      "train Loss: 0.7536 Acc: 0.8313\n",
      "val Loss: 0.7575 Acc: 0.8200\n",
      "test Loss: 0.7392 Acc: 0.8520\n",
      "Epoch 708/1499\n",
      "----------\n",
      "train Loss: 0.7502 Acc: 0.8336\n",
      "val Loss: 0.7396 Acc: 0.8360\n",
      "test Loss: 0.7427 Acc: 0.8520\n",
      "Epoch 709/1499\n",
      "----------\n",
      "train Loss: 0.7488 Acc: 0.8411\n",
      "val Loss: 0.7561 Acc: 0.8240\n",
      "test Loss: 0.7438 Acc: 0.8480\n",
      "Epoch 710/1499\n",
      "----------\n",
      "train Loss: 0.7553 Acc: 0.8284\n",
      "val Loss: 0.7510 Acc: 0.8280\n",
      "test Loss: 0.7442 Acc: 0.8520\n",
      "Epoch 711/1499\n",
      "----------\n",
      "train Loss: 0.7520 Acc: 0.8340\n",
      "val Loss: 0.7529 Acc: 0.8120\n",
      "test Loss: 0.7572 Acc: 0.8320\n",
      "Epoch 712/1499\n",
      "----------\n",
      "train Loss: 0.7513 Acc: 0.8336\n",
      "val Loss: 0.7533 Acc: 0.8240\n",
      "test Loss: 0.7409 Acc: 0.8560\n",
      "Epoch 713/1499\n",
      "----------\n",
      "train Loss: 0.7529 Acc: 0.8316\n",
      "val Loss: 0.7539 Acc: 0.8240\n",
      "test Loss: 0.7552 Acc: 0.8400\n",
      "Epoch 714/1499\n",
      "----------\n",
      "train Loss: 0.7488 Acc: 0.8342\n",
      "val Loss: 0.7532 Acc: 0.8240\n",
      "test Loss: 0.7522 Acc: 0.8520\n",
      "Epoch 715/1499\n",
      "----------\n",
      "train Loss: 0.7492 Acc: 0.8347\n",
      "val Loss: 0.7567 Acc: 0.8160\n",
      "test Loss: 0.7400 Acc: 0.8560\n",
      "Epoch 716/1499\n",
      "----------\n",
      "train Loss: 0.7511 Acc: 0.8324\n",
      "val Loss: 0.7627 Acc: 0.8040\n",
      "test Loss: 0.7427 Acc: 0.8600\n",
      "Epoch 717/1499\n",
      "----------\n",
      "train Loss: 0.7521 Acc: 0.8307\n",
      "val Loss: 0.7495 Acc: 0.8200\n",
      "test Loss: 0.7318 Acc: 0.8680\n",
      "Epoch 718/1499\n",
      "----------\n",
      "train Loss: 0.7538 Acc: 0.8293\n",
      "val Loss: 0.7409 Acc: 0.8320\n",
      "test Loss: 0.7371 Acc: 0.8640\n",
      "Epoch 719/1499\n",
      "----------\n",
      "train Loss: 0.7498 Acc: 0.8320\n",
      "val Loss: 0.7533 Acc: 0.8160\n",
      "test Loss: 0.7471 Acc: 0.8600\n",
      "Epoch 720/1499\n",
      "----------\n",
      "train Loss: 0.7493 Acc: 0.8362\n",
      "val Loss: 0.7532 Acc: 0.8040\n",
      "test Loss: 0.7466 Acc: 0.8480\n",
      "Epoch 721/1499\n",
      "----------\n",
      "train Loss: 0.7506 Acc: 0.8284\n",
      "val Loss: 0.7547 Acc: 0.8120\n",
      "test Loss: 0.7600 Acc: 0.8360\n",
      "Epoch 722/1499\n",
      "----------\n",
      "train Loss: 0.7508 Acc: 0.8329\n",
      "val Loss: 0.7520 Acc: 0.8200\n",
      "test Loss: 0.7359 Acc: 0.8600\n",
      "Epoch 723/1499\n",
      "----------\n",
      "train Loss: 0.7505 Acc: 0.8320\n",
      "val Loss: 0.7526 Acc: 0.8040\n",
      "test Loss: 0.7449 Acc: 0.8480\n",
      "Epoch 724/1499\n",
      "----------\n",
      "train Loss: 0.7531 Acc: 0.8280\n",
      "val Loss: 0.7603 Acc: 0.8080\n",
      "test Loss: 0.7415 Acc: 0.8640\n",
      "Epoch 725/1499\n",
      "----------\n",
      "train Loss: 0.7499 Acc: 0.8329\n",
      "val Loss: 0.7544 Acc: 0.8120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.7428 Acc: 0.8440\n",
      "Epoch 726/1499\n",
      "----------\n",
      "train Loss: 0.7477 Acc: 0.8320\n",
      "val Loss: 0.7497 Acc: 0.8200\n",
      "test Loss: 0.7468 Acc: 0.8440\n",
      "Epoch 727/1499\n",
      "----------\n",
      "train Loss: 0.7514 Acc: 0.8289\n",
      "val Loss: 0.7397 Acc: 0.8320\n",
      "test Loss: 0.7418 Acc: 0.8600\n",
      "Epoch 728/1499\n",
      "----------\n",
      "train Loss: 0.7483 Acc: 0.8329\n",
      "val Loss: 0.7532 Acc: 0.8120\n",
      "test Loss: 0.7366 Acc: 0.8680\n",
      "Epoch 729/1499\n",
      "----------\n",
      "train Loss: 0.7467 Acc: 0.8333\n",
      "val Loss: 0.7325 Acc: 0.8440\n",
      "test Loss: 0.7448 Acc: 0.8480\n",
      "Epoch 730/1499\n",
      "----------\n",
      "train Loss: 0.7460 Acc: 0.8340\n",
      "val Loss: 0.7444 Acc: 0.8320\n",
      "test Loss: 0.7297 Acc: 0.8720\n",
      "Epoch 731/1499\n",
      "----------\n",
      "train Loss: 0.7487 Acc: 0.8302\n",
      "val Loss: 0.7446 Acc: 0.8320\n",
      "test Loss: 0.7416 Acc: 0.8600\n",
      "Epoch 732/1499\n",
      "----------\n",
      "train Loss: 0.7466 Acc: 0.8387\n",
      "val Loss: 0.7662 Acc: 0.7920\n",
      "test Loss: 0.7403 Acc: 0.8600\n",
      "Epoch 733/1499\n",
      "----------\n",
      "train Loss: 0.7464 Acc: 0.8364\n",
      "val Loss: 0.7507 Acc: 0.8280\n",
      "test Loss: 0.7410 Acc: 0.8560\n",
      "Epoch 734/1499\n",
      "----------\n",
      "train Loss: 0.7499 Acc: 0.8296\n",
      "val Loss: 0.7555 Acc: 0.8120\n",
      "test Loss: 0.7425 Acc: 0.8440\n",
      "Epoch 735/1499\n",
      "----------\n",
      "train Loss: 0.7465 Acc: 0.8349\n",
      "val Loss: 0.7380 Acc: 0.8240\n",
      "test Loss: 0.7331 Acc: 0.8640\n",
      "Epoch 736/1499\n",
      "----------\n",
      "train Loss: 0.7473 Acc: 0.8327\n",
      "val Loss: 0.7439 Acc: 0.8280\n",
      "test Loss: 0.7510 Acc: 0.8440\n",
      "Epoch 737/1499\n",
      "----------\n",
      "train Loss: 0.7478 Acc: 0.8331\n",
      "val Loss: 0.7391 Acc: 0.8400\n",
      "test Loss: 0.7402 Acc: 0.8520\n",
      "Epoch 738/1499\n",
      "----------\n",
      "train Loss: 0.7480 Acc: 0.8304\n",
      "val Loss: 0.7531 Acc: 0.8160\n",
      "test Loss: 0.7506 Acc: 0.8400\n",
      "Epoch 739/1499\n",
      "----------\n",
      "train Loss: 0.7457 Acc: 0.8342\n",
      "val Loss: 0.7554 Acc: 0.8080\n",
      "test Loss: 0.7468 Acc: 0.8440\n",
      "Epoch 740/1499\n",
      "----------\n",
      "train Loss: 0.7480 Acc: 0.8320\n",
      "val Loss: 0.7395 Acc: 0.8360\n",
      "test Loss: 0.7342 Acc: 0.8640\n",
      "Epoch 741/1499\n",
      "----------\n",
      "train Loss: 0.7499 Acc: 0.8280\n",
      "val Loss: 0.7544 Acc: 0.8200\n",
      "test Loss: 0.7243 Acc: 0.8800\n",
      "Epoch 742/1499\n",
      "----------\n",
      "train Loss: 0.7480 Acc: 0.8309\n",
      "val Loss: 0.7571 Acc: 0.8000\n",
      "test Loss: 0.7592 Acc: 0.8280\n",
      "Epoch 743/1499\n",
      "----------\n",
      "train Loss: 0.7467 Acc: 0.8340\n",
      "val Loss: 0.7411 Acc: 0.8360\n",
      "test Loss: 0.7562 Acc: 0.8240\n",
      "Epoch 744/1499\n",
      "----------\n",
      "train Loss: 0.7465 Acc: 0.8316\n",
      "val Loss: 0.7311 Acc: 0.8400\n",
      "test Loss: 0.7386 Acc: 0.8520\n",
      "Epoch 745/1499\n",
      "----------\n",
      "train Loss: 0.7477 Acc: 0.8296\n",
      "val Loss: 0.7387 Acc: 0.8240\n",
      "test Loss: 0.7301 Acc: 0.8720\n",
      "Epoch 746/1499\n",
      "----------\n",
      "train Loss: 0.7474 Acc: 0.8316\n",
      "val Loss: 0.7487 Acc: 0.8160\n",
      "test Loss: 0.7438 Acc: 0.8600\n",
      "Epoch 747/1499\n",
      "----------\n",
      "train Loss: 0.7468 Acc: 0.8322\n",
      "val Loss: 0.7471 Acc: 0.8200\n",
      "test Loss: 0.7343 Acc: 0.8520\n",
      "Epoch 748/1499\n",
      "----------\n",
      "train Loss: 0.7449 Acc: 0.8309\n",
      "val Loss: 0.7334 Acc: 0.8560\n",
      "test Loss: 0.7375 Acc: 0.8520\n",
      "Epoch 749/1499\n",
      "----------\n",
      "train Loss: 0.7451 Acc: 0.8347\n",
      "val Loss: 0.7413 Acc: 0.8320\n",
      "test Loss: 0.7250 Acc: 0.8680\n",
      "Epoch 750/1499\n",
      "----------\n",
      "train Loss: 0.7423 Acc: 0.8351\n",
      "val Loss: 0.7458 Acc: 0.8160\n",
      "test Loss: 0.7256 Acc: 0.8720\n",
      "Epoch 751/1499\n",
      "----------\n",
      "train Loss: 0.7433 Acc: 0.8367\n",
      "val Loss: 0.7434 Acc: 0.8200\n",
      "test Loss: 0.7472 Acc: 0.8440\n",
      "Epoch 752/1499\n",
      "----------\n",
      "train Loss: 0.7463 Acc: 0.8300\n",
      "val Loss: 0.7383 Acc: 0.8320\n",
      "test Loss: 0.7235 Acc: 0.8720\n",
      "Epoch 753/1499\n",
      "----------\n",
      "train Loss: 0.7460 Acc: 0.8322\n",
      "val Loss: 0.7324 Acc: 0.8400\n",
      "test Loss: 0.7403 Acc: 0.8480\n",
      "Epoch 754/1499\n",
      "----------\n",
      "train Loss: 0.7435 Acc: 0.8342\n",
      "val Loss: 0.7545 Acc: 0.8200\n",
      "test Loss: 0.7376 Acc: 0.8480\n",
      "Epoch 755/1499\n",
      "----------\n",
      "train Loss: 0.7444 Acc: 0.8362\n",
      "val Loss: 0.7494 Acc: 0.8120\n",
      "test Loss: 0.7373 Acc: 0.8600\n",
      "Epoch 756/1499\n",
      "----------\n",
      "train Loss: 0.7462 Acc: 0.8307\n",
      "val Loss: 0.7393 Acc: 0.8400\n",
      "test Loss: 0.7469 Acc: 0.8400\n",
      "Epoch 757/1499\n",
      "----------\n",
      "train Loss: 0.7425 Acc: 0.8362\n",
      "val Loss: 0.7441 Acc: 0.8160\n",
      "test Loss: 0.7431 Acc: 0.8600\n",
      "Epoch 758/1499\n",
      "----------\n",
      "train Loss: 0.7431 Acc: 0.8364\n",
      "val Loss: 0.7658 Acc: 0.7920\n",
      "test Loss: 0.7361 Acc: 0.8640\n",
      "Epoch 759/1499\n",
      "----------\n",
      "train Loss: 0.7426 Acc: 0.8358\n",
      "val Loss: 0.7595 Acc: 0.8000\n",
      "test Loss: 0.7440 Acc: 0.8480\n",
      "Epoch 760/1499\n",
      "----------\n",
      "train Loss: 0.7471 Acc: 0.8273\n",
      "val Loss: 0.7376 Acc: 0.8360\n",
      "test Loss: 0.7306 Acc: 0.8520\n",
      "Epoch 761/1499\n",
      "----------\n",
      "train Loss: 0.7432 Acc: 0.8322\n",
      "val Loss: 0.7486 Acc: 0.8200\n",
      "test Loss: 0.7447 Acc: 0.8400\n",
      "Epoch 762/1499\n",
      "----------\n",
      "train Loss: 0.7429 Acc: 0.8344\n",
      "val Loss: 0.7395 Acc: 0.8280\n",
      "test Loss: 0.7270 Acc: 0.8680\n",
      "Epoch 763/1499\n",
      "----------\n",
      "train Loss: 0.7409 Acc: 0.8367\n",
      "val Loss: 0.7435 Acc: 0.8320\n",
      "test Loss: 0.7364 Acc: 0.8480\n",
      "Epoch 764/1499\n",
      "----------\n",
      "train Loss: 0.7406 Acc: 0.8351\n",
      "val Loss: 0.7273 Acc: 0.8480\n",
      "test Loss: 0.7513 Acc: 0.8280\n",
      "Epoch 765/1499\n",
      "----------\n",
      "train Loss: 0.7443 Acc: 0.8293\n",
      "val Loss: 0.7375 Acc: 0.8320\n",
      "test Loss: 0.7376 Acc: 0.8560\n",
      "Epoch 766/1499\n",
      "----------\n",
      "train Loss: 0.7424 Acc: 0.8356\n",
      "val Loss: 0.7523 Acc: 0.8000\n",
      "test Loss: 0.7268 Acc: 0.8640\n",
      "Epoch 767/1499\n",
      "----------\n",
      "train Loss: 0.7389 Acc: 0.8391\n",
      "val Loss: 0.7447 Acc: 0.8200\n",
      "test Loss: 0.7416 Acc: 0.8440\n",
      "Epoch 768/1499\n",
      "----------\n",
      "train Loss: 0.7441 Acc: 0.8318\n",
      "val Loss: 0.7337 Acc: 0.8400\n",
      "test Loss: 0.7395 Acc: 0.8360\n",
      "Epoch 769/1499\n",
      "----------\n",
      "train Loss: 0.7389 Acc: 0.8409\n",
      "val Loss: 0.7614 Acc: 0.7960\n",
      "test Loss: 0.7287 Acc: 0.8560\n",
      "Epoch 770/1499\n",
      "----------\n",
      "train Loss: 0.7430 Acc: 0.8329\n",
      "val Loss: 0.7388 Acc: 0.8320\n",
      "test Loss: 0.7311 Acc: 0.8560\n",
      "Epoch 771/1499\n",
      "----------\n",
      "train Loss: 0.7438 Acc: 0.8320\n",
      "val Loss: 0.7545 Acc: 0.8160\n",
      "test Loss: 0.7413 Acc: 0.8600\n",
      "Epoch 772/1499\n",
      "----------\n",
      "train Loss: 0.7402 Acc: 0.8327\n",
      "val Loss: 0.7304 Acc: 0.8440\n",
      "test Loss: 0.7275 Acc: 0.8600\n",
      "Epoch 773/1499\n",
      "----------\n",
      "train Loss: 0.7399 Acc: 0.8367\n",
      "val Loss: 0.7417 Acc: 0.8280\n",
      "test Loss: 0.7306 Acc: 0.8640\n",
      "Epoch 774/1499\n",
      "----------\n",
      "train Loss: 0.7401 Acc: 0.8340\n",
      "val Loss: 0.7527 Acc: 0.8080\n",
      "test Loss: 0.7240 Acc: 0.8680\n",
      "Epoch 775/1499\n",
      "----------\n",
      "train Loss: 0.7410 Acc: 0.8331\n",
      "val Loss: 0.7466 Acc: 0.8320\n",
      "test Loss: 0.7220 Acc: 0.8560\n",
      "Epoch 776/1499\n",
      "----------\n",
      "train Loss: 0.7439 Acc: 0.8316\n",
      "val Loss: 0.7388 Acc: 0.8240\n",
      "test Loss: 0.7352 Acc: 0.8440\n",
      "Epoch 777/1499\n",
      "----------\n",
      "train Loss: 0.7439 Acc: 0.8282\n",
      "val Loss: 0.7370 Acc: 0.8360\n",
      "test Loss: 0.7274 Acc: 0.8560\n",
      "Epoch 778/1499\n",
      "----------\n",
      "train Loss: 0.7411 Acc: 0.8327\n",
      "val Loss: 0.7628 Acc: 0.7920\n",
      "test Loss: 0.7312 Acc: 0.8600\n",
      "Epoch 779/1499\n",
      "----------\n",
      "train Loss: 0.7439 Acc: 0.8302\n",
      "val Loss: 0.7478 Acc: 0.8160\n",
      "test Loss: 0.7362 Acc: 0.8480\n",
      "Epoch 780/1499\n",
      "----------\n",
      "train Loss: 0.7416 Acc: 0.8338\n",
      "val Loss: 0.7369 Acc: 0.8320\n",
      "test Loss: 0.7404 Acc: 0.8240\n",
      "Epoch 781/1499\n",
      "----------\n",
      "train Loss: 0.7445 Acc: 0.8287\n",
      "val Loss: 0.7481 Acc: 0.8120\n",
      "test Loss: 0.7455 Acc: 0.8320\n",
      "Epoch 782/1499\n",
      "----------\n",
      "train Loss: 0.7396 Acc: 0.8353\n",
      "val Loss: 0.7313 Acc: 0.8480\n",
      "test Loss: 0.7330 Acc: 0.8600\n",
      "Epoch 783/1499\n",
      "----------\n",
      "train Loss: 0.7397 Acc: 0.8338\n",
      "val Loss: 0.7346 Acc: 0.8320\n",
      "test Loss: 0.7443 Acc: 0.8360\n",
      "Epoch 784/1499\n",
      "----------\n",
      "train Loss: 0.7393 Acc: 0.8371\n",
      "val Loss: 0.7411 Acc: 0.8120\n",
      "test Loss: 0.7427 Acc: 0.8360\n",
      "Epoch 785/1499\n",
      "----------\n",
      "train Loss: 0.7391 Acc: 0.8367\n",
      "val Loss: 0.7333 Acc: 0.8320\n",
      "test Loss: 0.7374 Acc: 0.8480\n",
      "Epoch 786/1499\n",
      "----------\n",
      "train Loss: 0.7417 Acc: 0.8338\n",
      "val Loss: 0.7414 Acc: 0.8240\n",
      "test Loss: 0.7367 Acc: 0.8560\n",
      "Epoch 787/1499\n",
      "----------\n",
      "train Loss: 0.7386 Acc: 0.8380\n",
      "val Loss: 0.7389 Acc: 0.8320\n",
      "test Loss: 0.7208 Acc: 0.8720\n",
      "Epoch 788/1499\n",
      "----------\n",
      "train Loss: 0.7386 Acc: 0.8364\n",
      "val Loss: 0.7392 Acc: 0.8240\n",
      "test Loss: 0.7364 Acc: 0.8400\n",
      "Epoch 789/1499\n",
      "----------\n",
      "train Loss: 0.7391 Acc: 0.8371\n",
      "val Loss: 0.7620 Acc: 0.7960\n",
      "test Loss: 0.7330 Acc: 0.8440\n",
      "Epoch 790/1499\n",
      "----------\n",
      "train Loss: 0.7405 Acc: 0.8331\n",
      "val Loss: 0.7477 Acc: 0.8120\n",
      "test Loss: 0.7489 Acc: 0.8320\n",
      "Epoch 791/1499\n",
      "----------\n",
      "train Loss: 0.7430 Acc: 0.8276\n",
      "val Loss: 0.7343 Acc: 0.8320\n",
      "test Loss: 0.7451 Acc: 0.8280\n",
      "Epoch 792/1499\n",
      "----------\n",
      "train Loss: 0.7367 Acc: 0.8396\n",
      "val Loss: 0.7546 Acc: 0.8200\n",
      "test Loss: 0.7373 Acc: 0.8480\n",
      "Epoch 793/1499\n",
      "----------\n",
      "train Loss: 0.7396 Acc: 0.8344\n",
      "val Loss: 0.7299 Acc: 0.8400\n",
      "test Loss: 0.7201 Acc: 0.8760\n",
      "Epoch 794/1499\n",
      "----------\n",
      "train Loss: 0.7387 Acc: 0.8367\n",
      "val Loss: 0.7386 Acc: 0.8160\n",
      "test Loss: 0.7502 Acc: 0.8240\n",
      "Epoch 795/1499\n",
      "----------\n",
      "train Loss: 0.7380 Acc: 0.8362\n",
      "val Loss: 0.7374 Acc: 0.8280\n",
      "test Loss: 0.7392 Acc: 0.8440\n",
      "Epoch 796/1499\n",
      "----------\n",
      "train Loss: 0.7375 Acc: 0.8373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.7413 Acc: 0.8200\n",
      "test Loss: 0.7439 Acc: 0.8320\n",
      "Epoch 797/1499\n",
      "----------\n",
      "train Loss: 0.7388 Acc: 0.8371\n",
      "val Loss: 0.7312 Acc: 0.8320\n",
      "test Loss: 0.7277 Acc: 0.8520\n",
      "Epoch 798/1499\n",
      "----------\n",
      "train Loss: 0.7418 Acc: 0.8309\n",
      "val Loss: 0.7415 Acc: 0.8240\n",
      "test Loss: 0.7289 Acc: 0.8520\n",
      "Epoch 799/1499\n",
      "----------\n",
      "train Loss: 0.7380 Acc: 0.8371\n",
      "val Loss: 0.7337 Acc: 0.8360\n",
      "test Loss: 0.7098 Acc: 0.8840\n",
      "Epoch 800/1499\n",
      "----------\n",
      "train Loss: 0.7385 Acc: 0.8356\n",
      "val Loss: 0.7328 Acc: 0.8240\n",
      "test Loss: 0.7416 Acc: 0.8400\n",
      "Epoch 801/1499\n",
      "----------\n",
      "train Loss: 0.7374 Acc: 0.8373\n",
      "val Loss: 0.7684 Acc: 0.7800\n",
      "test Loss: 0.7333 Acc: 0.8440\n",
      "Epoch 802/1499\n",
      "----------\n",
      "train Loss: 0.7379 Acc: 0.8342\n",
      "val Loss: 0.7304 Acc: 0.8320\n",
      "test Loss: 0.7300 Acc: 0.8560\n",
      "Epoch 803/1499\n",
      "----------\n",
      "train Loss: 0.7403 Acc: 0.8342\n",
      "val Loss: 0.7343 Acc: 0.8280\n",
      "test Loss: 0.7394 Acc: 0.8520\n",
      "Epoch 804/1499\n",
      "----------\n",
      "train Loss: 0.7368 Acc: 0.8360\n",
      "val Loss: 0.7387 Acc: 0.8360\n",
      "test Loss: 0.7240 Acc: 0.8680\n",
      "Epoch 805/1499\n",
      "----------\n",
      "train Loss: 0.7339 Acc: 0.8393\n",
      "val Loss: 0.7421 Acc: 0.8280\n",
      "test Loss: 0.7297 Acc: 0.8560\n",
      "Epoch 806/1499\n",
      "----------\n",
      "train Loss: 0.7381 Acc: 0.8353\n",
      "val Loss: 0.7349 Acc: 0.8400\n",
      "test Loss: 0.7186 Acc: 0.8720\n",
      "Epoch 807/1499\n",
      "----------\n",
      "train Loss: 0.7403 Acc: 0.8322\n",
      "val Loss: 0.7361 Acc: 0.8360\n",
      "test Loss: 0.7301 Acc: 0.8480\n",
      "Epoch 808/1499\n",
      "----------\n",
      "train Loss: 0.7368 Acc: 0.8336\n",
      "val Loss: 0.7325 Acc: 0.8240\n",
      "test Loss: 0.7276 Acc: 0.8520\n",
      "Epoch 809/1499\n",
      "----------\n",
      "train Loss: 0.7343 Acc: 0.8398\n",
      "val Loss: 0.7452 Acc: 0.8080\n",
      "test Loss: 0.7216 Acc: 0.8600\n",
      "Epoch 810/1499\n",
      "----------\n",
      "train Loss: 0.7386 Acc: 0.8353\n",
      "val Loss: 0.7327 Acc: 0.8320\n",
      "test Loss: 0.7304 Acc: 0.8560\n",
      "Epoch 811/1499\n",
      "----------\n",
      "train Loss: 0.7362 Acc: 0.8373\n",
      "val Loss: 0.7392 Acc: 0.8320\n",
      "test Loss: 0.7208 Acc: 0.8560\n",
      "Epoch 812/1499\n",
      "----------\n",
      "train Loss: 0.7361 Acc: 0.8351\n",
      "val Loss: 0.7451 Acc: 0.8080\n",
      "test Loss: 0.7334 Acc: 0.8360\n",
      "Epoch 813/1499\n",
      "----------\n",
      "train Loss: 0.7357 Acc: 0.8378\n",
      "val Loss: 0.7448 Acc: 0.8200\n",
      "test Loss: 0.7250 Acc: 0.8560\n",
      "Epoch 814/1499\n",
      "----------\n",
      "train Loss: 0.7387 Acc: 0.8340\n",
      "val Loss: 0.7311 Acc: 0.8360\n",
      "test Loss: 0.7266 Acc: 0.8600\n",
      "Epoch 815/1499\n",
      "----------\n",
      "train Loss: 0.7346 Acc: 0.8404\n",
      "val Loss: 0.7405 Acc: 0.8240\n",
      "test Loss: 0.7373 Acc: 0.8360\n",
      "Epoch 816/1499\n",
      "----------\n",
      "train Loss: 0.7367 Acc: 0.8338\n",
      "val Loss: 0.7435 Acc: 0.8240\n",
      "test Loss: 0.7358 Acc: 0.8480\n",
      "Epoch 817/1499\n",
      "----------\n",
      "train Loss: 0.7312 Acc: 0.8413\n",
      "val Loss: 0.7311 Acc: 0.8360\n",
      "test Loss: 0.7321 Acc: 0.8560\n",
      "Epoch 818/1499\n",
      "----------\n",
      "train Loss: 0.7376 Acc: 0.8349\n",
      "val Loss: 0.7309 Acc: 0.8400\n",
      "test Loss: 0.7228 Acc: 0.8520\n",
      "Epoch 819/1499\n",
      "----------\n",
      "train Loss: 0.7364 Acc: 0.8356\n",
      "val Loss: 0.7283 Acc: 0.8400\n",
      "test Loss: 0.7199 Acc: 0.8720\n",
      "Epoch 820/1499\n",
      "----------\n",
      "train Loss: 0.7371 Acc: 0.8338\n",
      "val Loss: 0.7416 Acc: 0.8160\n",
      "test Loss: 0.7192 Acc: 0.8560\n",
      "Epoch 821/1499\n",
      "----------\n",
      "train Loss: 0.7347 Acc: 0.8384\n",
      "val Loss: 0.7417 Acc: 0.8200\n",
      "test Loss: 0.7256 Acc: 0.8560\n",
      "Epoch 822/1499\n",
      "----------\n",
      "train Loss: 0.7343 Acc: 0.8393\n",
      "val Loss: 0.7249 Acc: 0.8440\n",
      "test Loss: 0.7308 Acc: 0.8440\n",
      "Epoch 823/1499\n",
      "----------\n",
      "train Loss: 0.7343 Acc: 0.8380\n",
      "val Loss: 0.7265 Acc: 0.8240\n",
      "test Loss: 0.7218 Acc: 0.8600\n",
      "Epoch 824/1499\n",
      "----------\n",
      "train Loss: 0.7338 Acc: 0.8402\n",
      "val Loss: 0.7371 Acc: 0.8320\n",
      "test Loss: 0.7217 Acc: 0.8600\n",
      "Epoch 825/1499\n",
      "----------\n",
      "train Loss: 0.7348 Acc: 0.8393\n",
      "val Loss: 0.7385 Acc: 0.8240\n",
      "test Loss: 0.7316 Acc: 0.8400\n",
      "Epoch 826/1499\n",
      "----------\n",
      "train Loss: 0.7321 Acc: 0.8416\n",
      "val Loss: 0.7523 Acc: 0.8000\n",
      "test Loss: 0.7318 Acc: 0.8440\n",
      "Epoch 827/1499\n",
      "----------\n",
      "train Loss: 0.7375 Acc: 0.8353\n",
      "val Loss: 0.7433 Acc: 0.8040\n",
      "test Loss: 0.7253 Acc: 0.8560\n",
      "Epoch 828/1499\n",
      "----------\n",
      "train Loss: 0.7342 Acc: 0.8342\n",
      "val Loss: 0.7289 Acc: 0.8280\n",
      "test Loss: 0.7280 Acc: 0.8560\n",
      "Epoch 829/1499\n",
      "----------\n",
      "train Loss: 0.7357 Acc: 0.8347\n",
      "val Loss: 0.7344 Acc: 0.8280\n",
      "test Loss: 0.7402 Acc: 0.8360\n",
      "Epoch 830/1499\n",
      "----------\n",
      "train Loss: 0.7355 Acc: 0.8367\n",
      "val Loss: 0.7323 Acc: 0.8240\n",
      "test Loss: 0.7200 Acc: 0.8600\n",
      "Epoch 831/1499\n",
      "----------\n",
      "train Loss: 0.7331 Acc: 0.8378\n",
      "val Loss: 0.7378 Acc: 0.8200\n",
      "test Loss: 0.7418 Acc: 0.8400\n",
      "Epoch 832/1499\n",
      "----------\n",
      "train Loss: 0.7378 Acc: 0.8318\n",
      "val Loss: 0.7298 Acc: 0.8360\n",
      "test Loss: 0.7375 Acc: 0.8400\n",
      "Epoch 833/1499\n",
      "----------\n",
      "train Loss: 0.7323 Acc: 0.8396\n",
      "val Loss: 0.7272 Acc: 0.8280\n",
      "test Loss: 0.7300 Acc: 0.8480\n",
      "Epoch 834/1499\n",
      "----------\n",
      "train Loss: 0.7345 Acc: 0.8373\n",
      "val Loss: 0.7115 Acc: 0.8720\n",
      "test Loss: 0.7218 Acc: 0.8560\n",
      "Epoch 835/1499\n",
      "----------\n",
      "train Loss: 0.7348 Acc: 0.8351\n",
      "val Loss: 0.7310 Acc: 0.8280\n",
      "test Loss: 0.7285 Acc: 0.8600\n",
      "Epoch 836/1499\n",
      "----------\n",
      "train Loss: 0.7325 Acc: 0.8371\n",
      "val Loss: 0.7343 Acc: 0.8240\n",
      "test Loss: 0.7270 Acc: 0.8640\n",
      "Epoch 837/1499\n",
      "----------\n",
      "train Loss: 0.7314 Acc: 0.8398\n",
      "val Loss: 0.7530 Acc: 0.8000\n",
      "test Loss: 0.7329 Acc: 0.8520\n",
      "Epoch 838/1499\n",
      "----------\n",
      "train Loss: 0.7321 Acc: 0.8409\n",
      "val Loss: 0.7267 Acc: 0.8320\n",
      "test Loss: 0.7222 Acc: 0.8480\n",
      "Epoch 839/1499\n",
      "----------\n",
      "train Loss: 0.7342 Acc: 0.8347\n",
      "val Loss: 0.7304 Acc: 0.8360\n",
      "test Loss: 0.7469 Acc: 0.8160\n",
      "Epoch 840/1499\n",
      "----------\n",
      "train Loss: 0.7305 Acc: 0.8393\n",
      "val Loss: 0.7264 Acc: 0.8360\n",
      "test Loss: 0.7254 Acc: 0.8520\n",
      "Epoch 841/1499\n",
      "----------\n",
      "train Loss: 0.7342 Acc: 0.8358\n",
      "val Loss: 0.7373 Acc: 0.8280\n",
      "test Loss: 0.7219 Acc: 0.8560\n",
      "Epoch 842/1499\n",
      "----------\n",
      "train Loss: 0.7367 Acc: 0.8298\n",
      "val Loss: 0.7398 Acc: 0.8240\n",
      "test Loss: 0.7118 Acc: 0.8800\n",
      "Epoch 843/1499\n",
      "----------\n",
      "train Loss: 0.7345 Acc: 0.8327\n",
      "val Loss: 0.7344 Acc: 0.8240\n",
      "test Loss: 0.7260 Acc: 0.8600\n",
      "Epoch 844/1499\n",
      "----------\n",
      "train Loss: 0.7389 Acc: 0.8284\n",
      "val Loss: 0.7517 Acc: 0.8000\n",
      "test Loss: 0.7290 Acc: 0.8480\n",
      "Epoch 845/1499\n",
      "----------\n",
      "train Loss: 0.7313 Acc: 0.8387\n",
      "val Loss: 0.7390 Acc: 0.8200\n",
      "test Loss: 0.7342 Acc: 0.8520\n",
      "Epoch 846/1499\n",
      "----------\n",
      "train Loss: 0.7332 Acc: 0.8369\n",
      "val Loss: 0.7331 Acc: 0.8280\n",
      "test Loss: 0.7219 Acc: 0.8560\n",
      "Epoch 847/1499\n",
      "----------\n",
      "train Loss: 0.7316 Acc: 0.8407\n",
      "val Loss: 0.7342 Acc: 0.8200\n",
      "test Loss: 0.7404 Acc: 0.8360\n",
      "Epoch 848/1499\n",
      "----------\n",
      "train Loss: 0.7319 Acc: 0.8360\n",
      "val Loss: 0.7251 Acc: 0.8280\n",
      "test Loss: 0.7242 Acc: 0.8560\n",
      "Epoch 849/1499\n",
      "----------\n",
      "train Loss: 0.7323 Acc: 0.8347\n",
      "val Loss: 0.7399 Acc: 0.8160\n",
      "test Loss: 0.7214 Acc: 0.8480\n",
      "Epoch 850/1499\n",
      "----------\n",
      "train Loss: 0.7339 Acc: 0.8347\n",
      "val Loss: 0.7342 Acc: 0.8280\n",
      "test Loss: 0.7129 Acc: 0.8560\n",
      "Epoch 851/1499\n",
      "----------\n",
      "train Loss: 0.7335 Acc: 0.8344\n",
      "val Loss: 0.7326 Acc: 0.8240\n",
      "test Loss: 0.7172 Acc: 0.8640\n",
      "Epoch 852/1499\n",
      "----------\n",
      "train Loss: 0.7319 Acc: 0.8378\n",
      "val Loss: 0.7176 Acc: 0.8520\n",
      "test Loss: 0.7209 Acc: 0.8520\n",
      "Epoch 853/1499\n",
      "----------\n",
      "train Loss: 0.7313 Acc: 0.8384\n",
      "val Loss: 0.7285 Acc: 0.8200\n",
      "test Loss: 0.7128 Acc: 0.8680\n",
      "Epoch 854/1499\n",
      "----------\n",
      "train Loss: 0.7329 Acc: 0.8360\n",
      "val Loss: 0.7252 Acc: 0.8400\n",
      "test Loss: 0.7155 Acc: 0.8720\n",
      "Epoch 855/1499\n",
      "----------\n",
      "train Loss: 0.7319 Acc: 0.8333\n",
      "val Loss: 0.7306 Acc: 0.8280\n",
      "test Loss: 0.7342 Acc: 0.8400\n",
      "Epoch 856/1499\n",
      "----------\n",
      "train Loss: 0.7293 Acc: 0.8367\n",
      "val Loss: 0.7441 Acc: 0.8200\n",
      "test Loss: 0.7340 Acc: 0.8440\n",
      "Epoch 857/1499\n",
      "----------\n",
      "train Loss: 0.7308 Acc: 0.8331\n",
      "val Loss: 0.7218 Acc: 0.8400\n",
      "test Loss: 0.7287 Acc: 0.8400\n",
      "Epoch 858/1499\n",
      "----------\n",
      "train Loss: 0.7313 Acc: 0.8369\n",
      "val Loss: 0.7237 Acc: 0.8400\n",
      "test Loss: 0.7236 Acc: 0.8480\n",
      "Epoch 859/1499\n",
      "----------\n",
      "train Loss: 0.7280 Acc: 0.8429\n",
      "val Loss: 0.7394 Acc: 0.8160\n",
      "test Loss: 0.7173 Acc: 0.8600\n",
      "Epoch 860/1499\n",
      "----------\n",
      "train Loss: 0.7308 Acc: 0.8389\n",
      "val Loss: 0.7276 Acc: 0.8280\n",
      "test Loss: 0.7232 Acc: 0.8520\n",
      "Epoch 861/1499\n",
      "----------\n",
      "train Loss: 0.7350 Acc: 0.8309\n",
      "val Loss: 0.7264 Acc: 0.8440\n",
      "test Loss: 0.7259 Acc: 0.8640\n",
      "Epoch 862/1499\n",
      "----------\n",
      "train Loss: 0.7354 Acc: 0.8293\n",
      "val Loss: 0.7273 Acc: 0.8240\n",
      "test Loss: 0.7376 Acc: 0.8360\n",
      "Epoch 863/1499\n",
      "----------\n",
      "train Loss: 0.7288 Acc: 0.8393\n",
      "val Loss: 0.7322 Acc: 0.8160\n",
      "test Loss: 0.7164 Acc: 0.8560\n",
      "Epoch 864/1499\n",
      "----------\n",
      "train Loss: 0.7329 Acc: 0.8356\n",
      "val Loss: 0.7315 Acc: 0.8240\n",
      "test Loss: 0.7118 Acc: 0.8640\n",
      "Epoch 865/1499\n",
      "----------\n",
      "train Loss: 0.7262 Acc: 0.8429\n",
      "val Loss: 0.7372 Acc: 0.8080\n",
      "test Loss: 0.7268 Acc: 0.8440\n",
      "Epoch 866/1499\n",
      "----------\n",
      "train Loss: 0.7335 Acc: 0.8340\n",
      "val Loss: 0.7133 Acc: 0.8520\n",
      "test Loss: 0.7077 Acc: 0.8720\n",
      "Epoch 867/1499\n",
      "----------\n",
      "train Loss: 0.7303 Acc: 0.8376\n",
      "val Loss: 0.7324 Acc: 0.8160\n",
      "test Loss: 0.7227 Acc: 0.8440\n",
      "Epoch 868/1499\n",
      "----------\n",
      "train Loss: 0.7337 Acc: 0.8322\n",
      "val Loss: 0.7317 Acc: 0.8240\n",
      "test Loss: 0.7097 Acc: 0.8680\n",
      "Epoch 869/1499\n",
      "----------\n",
      "train Loss: 0.7293 Acc: 0.8389\n",
      "val Loss: 0.7298 Acc: 0.8240\n",
      "test Loss: 0.7132 Acc: 0.8720\n",
      "Epoch 870/1499\n",
      "----------\n",
      "train Loss: 0.7305 Acc: 0.8351\n",
      "val Loss: 0.7156 Acc: 0.8440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.7309 Acc: 0.8360\n",
      "Epoch 871/1499\n",
      "----------\n",
      "train Loss: 0.7327 Acc: 0.8340\n",
      "val Loss: 0.7348 Acc: 0.8160\n",
      "test Loss: 0.7246 Acc: 0.8440\n",
      "Epoch 872/1499\n",
      "----------\n",
      "train Loss: 0.7273 Acc: 0.8382\n",
      "val Loss: 0.7189 Acc: 0.8360\n",
      "test Loss: 0.7223 Acc: 0.8560\n",
      "Epoch 873/1499\n",
      "----------\n",
      "train Loss: 0.7270 Acc: 0.8433\n",
      "val Loss: 0.7393 Acc: 0.8040\n",
      "test Loss: 0.7129 Acc: 0.8640\n",
      "Epoch 874/1499\n",
      "----------\n",
      "train Loss: 0.7309 Acc: 0.8358\n",
      "val Loss: 0.7365 Acc: 0.8120\n",
      "test Loss: 0.7193 Acc: 0.8600\n",
      "Epoch 875/1499\n",
      "----------\n",
      "train Loss: 0.7350 Acc: 0.8289\n",
      "val Loss: 0.7305 Acc: 0.8200\n",
      "test Loss: 0.7079 Acc: 0.8760\n",
      "Epoch 876/1499\n",
      "----------\n",
      "train Loss: 0.7313 Acc: 0.8331\n",
      "val Loss: 0.7247 Acc: 0.8280\n",
      "test Loss: 0.7345 Acc: 0.8480\n",
      "Epoch 877/1499\n",
      "----------\n",
      "train Loss: 0.7302 Acc: 0.8333\n",
      "val Loss: 0.7316 Acc: 0.8200\n",
      "test Loss: 0.7274 Acc: 0.8360\n",
      "Epoch 878/1499\n",
      "----------\n",
      "train Loss: 0.7320 Acc: 0.8311\n",
      "val Loss: 0.7355 Acc: 0.8200\n",
      "test Loss: 0.7231 Acc: 0.8560\n",
      "Epoch 879/1499\n",
      "----------\n",
      "train Loss: 0.7295 Acc: 0.8349\n",
      "val Loss: 0.7290 Acc: 0.8280\n",
      "test Loss: 0.7373 Acc: 0.8360\n",
      "Epoch 880/1499\n",
      "----------\n",
      "train Loss: 0.7297 Acc: 0.8353\n",
      "val Loss: 0.7246 Acc: 0.8280\n",
      "test Loss: 0.7112 Acc: 0.8760\n",
      "Epoch 881/1499\n",
      "----------\n",
      "train Loss: 0.7281 Acc: 0.8340\n",
      "val Loss: 0.7280 Acc: 0.8240\n",
      "test Loss: 0.7202 Acc: 0.8520\n",
      "Epoch 882/1499\n",
      "----------\n",
      "train Loss: 0.7323 Acc: 0.8307\n",
      "val Loss: 0.7324 Acc: 0.8240\n",
      "test Loss: 0.7247 Acc: 0.8480\n",
      "Epoch 883/1499\n",
      "----------\n",
      "train Loss: 0.7266 Acc: 0.8404\n",
      "val Loss: 0.7318 Acc: 0.8160\n",
      "test Loss: 0.7199 Acc: 0.8560\n",
      "Epoch 884/1499\n",
      "----------\n",
      "train Loss: 0.7292 Acc: 0.8342\n",
      "val Loss: 0.7289 Acc: 0.8240\n",
      "test Loss: 0.7265 Acc: 0.8400\n",
      "Epoch 885/1499\n",
      "----------\n",
      "train Loss: 0.7286 Acc: 0.8376\n",
      "val Loss: 0.7355 Acc: 0.8280\n",
      "test Loss: 0.7273 Acc: 0.8560\n",
      "Epoch 886/1499\n",
      "----------\n",
      "train Loss: 0.7311 Acc: 0.8336\n",
      "val Loss: 0.7382 Acc: 0.8080\n",
      "test Loss: 0.7261 Acc: 0.8400\n",
      "Epoch 887/1499\n",
      "----------\n",
      "train Loss: 0.7299 Acc: 0.8351\n",
      "val Loss: 0.7234 Acc: 0.8280\n",
      "test Loss: 0.7260 Acc: 0.8560\n",
      "Epoch 888/1499\n",
      "----------\n",
      "train Loss: 0.7299 Acc: 0.8376\n",
      "val Loss: 0.7482 Acc: 0.7880\n",
      "test Loss: 0.7185 Acc: 0.8600\n",
      "Epoch 889/1499\n",
      "----------\n",
      "train Loss: 0.7284 Acc: 0.8364\n",
      "val Loss: 0.7375 Acc: 0.8240\n",
      "test Loss: 0.7224 Acc: 0.8520\n",
      "Epoch 890/1499\n",
      "----------\n",
      "train Loss: 0.7292 Acc: 0.8364\n",
      "val Loss: 0.7210 Acc: 0.8440\n",
      "test Loss: 0.7189 Acc: 0.8560\n",
      "Epoch 891/1499\n",
      "----------\n",
      "train Loss: 0.7282 Acc: 0.8353\n",
      "val Loss: 0.7213 Acc: 0.8400\n",
      "test Loss: 0.7351 Acc: 0.8320\n",
      "Epoch 892/1499\n",
      "----------\n",
      "train Loss: 0.7293 Acc: 0.8344\n",
      "val Loss: 0.7275 Acc: 0.8240\n",
      "test Loss: 0.7266 Acc: 0.8440\n",
      "Epoch 893/1499\n",
      "----------\n",
      "train Loss: 0.7279 Acc: 0.8384\n",
      "val Loss: 0.7266 Acc: 0.8240\n",
      "test Loss: 0.7202 Acc: 0.8560\n",
      "Epoch 894/1499\n",
      "----------\n",
      "train Loss: 0.7301 Acc: 0.8364\n",
      "val Loss: 0.7218 Acc: 0.8320\n",
      "test Loss: 0.7174 Acc: 0.8560\n",
      "Epoch 895/1499\n",
      "----------\n",
      "train Loss: 0.7279 Acc: 0.8384\n",
      "val Loss: 0.7311 Acc: 0.8240\n",
      "test Loss: 0.7082 Acc: 0.8680\n",
      "Epoch 896/1499\n",
      "----------\n",
      "train Loss: 0.7285 Acc: 0.8364\n",
      "val Loss: 0.7390 Acc: 0.8000\n",
      "test Loss: 0.7232 Acc: 0.8520\n",
      "Epoch 897/1499\n",
      "----------\n",
      "train Loss: 0.7263 Acc: 0.8409\n",
      "val Loss: 0.7187 Acc: 0.8480\n",
      "test Loss: 0.7002 Acc: 0.8800\n",
      "Epoch 898/1499\n",
      "----------\n",
      "train Loss: 0.7244 Acc: 0.8420\n",
      "val Loss: 0.7279 Acc: 0.8320\n",
      "test Loss: 0.7145 Acc: 0.8680\n",
      "Epoch 899/1499\n",
      "----------\n",
      "train Loss: 0.7319 Acc: 0.8276\n",
      "val Loss: 0.7349 Acc: 0.8320\n",
      "test Loss: 0.7133 Acc: 0.8640\n",
      "Epoch 900/1499\n",
      "----------\n",
      "train Loss: 0.7269 Acc: 0.8380\n",
      "val Loss: 0.7402 Acc: 0.8000\n",
      "test Loss: 0.7100 Acc: 0.8720\n",
      "Epoch 901/1499\n",
      "----------\n",
      "train Loss: 0.7266 Acc: 0.8376\n",
      "val Loss: 0.7362 Acc: 0.8080\n",
      "test Loss: 0.7089 Acc: 0.8600\n",
      "Epoch 902/1499\n",
      "----------\n",
      "train Loss: 0.7278 Acc: 0.8362\n",
      "val Loss: 0.7398 Acc: 0.8160\n",
      "test Loss: 0.7177 Acc: 0.8560\n",
      "Epoch 903/1499\n",
      "----------\n",
      "train Loss: 0.7295 Acc: 0.8336\n",
      "val Loss: 0.7200 Acc: 0.8240\n",
      "test Loss: 0.7282 Acc: 0.8440\n",
      "Epoch 904/1499\n",
      "----------\n",
      "train Loss: 0.7271 Acc: 0.8371\n",
      "val Loss: 0.7270 Acc: 0.8280\n",
      "test Loss: 0.7170 Acc: 0.8600\n",
      "Epoch 905/1499\n",
      "----------\n",
      "train Loss: 0.7288 Acc: 0.8333\n",
      "val Loss: 0.7269 Acc: 0.8200\n",
      "test Loss: 0.7135 Acc: 0.8600\n",
      "Epoch 906/1499\n",
      "----------\n",
      "train Loss: 0.7249 Acc: 0.8389\n",
      "val Loss: 0.7321 Acc: 0.8240\n",
      "test Loss: 0.7212 Acc: 0.8600\n",
      "Epoch 907/1499\n",
      "----------\n",
      "train Loss: 0.7279 Acc: 0.8342\n",
      "val Loss: 0.7237 Acc: 0.8320\n",
      "test Loss: 0.7201 Acc: 0.8480\n",
      "Epoch 908/1499\n",
      "----------\n",
      "train Loss: 0.7265 Acc: 0.8353\n",
      "val Loss: 0.7392 Acc: 0.8120\n",
      "test Loss: 0.7194 Acc: 0.8520\n",
      "Epoch 909/1499\n",
      "----------\n",
      "train Loss: 0.7276 Acc: 0.8358\n",
      "val Loss: 0.7281 Acc: 0.8160\n",
      "test Loss: 0.7261 Acc: 0.8440\n",
      "Epoch 910/1499\n",
      "----------\n",
      "train Loss: 0.7270 Acc: 0.8389\n",
      "val Loss: 0.7168 Acc: 0.8480\n",
      "test Loss: 0.7284 Acc: 0.8480\n",
      "Epoch 911/1499\n",
      "----------\n",
      "train Loss: 0.7295 Acc: 0.8331\n",
      "val Loss: 0.7340 Acc: 0.8200\n",
      "test Loss: 0.7208 Acc: 0.8400\n",
      "Epoch 912/1499\n",
      "----------\n",
      "train Loss: 0.7295 Acc: 0.8320\n",
      "val Loss: 0.7309 Acc: 0.8120\n",
      "test Loss: 0.7141 Acc: 0.8600\n",
      "Epoch 913/1499\n",
      "----------\n",
      "train Loss: 0.7281 Acc: 0.8351\n",
      "val Loss: 0.7297 Acc: 0.8160\n",
      "test Loss: 0.7282 Acc: 0.8400\n",
      "Epoch 914/1499\n",
      "----------\n",
      "train Loss: 0.7262 Acc: 0.8389\n",
      "val Loss: 0.7294 Acc: 0.8160\n",
      "test Loss: 0.7224 Acc: 0.8480\n",
      "Epoch 915/1499\n",
      "----------\n",
      "train Loss: 0.7253 Acc: 0.8360\n",
      "val Loss: 0.7265 Acc: 0.8360\n",
      "test Loss: 0.7306 Acc: 0.8320\n",
      "Epoch 916/1499\n",
      "----------\n",
      "train Loss: 0.7256 Acc: 0.8353\n",
      "val Loss: 0.7198 Acc: 0.8360\n",
      "test Loss: 0.7072 Acc: 0.8600\n",
      "Epoch 917/1499\n",
      "----------\n",
      "train Loss: 0.7233 Acc: 0.8420\n",
      "val Loss: 0.7289 Acc: 0.8160\n",
      "test Loss: 0.7098 Acc: 0.8720\n",
      "Epoch 918/1499\n",
      "----------\n",
      "train Loss: 0.7266 Acc: 0.8373\n",
      "val Loss: 0.7257 Acc: 0.8320\n",
      "test Loss: 0.7320 Acc: 0.8400\n",
      "Epoch 919/1499\n",
      "----------\n",
      "train Loss: 0.7257 Acc: 0.8393\n",
      "val Loss: 0.7331 Acc: 0.8000\n",
      "test Loss: 0.7245 Acc: 0.8440\n",
      "Epoch 920/1499\n",
      "----------\n",
      "train Loss: 0.7290 Acc: 0.8324\n",
      "val Loss: 0.7096 Acc: 0.8440\n",
      "test Loss: 0.7302 Acc: 0.8400\n",
      "Epoch 921/1499\n",
      "----------\n",
      "train Loss: 0.7252 Acc: 0.8384\n",
      "val Loss: 0.7279 Acc: 0.8200\n",
      "test Loss: 0.7328 Acc: 0.8400\n",
      "Epoch 922/1499\n",
      "----------\n",
      "train Loss: 0.7274 Acc: 0.8336\n",
      "val Loss: 0.7263 Acc: 0.8320\n",
      "test Loss: 0.7271 Acc: 0.8360\n",
      "Epoch 923/1499\n",
      "----------\n",
      "train Loss: 0.7278 Acc: 0.8340\n",
      "val Loss: 0.7395 Acc: 0.8040\n",
      "test Loss: 0.7091 Acc: 0.8640\n",
      "Epoch 924/1499\n",
      "----------\n",
      "train Loss: 0.7264 Acc: 0.8358\n",
      "val Loss: 0.7052 Acc: 0.8520\n",
      "test Loss: 0.7349 Acc: 0.8240\n",
      "Epoch 925/1499\n",
      "----------\n",
      "train Loss: 0.7224 Acc: 0.8396\n",
      "val Loss: 0.7311 Acc: 0.8160\n",
      "test Loss: 0.7091 Acc: 0.8560\n",
      "Epoch 926/1499\n",
      "----------\n",
      "train Loss: 0.7252 Acc: 0.8360\n",
      "val Loss: 0.7225 Acc: 0.8440\n",
      "test Loss: 0.7163 Acc: 0.8560\n",
      "Epoch 927/1499\n",
      "----------\n",
      "train Loss: 0.7284 Acc: 0.8313\n",
      "val Loss: 0.7275 Acc: 0.8240\n",
      "test Loss: 0.7197 Acc: 0.8480\n",
      "Epoch 928/1499\n",
      "----------\n",
      "train Loss: 0.7267 Acc: 0.8396\n",
      "val Loss: 0.7278 Acc: 0.8320\n",
      "test Loss: 0.7231 Acc: 0.8440\n",
      "Epoch 929/1499\n",
      "----------\n",
      "train Loss: 0.7223 Acc: 0.8393\n",
      "val Loss: 0.7119 Acc: 0.8400\n",
      "test Loss: 0.7346 Acc: 0.8280\n",
      "Epoch 930/1499\n",
      "----------\n",
      "train Loss: 0.7264 Acc: 0.8360\n",
      "val Loss: 0.7296 Acc: 0.8320\n",
      "test Loss: 0.7098 Acc: 0.8680\n",
      "Epoch 931/1499\n",
      "----------\n",
      "train Loss: 0.7233 Acc: 0.8404\n",
      "val Loss: 0.7220 Acc: 0.8360\n",
      "test Loss: 0.7242 Acc: 0.8400\n",
      "Epoch 932/1499\n",
      "----------\n",
      "train Loss: 0.7275 Acc: 0.8313\n",
      "val Loss: 0.7198 Acc: 0.8320\n",
      "test Loss: 0.7255 Acc: 0.8480\n",
      "Epoch 933/1499\n",
      "----------\n",
      "train Loss: 0.7274 Acc: 0.8349\n",
      "val Loss: 0.7236 Acc: 0.8280\n",
      "test Loss: 0.7222 Acc: 0.8600\n",
      "Epoch 934/1499\n",
      "----------\n",
      "train Loss: 0.7248 Acc: 0.8364\n",
      "val Loss: 0.7342 Acc: 0.8200\n",
      "test Loss: 0.7126 Acc: 0.8680\n",
      "Epoch 935/1499\n",
      "----------\n",
      "train Loss: 0.7216 Acc: 0.8424\n",
      "val Loss: 0.7302 Acc: 0.8200\n",
      "test Loss: 0.7189 Acc: 0.8560\n",
      "Epoch 936/1499\n",
      "----------\n",
      "train Loss: 0.7249 Acc: 0.8404\n",
      "val Loss: 0.7236 Acc: 0.8280\n",
      "test Loss: 0.6963 Acc: 0.8760\n",
      "Epoch 937/1499\n",
      "----------\n",
      "train Loss: 0.7226 Acc: 0.8380\n",
      "val Loss: 0.7250 Acc: 0.8200\n",
      "test Loss: 0.7200 Acc: 0.8480\n",
      "Epoch 938/1499\n",
      "----------\n",
      "train Loss: 0.7219 Acc: 0.8418\n",
      "val Loss: 0.7025 Acc: 0.8560\n",
      "test Loss: 0.7159 Acc: 0.8520\n",
      "Epoch 939/1499\n",
      "----------\n",
      "train Loss: 0.7254 Acc: 0.8382\n",
      "val Loss: 0.7312 Acc: 0.8240\n",
      "test Loss: 0.7346 Acc: 0.8280\n",
      "Epoch 940/1499\n",
      "----------\n",
      "train Loss: 0.7260 Acc: 0.8356\n",
      "val Loss: 0.7193 Acc: 0.8160\n",
      "test Loss: 0.7254 Acc: 0.8440\n",
      "Epoch 941/1499\n",
      "----------\n",
      "train Loss: 0.7239 Acc: 0.8384\n",
      "val Loss: 0.7231 Acc: 0.8280\n",
      "test Loss: 0.7216 Acc: 0.8520\n",
      "Epoch 942/1499\n",
      "----------\n",
      "train Loss: 0.7224 Acc: 0.8416\n",
      "val Loss: 0.7332 Acc: 0.8240\n",
      "test Loss: 0.7038 Acc: 0.8720\n",
      "Epoch 943/1499\n",
      "----------\n",
      "train Loss: 0.7233 Acc: 0.8409\n",
      "val Loss: 0.7226 Acc: 0.8320\n",
      "test Loss: 0.7095 Acc: 0.8560\n",
      "Epoch 944/1499\n",
      "----------\n",
      "train Loss: 0.7234 Acc: 0.8382\n",
      "val Loss: 0.7201 Acc: 0.8280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.7168 Acc: 0.8600\n",
      "Epoch 945/1499\n",
      "----------\n",
      "train Loss: 0.7272 Acc: 0.8338\n",
      "val Loss: 0.7118 Acc: 0.8400\n",
      "test Loss: 0.7329 Acc: 0.8320\n",
      "Epoch 946/1499\n",
      "----------\n",
      "train Loss: 0.7247 Acc: 0.8340\n",
      "val Loss: 0.7152 Acc: 0.8320\n",
      "test Loss: 0.7322 Acc: 0.8400\n",
      "Epoch 947/1499\n",
      "----------\n",
      "train Loss: 0.7208 Acc: 0.8447\n",
      "val Loss: 0.7298 Acc: 0.8240\n",
      "test Loss: 0.7315 Acc: 0.8240\n",
      "Epoch 948/1499\n",
      "----------\n",
      "train Loss: 0.7258 Acc: 0.8364\n",
      "val Loss: 0.7340 Acc: 0.7960\n",
      "test Loss: 0.7278 Acc: 0.8360\n",
      "Epoch 949/1499\n",
      "----------\n",
      "train Loss: 0.7231 Acc: 0.8393\n",
      "val Loss: 0.7244 Acc: 0.8320\n",
      "test Loss: 0.7122 Acc: 0.8640\n",
      "Epoch 950/1499\n",
      "----------\n",
      "train Loss: 0.7198 Acc: 0.8451\n",
      "val Loss: 0.7323 Acc: 0.8080\n",
      "test Loss: 0.7249 Acc: 0.8480\n",
      "Epoch 951/1499\n",
      "----------\n",
      "train Loss: 0.7188 Acc: 0.8431\n",
      "val Loss: 0.7088 Acc: 0.8480\n",
      "test Loss: 0.7178 Acc: 0.8440\n",
      "Epoch 952/1499\n",
      "----------\n",
      "train Loss: 0.7248 Acc: 0.8373\n",
      "val Loss: 0.7084 Acc: 0.8480\n",
      "test Loss: 0.7129 Acc: 0.8600\n",
      "Epoch 953/1499\n",
      "----------\n",
      "train Loss: 0.7236 Acc: 0.8382\n",
      "val Loss: 0.7173 Acc: 0.8320\n",
      "test Loss: 0.7225 Acc: 0.8440\n",
      "Epoch 954/1499\n",
      "----------\n",
      "train Loss: 0.7263 Acc: 0.8331\n",
      "val Loss: 0.7180 Acc: 0.8320\n",
      "test Loss: 0.7091 Acc: 0.8600\n",
      "Epoch 955/1499\n",
      "----------\n",
      "train Loss: 0.7210 Acc: 0.8420\n",
      "val Loss: 0.7185 Acc: 0.8360\n",
      "test Loss: 0.7052 Acc: 0.8680\n",
      "Epoch 956/1499\n",
      "----------\n",
      "train Loss: 0.7252 Acc: 0.8322\n",
      "val Loss: 0.7213 Acc: 0.8480\n",
      "test Loss: 0.7202 Acc: 0.8520\n",
      "Epoch 957/1499\n",
      "----------\n",
      "train Loss: 0.7190 Acc: 0.8442\n",
      "val Loss: 0.7263 Acc: 0.8160\n",
      "test Loss: 0.7150 Acc: 0.8640\n",
      "Epoch 958/1499\n",
      "----------\n",
      "train Loss: 0.7230 Acc: 0.8389\n",
      "val Loss: 0.7099 Acc: 0.8480\n",
      "test Loss: 0.7196 Acc: 0.8440\n",
      "Epoch 959/1499\n",
      "----------\n",
      "train Loss: 0.7206 Acc: 0.8418\n",
      "val Loss: 0.7324 Acc: 0.8120\n",
      "test Loss: 0.7245 Acc: 0.8480\n",
      "Epoch 960/1499\n",
      "----------\n",
      "train Loss: 0.7255 Acc: 0.8324\n",
      "val Loss: 0.7224 Acc: 0.8240\n",
      "test Loss: 0.7178 Acc: 0.8560\n",
      "Epoch 961/1499\n",
      "----------\n",
      "train Loss: 0.7203 Acc: 0.8396\n",
      "val Loss: 0.7150 Acc: 0.8400\n",
      "test Loss: 0.7189 Acc: 0.8520\n",
      "Epoch 962/1499\n",
      "----------\n",
      "train Loss: 0.7230 Acc: 0.8378\n",
      "val Loss: 0.7212 Acc: 0.8440\n",
      "test Loss: 0.7234 Acc: 0.8440\n",
      "Epoch 963/1499\n",
      "----------\n",
      "train Loss: 0.7233 Acc: 0.8373\n",
      "val Loss: 0.7305 Acc: 0.8120\n",
      "test Loss: 0.7104 Acc: 0.8560\n",
      "Epoch 964/1499\n",
      "----------\n",
      "train Loss: 0.7203 Acc: 0.8416\n",
      "val Loss: 0.7183 Acc: 0.8360\n",
      "test Loss: 0.7080 Acc: 0.8680\n",
      "Epoch 965/1499\n",
      "----------\n",
      "train Loss: 0.7214 Acc: 0.8411\n",
      "val Loss: 0.7238 Acc: 0.8360\n",
      "test Loss: 0.7184 Acc: 0.8560\n",
      "Epoch 966/1499\n",
      "----------\n",
      "train Loss: 0.7248 Acc: 0.8338\n",
      "val Loss: 0.7117 Acc: 0.8400\n",
      "test Loss: 0.7225 Acc: 0.8440\n",
      "Epoch 967/1499\n",
      "----------\n",
      "train Loss: 0.7265 Acc: 0.8322\n",
      "val Loss: 0.7218 Acc: 0.8280\n",
      "test Loss: 0.7244 Acc: 0.8520\n",
      "Epoch 968/1499\n",
      "----------\n",
      "train Loss: 0.7212 Acc: 0.8413\n",
      "val Loss: 0.7286 Acc: 0.8200\n",
      "test Loss: 0.7082 Acc: 0.8680\n",
      "Epoch 969/1499\n",
      "----------\n",
      "train Loss: 0.7214 Acc: 0.8400\n",
      "val Loss: 0.7140 Acc: 0.8400\n",
      "test Loss: 0.7158 Acc: 0.8520\n",
      "Epoch 970/1499\n",
      "----------\n",
      "train Loss: 0.7248 Acc: 0.8353\n",
      "val Loss: 0.7170 Acc: 0.8360\n",
      "test Loss: 0.7211 Acc: 0.8400\n",
      "Epoch 971/1499\n",
      "----------\n",
      "train Loss: 0.7219 Acc: 0.8373\n",
      "val Loss: 0.7301 Acc: 0.8200\n",
      "test Loss: 0.7163 Acc: 0.8600\n",
      "Epoch 972/1499\n",
      "----------\n",
      "train Loss: 0.7214 Acc: 0.8376\n",
      "val Loss: 0.7224 Acc: 0.8240\n",
      "test Loss: 0.7376 Acc: 0.8320\n",
      "Epoch 973/1499\n",
      "----------\n",
      "train Loss: 0.7243 Acc: 0.8364\n",
      "val Loss: 0.7214 Acc: 0.8320\n",
      "test Loss: 0.7218 Acc: 0.8400\n",
      "Epoch 974/1499\n",
      "----------\n",
      "train Loss: 0.7180 Acc: 0.8449\n",
      "val Loss: 0.7164 Acc: 0.8400\n",
      "test Loss: 0.7298 Acc: 0.8400\n",
      "Epoch 975/1499\n",
      "----------\n",
      "train Loss: 0.7189 Acc: 0.8420\n",
      "val Loss: 0.7067 Acc: 0.8520\n",
      "test Loss: 0.7079 Acc: 0.8600\n",
      "Epoch 976/1499\n",
      "----------\n",
      "train Loss: 0.7225 Acc: 0.8369\n",
      "val Loss: 0.7148 Acc: 0.8360\n",
      "test Loss: 0.7178 Acc: 0.8560\n",
      "Epoch 977/1499\n",
      "----------\n",
      "train Loss: 0.7209 Acc: 0.8380\n",
      "val Loss: 0.7288 Acc: 0.8320\n",
      "test Loss: 0.7306 Acc: 0.8240\n",
      "Epoch 978/1499\n",
      "----------\n",
      "train Loss: 0.7237 Acc: 0.8358\n",
      "val Loss: 0.7367 Acc: 0.8000\n",
      "test Loss: 0.7131 Acc: 0.8520\n",
      "Epoch 979/1499\n",
      "----------\n",
      "train Loss: 0.7260 Acc: 0.8324\n",
      "val Loss: 0.7301 Acc: 0.8280\n",
      "test Loss: 0.7129 Acc: 0.8520\n",
      "Epoch 980/1499\n",
      "----------\n",
      "train Loss: 0.7190 Acc: 0.8433\n",
      "val Loss: 0.7179 Acc: 0.8280\n",
      "test Loss: 0.7303 Acc: 0.8280\n",
      "Epoch 981/1499\n",
      "----------\n",
      "train Loss: 0.7216 Acc: 0.8393\n",
      "val Loss: 0.7344 Acc: 0.8280\n",
      "test Loss: 0.7221 Acc: 0.8320\n",
      "Epoch 982/1499\n",
      "----------\n",
      "train Loss: 0.7227 Acc: 0.8358\n",
      "val Loss: 0.7285 Acc: 0.8240\n",
      "test Loss: 0.7201 Acc: 0.8480\n",
      "Epoch 983/1499\n",
      "----------\n",
      "train Loss: 0.7222 Acc: 0.8382\n",
      "val Loss: 0.7245 Acc: 0.8280\n",
      "test Loss: 0.7221 Acc: 0.8440\n",
      "Epoch 984/1499\n",
      "----------\n",
      "train Loss: 0.7232 Acc: 0.8342\n",
      "val Loss: 0.7208 Acc: 0.8360\n",
      "test Loss: 0.7074 Acc: 0.8520\n",
      "Epoch 985/1499\n",
      "----------\n",
      "train Loss: 0.7235 Acc: 0.8342\n",
      "val Loss: 0.7222 Acc: 0.8240\n",
      "test Loss: 0.7101 Acc: 0.8640\n",
      "Epoch 986/1499\n",
      "----------\n",
      "train Loss: 0.7230 Acc: 0.8342\n",
      "val Loss: 0.7329 Acc: 0.8120\n",
      "test Loss: 0.7166 Acc: 0.8440\n",
      "Epoch 987/1499\n",
      "----------\n",
      "train Loss: 0.7228 Acc: 0.8360\n",
      "val Loss: 0.7093 Acc: 0.8480\n",
      "test Loss: 0.7155 Acc: 0.8600\n",
      "Epoch 988/1499\n",
      "----------\n",
      "train Loss: 0.7203 Acc: 0.8391\n",
      "val Loss: 0.7432 Acc: 0.8000\n",
      "test Loss: 0.7224 Acc: 0.8440\n",
      "Epoch 989/1499\n",
      "----------\n",
      "train Loss: 0.7211 Acc: 0.8376\n",
      "val Loss: 0.7177 Acc: 0.8240\n",
      "test Loss: 0.7171 Acc: 0.8440\n",
      "Epoch 990/1499\n",
      "----------\n",
      "train Loss: 0.7230 Acc: 0.8338\n",
      "val Loss: 0.7285 Acc: 0.8160\n",
      "test Loss: 0.7223 Acc: 0.8480\n",
      "Epoch 991/1499\n",
      "----------\n",
      "train Loss: 0.7189 Acc: 0.8400\n",
      "val Loss: 0.7462 Acc: 0.7960\n",
      "test Loss: 0.7184 Acc: 0.8520\n",
      "Epoch 992/1499\n",
      "----------\n",
      "train Loss: 0.7219 Acc: 0.8367\n",
      "val Loss: 0.7072 Acc: 0.8480\n",
      "test Loss: 0.7071 Acc: 0.8680\n",
      "Epoch 993/1499\n",
      "----------\n",
      "train Loss: 0.7232 Acc: 0.8351\n",
      "val Loss: 0.7334 Acc: 0.8240\n",
      "test Loss: 0.7207 Acc: 0.8400\n",
      "Epoch 994/1499\n",
      "----------\n",
      "train Loss: 0.7205 Acc: 0.8413\n",
      "val Loss: 0.7407 Acc: 0.8000\n",
      "test Loss: 0.7195 Acc: 0.8440\n",
      "Epoch 995/1499\n",
      "----------\n",
      "train Loss: 0.7203 Acc: 0.8389\n",
      "val Loss: 0.7192 Acc: 0.8360\n",
      "test Loss: 0.7235 Acc: 0.8480\n",
      "Epoch 996/1499\n",
      "----------\n",
      "train Loss: 0.7217 Acc: 0.8400\n",
      "val Loss: 0.7164 Acc: 0.8360\n",
      "test Loss: 0.7095 Acc: 0.8520\n",
      "Epoch 997/1499\n",
      "----------\n",
      "train Loss: 0.7191 Acc: 0.8404\n",
      "val Loss: 0.7293 Acc: 0.8200\n",
      "test Loss: 0.7086 Acc: 0.8600\n",
      "Epoch 998/1499\n",
      "----------\n",
      "train Loss: 0.7215 Acc: 0.8371\n",
      "val Loss: 0.7397 Acc: 0.8080\n",
      "test Loss: 0.7098 Acc: 0.8600\n",
      "Epoch 999/1499\n",
      "----------\n",
      "train Loss: 0.7232 Acc: 0.8351\n",
      "val Loss: 0.7126 Acc: 0.8320\n",
      "test Loss: 0.7094 Acc: 0.8640\n",
      "Epoch 1000/1499\n",
      "----------\n",
      "train Loss: 0.7215 Acc: 0.8356\n",
      "val Loss: 0.7210 Acc: 0.8360\n",
      "test Loss: 0.7198 Acc: 0.8440\n",
      "Epoch 1001/1499\n",
      "----------\n",
      "train Loss: 0.7178 Acc: 0.8411\n",
      "val Loss: 0.7245 Acc: 0.8320\n",
      "test Loss: 0.7160 Acc: 0.8520\n",
      "Epoch 1002/1499\n",
      "----------\n",
      "train Loss: 0.7242 Acc: 0.8320\n",
      "val Loss: 0.7205 Acc: 0.8320\n",
      "test Loss: 0.7169 Acc: 0.8440\n",
      "Epoch 1003/1499\n",
      "----------\n",
      "train Loss: 0.7249 Acc: 0.8340\n",
      "val Loss: 0.7093 Acc: 0.8440\n",
      "test Loss: 0.7331 Acc: 0.8360\n",
      "Epoch 1004/1499\n",
      "----------\n",
      "train Loss: 0.7232 Acc: 0.8336\n",
      "val Loss: 0.7279 Acc: 0.8320\n",
      "test Loss: 0.7162 Acc: 0.8440\n",
      "Epoch 1005/1499\n",
      "----------\n",
      "train Loss: 0.7213 Acc: 0.8367\n",
      "val Loss: 0.7428 Acc: 0.8040\n",
      "test Loss: 0.7094 Acc: 0.8680\n",
      "Epoch 1006/1499\n",
      "----------\n",
      "train Loss: 0.7199 Acc: 0.8344\n",
      "val Loss: 0.7312 Acc: 0.8280\n",
      "test Loss: 0.7184 Acc: 0.8480\n",
      "Epoch 1007/1499\n",
      "----------\n",
      "train Loss: 0.7153 Acc: 0.8458\n",
      "val Loss: 0.7293 Acc: 0.8120\n",
      "test Loss: 0.7069 Acc: 0.8560\n",
      "Epoch 1008/1499\n",
      "----------\n",
      "train Loss: 0.7166 Acc: 0.8416\n",
      "val Loss: 0.7187 Acc: 0.8280\n",
      "test Loss: 0.7198 Acc: 0.8640\n",
      "Epoch 1009/1499\n",
      "----------\n",
      "train Loss: 0.7196 Acc: 0.8391\n",
      "val Loss: 0.7339 Acc: 0.8120\n",
      "test Loss: 0.7071 Acc: 0.8640\n",
      "Epoch 1010/1499\n",
      "----------\n",
      "train Loss: 0.7184 Acc: 0.8411\n",
      "val Loss: 0.7239 Acc: 0.8240\n",
      "test Loss: 0.7147 Acc: 0.8400\n",
      "Epoch 1011/1499\n",
      "----------\n",
      "train Loss: 0.7160 Acc: 0.8433\n",
      "val Loss: 0.7334 Acc: 0.8080\n",
      "test Loss: 0.7237 Acc: 0.8400\n",
      "Epoch 1012/1499\n",
      "----------\n",
      "train Loss: 0.7206 Acc: 0.8387\n",
      "val Loss: 0.7480 Acc: 0.7880\n",
      "test Loss: 0.7120 Acc: 0.8520\n",
      "Epoch 1013/1499\n",
      "----------\n",
      "train Loss: 0.7174 Acc: 0.8420\n",
      "val Loss: 0.7251 Acc: 0.8240\n",
      "test Loss: 0.7138 Acc: 0.8560\n",
      "Epoch 1014/1499\n",
      "----------\n",
      "train Loss: 0.7187 Acc: 0.8393\n",
      "val Loss: 0.7210 Acc: 0.8400\n",
      "test Loss: 0.7041 Acc: 0.8840\n",
      "Epoch 1015/1499\n",
      "----------\n",
      "train Loss: 0.7216 Acc: 0.8336\n",
      "val Loss: 0.7187 Acc: 0.8320\n",
      "test Loss: 0.7156 Acc: 0.8520\n",
      "Epoch 1016/1499\n",
      "----------\n",
      "train Loss: 0.7205 Acc: 0.8364\n",
      "val Loss: 0.7151 Acc: 0.8320\n",
      "test Loss: 0.6988 Acc: 0.8680\n",
      "Epoch 1017/1499\n",
      "----------\n",
      "train Loss: 0.7144 Acc: 0.8467\n",
      "val Loss: 0.7234 Acc: 0.8280\n",
      "test Loss: 0.7252 Acc: 0.8320\n",
      "Epoch 1018/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.7167 Acc: 0.8413\n",
      "val Loss: 0.7267 Acc: 0.8320\n",
      "test Loss: 0.7212 Acc: 0.8440\n",
      "Epoch 1019/1499\n",
      "----------\n",
      "train Loss: 0.7214 Acc: 0.8358\n",
      "val Loss: 0.7076 Acc: 0.8480\n",
      "test Loss: 0.7175 Acc: 0.8480\n",
      "Epoch 1020/1499\n",
      "----------\n",
      "train Loss: 0.7169 Acc: 0.8413\n",
      "val Loss: 0.7168 Acc: 0.8400\n",
      "test Loss: 0.7049 Acc: 0.8600\n",
      "Epoch 1021/1499\n",
      "----------\n",
      "train Loss: 0.7183 Acc: 0.8387\n",
      "val Loss: 0.7126 Acc: 0.8360\n",
      "test Loss: 0.7275 Acc: 0.8360\n",
      "Epoch 1022/1499\n",
      "----------\n",
      "train Loss: 0.7137 Acc: 0.8471\n",
      "val Loss: 0.7118 Acc: 0.8440\n",
      "test Loss: 0.7085 Acc: 0.8600\n",
      "Epoch 1023/1499\n",
      "----------\n",
      "train Loss: 0.7185 Acc: 0.8382\n",
      "val Loss: 0.7147 Acc: 0.8440\n",
      "test Loss: 0.7235 Acc: 0.8400\n",
      "Epoch 1024/1499\n",
      "----------\n",
      "train Loss: 0.7162 Acc: 0.8444\n",
      "val Loss: 0.7088 Acc: 0.8600\n",
      "test Loss: 0.7190 Acc: 0.8440\n",
      "Epoch 1025/1499\n",
      "----------\n",
      "train Loss: 0.7240 Acc: 0.8342\n",
      "val Loss: 0.7241 Acc: 0.8240\n",
      "test Loss: 0.7106 Acc: 0.8600\n",
      "Epoch 1026/1499\n",
      "----------\n",
      "train Loss: 0.7187 Acc: 0.8373\n",
      "val Loss: 0.7179 Acc: 0.8360\n",
      "test Loss: 0.7048 Acc: 0.8640\n",
      "Epoch 1027/1499\n",
      "----------\n",
      "train Loss: 0.7155 Acc: 0.8418\n",
      "val Loss: 0.7342 Acc: 0.8120\n",
      "test Loss: 0.7100 Acc: 0.8560\n",
      "Epoch 1028/1499\n",
      "----------\n",
      "train Loss: 0.7192 Acc: 0.8380\n",
      "val Loss: 0.7142 Acc: 0.8440\n",
      "test Loss: 0.7161 Acc: 0.8440\n",
      "Epoch 1029/1499\n",
      "----------\n",
      "train Loss: 0.7181 Acc: 0.8384\n",
      "val Loss: 0.7375 Acc: 0.8160\n",
      "test Loss: 0.7136 Acc: 0.8600\n",
      "Epoch 1030/1499\n",
      "----------\n",
      "train Loss: 0.7195 Acc: 0.8389\n",
      "val Loss: 0.7281 Acc: 0.8240\n",
      "test Loss: 0.7059 Acc: 0.8680\n",
      "Epoch 1031/1499\n",
      "----------\n",
      "train Loss: 0.7185 Acc: 0.8396\n",
      "val Loss: 0.7090 Acc: 0.8520\n",
      "test Loss: 0.7154 Acc: 0.8520\n",
      "Epoch 1032/1499\n",
      "----------\n",
      "train Loss: 0.7170 Acc: 0.8420\n",
      "val Loss: 0.7077 Acc: 0.8520\n",
      "test Loss: 0.7214 Acc: 0.8400\n",
      "Epoch 1033/1499\n",
      "----------\n",
      "train Loss: 0.7190 Acc: 0.8378\n",
      "val Loss: 0.7068 Acc: 0.8560\n",
      "test Loss: 0.7102 Acc: 0.8480\n",
      "Epoch 1034/1499\n",
      "----------\n",
      "train Loss: 0.7175 Acc: 0.8431\n",
      "val Loss: 0.7160 Acc: 0.8360\n",
      "test Loss: 0.7006 Acc: 0.8760\n",
      "Epoch 1035/1499\n",
      "----------\n",
      "train Loss: 0.7196 Acc: 0.8373\n",
      "val Loss: 0.7276 Acc: 0.8240\n",
      "test Loss: 0.7313 Acc: 0.8440\n",
      "Epoch 1036/1499\n",
      "----------\n",
      "train Loss: 0.7179 Acc: 0.8393\n",
      "val Loss: 0.7162 Acc: 0.8400\n",
      "test Loss: 0.7030 Acc: 0.8640\n",
      "Epoch 1037/1499\n",
      "----------\n",
      "train Loss: 0.7158 Acc: 0.8431\n",
      "val Loss: 0.7211 Acc: 0.8280\n",
      "test Loss: 0.7134 Acc: 0.8440\n",
      "Epoch 1038/1499\n",
      "----------\n",
      "train Loss: 0.7185 Acc: 0.8389\n",
      "val Loss: 0.7245 Acc: 0.8440\n",
      "test Loss: 0.7199 Acc: 0.8400\n",
      "Epoch 1039/1499\n",
      "----------\n",
      "train Loss: 0.7159 Acc: 0.8407\n",
      "val Loss: 0.7196 Acc: 0.8360\n",
      "test Loss: 0.6986 Acc: 0.8720\n",
      "Epoch 1040/1499\n",
      "----------\n",
      "train Loss: 0.7180 Acc: 0.8351\n",
      "val Loss: 0.7106 Acc: 0.8440\n",
      "test Loss: 0.7122 Acc: 0.8600\n",
      "Epoch 1041/1499\n",
      "----------\n",
      "train Loss: 0.7187 Acc: 0.8398\n",
      "val Loss: 0.7100 Acc: 0.8480\n",
      "test Loss: 0.7191 Acc: 0.8520\n",
      "Epoch 1042/1499\n",
      "----------\n",
      "train Loss: 0.7153 Acc: 0.8444\n",
      "val Loss: 0.7100 Acc: 0.8440\n",
      "test Loss: 0.7181 Acc: 0.8360\n",
      "Epoch 1043/1499\n",
      "----------\n",
      "train Loss: 0.7150 Acc: 0.8411\n",
      "val Loss: 0.7147 Acc: 0.8320\n",
      "test Loss: 0.6977 Acc: 0.8760\n",
      "Epoch 1044/1499\n",
      "----------\n",
      "train Loss: 0.7174 Acc: 0.8436\n",
      "val Loss: 0.7329 Acc: 0.8200\n",
      "test Loss: 0.7208 Acc: 0.8400\n",
      "Epoch 1045/1499\n",
      "----------\n",
      "train Loss: 0.7188 Acc: 0.8393\n",
      "val Loss: 0.7162 Acc: 0.8400\n",
      "test Loss: 0.7067 Acc: 0.8680\n",
      "Epoch 1046/1499\n",
      "----------\n",
      "train Loss: 0.7174 Acc: 0.8398\n",
      "val Loss: 0.7322 Acc: 0.8160\n",
      "test Loss: 0.6983 Acc: 0.8720\n",
      "Epoch 1047/1499\n",
      "----------\n",
      "train Loss: 0.7151 Acc: 0.8429\n",
      "val Loss: 0.7152 Acc: 0.8320\n",
      "test Loss: 0.7010 Acc: 0.8720\n",
      "Epoch 1048/1499\n",
      "----------\n",
      "train Loss: 0.7165 Acc: 0.8424\n",
      "val Loss: 0.7203 Acc: 0.8280\n",
      "test Loss: 0.7048 Acc: 0.8600\n",
      "Epoch 1049/1499\n",
      "----------\n",
      "train Loss: 0.7154 Acc: 0.8424\n",
      "val Loss: 0.7114 Acc: 0.8480\n",
      "test Loss: 0.6999 Acc: 0.8760\n",
      "Epoch 1050/1499\n",
      "----------\n",
      "train Loss: 0.7178 Acc: 0.8378\n",
      "val Loss: 0.7259 Acc: 0.8360\n",
      "test Loss: 0.7178 Acc: 0.8480\n",
      "Epoch 1051/1499\n",
      "----------\n",
      "train Loss: 0.7192 Acc: 0.8358\n",
      "val Loss: 0.7163 Acc: 0.8520\n",
      "test Loss: 0.7154 Acc: 0.8560\n",
      "Epoch 1052/1499\n",
      "----------\n",
      "train Loss: 0.7158 Acc: 0.8416\n",
      "val Loss: 0.7200 Acc: 0.8360\n",
      "test Loss: 0.7056 Acc: 0.8560\n",
      "Epoch 1053/1499\n",
      "----------\n",
      "train Loss: 0.7149 Acc: 0.8404\n",
      "val Loss: 0.7110 Acc: 0.8440\n",
      "test Loss: 0.7251 Acc: 0.8400\n",
      "Epoch 1054/1499\n",
      "----------\n",
      "train Loss: 0.7188 Acc: 0.8371\n",
      "val Loss: 0.7267 Acc: 0.8320\n",
      "test Loss: 0.6960 Acc: 0.8840\n",
      "Epoch 1055/1499\n",
      "----------\n",
      "train Loss: 0.7140 Acc: 0.8431\n",
      "val Loss: 0.7220 Acc: 0.8280\n",
      "test Loss: 0.7191 Acc: 0.8400\n",
      "Epoch 1056/1499\n",
      "----------\n",
      "train Loss: 0.7136 Acc: 0.8449\n",
      "val Loss: 0.7080 Acc: 0.8520\n",
      "test Loss: 0.7139 Acc: 0.8600\n",
      "Epoch 1057/1499\n",
      "----------\n",
      "train Loss: 0.7189 Acc: 0.8378\n",
      "val Loss: 0.7055 Acc: 0.8520\n",
      "test Loss: 0.7077 Acc: 0.8600\n",
      "Epoch 1058/1499\n",
      "----------\n",
      "train Loss: 0.7152 Acc: 0.8424\n",
      "val Loss: 0.7202 Acc: 0.8360\n",
      "test Loss: 0.7001 Acc: 0.8640\n",
      "Epoch 1059/1499\n",
      "----------\n",
      "train Loss: 0.7185 Acc: 0.8387\n",
      "val Loss: 0.7326 Acc: 0.8120\n",
      "test Loss: 0.6983 Acc: 0.8800\n",
      "Epoch 1060/1499\n",
      "----------\n",
      "train Loss: 0.7229 Acc: 0.8324\n",
      "val Loss: 0.7202 Acc: 0.8400\n",
      "test Loss: 0.7217 Acc: 0.8320\n",
      "Epoch 1061/1499\n",
      "----------\n",
      "train Loss: 0.7150 Acc: 0.8442\n",
      "val Loss: 0.7309 Acc: 0.8240\n",
      "test Loss: 0.7061 Acc: 0.8680\n",
      "Epoch 1062/1499\n",
      "----------\n",
      "train Loss: 0.7125 Acc: 0.8424\n",
      "val Loss: 0.7115 Acc: 0.8400\n",
      "test Loss: 0.7052 Acc: 0.8640\n",
      "Epoch 1063/1499\n",
      "----------\n",
      "train Loss: 0.7120 Acc: 0.8462\n",
      "val Loss: 0.7277 Acc: 0.8240\n",
      "test Loss: 0.7028 Acc: 0.8600\n",
      "Epoch 1064/1499\n",
      "----------\n",
      "train Loss: 0.7175 Acc: 0.8400\n",
      "val Loss: 0.7183 Acc: 0.8360\n",
      "test Loss: 0.7169 Acc: 0.8440\n",
      "Epoch 1065/1499\n",
      "----------\n",
      "train Loss: 0.7155 Acc: 0.8416\n",
      "val Loss: 0.7082 Acc: 0.8680\n",
      "test Loss: 0.7015 Acc: 0.8640\n",
      "Epoch 1066/1499\n",
      "----------\n",
      "train Loss: 0.7191 Acc: 0.8393\n",
      "val Loss: 0.7341 Acc: 0.8160\n",
      "test Loss: 0.7250 Acc: 0.8360\n",
      "Epoch 1067/1499\n",
      "----------\n",
      "train Loss: 0.7199 Acc: 0.8333\n",
      "val Loss: 0.7368 Acc: 0.8120\n",
      "test Loss: 0.7172 Acc: 0.8400\n",
      "Epoch 1068/1499\n",
      "----------\n",
      "train Loss: 0.7163 Acc: 0.8413\n",
      "val Loss: 0.7219 Acc: 0.8360\n",
      "test Loss: 0.7111 Acc: 0.8520\n",
      "Epoch 1069/1499\n",
      "----------\n",
      "train Loss: 0.7208 Acc: 0.8364\n",
      "val Loss: 0.7446 Acc: 0.7880\n",
      "test Loss: 0.7002 Acc: 0.8680\n",
      "Epoch 1070/1499\n",
      "----------\n",
      "train Loss: 0.7153 Acc: 0.8436\n",
      "val Loss: 0.7277 Acc: 0.8240\n",
      "test Loss: 0.7031 Acc: 0.8560\n",
      "Epoch 1071/1499\n",
      "----------\n",
      "train Loss: 0.7158 Acc: 0.8427\n",
      "val Loss: 0.7288 Acc: 0.8240\n",
      "test Loss: 0.7076 Acc: 0.8640\n",
      "Epoch 1072/1499\n",
      "----------\n",
      "train Loss: 0.7141 Acc: 0.8444\n",
      "val Loss: 0.7107 Acc: 0.8400\n",
      "test Loss: 0.6908 Acc: 0.8800\n",
      "Epoch 1073/1499\n",
      "----------\n",
      "train Loss: 0.7158 Acc: 0.8402\n",
      "val Loss: 0.7188 Acc: 0.8360\n",
      "test Loss: 0.7046 Acc: 0.8640\n",
      "Epoch 1074/1499\n",
      "----------\n",
      "train Loss: 0.7156 Acc: 0.8409\n",
      "val Loss: 0.7085 Acc: 0.8560\n",
      "test Loss: 0.7105 Acc: 0.8640\n",
      "Epoch 1075/1499\n",
      "----------\n",
      "train Loss: 0.7193 Acc: 0.8380\n",
      "val Loss: 0.7324 Acc: 0.8240\n",
      "test Loss: 0.7057 Acc: 0.8600\n",
      "Epoch 1076/1499\n",
      "----------\n",
      "train Loss: 0.7167 Acc: 0.8391\n",
      "val Loss: 0.7217 Acc: 0.8360\n",
      "test Loss: 0.6986 Acc: 0.8800\n",
      "Epoch 1077/1499\n",
      "----------\n",
      "train Loss: 0.7197 Acc: 0.8347\n",
      "val Loss: 0.7169 Acc: 0.8320\n",
      "test Loss: 0.7024 Acc: 0.8600\n",
      "Epoch 1078/1499\n",
      "----------\n",
      "train Loss: 0.7169 Acc: 0.8371\n",
      "val Loss: 0.7156 Acc: 0.8440\n",
      "test Loss: 0.7138 Acc: 0.8480\n",
      "Epoch 1079/1499\n",
      "----------\n",
      "train Loss: 0.7162 Acc: 0.8393\n",
      "val Loss: 0.7101 Acc: 0.8600\n",
      "test Loss: 0.7031 Acc: 0.8720\n",
      "Epoch 1080/1499\n",
      "----------\n",
      "train Loss: 0.7141 Acc: 0.8413\n",
      "val Loss: 0.7287 Acc: 0.8240\n",
      "test Loss: 0.7010 Acc: 0.8640\n",
      "Epoch 1081/1499\n",
      "----------\n",
      "train Loss: 0.7148 Acc: 0.8409\n",
      "val Loss: 0.7121 Acc: 0.8400\n",
      "test Loss: 0.6996 Acc: 0.8640\n",
      "Epoch 1082/1499\n",
      "----------\n",
      "train Loss: 0.7173 Acc: 0.8389\n",
      "val Loss: 0.7094 Acc: 0.8560\n",
      "test Loss: 0.7154 Acc: 0.8480\n",
      "Epoch 1083/1499\n",
      "----------\n",
      "train Loss: 0.7165 Acc: 0.8393\n",
      "val Loss: 0.7259 Acc: 0.8240\n",
      "test Loss: 0.7233 Acc: 0.8400\n",
      "Epoch 1084/1499\n",
      "----------\n",
      "train Loss: 0.7169 Acc: 0.8400\n",
      "val Loss: 0.7254 Acc: 0.8240\n",
      "test Loss: 0.7158 Acc: 0.8480\n",
      "Epoch 1085/1499\n",
      "----------\n",
      "train Loss: 0.7178 Acc: 0.8387\n",
      "val Loss: 0.7309 Acc: 0.8120\n",
      "test Loss: 0.6958 Acc: 0.8720\n",
      "Epoch 1086/1499\n",
      "----------\n",
      "train Loss: 0.7147 Acc: 0.8433\n",
      "val Loss: 0.7149 Acc: 0.8360\n",
      "test Loss: 0.7222 Acc: 0.8400\n",
      "Epoch 1087/1499\n",
      "----------\n",
      "train Loss: 0.7157 Acc: 0.8402\n",
      "val Loss: 0.7176 Acc: 0.8400\n",
      "test Loss: 0.7015 Acc: 0.8600\n",
      "Epoch 1088/1499\n",
      "----------\n",
      "train Loss: 0.7157 Acc: 0.8418\n",
      "val Loss: 0.7171 Acc: 0.8400\n",
      "test Loss: 0.7239 Acc: 0.8280\n",
      "Epoch 1089/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.7149 Acc: 0.8420\n",
      "val Loss: 0.7259 Acc: 0.8320\n",
      "test Loss: 0.6940 Acc: 0.8760\n",
      "Epoch 1090/1499\n",
      "----------\n",
      "train Loss: 0.7154 Acc: 0.8393\n",
      "val Loss: 0.7168 Acc: 0.8400\n",
      "test Loss: 0.7080 Acc: 0.8560\n",
      "Epoch 1091/1499\n",
      "----------\n",
      "train Loss: 0.7123 Acc: 0.8473\n",
      "val Loss: 0.7176 Acc: 0.8440\n",
      "test Loss: 0.7052 Acc: 0.8680\n",
      "Epoch 1092/1499\n",
      "----------\n",
      "train Loss: 0.7160 Acc: 0.8387\n",
      "val Loss: 0.7166 Acc: 0.8400\n",
      "test Loss: 0.7012 Acc: 0.8640\n",
      "Epoch 1093/1499\n",
      "----------\n",
      "train Loss: 0.7137 Acc: 0.8424\n",
      "val Loss: 0.7211 Acc: 0.8400\n",
      "test Loss: 0.7273 Acc: 0.8320\n",
      "Epoch 1094/1499\n",
      "----------\n",
      "train Loss: 0.7137 Acc: 0.8424\n",
      "val Loss: 0.7161 Acc: 0.8400\n",
      "test Loss: 0.7037 Acc: 0.8640\n",
      "Epoch 1095/1499\n",
      "----------\n",
      "train Loss: 0.7128 Acc: 0.8418\n",
      "val Loss: 0.7323 Acc: 0.8200\n",
      "test Loss: 0.7128 Acc: 0.8560\n",
      "Epoch 1096/1499\n",
      "----------\n",
      "train Loss: 0.7155 Acc: 0.8393\n",
      "val Loss: 0.7095 Acc: 0.8440\n",
      "test Loss: 0.7121 Acc: 0.8440\n",
      "Epoch 1097/1499\n",
      "----------\n",
      "train Loss: 0.7189 Acc: 0.8373\n",
      "val Loss: 0.7258 Acc: 0.8240\n",
      "test Loss: 0.7118 Acc: 0.8560\n",
      "Epoch 1098/1499\n",
      "----------\n",
      "train Loss: 0.7121 Acc: 0.8429\n",
      "val Loss: 0.7121 Acc: 0.8520\n",
      "test Loss: 0.6982 Acc: 0.8720\n",
      "Epoch 1099/1499\n",
      "----------\n",
      "train Loss: 0.7139 Acc: 0.8447\n",
      "val Loss: 0.7100 Acc: 0.8560\n",
      "test Loss: 0.7293 Acc: 0.8360\n",
      "Epoch 1100/1499\n",
      "----------\n",
      "train Loss: 0.7138 Acc: 0.8440\n",
      "val Loss: 0.7232 Acc: 0.8400\n",
      "test Loss: 0.7041 Acc: 0.8760\n",
      "Epoch 1101/1499\n",
      "----------\n",
      "train Loss: 0.7127 Acc: 0.8447\n",
      "val Loss: 0.7231 Acc: 0.8280\n",
      "test Loss: 0.6968 Acc: 0.8760\n",
      "Epoch 1102/1499\n",
      "----------\n",
      "train Loss: 0.7117 Acc: 0.8451\n",
      "val Loss: 0.7230 Acc: 0.8320\n",
      "test Loss: 0.7043 Acc: 0.8600\n",
      "Epoch 1103/1499\n",
      "----------\n",
      "train Loss: 0.7128 Acc: 0.8438\n",
      "val Loss: 0.7051 Acc: 0.8560\n",
      "test Loss: 0.7044 Acc: 0.8680\n",
      "Epoch 1104/1499\n",
      "----------\n",
      "train Loss: 0.7123 Acc: 0.8427\n",
      "val Loss: 0.7095 Acc: 0.8480\n",
      "test Loss: 0.7166 Acc: 0.8520\n",
      "Epoch 1105/1499\n",
      "----------\n",
      "train Loss: 0.7149 Acc: 0.8418\n",
      "val Loss: 0.7211 Acc: 0.8360\n",
      "test Loss: 0.7093 Acc: 0.8520\n",
      "Epoch 1106/1499\n",
      "----------\n",
      "train Loss: 0.7134 Acc: 0.8440\n",
      "val Loss: 0.7105 Acc: 0.8520\n",
      "test Loss: 0.7078 Acc: 0.8520\n",
      "Epoch 1107/1499\n",
      "----------\n",
      "train Loss: 0.7144 Acc: 0.8433\n",
      "val Loss: 0.7104 Acc: 0.8480\n",
      "test Loss: 0.7052 Acc: 0.8600\n",
      "Epoch 1108/1499\n",
      "----------\n",
      "train Loss: 0.7139 Acc: 0.8424\n",
      "val Loss: 0.7346 Acc: 0.8120\n",
      "test Loss: 0.7036 Acc: 0.8640\n",
      "Epoch 1109/1499\n",
      "----------\n",
      "train Loss: 0.7133 Acc: 0.8411\n",
      "val Loss: 0.7147 Acc: 0.8400\n",
      "test Loss: 0.6872 Acc: 0.8760\n",
      "Epoch 1110/1499\n",
      "----------\n",
      "train Loss: 0.7114 Acc: 0.8469\n",
      "val Loss: 0.7375 Acc: 0.8120\n",
      "test Loss: 0.7157 Acc: 0.8480\n",
      "Epoch 1111/1499\n",
      "----------\n",
      "train Loss: 0.7136 Acc: 0.8427\n",
      "val Loss: 0.6992 Acc: 0.8600\n",
      "test Loss: 0.7163 Acc: 0.8440\n",
      "Epoch 1112/1499\n",
      "----------\n",
      "train Loss: 0.7145 Acc: 0.8378\n",
      "val Loss: 0.7125 Acc: 0.8360\n",
      "test Loss: 0.7237 Acc: 0.8440\n",
      "Epoch 1113/1499\n",
      "----------\n",
      "train Loss: 0.7137 Acc: 0.8416\n",
      "val Loss: 0.7240 Acc: 0.8280\n",
      "test Loss: 0.7131 Acc: 0.8640\n",
      "Epoch 1114/1499\n",
      "----------\n",
      "train Loss: 0.7117 Acc: 0.8440\n",
      "val Loss: 0.7068 Acc: 0.8400\n",
      "test Loss: 0.6953 Acc: 0.8760\n",
      "Epoch 1115/1499\n",
      "----------\n",
      "train Loss: 0.7135 Acc: 0.8398\n",
      "val Loss: 0.7266 Acc: 0.8120\n",
      "test Loss: 0.6994 Acc: 0.8640\n",
      "Epoch 1116/1499\n",
      "----------\n",
      "train Loss: 0.7146 Acc: 0.8418\n",
      "val Loss: 0.7209 Acc: 0.8240\n",
      "test Loss: 0.7124 Acc: 0.8480\n",
      "Epoch 1117/1499\n",
      "----------\n",
      "train Loss: 0.7130 Acc: 0.8464\n",
      "val Loss: 0.7262 Acc: 0.8240\n",
      "test Loss: 0.7060 Acc: 0.8640\n",
      "Epoch 1118/1499\n",
      "----------\n",
      "train Loss: 0.7135 Acc: 0.8411\n",
      "val Loss: 0.7066 Acc: 0.8400\n",
      "test Loss: 0.7010 Acc: 0.8600\n",
      "Epoch 1119/1499\n",
      "----------\n",
      "train Loss: 0.7160 Acc: 0.8393\n",
      "val Loss: 0.7099 Acc: 0.8360\n",
      "test Loss: 0.7124 Acc: 0.8480\n",
      "Epoch 1120/1499\n",
      "----------\n",
      "train Loss: 0.7125 Acc: 0.8449\n",
      "val Loss: 0.7094 Acc: 0.8400\n",
      "test Loss: 0.7111 Acc: 0.8560\n",
      "Epoch 1121/1499\n",
      "----------\n",
      "train Loss: 0.7128 Acc: 0.8464\n",
      "val Loss: 0.7317 Acc: 0.8080\n",
      "test Loss: 0.7095 Acc: 0.8560\n",
      "Epoch 1122/1499\n",
      "----------\n",
      "train Loss: 0.7123 Acc: 0.8433\n",
      "val Loss: 0.7355 Acc: 0.8200\n",
      "test Loss: 0.7052 Acc: 0.8560\n",
      "Epoch 1123/1499\n",
      "----------\n",
      "train Loss: 0.7121 Acc: 0.8413\n",
      "val Loss: 0.7157 Acc: 0.8360\n",
      "test Loss: 0.7084 Acc: 0.8600\n",
      "Epoch 1124/1499\n",
      "----------\n",
      "train Loss: 0.7108 Acc: 0.8433\n",
      "val Loss: 0.7064 Acc: 0.8440\n",
      "test Loss: 0.7063 Acc: 0.8600\n",
      "Epoch 1125/1499\n",
      "----------\n",
      "train Loss: 0.7119 Acc: 0.8433\n",
      "val Loss: 0.7136 Acc: 0.8400\n",
      "test Loss: 0.7100 Acc: 0.8600\n",
      "Epoch 1126/1499\n",
      "----------\n",
      "train Loss: 0.7127 Acc: 0.8418\n",
      "val Loss: 0.7134 Acc: 0.8240\n",
      "test Loss: 0.7055 Acc: 0.8720\n",
      "Epoch 1127/1499\n",
      "----------\n",
      "train Loss: 0.7136 Acc: 0.8391\n",
      "val Loss: 0.7184 Acc: 0.8400\n",
      "test Loss: 0.7104 Acc: 0.8480\n",
      "Epoch 1128/1499\n",
      "----------\n",
      "train Loss: 0.7176 Acc: 0.8378\n",
      "val Loss: 0.7078 Acc: 0.8400\n",
      "test Loss: 0.7214 Acc: 0.8400\n",
      "Epoch 1129/1499\n",
      "----------\n",
      "train Loss: 0.7113 Acc: 0.8404\n",
      "val Loss: 0.7157 Acc: 0.8320\n",
      "test Loss: 0.6977 Acc: 0.8600\n",
      "Epoch 1130/1499\n",
      "----------\n",
      "train Loss: 0.7127 Acc: 0.8436\n",
      "val Loss: 0.7075 Acc: 0.8440\n",
      "test Loss: 0.7139 Acc: 0.8480\n",
      "Epoch 1131/1499\n",
      "----------\n",
      "train Loss: 0.7144 Acc: 0.8411\n",
      "val Loss: 0.7140 Acc: 0.8360\n",
      "test Loss: 0.7180 Acc: 0.8440\n",
      "Epoch 1132/1499\n",
      "----------\n",
      "train Loss: 0.7106 Acc: 0.8444\n",
      "val Loss: 0.7189 Acc: 0.8240\n",
      "test Loss: 0.7175 Acc: 0.8400\n",
      "Epoch 1133/1499\n",
      "----------\n",
      "train Loss: 0.7135 Acc: 0.8371\n",
      "val Loss: 0.7215 Acc: 0.8280\n",
      "test Loss: 0.7262 Acc: 0.8360\n",
      "Epoch 1134/1499\n",
      "----------\n",
      "train Loss: 0.7078 Acc: 0.8487\n",
      "val Loss: 0.7148 Acc: 0.8400\n",
      "test Loss: 0.6966 Acc: 0.8680\n",
      "Epoch 1135/1499\n",
      "----------\n",
      "train Loss: 0.7142 Acc: 0.8382\n",
      "val Loss: 0.7145 Acc: 0.8480\n",
      "test Loss: 0.6953 Acc: 0.8720\n",
      "Epoch 1136/1499\n",
      "----------\n",
      "train Loss: 0.7133 Acc: 0.8400\n",
      "val Loss: 0.7080 Acc: 0.8440\n",
      "test Loss: 0.6901 Acc: 0.8800\n",
      "Epoch 1137/1499\n",
      "----------\n",
      "train Loss: 0.7115 Acc: 0.8440\n",
      "val Loss: 0.7041 Acc: 0.8600\n",
      "test Loss: 0.7026 Acc: 0.8680\n",
      "Epoch 1138/1499\n",
      "----------\n",
      "train Loss: 0.7117 Acc: 0.8413\n",
      "val Loss: 0.7128 Acc: 0.8480\n",
      "test Loss: 0.7077 Acc: 0.8480\n",
      "Epoch 1139/1499\n",
      "----------\n",
      "train Loss: 0.7101 Acc: 0.8464\n",
      "val Loss: 0.7123 Acc: 0.8440\n",
      "test Loss: 0.7071 Acc: 0.8520\n",
      "Epoch 1140/1499\n",
      "----------\n",
      "train Loss: 0.7134 Acc: 0.8418\n",
      "val Loss: 0.7262 Acc: 0.8280\n",
      "test Loss: 0.7133 Acc: 0.8440\n",
      "Epoch 1141/1499\n",
      "----------\n",
      "train Loss: 0.7081 Acc: 0.8476\n",
      "val Loss: 0.7185 Acc: 0.8320\n",
      "test Loss: 0.7121 Acc: 0.8560\n",
      "Epoch 1142/1499\n",
      "----------\n",
      "train Loss: 0.7115 Acc: 0.8422\n",
      "val Loss: 0.7141 Acc: 0.8360\n",
      "test Loss: 0.6849 Acc: 0.8760\n",
      "Epoch 1143/1499\n",
      "----------\n",
      "train Loss: 0.7097 Acc: 0.8458\n",
      "val Loss: 0.7161 Acc: 0.8320\n",
      "test Loss: 0.7023 Acc: 0.8680\n",
      "Epoch 1144/1499\n",
      "----------\n",
      "train Loss: 0.7123 Acc: 0.8429\n",
      "val Loss: 0.7035 Acc: 0.8560\n",
      "test Loss: 0.7047 Acc: 0.8640\n",
      "Epoch 1145/1499\n",
      "----------\n",
      "train Loss: 0.7115 Acc: 0.8433\n",
      "val Loss: 0.7090 Acc: 0.8360\n",
      "test Loss: 0.7219 Acc: 0.8400\n",
      "Epoch 1146/1499\n",
      "----------\n",
      "train Loss: 0.7103 Acc: 0.8464\n",
      "val Loss: 0.7038 Acc: 0.8480\n",
      "test Loss: 0.6976 Acc: 0.8760\n",
      "Epoch 1147/1499\n",
      "----------\n",
      "train Loss: 0.7128 Acc: 0.8451\n",
      "val Loss: 0.7125 Acc: 0.8400\n",
      "test Loss: 0.7062 Acc: 0.8520\n",
      "Epoch 1148/1499\n",
      "----------\n",
      "train Loss: 0.7148 Acc: 0.8389\n",
      "val Loss: 0.7305 Acc: 0.8160\n",
      "test Loss: 0.7129 Acc: 0.8480\n",
      "Epoch 1149/1499\n",
      "----------\n",
      "train Loss: 0.7153 Acc: 0.8367\n",
      "val Loss: 0.7170 Acc: 0.8240\n",
      "test Loss: 0.7139 Acc: 0.8440\n",
      "Epoch 1150/1499\n",
      "----------\n",
      "train Loss: 0.7099 Acc: 0.8424\n",
      "val Loss: 0.7137 Acc: 0.8320\n",
      "test Loss: 0.7059 Acc: 0.8600\n",
      "Epoch 1151/1499\n",
      "----------\n",
      "train Loss: 0.7134 Acc: 0.8387\n",
      "val Loss: 0.7238 Acc: 0.8240\n",
      "test Loss: 0.7154 Acc: 0.8320\n",
      "Epoch 1152/1499\n",
      "----------\n",
      "train Loss: 0.7118 Acc: 0.8424\n",
      "val Loss: 0.7215 Acc: 0.8240\n",
      "test Loss: 0.7107 Acc: 0.8520\n",
      "Epoch 1153/1499\n",
      "----------\n",
      "train Loss: 0.7105 Acc: 0.8440\n",
      "val Loss: 0.7031 Acc: 0.8600\n",
      "test Loss: 0.7030 Acc: 0.8640\n",
      "Epoch 1154/1499\n",
      "----------\n",
      "train Loss: 0.7131 Acc: 0.8407\n",
      "val Loss: 0.7022 Acc: 0.8480\n",
      "test Loss: 0.6956 Acc: 0.8720\n",
      "Epoch 1155/1499\n",
      "----------\n",
      "train Loss: 0.7134 Acc: 0.8396\n",
      "val Loss: 0.7100 Acc: 0.8400\n",
      "test Loss: 0.7122 Acc: 0.8520\n",
      "Epoch 1156/1499\n",
      "----------\n",
      "train Loss: 0.7134 Acc: 0.8389\n",
      "val Loss: 0.7037 Acc: 0.8560\n",
      "test Loss: 0.6956 Acc: 0.8640\n",
      "Epoch 1157/1499\n",
      "----------\n",
      "train Loss: 0.7097 Acc: 0.8447\n",
      "val Loss: 0.7184 Acc: 0.8240\n",
      "test Loss: 0.7061 Acc: 0.8600\n",
      "Epoch 1158/1499\n",
      "----------\n",
      "train Loss: 0.7124 Acc: 0.8404\n",
      "val Loss: 0.7097 Acc: 0.8440\n",
      "test Loss: 0.7094 Acc: 0.8560\n",
      "Epoch 1159/1499\n",
      "----------\n",
      "train Loss: 0.7135 Acc: 0.8391\n",
      "val Loss: 0.7137 Acc: 0.8320\n",
      "test Loss: 0.7014 Acc: 0.8680\n",
      "Epoch 1160/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.7133 Acc: 0.8389\n",
      "val Loss: 0.7099 Acc: 0.8320\n",
      "test Loss: 0.7026 Acc: 0.8600\n",
      "Epoch 1161/1499\n",
      "----------\n",
      "train Loss: 0.7088 Acc: 0.8427\n",
      "val Loss: 0.7183 Acc: 0.8440\n",
      "test Loss: 0.7036 Acc: 0.8560\n",
      "Epoch 1162/1499\n",
      "----------\n",
      "train Loss: 0.7082 Acc: 0.8469\n",
      "val Loss: 0.7165 Acc: 0.8360\n",
      "test Loss: 0.6994 Acc: 0.8640\n",
      "Epoch 1163/1499\n",
      "----------\n",
      "train Loss: 0.7122 Acc: 0.8409\n",
      "val Loss: 0.6984 Acc: 0.8640\n",
      "test Loss: 0.7039 Acc: 0.8640\n",
      "Epoch 1164/1499\n",
      "----------\n",
      "train Loss: 0.7121 Acc: 0.8424\n",
      "val Loss: 0.7206 Acc: 0.8360\n",
      "test Loss: 0.7077 Acc: 0.8520\n",
      "Epoch 1165/1499\n",
      "----------\n",
      "train Loss: 0.7137 Acc: 0.8416\n",
      "val Loss: 0.7114 Acc: 0.8480\n",
      "test Loss: 0.7000 Acc: 0.8640\n",
      "Epoch 1166/1499\n",
      "----------\n",
      "train Loss: 0.7151 Acc: 0.8362\n",
      "val Loss: 0.7228 Acc: 0.8280\n",
      "test Loss: 0.7240 Acc: 0.8280\n",
      "Epoch 1167/1499\n",
      "----------\n",
      "train Loss: 0.7140 Acc: 0.8360\n",
      "val Loss: 0.7092 Acc: 0.8480\n",
      "test Loss: 0.7223 Acc: 0.8280\n",
      "Epoch 1168/1499\n",
      "----------\n",
      "train Loss: 0.7094 Acc: 0.8451\n",
      "val Loss: 0.7249 Acc: 0.8280\n",
      "test Loss: 0.7090 Acc: 0.8560\n",
      "Epoch 1169/1499\n",
      "----------\n",
      "train Loss: 0.7117 Acc: 0.8391\n",
      "val Loss: 0.7142 Acc: 0.8320\n",
      "test Loss: 0.6996 Acc: 0.8680\n",
      "Epoch 1170/1499\n",
      "----------\n",
      "train Loss: 0.7157 Acc: 0.8387\n",
      "val Loss: 0.7170 Acc: 0.8400\n",
      "test Loss: 0.7171 Acc: 0.8320\n",
      "Epoch 1171/1499\n",
      "----------\n",
      "train Loss: 0.7098 Acc: 0.8449\n",
      "val Loss: 0.7295 Acc: 0.8280\n",
      "test Loss: 0.7097 Acc: 0.8520\n",
      "Epoch 1172/1499\n",
      "----------\n",
      "train Loss: 0.7075 Acc: 0.8471\n",
      "val Loss: 0.7170 Acc: 0.8240\n",
      "test Loss: 0.7100 Acc: 0.8440\n",
      "Epoch 1173/1499\n",
      "----------\n",
      "train Loss: 0.7089 Acc: 0.8458\n",
      "val Loss: 0.7113 Acc: 0.8400\n",
      "test Loss: 0.7074 Acc: 0.8480\n",
      "Epoch 1174/1499\n",
      "----------\n",
      "train Loss: 0.7115 Acc: 0.8389\n",
      "val Loss: 0.7055 Acc: 0.8520\n",
      "test Loss: 0.7010 Acc: 0.8640\n",
      "Epoch 1175/1499\n",
      "----------\n",
      "train Loss: 0.7096 Acc: 0.8431\n",
      "val Loss: 0.7192 Acc: 0.8360\n",
      "test Loss: 0.6985 Acc: 0.8680\n",
      "Epoch 1176/1499\n",
      "----------\n",
      "train Loss: 0.7129 Acc: 0.8402\n",
      "val Loss: 0.7243 Acc: 0.8320\n",
      "test Loss: 0.7026 Acc: 0.8560\n",
      "Epoch 1177/1499\n",
      "----------\n",
      "train Loss: 0.7092 Acc: 0.8422\n",
      "val Loss: 0.7113 Acc: 0.8400\n",
      "test Loss: 0.7087 Acc: 0.8480\n",
      "Epoch 1178/1499\n",
      "----------\n",
      "train Loss: 0.7133 Acc: 0.8376\n",
      "val Loss: 0.7048 Acc: 0.8400\n",
      "test Loss: 0.7117 Acc: 0.8480\n",
      "Epoch 1179/1499\n",
      "----------\n",
      "train Loss: 0.7087 Acc: 0.8438\n",
      "val Loss: 0.6975 Acc: 0.8560\n",
      "test Loss: 0.7115 Acc: 0.8480\n",
      "Epoch 1180/1499\n",
      "----------\n",
      "train Loss: 0.7079 Acc: 0.8456\n",
      "val Loss: 0.7089 Acc: 0.8440\n",
      "test Loss: 0.7096 Acc: 0.8440\n",
      "Epoch 1181/1499\n",
      "----------\n",
      "train Loss: 0.7089 Acc: 0.8444\n",
      "val Loss: 0.7050 Acc: 0.8560\n",
      "test Loss: 0.7168 Acc: 0.8400\n",
      "Epoch 1182/1499\n",
      "----------\n",
      "train Loss: 0.7097 Acc: 0.8402\n",
      "val Loss: 0.7101 Acc: 0.8520\n",
      "test Loss: 0.7127 Acc: 0.8440\n",
      "Epoch 1183/1499\n",
      "----------\n",
      "train Loss: 0.7117 Acc: 0.8396\n",
      "val Loss: 0.7105 Acc: 0.8520\n",
      "test Loss: 0.6968 Acc: 0.8600\n",
      "Epoch 1184/1499\n",
      "----------\n",
      "train Loss: 0.7134 Acc: 0.8389\n",
      "val Loss: 0.7103 Acc: 0.8520\n",
      "test Loss: 0.7035 Acc: 0.8560\n",
      "Epoch 1185/1499\n",
      "----------\n",
      "train Loss: 0.7102 Acc: 0.8413\n",
      "val Loss: 0.7211 Acc: 0.8440\n",
      "test Loss: 0.7164 Acc: 0.8400\n",
      "Epoch 1186/1499\n",
      "----------\n",
      "train Loss: 0.7095 Acc: 0.8442\n",
      "val Loss: 0.7190 Acc: 0.8320\n",
      "test Loss: 0.7125 Acc: 0.8560\n",
      "Epoch 1187/1499\n",
      "----------\n",
      "train Loss: 0.7104 Acc: 0.8418\n",
      "val Loss: 0.7139 Acc: 0.8440\n",
      "test Loss: 0.7153 Acc: 0.8560\n",
      "Epoch 1188/1499\n",
      "----------\n",
      "train Loss: 0.7091 Acc: 0.8420\n",
      "val Loss: 0.7089 Acc: 0.8480\n",
      "test Loss: 0.7276 Acc: 0.8240\n",
      "Epoch 1189/1499\n",
      "----------\n",
      "train Loss: 0.7089 Acc: 0.8460\n",
      "val Loss: 0.7065 Acc: 0.8520\n",
      "test Loss: 0.6920 Acc: 0.8760\n",
      "Epoch 1190/1499\n",
      "----------\n",
      "train Loss: 0.7118 Acc: 0.8402\n",
      "val Loss: 0.7210 Acc: 0.8360\n",
      "test Loss: 0.7185 Acc: 0.8400\n",
      "Epoch 1191/1499\n",
      "----------\n",
      "train Loss: 0.7104 Acc: 0.8411\n",
      "val Loss: 0.7138 Acc: 0.8400\n",
      "test Loss: 0.7017 Acc: 0.8640\n",
      "Epoch 1192/1499\n",
      "----------\n",
      "train Loss: 0.7110 Acc: 0.8444\n",
      "val Loss: 0.7190 Acc: 0.8280\n",
      "test Loss: 0.7078 Acc: 0.8440\n",
      "Epoch 1193/1499\n",
      "----------\n",
      "train Loss: 0.7091 Acc: 0.8453\n",
      "val Loss: 0.7146 Acc: 0.8320\n",
      "test Loss: 0.7151 Acc: 0.8440\n",
      "Epoch 1194/1499\n",
      "----------\n",
      "train Loss: 0.7112 Acc: 0.8402\n",
      "val Loss: 0.7186 Acc: 0.8320\n",
      "test Loss: 0.7074 Acc: 0.8600\n",
      "Epoch 1195/1499\n",
      "----------\n",
      "train Loss: 0.7098 Acc: 0.8391\n",
      "val Loss: 0.7157 Acc: 0.8320\n",
      "test Loss: 0.7071 Acc: 0.8520\n",
      "Epoch 1196/1499\n",
      "----------\n",
      "train Loss: 0.7099 Acc: 0.8431\n",
      "val Loss: 0.7161 Acc: 0.8280\n",
      "test Loss: 0.7144 Acc: 0.8440\n",
      "Epoch 1197/1499\n",
      "----------\n",
      "train Loss: 0.7070 Acc: 0.8478\n",
      "val Loss: 0.7204 Acc: 0.8280\n",
      "test Loss: 0.7062 Acc: 0.8560\n",
      "Epoch 1198/1499\n",
      "----------\n",
      "train Loss: 0.7115 Acc: 0.8391\n",
      "val Loss: 0.7069 Acc: 0.8520\n",
      "test Loss: 0.7114 Acc: 0.8520\n",
      "Epoch 1199/1499\n",
      "----------\n",
      "train Loss: 0.7088 Acc: 0.8453\n",
      "val Loss: 0.7146 Acc: 0.8440\n",
      "test Loss: 0.6960 Acc: 0.8680\n",
      "Epoch 1200/1499\n",
      "----------\n",
      "train Loss: 0.7085 Acc: 0.8442\n",
      "val Loss: 0.7185 Acc: 0.8400\n",
      "test Loss: 0.7113 Acc: 0.8440\n",
      "Epoch 1201/1499\n",
      "----------\n",
      "train Loss: 0.7084 Acc: 0.8444\n",
      "val Loss: 0.7081 Acc: 0.8400\n",
      "test Loss: 0.7077 Acc: 0.8600\n",
      "Epoch 1202/1499\n",
      "----------\n",
      "train Loss: 0.7090 Acc: 0.8418\n",
      "val Loss: 0.7080 Acc: 0.8560\n",
      "test Loss: 0.6906 Acc: 0.8680\n",
      "Epoch 1203/1499\n",
      "----------\n",
      "train Loss: 0.7092 Acc: 0.8418\n",
      "val Loss: 0.6984 Acc: 0.8480\n",
      "test Loss: 0.7000 Acc: 0.8560\n",
      "Epoch 1204/1499\n",
      "----------\n",
      "train Loss: 0.7062 Acc: 0.8476\n",
      "val Loss: 0.7100 Acc: 0.8480\n",
      "test Loss: 0.7075 Acc: 0.8520\n",
      "Epoch 1205/1499\n",
      "----------\n",
      "train Loss: 0.7136 Acc: 0.8382\n",
      "val Loss: 0.7198 Acc: 0.8280\n",
      "test Loss: 0.6922 Acc: 0.8680\n",
      "Epoch 1206/1499\n",
      "----------\n",
      "train Loss: 0.7076 Acc: 0.8462\n",
      "val Loss: 0.7097 Acc: 0.8440\n",
      "test Loss: 0.7071 Acc: 0.8560\n",
      "Epoch 1207/1499\n",
      "----------\n",
      "train Loss: 0.7095 Acc: 0.8424\n",
      "val Loss: 0.7103 Acc: 0.8440\n",
      "test Loss: 0.7221 Acc: 0.8320\n",
      "Epoch 1208/1499\n",
      "----------\n",
      "train Loss: 0.7127 Acc: 0.8371\n",
      "val Loss: 0.7162 Acc: 0.8320\n",
      "test Loss: 0.7246 Acc: 0.8280\n",
      "Epoch 1209/1499\n",
      "----------\n",
      "train Loss: 0.7107 Acc: 0.8413\n",
      "val Loss: 0.7123 Acc: 0.8360\n",
      "test Loss: 0.6961 Acc: 0.8720\n",
      "Epoch 1210/1499\n",
      "----------\n",
      "train Loss: 0.7100 Acc: 0.8416\n",
      "val Loss: 0.7202 Acc: 0.8280\n",
      "test Loss: 0.7067 Acc: 0.8520\n",
      "Epoch 1211/1499\n",
      "----------\n",
      "train Loss: 0.7097 Acc: 0.8438\n",
      "val Loss: 0.7149 Acc: 0.8320\n",
      "test Loss: 0.7068 Acc: 0.8440\n",
      "Epoch 1212/1499\n",
      "----------\n",
      "train Loss: 0.7121 Acc: 0.8404\n",
      "val Loss: 0.7142 Acc: 0.8400\n",
      "test Loss: 0.6986 Acc: 0.8640\n",
      "Epoch 1213/1499\n",
      "----------\n",
      "train Loss: 0.7079 Acc: 0.8464\n",
      "val Loss: 0.6996 Acc: 0.8640\n",
      "test Loss: 0.7009 Acc: 0.8680\n",
      "Epoch 1214/1499\n",
      "----------\n",
      "train Loss: 0.7132 Acc: 0.8387\n",
      "val Loss: 0.6983 Acc: 0.8640\n",
      "test Loss: 0.6942 Acc: 0.8720\n",
      "Epoch 1215/1499\n",
      "----------\n",
      "train Loss: 0.7097 Acc: 0.8418\n",
      "val Loss: 0.7101 Acc: 0.8440\n",
      "test Loss: 0.7089 Acc: 0.8520\n",
      "Epoch 1216/1499\n",
      "----------\n",
      "train Loss: 0.7093 Acc: 0.8431\n",
      "val Loss: 0.7040 Acc: 0.8560\n",
      "test Loss: 0.7230 Acc: 0.8320\n",
      "Epoch 1217/1499\n",
      "----------\n",
      "train Loss: 0.7068 Acc: 0.8464\n",
      "val Loss: 0.7183 Acc: 0.8360\n",
      "test Loss: 0.7031 Acc: 0.8600\n",
      "Epoch 1218/1499\n",
      "----------\n",
      "train Loss: 0.7069 Acc: 0.8440\n",
      "val Loss: 0.7088 Acc: 0.8440\n",
      "test Loss: 0.7231 Acc: 0.8480\n",
      "Epoch 1219/1499\n",
      "----------\n",
      "train Loss: 0.7136 Acc: 0.8373\n",
      "val Loss: 0.7245 Acc: 0.8120\n",
      "test Loss: 0.6989 Acc: 0.8560\n",
      "Epoch 1220/1499\n",
      "----------\n",
      "train Loss: 0.7090 Acc: 0.8433\n",
      "val Loss: 0.7127 Acc: 0.8400\n",
      "test Loss: 0.7140 Acc: 0.8480\n",
      "Epoch 1221/1499\n",
      "----------\n",
      "train Loss: 0.7117 Acc: 0.8378\n",
      "val Loss: 0.7156 Acc: 0.8320\n",
      "test Loss: 0.7033 Acc: 0.8640\n",
      "Epoch 1222/1499\n",
      "----------\n",
      "train Loss: 0.7122 Acc: 0.8364\n",
      "val Loss: 0.7148 Acc: 0.8360\n",
      "test Loss: 0.7009 Acc: 0.8560\n",
      "Epoch 1223/1499\n",
      "----------\n",
      "train Loss: 0.7074 Acc: 0.8460\n",
      "val Loss: 0.7201 Acc: 0.8200\n",
      "test Loss: 0.7003 Acc: 0.8560\n",
      "Epoch 1224/1499\n",
      "----------\n",
      "train Loss: 0.7112 Acc: 0.8387\n",
      "val Loss: 0.7001 Acc: 0.8640\n",
      "test Loss: 0.7086 Acc: 0.8520\n",
      "Epoch 1225/1499\n",
      "----------\n",
      "train Loss: 0.7069 Acc: 0.8433\n",
      "val Loss: 0.7175 Acc: 0.8360\n",
      "test Loss: 0.6991 Acc: 0.8560\n",
      "Epoch 1226/1499\n",
      "----------\n",
      "train Loss: 0.7120 Acc: 0.8364\n",
      "val Loss: 0.7029 Acc: 0.8480\n",
      "test Loss: 0.7153 Acc: 0.8400\n",
      "Epoch 1227/1499\n",
      "----------\n",
      "train Loss: 0.7069 Acc: 0.8440\n",
      "val Loss: 0.7116 Acc: 0.8360\n",
      "test Loss: 0.7305 Acc: 0.8360\n",
      "Epoch 1228/1499\n",
      "----------\n",
      "train Loss: 0.7117 Acc: 0.8400\n",
      "val Loss: 0.7170 Acc: 0.8360\n",
      "test Loss: 0.6970 Acc: 0.8600\n",
      "Epoch 1229/1499\n",
      "----------\n",
      "train Loss: 0.7102 Acc: 0.8378\n",
      "val Loss: 0.6993 Acc: 0.8600\n",
      "test Loss: 0.7089 Acc: 0.8600\n",
      "Epoch 1230/1499\n",
      "----------\n",
      "train Loss: 0.7102 Acc: 0.8402\n",
      "val Loss: 0.7122 Acc: 0.8440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.7115 Acc: 0.8520\n",
      "Epoch 1231/1499\n",
      "----------\n",
      "train Loss: 0.7068 Acc: 0.8469\n",
      "val Loss: 0.7174 Acc: 0.8360\n",
      "test Loss: 0.7005 Acc: 0.8520\n",
      "Epoch 1232/1499\n",
      "----------\n",
      "train Loss: 0.7092 Acc: 0.8396\n",
      "val Loss: 0.7139 Acc: 0.8360\n",
      "test Loss: 0.7085 Acc: 0.8520\n",
      "Epoch 1233/1499\n",
      "----------\n",
      "train Loss: 0.7089 Acc: 0.8431\n",
      "val Loss: 0.7227 Acc: 0.8240\n",
      "test Loss: 0.7096 Acc: 0.8520\n",
      "Epoch 1234/1499\n",
      "----------\n",
      "train Loss: 0.7066 Acc: 0.8447\n",
      "val Loss: 0.7053 Acc: 0.8600\n",
      "test Loss: 0.7060 Acc: 0.8560\n",
      "Epoch 1235/1499\n",
      "----------\n",
      "train Loss: 0.7073 Acc: 0.8436\n",
      "val Loss: 0.7062 Acc: 0.8480\n",
      "test Loss: 0.6957 Acc: 0.8720\n",
      "Epoch 1236/1499\n",
      "----------\n",
      "train Loss: 0.7109 Acc: 0.8409\n",
      "val Loss: 0.7134 Acc: 0.8480\n",
      "test Loss: 0.7147 Acc: 0.8480\n",
      "Epoch 1237/1499\n",
      "----------\n",
      "train Loss: 0.7108 Acc: 0.8407\n",
      "val Loss: 0.7005 Acc: 0.8600\n",
      "test Loss: 0.6987 Acc: 0.8680\n",
      "Epoch 1238/1499\n",
      "----------\n",
      "train Loss: 0.7123 Acc: 0.8382\n",
      "val Loss: 0.6951 Acc: 0.8640\n",
      "test Loss: 0.6994 Acc: 0.8680\n",
      "Epoch 1239/1499\n",
      "----------\n",
      "train Loss: 0.7074 Acc: 0.8427\n",
      "val Loss: 0.7140 Acc: 0.8360\n",
      "test Loss: 0.7094 Acc: 0.8640\n",
      "Epoch 1240/1499\n",
      "----------\n",
      "train Loss: 0.7085 Acc: 0.8404\n",
      "val Loss: 0.7133 Acc: 0.8480\n",
      "test Loss: 0.7164 Acc: 0.8440\n",
      "Epoch 1241/1499\n",
      "----------\n",
      "train Loss: 0.7045 Acc: 0.8476\n",
      "val Loss: 0.7169 Acc: 0.8360\n",
      "test Loss: 0.7041 Acc: 0.8520\n",
      "Epoch 1242/1499\n",
      "----------\n",
      "train Loss: 0.7072 Acc: 0.8460\n",
      "val Loss: 0.7103 Acc: 0.8480\n",
      "test Loss: 0.6979 Acc: 0.8680\n",
      "Epoch 1243/1499\n",
      "----------\n",
      "train Loss: 0.7077 Acc: 0.8427\n",
      "val Loss: 0.7195 Acc: 0.8320\n",
      "test Loss: 0.7104 Acc: 0.8640\n",
      "Epoch 1244/1499\n",
      "----------\n",
      "train Loss: 0.7108 Acc: 0.8400\n",
      "val Loss: 0.7091 Acc: 0.8520\n",
      "test Loss: 0.7101 Acc: 0.8520\n",
      "Epoch 1245/1499\n",
      "----------\n",
      "train Loss: 0.7093 Acc: 0.8404\n",
      "val Loss: 0.7172 Acc: 0.8400\n",
      "test Loss: 0.7119 Acc: 0.8480\n",
      "Epoch 1246/1499\n",
      "----------\n",
      "train Loss: 0.7063 Acc: 0.8456\n",
      "val Loss: 0.7022 Acc: 0.8560\n",
      "test Loss: 0.7123 Acc: 0.8480\n",
      "Epoch 1247/1499\n",
      "----------\n",
      "train Loss: 0.7053 Acc: 0.8478\n",
      "val Loss: 0.7095 Acc: 0.8440\n",
      "test Loss: 0.7180 Acc: 0.8280\n",
      "Epoch 1248/1499\n",
      "----------\n",
      "train Loss: 0.7068 Acc: 0.8458\n",
      "val Loss: 0.7214 Acc: 0.8240\n",
      "test Loss: 0.6960 Acc: 0.8600\n",
      "Epoch 1249/1499\n",
      "----------\n",
      "train Loss: 0.7049 Acc: 0.8484\n",
      "val Loss: 0.7026 Acc: 0.8480\n",
      "test Loss: 0.7218 Acc: 0.8440\n",
      "Epoch 1250/1499\n",
      "----------\n",
      "train Loss: 0.7073 Acc: 0.8451\n",
      "val Loss: 0.7159 Acc: 0.8360\n",
      "test Loss: 0.6958 Acc: 0.8640\n",
      "Epoch 1251/1499\n",
      "----------\n",
      "train Loss: 0.7117 Acc: 0.8369\n",
      "val Loss: 0.7300 Acc: 0.8120\n",
      "test Loss: 0.7007 Acc: 0.8640\n",
      "Epoch 1252/1499\n",
      "----------\n",
      "train Loss: 0.7107 Acc: 0.8420\n",
      "val Loss: 0.6969 Acc: 0.8600\n",
      "test Loss: 0.7117 Acc: 0.8400\n",
      "Epoch 1253/1499\n",
      "----------\n",
      "train Loss: 0.7063 Acc: 0.8451\n",
      "val Loss: 0.6991 Acc: 0.8440\n",
      "test Loss: 0.7160 Acc: 0.8520\n",
      "Epoch 1254/1499\n",
      "----------\n",
      "train Loss: 0.7068 Acc: 0.8469\n",
      "val Loss: 0.7021 Acc: 0.8440\n",
      "test Loss: 0.7032 Acc: 0.8640\n",
      "Epoch 1255/1499\n",
      "----------\n",
      "train Loss: 0.7073 Acc: 0.8449\n",
      "val Loss: 0.7157 Acc: 0.8280\n",
      "test Loss: 0.7062 Acc: 0.8600\n",
      "Epoch 1256/1499\n",
      "----------\n",
      "train Loss: 0.7091 Acc: 0.8420\n",
      "val Loss: 0.7043 Acc: 0.8400\n",
      "test Loss: 0.6927 Acc: 0.8680\n",
      "Epoch 1257/1499\n",
      "----------\n",
      "train Loss: 0.7092 Acc: 0.8400\n",
      "val Loss: 0.7096 Acc: 0.8320\n",
      "test Loss: 0.7059 Acc: 0.8640\n",
      "Epoch 1258/1499\n",
      "----------\n",
      "train Loss: 0.7091 Acc: 0.8402\n",
      "val Loss: 0.7173 Acc: 0.8240\n",
      "test Loss: 0.7043 Acc: 0.8560\n",
      "Epoch 1259/1499\n",
      "----------\n",
      "train Loss: 0.7090 Acc: 0.8413\n",
      "val Loss: 0.7029 Acc: 0.8600\n",
      "test Loss: 0.7073 Acc: 0.8520\n",
      "Epoch 1260/1499\n",
      "----------\n",
      "train Loss: 0.7092 Acc: 0.8427\n",
      "val Loss: 0.7193 Acc: 0.8320\n",
      "test Loss: 0.7107 Acc: 0.8560\n",
      "Epoch 1261/1499\n",
      "----------\n",
      "train Loss: 0.7048 Acc: 0.8502\n",
      "val Loss: 0.7194 Acc: 0.8360\n",
      "test Loss: 0.7095 Acc: 0.8440\n",
      "Epoch 1262/1499\n",
      "----------\n",
      "train Loss: 0.7053 Acc: 0.8471\n",
      "val Loss: 0.7020 Acc: 0.8520\n",
      "test Loss: 0.6925 Acc: 0.8640\n",
      "Epoch 1263/1499\n",
      "----------\n",
      "train Loss: 0.7082 Acc: 0.8418\n",
      "val Loss: 0.7092 Acc: 0.8400\n",
      "test Loss: 0.7132 Acc: 0.8440\n",
      "Epoch 1264/1499\n",
      "----------\n",
      "train Loss: 0.7033 Acc: 0.8496\n",
      "val Loss: 0.7069 Acc: 0.8440\n",
      "test Loss: 0.7176 Acc: 0.8280\n",
      "Epoch 1265/1499\n",
      "----------\n",
      "train Loss: 0.7040 Acc: 0.8447\n",
      "val Loss: 0.7073 Acc: 0.8480\n",
      "test Loss: 0.7118 Acc: 0.8520\n",
      "Epoch 1266/1499\n",
      "----------\n",
      "train Loss: 0.7077 Acc: 0.8447\n",
      "val Loss: 0.7052 Acc: 0.8640\n",
      "test Loss: 0.6940 Acc: 0.8840\n",
      "Epoch 1267/1499\n",
      "----------\n",
      "train Loss: 0.7057 Acc: 0.8464\n",
      "val Loss: 0.7032 Acc: 0.8560\n",
      "test Loss: 0.7043 Acc: 0.8560\n",
      "Epoch 1268/1499\n",
      "----------\n",
      "train Loss: 0.7114 Acc: 0.8382\n",
      "val Loss: 0.7261 Acc: 0.8160\n",
      "test Loss: 0.7082 Acc: 0.8640\n",
      "Epoch 1269/1499\n",
      "----------\n",
      "train Loss: 0.7086 Acc: 0.8391\n",
      "val Loss: 0.7056 Acc: 0.8440\n",
      "test Loss: 0.6980 Acc: 0.8640\n",
      "Epoch 1270/1499\n",
      "----------\n",
      "train Loss: 0.7038 Acc: 0.8489\n",
      "val Loss: 0.7117 Acc: 0.8400\n",
      "test Loss: 0.7076 Acc: 0.8480\n",
      "Epoch 1271/1499\n",
      "----------\n",
      "train Loss: 0.7078 Acc: 0.8404\n",
      "val Loss: 0.7239 Acc: 0.8320\n",
      "test Loss: 0.7037 Acc: 0.8560\n",
      "Epoch 1272/1499\n",
      "----------\n",
      "train Loss: 0.7052 Acc: 0.8451\n",
      "val Loss: 0.7165 Acc: 0.8280\n",
      "test Loss: 0.6923 Acc: 0.8680\n",
      "Epoch 1273/1499\n",
      "----------\n",
      "train Loss: 0.7090 Acc: 0.8407\n",
      "val Loss: 0.7202 Acc: 0.8280\n",
      "test Loss: 0.6901 Acc: 0.8760\n",
      "Epoch 1274/1499\n",
      "----------\n",
      "train Loss: 0.7092 Acc: 0.8413\n",
      "val Loss: 0.7073 Acc: 0.8520\n",
      "test Loss: 0.7098 Acc: 0.8440\n",
      "Epoch 1275/1499\n",
      "----------\n",
      "train Loss: 0.7084 Acc: 0.8436\n",
      "val Loss: 0.7125 Acc: 0.8360\n",
      "test Loss: 0.6985 Acc: 0.8600\n",
      "Epoch 1276/1499\n",
      "----------\n",
      "train Loss: 0.7088 Acc: 0.8424\n",
      "val Loss: 0.6913 Acc: 0.8640\n",
      "test Loss: 0.7257 Acc: 0.8240\n",
      "Epoch 1277/1499\n",
      "----------\n",
      "train Loss: 0.7101 Acc: 0.8440\n",
      "val Loss: 0.7107 Acc: 0.8360\n",
      "test Loss: 0.7188 Acc: 0.8280\n",
      "Epoch 1278/1499\n",
      "----------\n",
      "train Loss: 0.7045 Acc: 0.8460\n",
      "val Loss: 0.7208 Acc: 0.8400\n",
      "test Loss: 0.7035 Acc: 0.8680\n",
      "Epoch 1279/1499\n",
      "----------\n",
      "train Loss: 0.7062 Acc: 0.8451\n",
      "val Loss: 0.7078 Acc: 0.8440\n",
      "test Loss: 0.7088 Acc: 0.8480\n",
      "Epoch 1280/1499\n",
      "----------\n",
      "train Loss: 0.7071 Acc: 0.8447\n",
      "val Loss: 0.7136 Acc: 0.8400\n",
      "test Loss: 0.7038 Acc: 0.8640\n",
      "Epoch 1281/1499\n",
      "----------\n",
      "train Loss: 0.7067 Acc: 0.8442\n",
      "val Loss: 0.7211 Acc: 0.8240\n",
      "test Loss: 0.7096 Acc: 0.8480\n",
      "Epoch 1282/1499\n",
      "----------\n",
      "train Loss: 0.7082 Acc: 0.8444\n",
      "val Loss: 0.7241 Acc: 0.8160\n",
      "test Loss: 0.7085 Acc: 0.8480\n",
      "Epoch 1283/1499\n",
      "----------\n",
      "train Loss: 0.7060 Acc: 0.8449\n",
      "val Loss: 0.7167 Acc: 0.8280\n",
      "test Loss: 0.6992 Acc: 0.8600\n",
      "Epoch 1284/1499\n",
      "----------\n",
      "train Loss: 0.7077 Acc: 0.8456\n",
      "val Loss: 0.7163 Acc: 0.8400\n",
      "test Loss: 0.7064 Acc: 0.8560\n",
      "Epoch 1285/1499\n",
      "----------\n",
      "train Loss: 0.7033 Acc: 0.8482\n",
      "val Loss: 0.7161 Acc: 0.8200\n",
      "test Loss: 0.7092 Acc: 0.8520\n",
      "Epoch 1286/1499\n",
      "----------\n",
      "train Loss: 0.7074 Acc: 0.8442\n",
      "val Loss: 0.7047 Acc: 0.8480\n",
      "test Loss: 0.7046 Acc: 0.8600\n",
      "Epoch 1287/1499\n",
      "----------\n",
      "train Loss: 0.7039 Acc: 0.8493\n",
      "val Loss: 0.7161 Acc: 0.8320\n",
      "test Loss: 0.7025 Acc: 0.8600\n",
      "Epoch 1288/1499\n",
      "----------\n",
      "train Loss: 0.7043 Acc: 0.8464\n",
      "val Loss: 0.7243 Acc: 0.8080\n",
      "test Loss: 0.7130 Acc: 0.8440\n",
      "Epoch 1289/1499\n",
      "----------\n",
      "train Loss: 0.7037 Acc: 0.8496\n",
      "val Loss: 0.7138 Acc: 0.8240\n",
      "test Loss: 0.7219 Acc: 0.8320\n",
      "Epoch 1290/1499\n",
      "----------\n",
      "train Loss: 0.7066 Acc: 0.8456\n",
      "val Loss: 0.7147 Acc: 0.8320\n",
      "test Loss: 0.6999 Acc: 0.8560\n",
      "Epoch 1291/1499\n",
      "----------\n",
      "train Loss: 0.7079 Acc: 0.8440\n",
      "val Loss: 0.7141 Acc: 0.8320\n",
      "test Loss: 0.7023 Acc: 0.8520\n",
      "Epoch 1292/1499\n",
      "----------\n",
      "train Loss: 0.7077 Acc: 0.8436\n",
      "val Loss: 0.7173 Acc: 0.8240\n",
      "test Loss: 0.6981 Acc: 0.8680\n",
      "Epoch 1293/1499\n",
      "----------\n",
      "train Loss: 0.7045 Acc: 0.8462\n",
      "val Loss: 0.7074 Acc: 0.8480\n",
      "test Loss: 0.6932 Acc: 0.8680\n",
      "Epoch 1294/1499\n",
      "----------\n",
      "train Loss: 0.7086 Acc: 0.8420\n",
      "val Loss: 0.7214 Acc: 0.8160\n",
      "test Loss: 0.7006 Acc: 0.8640\n",
      "Epoch 1295/1499\n",
      "----------\n",
      "train Loss: 0.7066 Acc: 0.8447\n",
      "val Loss: 0.7013 Acc: 0.8440\n",
      "test Loss: 0.7092 Acc: 0.8440\n",
      "Epoch 1296/1499\n",
      "----------\n",
      "train Loss: 0.7084 Acc: 0.8422\n",
      "val Loss: 0.7111 Acc: 0.8360\n",
      "test Loss: 0.7056 Acc: 0.8480\n",
      "Epoch 1297/1499\n",
      "----------\n",
      "train Loss: 0.7062 Acc: 0.8438\n",
      "val Loss: 0.7213 Acc: 0.8280\n",
      "test Loss: 0.7016 Acc: 0.8680\n",
      "Epoch 1298/1499\n",
      "----------\n",
      "train Loss: 0.7063 Acc: 0.8458\n",
      "val Loss: 0.7174 Acc: 0.8240\n",
      "test Loss: 0.7056 Acc: 0.8600\n",
      "Epoch 1299/1499\n",
      "----------\n",
      "train Loss: 0.7050 Acc: 0.8467\n",
      "val Loss: 0.6993 Acc: 0.8520\n",
      "test Loss: 0.6942 Acc: 0.8680\n",
      "Epoch 1300/1499\n",
      "----------\n",
      "train Loss: 0.7042 Acc: 0.8471\n",
      "val Loss: 0.7071 Acc: 0.8440\n",
      "test Loss: 0.7161 Acc: 0.8440\n",
      "Epoch 1301/1499\n",
      "----------\n",
      "train Loss: 0.7050 Acc: 0.8471\n",
      "val Loss: 0.7101 Acc: 0.8400\n",
      "test Loss: 0.6960 Acc: 0.8680\n",
      "Epoch 1302/1499\n",
      "----------\n",
      "train Loss: 0.7052 Acc: 0.8469\n",
      "val Loss: 0.7210 Acc: 0.8240\n",
      "test Loss: 0.6949 Acc: 0.8680\n",
      "Epoch 1303/1499\n",
      "----------\n",
      "train Loss: 0.7095 Acc: 0.8393\n",
      "val Loss: 0.6947 Acc: 0.8520\n",
      "test Loss: 0.6886 Acc: 0.8760\n",
      "Epoch 1304/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.7054 Acc: 0.8449\n",
      "val Loss: 0.7102 Acc: 0.8480\n",
      "test Loss: 0.7032 Acc: 0.8600\n",
      "Epoch 1305/1499\n",
      "----------\n",
      "train Loss: 0.7090 Acc: 0.8416\n",
      "val Loss: 0.7125 Acc: 0.8360\n",
      "test Loss: 0.7035 Acc: 0.8520\n",
      "Epoch 1306/1499\n",
      "----------\n",
      "train Loss: 0.7084 Acc: 0.8440\n",
      "val Loss: 0.7003 Acc: 0.8480\n",
      "test Loss: 0.6932 Acc: 0.8720\n",
      "Epoch 1307/1499\n",
      "----------\n",
      "train Loss: 0.7068 Acc: 0.8431\n",
      "val Loss: 0.6957 Acc: 0.8560\n",
      "test Loss: 0.7029 Acc: 0.8560\n",
      "Epoch 1308/1499\n",
      "----------\n",
      "train Loss: 0.7023 Acc: 0.8498\n",
      "val Loss: 0.7066 Acc: 0.8400\n",
      "test Loss: 0.6951 Acc: 0.8720\n",
      "Epoch 1309/1499\n",
      "----------\n",
      "train Loss: 0.7042 Acc: 0.8476\n",
      "val Loss: 0.7202 Acc: 0.8160\n",
      "test Loss: 0.7138 Acc: 0.8400\n",
      "Epoch 1310/1499\n",
      "----------\n",
      "train Loss: 0.7064 Acc: 0.8418\n",
      "val Loss: 0.7076 Acc: 0.8440\n",
      "test Loss: 0.6913 Acc: 0.8680\n",
      "Epoch 1311/1499\n",
      "----------\n",
      "train Loss: 0.7053 Acc: 0.8462\n",
      "val Loss: 0.7116 Acc: 0.8400\n",
      "test Loss: 0.6877 Acc: 0.8800\n",
      "Epoch 1312/1499\n",
      "----------\n",
      "train Loss: 0.7037 Acc: 0.8476\n",
      "val Loss: 0.7198 Acc: 0.8240\n",
      "test Loss: 0.7038 Acc: 0.8520\n",
      "Epoch 1313/1499\n",
      "----------\n",
      "train Loss: 0.7071 Acc: 0.8444\n",
      "val Loss: 0.7160 Acc: 0.8200\n",
      "test Loss: 0.6986 Acc: 0.8560\n",
      "Epoch 1314/1499\n",
      "----------\n",
      "train Loss: 0.7081 Acc: 0.8436\n",
      "val Loss: 0.7081 Acc: 0.8400\n",
      "test Loss: 0.6966 Acc: 0.8680\n",
      "Epoch 1315/1499\n",
      "----------\n",
      "train Loss: 0.7067 Acc: 0.8447\n",
      "val Loss: 0.7180 Acc: 0.8160\n",
      "test Loss: 0.6987 Acc: 0.8600\n",
      "Epoch 1316/1499\n",
      "----------\n",
      "train Loss: 0.7054 Acc: 0.8431\n",
      "val Loss: 0.7119 Acc: 0.8440\n",
      "test Loss: 0.6932 Acc: 0.8720\n",
      "Epoch 1317/1499\n",
      "----------\n",
      "train Loss: 0.7053 Acc: 0.8469\n",
      "val Loss: 0.7193 Acc: 0.8160\n",
      "test Loss: 0.6958 Acc: 0.8600\n",
      "Epoch 1318/1499\n",
      "----------\n",
      "train Loss: 0.7090 Acc: 0.8416\n",
      "val Loss: 0.7287 Acc: 0.8320\n",
      "test Loss: 0.7043 Acc: 0.8560\n",
      "Epoch 1319/1499\n",
      "----------\n",
      "train Loss: 0.7037 Acc: 0.8498\n",
      "val Loss: 0.7015 Acc: 0.8600\n",
      "test Loss: 0.6967 Acc: 0.8600\n",
      "Epoch 1320/1499\n",
      "----------\n",
      "train Loss: 0.7077 Acc: 0.8433\n",
      "val Loss: 0.7089 Acc: 0.8360\n",
      "test Loss: 0.7124 Acc: 0.8480\n",
      "Epoch 1321/1499\n",
      "----------\n",
      "train Loss: 0.7036 Acc: 0.8493\n",
      "val Loss: 0.7011 Acc: 0.8480\n",
      "test Loss: 0.7003 Acc: 0.8680\n",
      "Epoch 1322/1499\n",
      "----------\n",
      "train Loss: 0.7027 Acc: 0.8493\n",
      "val Loss: 0.7202 Acc: 0.8240\n",
      "test Loss: 0.7001 Acc: 0.8640\n",
      "Epoch 1323/1499\n",
      "----------\n",
      "train Loss: 0.7077 Acc: 0.8440\n",
      "val Loss: 0.7047 Acc: 0.8440\n",
      "test Loss: 0.7071 Acc: 0.8560\n",
      "Epoch 1324/1499\n",
      "----------\n",
      "train Loss: 0.7034 Acc: 0.8480\n",
      "val Loss: 0.7058 Acc: 0.8400\n",
      "test Loss: 0.7102 Acc: 0.8480\n",
      "Epoch 1325/1499\n",
      "----------\n",
      "train Loss: 0.7045 Acc: 0.8464\n",
      "val Loss: 0.7228 Acc: 0.8200\n",
      "test Loss: 0.7108 Acc: 0.8440\n",
      "Epoch 1326/1499\n",
      "----------\n",
      "train Loss: 0.7073 Acc: 0.8429\n",
      "val Loss: 0.7140 Acc: 0.8360\n",
      "test Loss: 0.6922 Acc: 0.8800\n",
      "Epoch 1327/1499\n",
      "----------\n",
      "train Loss: 0.7047 Acc: 0.8456\n",
      "val Loss: 0.6988 Acc: 0.8560\n",
      "test Loss: 0.6993 Acc: 0.8560\n",
      "Epoch 1328/1499\n",
      "----------\n",
      "train Loss: 0.7065 Acc: 0.8424\n",
      "val Loss: 0.7124 Acc: 0.8320\n",
      "test Loss: 0.7115 Acc: 0.8440\n",
      "Epoch 1329/1499\n",
      "----------\n",
      "train Loss: 0.7054 Acc: 0.8464\n",
      "val Loss: 0.7238 Acc: 0.8160\n",
      "test Loss: 0.7072 Acc: 0.8480\n",
      "Epoch 1330/1499\n",
      "----------\n",
      "train Loss: 0.7105 Acc: 0.8382\n",
      "val Loss: 0.7085 Acc: 0.8440\n",
      "test Loss: 0.6953 Acc: 0.8600\n",
      "Epoch 1331/1499\n",
      "----------\n",
      "train Loss: 0.7042 Acc: 0.8458\n",
      "val Loss: 0.7075 Acc: 0.8480\n",
      "test Loss: 0.7062 Acc: 0.8520\n",
      "Epoch 1332/1499\n",
      "----------\n",
      "train Loss: 0.7071 Acc: 0.8420\n",
      "val Loss: 0.7246 Acc: 0.8160\n",
      "test Loss: 0.6966 Acc: 0.8640\n",
      "Epoch 1333/1499\n",
      "----------\n",
      "train Loss: 0.7021 Acc: 0.8489\n",
      "val Loss: 0.7052 Acc: 0.8440\n",
      "test Loss: 0.7139 Acc: 0.8440\n",
      "Epoch 1334/1499\n",
      "----------\n",
      "train Loss: 0.7035 Acc: 0.8487\n",
      "val Loss: 0.7072 Acc: 0.8320\n",
      "test Loss: 0.7025 Acc: 0.8440\n",
      "Epoch 1335/1499\n",
      "----------\n",
      "train Loss: 0.7073 Acc: 0.8400\n",
      "val Loss: 0.7116 Acc: 0.8360\n",
      "test Loss: 0.7081 Acc: 0.8520\n",
      "Epoch 1336/1499\n",
      "----------\n",
      "train Loss: 0.7071 Acc: 0.8444\n",
      "val Loss: 0.7217 Acc: 0.8240\n",
      "test Loss: 0.7080 Acc: 0.8520\n",
      "Epoch 1337/1499\n",
      "----------\n",
      "train Loss: 0.7035 Acc: 0.8491\n",
      "val Loss: 0.7081 Acc: 0.8440\n",
      "test Loss: 0.6907 Acc: 0.8680\n",
      "Epoch 1338/1499\n",
      "----------\n",
      "train Loss: 0.7066 Acc: 0.8436\n",
      "val Loss: 0.7014 Acc: 0.8480\n",
      "test Loss: 0.7121 Acc: 0.8600\n",
      "Epoch 1339/1499\n",
      "----------\n",
      "train Loss: 0.7013 Acc: 0.8522\n",
      "val Loss: 0.7190 Acc: 0.8280\n",
      "test Loss: 0.6942 Acc: 0.8720\n",
      "Epoch 1340/1499\n",
      "----------\n",
      "train Loss: 0.7061 Acc: 0.8420\n",
      "val Loss: 0.6973 Acc: 0.8520\n",
      "test Loss: 0.7001 Acc: 0.8600\n",
      "Epoch 1341/1499\n",
      "----------\n",
      "train Loss: 0.7012 Acc: 0.8500\n",
      "val Loss: 0.7190 Acc: 0.8280\n",
      "test Loss: 0.6937 Acc: 0.8800\n",
      "Epoch 1342/1499\n",
      "----------\n",
      "train Loss: 0.7092 Acc: 0.8404\n",
      "val Loss: 0.7074 Acc: 0.8480\n",
      "test Loss: 0.7133 Acc: 0.8480\n",
      "Epoch 1343/1499\n",
      "----------\n",
      "train Loss: 0.7024 Acc: 0.8460\n",
      "val Loss: 0.7139 Acc: 0.8400\n",
      "test Loss: 0.6998 Acc: 0.8440\n",
      "Epoch 1344/1499\n",
      "----------\n",
      "train Loss: 0.7059 Acc: 0.8429\n",
      "val Loss: 0.7064 Acc: 0.8360\n",
      "test Loss: 0.7236 Acc: 0.8280\n",
      "Epoch 1345/1499\n",
      "----------\n",
      "train Loss: 0.7074 Acc: 0.8413\n",
      "val Loss: 0.7102 Acc: 0.8440\n",
      "test Loss: 0.6952 Acc: 0.8640\n",
      "Epoch 1346/1499\n",
      "----------\n",
      "train Loss: 0.7051 Acc: 0.8418\n",
      "val Loss: 0.7010 Acc: 0.8520\n",
      "test Loss: 0.6988 Acc: 0.8680\n",
      "Epoch 1347/1499\n",
      "----------\n",
      "train Loss: 0.7027 Acc: 0.8493\n",
      "val Loss: 0.7057 Acc: 0.8440\n",
      "test Loss: 0.6942 Acc: 0.8600\n",
      "Epoch 1348/1499\n",
      "----------\n",
      "train Loss: 0.7059 Acc: 0.8453\n",
      "val Loss: 0.7030 Acc: 0.8560\n",
      "test Loss: 0.7013 Acc: 0.8600\n",
      "Epoch 1349/1499\n",
      "----------\n",
      "train Loss: 0.7061 Acc: 0.8447\n",
      "val Loss: 0.6919 Acc: 0.8680\n",
      "test Loss: 0.6922 Acc: 0.8720\n",
      "Epoch 1350/1499\n",
      "----------\n",
      "train Loss: 0.7048 Acc: 0.8451\n",
      "val Loss: 0.7173 Acc: 0.8280\n",
      "test Loss: 0.7208 Acc: 0.8320\n",
      "Epoch 1351/1499\n",
      "----------\n",
      "train Loss: 0.7091 Acc: 0.8387\n",
      "val Loss: 0.6919 Acc: 0.8560\n",
      "test Loss: 0.7108 Acc: 0.8520\n",
      "Epoch 1352/1499\n",
      "----------\n",
      "train Loss: 0.7051 Acc: 0.8462\n",
      "val Loss: 0.7002 Acc: 0.8520\n",
      "test Loss: 0.7183 Acc: 0.8320\n",
      "Epoch 1353/1499\n",
      "----------\n",
      "train Loss: 0.7069 Acc: 0.8436\n",
      "val Loss: 0.7162 Acc: 0.8280\n",
      "test Loss: 0.6997 Acc: 0.8520\n",
      "Epoch 1354/1499\n",
      "----------\n",
      "train Loss: 0.7049 Acc: 0.8464\n",
      "val Loss: 0.7004 Acc: 0.8480\n",
      "test Loss: 0.6977 Acc: 0.8560\n",
      "Epoch 1355/1499\n",
      "----------\n",
      "train Loss: 0.7015 Acc: 0.8511\n",
      "val Loss: 0.7063 Acc: 0.8600\n",
      "test Loss: 0.6985 Acc: 0.8560\n",
      "Epoch 1356/1499\n",
      "----------\n",
      "train Loss: 0.7049 Acc: 0.8458\n",
      "val Loss: 0.6925 Acc: 0.8680\n",
      "test Loss: 0.6952 Acc: 0.8640\n",
      "Epoch 1357/1499\n",
      "----------\n",
      "train Loss: 0.7012 Acc: 0.8522\n",
      "val Loss: 0.7027 Acc: 0.8480\n",
      "test Loss: 0.7017 Acc: 0.8520\n",
      "Epoch 1358/1499\n",
      "----------\n",
      "train Loss: 0.7058 Acc: 0.8442\n",
      "val Loss: 0.7069 Acc: 0.8440\n",
      "test Loss: 0.7092 Acc: 0.8440\n",
      "Epoch 1359/1499\n",
      "----------\n",
      "train Loss: 0.7069 Acc: 0.8418\n",
      "val Loss: 0.6969 Acc: 0.8640\n",
      "test Loss: 0.6905 Acc: 0.8680\n",
      "Epoch 1360/1499\n",
      "----------\n",
      "train Loss: 0.7023 Acc: 0.8522\n",
      "val Loss: 0.7093 Acc: 0.8400\n",
      "test Loss: 0.7190 Acc: 0.8280\n",
      "Epoch 1361/1499\n",
      "----------\n",
      "train Loss: 0.7053 Acc: 0.8460\n",
      "val Loss: 0.7211 Acc: 0.8240\n",
      "test Loss: 0.6944 Acc: 0.8600\n",
      "Epoch 1362/1499\n",
      "----------\n",
      "train Loss: 0.7027 Acc: 0.8491\n",
      "val Loss: 0.6974 Acc: 0.8480\n",
      "test Loss: 0.6976 Acc: 0.8640\n",
      "Epoch 1363/1499\n",
      "----------\n",
      "train Loss: 0.7073 Acc: 0.8427\n",
      "val Loss: 0.6928 Acc: 0.8640\n",
      "test Loss: 0.7304 Acc: 0.8200\n",
      "Epoch 1364/1499\n",
      "----------\n",
      "train Loss: 0.7041 Acc: 0.8453\n",
      "val Loss: 0.7157 Acc: 0.8280\n",
      "test Loss: 0.7024 Acc: 0.8600\n",
      "Epoch 1365/1499\n",
      "----------\n",
      "train Loss: 0.7034 Acc: 0.8480\n",
      "val Loss: 0.7084 Acc: 0.8400\n",
      "test Loss: 0.6895 Acc: 0.8640\n",
      "Epoch 1366/1499\n",
      "----------\n",
      "train Loss: 0.7053 Acc: 0.8451\n",
      "val Loss: 0.7164 Acc: 0.8400\n",
      "test Loss: 0.6913 Acc: 0.8640\n",
      "Epoch 1367/1499\n",
      "----------\n",
      "train Loss: 0.7039 Acc: 0.8444\n",
      "val Loss: 0.7201 Acc: 0.8200\n",
      "test Loss: 0.7166 Acc: 0.8280\n",
      "Epoch 1368/1499\n",
      "----------\n",
      "train Loss: 0.7046 Acc: 0.8451\n",
      "val Loss: 0.7059 Acc: 0.8520\n",
      "test Loss: 0.7102 Acc: 0.8440\n",
      "Epoch 1369/1499\n",
      "----------\n",
      "train Loss: 0.7010 Acc: 0.8502\n",
      "val Loss: 0.7019 Acc: 0.8480\n",
      "test Loss: 0.7139 Acc: 0.8400\n",
      "Epoch 1370/1499\n",
      "----------\n",
      "train Loss: 0.7048 Acc: 0.8451\n",
      "val Loss: 0.7277 Acc: 0.8120\n",
      "test Loss: 0.6951 Acc: 0.8680\n",
      "Epoch 1371/1499\n",
      "----------\n",
      "train Loss: 0.7002 Acc: 0.8500\n",
      "val Loss: 0.7105 Acc: 0.8360\n",
      "test Loss: 0.7294 Acc: 0.8360\n",
      "Epoch 1372/1499\n",
      "----------\n",
      "train Loss: 0.7037 Acc: 0.8469\n",
      "val Loss: 0.7192 Acc: 0.8280\n",
      "test Loss: 0.6904 Acc: 0.8800\n",
      "Epoch 1373/1499\n",
      "----------\n",
      "train Loss: 0.7038 Acc: 0.8464\n",
      "val Loss: 0.7010 Acc: 0.8520\n",
      "test Loss: 0.7076 Acc: 0.8400\n",
      "Epoch 1374/1499\n",
      "----------\n",
      "train Loss: 0.7046 Acc: 0.8469\n",
      "val Loss: 0.7090 Acc: 0.8360\n",
      "test Loss: 0.7012 Acc: 0.8600\n",
      "Epoch 1375/1499\n",
      "----------\n",
      "train Loss: 0.7048 Acc: 0.8469\n",
      "val Loss: 0.7250 Acc: 0.8200\n",
      "test Loss: 0.6932 Acc: 0.8640\n",
      "Epoch 1376/1499\n",
      "----------\n",
      "train Loss: 0.7046 Acc: 0.8462\n",
      "val Loss: 0.7072 Acc: 0.8440\n",
      "test Loss: 0.6861 Acc: 0.8760\n",
      "Epoch 1377/1499\n",
      "----------\n",
      "train Loss: 0.7032 Acc: 0.8482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.7010 Acc: 0.8480\n",
      "test Loss: 0.6904 Acc: 0.8640\n",
      "Epoch 1378/1499\n",
      "----------\n",
      "train Loss: 0.7059 Acc: 0.8462\n",
      "val Loss: 0.7246 Acc: 0.8120\n",
      "test Loss: 0.7020 Acc: 0.8640\n",
      "Epoch 1379/1499\n",
      "----------\n",
      "train Loss: 0.7026 Acc: 0.8462\n",
      "val Loss: 0.7060 Acc: 0.8520\n",
      "test Loss: 0.7268 Acc: 0.8240\n",
      "Epoch 1380/1499\n",
      "----------\n",
      "train Loss: 0.7033 Acc: 0.8480\n",
      "val Loss: 0.7106 Acc: 0.8360\n",
      "test Loss: 0.6951 Acc: 0.8640\n",
      "Epoch 1381/1499\n",
      "----------\n",
      "train Loss: 0.7066 Acc: 0.8422\n",
      "val Loss: 0.7153 Acc: 0.8400\n",
      "test Loss: 0.6984 Acc: 0.8640\n",
      "Epoch 1382/1499\n",
      "----------\n",
      "train Loss: 0.7063 Acc: 0.8449\n",
      "val Loss: 0.7015 Acc: 0.8560\n",
      "test Loss: 0.6970 Acc: 0.8640\n",
      "Epoch 1383/1499\n",
      "----------\n",
      "train Loss: 0.7044 Acc: 0.8429\n",
      "val Loss: 0.7088 Acc: 0.8320\n",
      "test Loss: 0.6938 Acc: 0.8680\n",
      "Epoch 1384/1499\n",
      "----------\n",
      "train Loss: 0.7039 Acc: 0.8471\n",
      "val Loss: 0.7299 Acc: 0.8000\n",
      "test Loss: 0.6840 Acc: 0.8720\n",
      "Epoch 1385/1499\n",
      "----------\n",
      "train Loss: 0.7063 Acc: 0.8416\n",
      "val Loss: 0.7078 Acc: 0.8520\n",
      "test Loss: 0.6947 Acc: 0.8640\n",
      "Epoch 1386/1499\n",
      "----------\n",
      "train Loss: 0.7044 Acc: 0.8469\n",
      "val Loss: 0.7020 Acc: 0.8520\n",
      "test Loss: 0.6982 Acc: 0.8680\n",
      "Epoch 1387/1499\n",
      "----------\n",
      "train Loss: 0.7034 Acc: 0.8473\n",
      "val Loss: 0.7138 Acc: 0.8280\n",
      "test Loss: 0.6992 Acc: 0.8600\n",
      "Epoch 1388/1499\n",
      "----------\n",
      "train Loss: 0.7072 Acc: 0.8429\n",
      "val Loss: 0.6927 Acc: 0.8400\n",
      "test Loss: 0.7230 Acc: 0.8400\n",
      "Epoch 1389/1499\n",
      "----------\n",
      "train Loss: 0.7052 Acc: 0.8460\n",
      "val Loss: 0.7043 Acc: 0.8440\n",
      "test Loss: 0.7055 Acc: 0.8560\n",
      "Epoch 1390/1499\n",
      "----------\n",
      "train Loss: 0.7070 Acc: 0.8413\n",
      "val Loss: 0.7351 Acc: 0.8120\n",
      "test Loss: 0.7104 Acc: 0.8400\n",
      "Epoch 1391/1499\n",
      "----------\n",
      "train Loss: 0.7022 Acc: 0.8493\n",
      "val Loss: 0.7210 Acc: 0.8120\n",
      "test Loss: 0.6983 Acc: 0.8640\n",
      "Epoch 1392/1499\n",
      "----------\n",
      "train Loss: 0.7023 Acc: 0.8473\n",
      "val Loss: 0.7111 Acc: 0.8360\n",
      "test Loss: 0.6958 Acc: 0.8680\n",
      "Epoch 1393/1499\n",
      "----------\n",
      "train Loss: 0.7069 Acc: 0.8440\n",
      "val Loss: 0.7038 Acc: 0.8560\n",
      "test Loss: 0.7064 Acc: 0.8480\n",
      "Epoch 1394/1499\n",
      "----------\n",
      "train Loss: 0.7046 Acc: 0.8484\n",
      "val Loss: 0.7172 Acc: 0.8240\n",
      "test Loss: 0.6961 Acc: 0.8680\n",
      "Epoch 1395/1499\n",
      "----------\n",
      "train Loss: 0.6987 Acc: 0.8527\n",
      "val Loss: 0.7007 Acc: 0.8480\n",
      "test Loss: 0.7005 Acc: 0.8640\n",
      "Epoch 1396/1499\n",
      "----------\n",
      "train Loss: 0.7056 Acc: 0.8411\n",
      "val Loss: 0.7209 Acc: 0.8200\n",
      "test Loss: 0.6924 Acc: 0.8760\n",
      "Epoch 1397/1499\n",
      "----------\n",
      "train Loss: 0.7064 Acc: 0.8409\n",
      "val Loss: 0.7110 Acc: 0.8400\n",
      "test Loss: 0.7091 Acc: 0.8520\n",
      "Epoch 1398/1499\n",
      "----------\n",
      "train Loss: 0.7041 Acc: 0.8449\n",
      "val Loss: 0.6975 Acc: 0.8600\n",
      "test Loss: 0.6972 Acc: 0.8560\n",
      "Epoch 1399/1499\n",
      "----------\n",
      "train Loss: 0.7030 Acc: 0.8482\n",
      "val Loss: 0.7042 Acc: 0.8520\n",
      "test Loss: 0.6875 Acc: 0.8760\n",
      "Epoch 1400/1499\n",
      "----------\n",
      "train Loss: 0.7058 Acc: 0.8456\n",
      "val Loss: 0.7021 Acc: 0.8440\n",
      "test Loss: 0.7110 Acc: 0.8400\n",
      "Epoch 1401/1499\n",
      "----------\n",
      "train Loss: 0.6998 Acc: 0.8522\n",
      "val Loss: 0.7147 Acc: 0.8280\n",
      "test Loss: 0.7166 Acc: 0.8520\n",
      "Epoch 1402/1499\n",
      "----------\n",
      "train Loss: 0.7047 Acc: 0.8444\n",
      "val Loss: 0.6954 Acc: 0.8480\n",
      "test Loss: 0.7020 Acc: 0.8600\n",
      "Epoch 1403/1499\n",
      "----------\n",
      "train Loss: 0.7032 Acc: 0.8471\n",
      "val Loss: 0.7126 Acc: 0.8320\n",
      "test Loss: 0.7111 Acc: 0.8480\n",
      "Epoch 1404/1499\n",
      "----------\n",
      "train Loss: 0.7063 Acc: 0.8396\n",
      "val Loss: 0.7058 Acc: 0.8440\n",
      "test Loss: 0.7105 Acc: 0.8520\n",
      "Epoch 1405/1499\n",
      "----------\n",
      "train Loss: 0.7019 Acc: 0.8453\n",
      "val Loss: 0.7106 Acc: 0.8400\n",
      "test Loss: 0.6877 Acc: 0.8800\n",
      "Epoch 1406/1499\n",
      "----------\n",
      "train Loss: 0.7031 Acc: 0.8482\n",
      "val Loss: 0.6983 Acc: 0.8600\n",
      "test Loss: 0.7172 Acc: 0.8440\n",
      "Epoch 1407/1499\n",
      "----------\n",
      "train Loss: 0.7029 Acc: 0.8496\n",
      "val Loss: 0.6851 Acc: 0.8640\n",
      "test Loss: 0.6959 Acc: 0.8600\n",
      "Epoch 1408/1499\n",
      "----------\n",
      "train Loss: 0.7022 Acc: 0.8451\n",
      "val Loss: 0.6923 Acc: 0.8640\n",
      "test Loss: 0.7154 Acc: 0.8520\n",
      "Epoch 1409/1499\n",
      "----------\n",
      "train Loss: 0.7051 Acc: 0.8416\n",
      "val Loss: 0.7089 Acc: 0.8240\n",
      "test Loss: 0.7071 Acc: 0.8440\n",
      "Epoch 1410/1499\n",
      "----------\n",
      "train Loss: 0.7037 Acc: 0.8458\n",
      "val Loss: 0.6986 Acc: 0.8600\n",
      "test Loss: 0.6995 Acc: 0.8600\n",
      "Epoch 1411/1499\n",
      "----------\n",
      "train Loss: 0.7049 Acc: 0.8451\n",
      "val Loss: 0.6953 Acc: 0.8520\n",
      "test Loss: 0.7014 Acc: 0.8640\n",
      "Epoch 1412/1499\n",
      "----------\n",
      "train Loss: 0.7019 Acc: 0.8509\n",
      "val Loss: 0.6969 Acc: 0.8520\n",
      "test Loss: 0.7009 Acc: 0.8560\n",
      "Epoch 1413/1499\n",
      "----------\n",
      "train Loss: 0.7005 Acc: 0.8524\n",
      "val Loss: 0.7090 Acc: 0.8240\n",
      "test Loss: 0.6969 Acc: 0.8600\n",
      "Epoch 1414/1499\n",
      "----------\n",
      "train Loss: 0.7025 Acc: 0.8498\n",
      "val Loss: 0.7016 Acc: 0.8480\n",
      "test Loss: 0.7174 Acc: 0.8360\n",
      "Epoch 1415/1499\n",
      "----------\n",
      "train Loss: 0.7058 Acc: 0.8442\n",
      "val Loss: 0.7047 Acc: 0.8480\n",
      "test Loss: 0.6889 Acc: 0.8840\n",
      "Epoch 1416/1499\n",
      "----------\n",
      "train Loss: 0.7036 Acc: 0.8489\n",
      "val Loss: 0.7095 Acc: 0.8480\n",
      "test Loss: 0.7075 Acc: 0.8480\n",
      "Epoch 1417/1499\n",
      "----------\n",
      "train Loss: 0.7031 Acc: 0.8467\n",
      "val Loss: 0.7069 Acc: 0.8440\n",
      "test Loss: 0.7051 Acc: 0.8520\n",
      "Epoch 1418/1499\n",
      "----------\n",
      "train Loss: 0.7050 Acc: 0.8431\n",
      "val Loss: 0.7098 Acc: 0.8400\n",
      "test Loss: 0.6982 Acc: 0.8640\n",
      "Epoch 1419/1499\n",
      "----------\n",
      "train Loss: 0.7023 Acc: 0.8489\n",
      "val Loss: 0.6966 Acc: 0.8480\n",
      "test Loss: 0.7072 Acc: 0.8520\n",
      "Epoch 1420/1499\n",
      "----------\n",
      "train Loss: 0.7066 Acc: 0.8398\n",
      "val Loss: 0.7212 Acc: 0.8160\n",
      "test Loss: 0.7025 Acc: 0.8560\n",
      "Epoch 1421/1499\n",
      "----------\n",
      "train Loss: 0.7083 Acc: 0.8436\n",
      "val Loss: 0.7226 Acc: 0.8280\n",
      "test Loss: 0.6881 Acc: 0.8720\n",
      "Epoch 1422/1499\n",
      "----------\n",
      "train Loss: 0.7048 Acc: 0.8467\n",
      "val Loss: 0.7023 Acc: 0.8480\n",
      "test Loss: 0.6935 Acc: 0.8640\n",
      "Epoch 1423/1499\n",
      "----------\n",
      "train Loss: 0.7014 Acc: 0.8507\n",
      "val Loss: 0.7040 Acc: 0.8520\n",
      "test Loss: 0.6875 Acc: 0.8720\n",
      "Epoch 1424/1499\n",
      "----------\n",
      "train Loss: 0.7067 Acc: 0.8433\n",
      "val Loss: 0.7143 Acc: 0.8320\n",
      "test Loss: 0.7028 Acc: 0.8600\n",
      "Epoch 1425/1499\n",
      "----------\n",
      "train Loss: 0.7024 Acc: 0.8484\n",
      "val Loss: 0.6980 Acc: 0.8600\n",
      "test Loss: 0.6994 Acc: 0.8640\n",
      "Epoch 1426/1499\n",
      "----------\n",
      "train Loss: 0.7024 Acc: 0.8478\n",
      "val Loss: 0.7086 Acc: 0.8400\n",
      "test Loss: 0.7005 Acc: 0.8600\n",
      "Epoch 1427/1499\n",
      "----------\n",
      "train Loss: 0.7032 Acc: 0.8478\n",
      "val Loss: 0.6947 Acc: 0.8520\n",
      "test Loss: 0.6981 Acc: 0.8600\n",
      "Epoch 1428/1499\n",
      "----------\n",
      "train Loss: 0.7036 Acc: 0.8458\n",
      "val Loss: 0.7145 Acc: 0.8280\n",
      "test Loss: 0.7081 Acc: 0.8400\n",
      "Epoch 1429/1499\n",
      "----------\n",
      "train Loss: 0.7014 Acc: 0.8502\n",
      "val Loss: 0.7090 Acc: 0.8480\n",
      "test Loss: 0.7069 Acc: 0.8520\n",
      "Epoch 1430/1499\n",
      "----------\n",
      "train Loss: 0.7053 Acc: 0.8422\n",
      "val Loss: 0.7189 Acc: 0.8480\n",
      "test Loss: 0.6992 Acc: 0.8640\n",
      "Epoch 1431/1499\n",
      "----------\n",
      "train Loss: 0.7024 Acc: 0.8467\n",
      "val Loss: 0.7157 Acc: 0.8240\n",
      "test Loss: 0.7017 Acc: 0.8600\n",
      "Epoch 1432/1499\n",
      "----------\n",
      "train Loss: 0.7043 Acc: 0.8447\n",
      "val Loss: 0.7059 Acc: 0.8400\n",
      "test Loss: 0.6997 Acc: 0.8600\n",
      "Epoch 1433/1499\n",
      "----------\n",
      "train Loss: 0.7040 Acc: 0.8453\n",
      "val Loss: 0.6935 Acc: 0.8600\n",
      "test Loss: 0.7128 Acc: 0.8400\n",
      "Epoch 1434/1499\n",
      "----------\n",
      "train Loss: 0.7022 Acc: 0.8496\n",
      "val Loss: 0.7134 Acc: 0.8320\n",
      "test Loss: 0.7056 Acc: 0.8520\n",
      "Epoch 1435/1499\n",
      "----------\n",
      "train Loss: 0.7058 Acc: 0.8456\n",
      "val Loss: 0.7059 Acc: 0.8480\n",
      "test Loss: 0.7126 Acc: 0.8440\n",
      "Epoch 1436/1499\n",
      "----------\n",
      "train Loss: 0.7051 Acc: 0.8456\n",
      "val Loss: 0.7049 Acc: 0.8360\n",
      "test Loss: 0.7063 Acc: 0.8560\n",
      "Epoch 1437/1499\n",
      "----------\n",
      "train Loss: 0.7022 Acc: 0.8453\n",
      "val Loss: 0.7238 Acc: 0.8240\n",
      "test Loss: 0.7030 Acc: 0.8520\n",
      "Epoch 1438/1499\n",
      "----------\n",
      "train Loss: 0.7011 Acc: 0.8491\n",
      "val Loss: 0.7228 Acc: 0.8200\n",
      "test Loss: 0.6906 Acc: 0.8680\n",
      "Epoch 1439/1499\n",
      "----------\n",
      "train Loss: 0.7057 Acc: 0.8447\n",
      "val Loss: 0.7223 Acc: 0.8200\n",
      "test Loss: 0.6890 Acc: 0.8800\n",
      "Epoch 1440/1499\n",
      "----------\n",
      "train Loss: 0.7026 Acc: 0.8460\n",
      "val Loss: 0.7071 Acc: 0.8280\n",
      "test Loss: 0.7000 Acc: 0.8520\n",
      "Epoch 1441/1499\n",
      "----------\n",
      "train Loss: 0.7041 Acc: 0.8462\n",
      "val Loss: 0.7082 Acc: 0.8400\n",
      "test Loss: 0.7070 Acc: 0.8560\n",
      "Epoch 1442/1499\n",
      "----------\n",
      "train Loss: 0.7060 Acc: 0.8456\n",
      "val Loss: 0.7031 Acc: 0.8400\n",
      "test Loss: 0.6929 Acc: 0.8760\n",
      "Epoch 1443/1499\n",
      "----------\n",
      "train Loss: 0.7030 Acc: 0.8476\n",
      "val Loss: 0.7019 Acc: 0.8560\n",
      "test Loss: 0.6964 Acc: 0.8560\n",
      "Epoch 1444/1499\n",
      "----------\n",
      "train Loss: 0.6986 Acc: 0.8547\n",
      "val Loss: 0.7031 Acc: 0.8480\n",
      "test Loss: 0.7084 Acc: 0.8400\n",
      "Epoch 1445/1499\n",
      "----------\n",
      "train Loss: 0.7052 Acc: 0.8440\n",
      "val Loss: 0.7098 Acc: 0.8440\n",
      "test Loss: 0.7043 Acc: 0.8520\n",
      "Epoch 1446/1499\n",
      "----------\n",
      "train Loss: 0.7019 Acc: 0.8491\n",
      "val Loss: 0.7013 Acc: 0.8560\n",
      "test Loss: 0.6935 Acc: 0.8640\n",
      "Epoch 1447/1499\n",
      "----------\n",
      "train Loss: 0.7018 Acc: 0.8502\n",
      "val Loss: 0.7002 Acc: 0.8520\n",
      "test Loss: 0.6976 Acc: 0.8640\n",
      "Epoch 1448/1499\n",
      "----------\n",
      "train Loss: 0.6993 Acc: 0.8522\n",
      "val Loss: 0.6990 Acc: 0.8520\n",
      "test Loss: 0.6933 Acc: 0.8720\n",
      "Epoch 1449/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.7019 Acc: 0.8496\n",
      "val Loss: 0.7191 Acc: 0.8160\n",
      "test Loss: 0.6997 Acc: 0.8600\n",
      "Epoch 1450/1499\n",
      "----------\n",
      "train Loss: 0.7020 Acc: 0.8473\n",
      "val Loss: 0.6992 Acc: 0.8480\n",
      "test Loss: 0.7100 Acc: 0.8400\n",
      "Epoch 1451/1499\n",
      "----------\n",
      "train Loss: 0.7034 Acc: 0.8464\n",
      "val Loss: 0.7110 Acc: 0.8520\n",
      "test Loss: 0.6942 Acc: 0.8680\n",
      "Epoch 1452/1499\n",
      "----------\n",
      "train Loss: 0.7077 Acc: 0.8420\n",
      "val Loss: 0.6972 Acc: 0.8480\n",
      "test Loss: 0.7022 Acc: 0.8520\n",
      "Epoch 1453/1499\n",
      "----------\n",
      "train Loss: 0.7012 Acc: 0.8504\n",
      "val Loss: 0.7142 Acc: 0.8320\n",
      "test Loss: 0.7025 Acc: 0.8480\n",
      "Epoch 1454/1499\n",
      "----------\n",
      "train Loss: 0.6968 Acc: 0.8558\n",
      "val Loss: 0.7024 Acc: 0.8560\n",
      "test Loss: 0.7189 Acc: 0.8440\n",
      "Epoch 1455/1499\n",
      "----------\n",
      "train Loss: 0.7007 Acc: 0.8509\n",
      "val Loss: 0.6993 Acc: 0.8520\n",
      "test Loss: 0.7047 Acc: 0.8480\n",
      "Epoch 1456/1499\n",
      "----------\n",
      "train Loss: 0.7014 Acc: 0.8482\n",
      "val Loss: 0.7252 Acc: 0.8160\n",
      "test Loss: 0.6967 Acc: 0.8680\n",
      "Epoch 1457/1499\n",
      "----------\n",
      "train Loss: 0.7052 Acc: 0.8431\n",
      "val Loss: 0.6978 Acc: 0.8480\n",
      "test Loss: 0.6916 Acc: 0.8640\n",
      "Epoch 1458/1499\n",
      "----------\n",
      "train Loss: 0.7000 Acc: 0.8522\n",
      "val Loss: 0.6985 Acc: 0.8560\n",
      "test Loss: 0.7027 Acc: 0.8560\n",
      "Epoch 1459/1499\n",
      "----------\n",
      "train Loss: 0.7022 Acc: 0.8473\n",
      "val Loss: 0.7021 Acc: 0.8440\n",
      "test Loss: 0.6855 Acc: 0.8840\n",
      "Epoch 1460/1499\n",
      "----------\n",
      "train Loss: 0.7021 Acc: 0.8467\n",
      "val Loss: 0.6997 Acc: 0.8520\n",
      "test Loss: 0.6963 Acc: 0.8640\n",
      "Epoch 1461/1499\n",
      "----------\n",
      "train Loss: 0.7022 Acc: 0.8482\n",
      "val Loss: 0.7221 Acc: 0.8120\n",
      "test Loss: 0.7023 Acc: 0.8680\n",
      "Epoch 1462/1499\n",
      "----------\n",
      "train Loss: 0.7049 Acc: 0.8458\n",
      "val Loss: 0.6896 Acc: 0.8640\n",
      "test Loss: 0.7039 Acc: 0.8520\n",
      "Epoch 1463/1499\n",
      "----------\n",
      "train Loss: 0.7059 Acc: 0.8424\n",
      "val Loss: 0.6990 Acc: 0.8440\n",
      "test Loss: 0.7017 Acc: 0.8640\n",
      "Epoch 1464/1499\n",
      "----------\n",
      "train Loss: 0.7007 Acc: 0.8509\n",
      "val Loss: 0.7129 Acc: 0.8360\n",
      "test Loss: 0.7030 Acc: 0.8600\n",
      "Epoch 1465/1499\n",
      "----------\n",
      "train Loss: 0.7009 Acc: 0.8502\n",
      "val Loss: 0.7044 Acc: 0.8440\n",
      "test Loss: 0.6902 Acc: 0.8680\n",
      "Epoch 1466/1499\n",
      "----------\n",
      "train Loss: 0.7033 Acc: 0.8469\n",
      "val Loss: 0.7086 Acc: 0.8360\n",
      "test Loss: 0.7032 Acc: 0.8480\n",
      "Epoch 1467/1499\n",
      "----------\n",
      "train Loss: 0.7036 Acc: 0.8476\n",
      "val Loss: 0.7007 Acc: 0.8520\n",
      "test Loss: 0.7092 Acc: 0.8600\n",
      "Epoch 1468/1499\n",
      "----------\n",
      "train Loss: 0.7018 Acc: 0.8487\n",
      "val Loss: 0.7021 Acc: 0.8560\n",
      "test Loss: 0.7037 Acc: 0.8600\n",
      "Epoch 1469/1499\n",
      "----------\n",
      "train Loss: 0.6980 Acc: 0.8540\n",
      "val Loss: 0.7097 Acc: 0.8440\n",
      "test Loss: 0.6973 Acc: 0.8560\n",
      "Epoch 1470/1499\n",
      "----------\n",
      "train Loss: 0.7025 Acc: 0.8458\n",
      "val Loss: 0.7150 Acc: 0.8320\n",
      "test Loss: 0.7082 Acc: 0.8520\n",
      "Epoch 1471/1499\n",
      "----------\n",
      "train Loss: 0.6979 Acc: 0.8544\n",
      "val Loss: 0.7124 Acc: 0.8400\n",
      "test Loss: 0.7011 Acc: 0.8600\n",
      "Epoch 1472/1499\n",
      "----------\n",
      "train Loss: 0.7005 Acc: 0.8513\n",
      "val Loss: 0.7101 Acc: 0.8480\n",
      "test Loss: 0.7029 Acc: 0.8560\n",
      "Epoch 1473/1499\n",
      "----------\n",
      "train Loss: 0.7008 Acc: 0.8496\n",
      "val Loss: 0.7080 Acc: 0.8440\n",
      "test Loss: 0.6864 Acc: 0.8680\n",
      "Epoch 1474/1499\n",
      "----------\n",
      "train Loss: 0.7007 Acc: 0.8496\n",
      "val Loss: 0.7078 Acc: 0.8560\n",
      "test Loss: 0.6920 Acc: 0.8680\n",
      "Epoch 1475/1499\n",
      "----------\n",
      "train Loss: 0.7019 Acc: 0.8491\n",
      "val Loss: 0.7050 Acc: 0.8480\n",
      "test Loss: 0.7032 Acc: 0.8520\n",
      "Epoch 1476/1499\n",
      "----------\n",
      "train Loss: 0.7023 Acc: 0.8467\n",
      "val Loss: 0.7091 Acc: 0.8360\n",
      "test Loss: 0.6935 Acc: 0.8800\n",
      "Epoch 1477/1499\n",
      "----------\n",
      "train Loss: 0.7013 Acc: 0.8502\n",
      "val Loss: 0.7054 Acc: 0.8560\n",
      "test Loss: 0.7081 Acc: 0.8400\n",
      "Epoch 1478/1499\n",
      "----------\n",
      "train Loss: 0.7004 Acc: 0.8489\n",
      "val Loss: 0.6984 Acc: 0.8600\n",
      "test Loss: 0.6934 Acc: 0.8680\n",
      "Epoch 1479/1499\n",
      "----------\n",
      "train Loss: 0.7064 Acc: 0.8436\n",
      "val Loss: 0.7239 Acc: 0.8240\n",
      "test Loss: 0.6891 Acc: 0.8680\n",
      "Epoch 1480/1499\n",
      "----------\n",
      "train Loss: 0.7019 Acc: 0.8473\n",
      "val Loss: 0.7050 Acc: 0.8520\n",
      "test Loss: 0.6989 Acc: 0.8600\n",
      "Epoch 1481/1499\n",
      "----------\n",
      "train Loss: 0.7006 Acc: 0.8476\n",
      "val Loss: 0.7018 Acc: 0.8520\n",
      "test Loss: 0.6996 Acc: 0.8640\n",
      "Epoch 1482/1499\n",
      "----------\n",
      "train Loss: 0.7021 Acc: 0.8484\n",
      "val Loss: 0.6998 Acc: 0.8520\n",
      "test Loss: 0.6977 Acc: 0.8560\n",
      "Epoch 1483/1499\n",
      "----------\n",
      "train Loss: 0.7029 Acc: 0.8469\n",
      "val Loss: 0.7121 Acc: 0.8280\n",
      "test Loss: 0.6818 Acc: 0.8720\n",
      "Epoch 1484/1499\n",
      "----------\n",
      "train Loss: 0.7004 Acc: 0.8493\n",
      "val Loss: 0.6992 Acc: 0.8560\n",
      "test Loss: 0.6894 Acc: 0.8640\n",
      "Epoch 1485/1499\n",
      "----------\n",
      "train Loss: 0.7016 Acc: 0.8496\n",
      "val Loss: 0.7082 Acc: 0.8360\n",
      "test Loss: 0.6989 Acc: 0.8480\n",
      "Epoch 1486/1499\n",
      "----------\n",
      "train Loss: 0.7004 Acc: 0.8491\n",
      "val Loss: 0.7246 Acc: 0.8200\n",
      "test Loss: 0.7010 Acc: 0.8600\n",
      "Epoch 1487/1499\n",
      "----------\n",
      "train Loss: 0.7000 Acc: 0.8520\n",
      "val Loss: 0.6969 Acc: 0.8560\n",
      "test Loss: 0.6883 Acc: 0.8680\n",
      "Epoch 1488/1499\n",
      "----------\n",
      "train Loss: 0.7034 Acc: 0.8442\n",
      "val Loss: 0.7101 Acc: 0.8400\n",
      "test Loss: 0.7039 Acc: 0.8560\n",
      "Epoch 1489/1499\n",
      "----------\n",
      "train Loss: 0.6996 Acc: 0.8496\n",
      "val Loss: 0.7024 Acc: 0.8440\n",
      "test Loss: 0.6821 Acc: 0.8760\n",
      "Epoch 1490/1499\n",
      "----------\n",
      "train Loss: 0.7013 Acc: 0.8493\n",
      "val Loss: 0.6993 Acc: 0.8560\n",
      "test Loss: 0.7021 Acc: 0.8440\n",
      "Epoch 1491/1499\n",
      "----------\n",
      "train Loss: 0.6971 Acc: 0.8524\n",
      "val Loss: 0.7059 Acc: 0.8520\n",
      "test Loss: 0.7050 Acc: 0.8440\n",
      "Epoch 1492/1499\n",
      "----------\n",
      "train Loss: 0.7009 Acc: 0.8511\n",
      "val Loss: 0.6973 Acc: 0.8480\n",
      "test Loss: 0.7020 Acc: 0.8520\n",
      "Epoch 1493/1499\n",
      "----------\n",
      "train Loss: 0.7024 Acc: 0.8473\n",
      "val Loss: 0.7065 Acc: 0.8400\n",
      "test Loss: 0.6904 Acc: 0.8640\n",
      "Epoch 1494/1499\n",
      "----------\n",
      "train Loss: 0.7048 Acc: 0.8456\n",
      "val Loss: 0.7013 Acc: 0.8440\n",
      "test Loss: 0.7043 Acc: 0.8440\n",
      "Epoch 1495/1499\n",
      "----------\n",
      "train Loss: 0.7020 Acc: 0.8473\n",
      "val Loss: 0.7059 Acc: 0.8360\n",
      "test Loss: 0.7059 Acc: 0.8440\n",
      "Epoch 1496/1499\n",
      "----------\n",
      "train Loss: 0.6987 Acc: 0.8513\n",
      "val Loss: 0.7081 Acc: 0.8320\n",
      "test Loss: 0.7044 Acc: 0.8520\n",
      "Epoch 1497/1499\n",
      "----------\n",
      "train Loss: 0.6997 Acc: 0.8513\n",
      "val Loss: 0.7161 Acc: 0.8280\n",
      "test Loss: 0.6879 Acc: 0.8680\n",
      "Epoch 1498/1499\n",
      "----------\n",
      "train Loss: 0.7018 Acc: 0.8484\n",
      "val Loss: 0.7103 Acc: 0.8360\n",
      "test Loss: 0.7192 Acc: 0.8280\n",
      "Epoch 1499/1499\n",
      "----------\n",
      "train Loss: 0.7045 Acc: 0.8464\n",
      "val Loss: 0.7068 Acc: 0.8480\n",
      "test Loss: 0.7160 Acc: 0.8360\n",
      "Training complete in 1m 24s\n",
      "Best test Acc: 0.884000\n",
      "Epoch 0/1499\n",
      "----------\n",
      "train Loss: 1.1065 Acc: 0.3380\n",
      "val Loss: 1.1044 Acc: 0.2880\n",
      "test Loss: 1.1047 Acc: 0.3520\n",
      "Epoch 1/1499\n",
      "----------\n",
      "train Loss: 1.1053 Acc: 0.3411\n",
      "val Loss: 1.1035 Acc: 0.3320\n",
      "test Loss: 1.1040 Acc: 0.3640\n",
      "Epoch 2/1499\n",
      "----------\n",
      "train Loss: 1.1047 Acc: 0.3336\n",
      "val Loss: 1.1023 Acc: 0.3320\n",
      "test Loss: 1.1038 Acc: 0.3520\n",
      "Epoch 3/1499\n",
      "----------\n",
      "train Loss: 1.1039 Acc: 0.3367\n",
      "val Loss: 1.1005 Acc: 0.3480\n",
      "test Loss: 1.1030 Acc: 0.3440\n",
      "Epoch 4/1499\n",
      "----------\n",
      "train Loss: 1.1033 Acc: 0.3398\n",
      "val Loss: 1.1015 Acc: 0.3320\n",
      "test Loss: 1.1021 Acc: 0.3520\n",
      "Epoch 5/1499\n",
      "----------\n",
      "train Loss: 1.1027 Acc: 0.3413\n",
      "val Loss: 1.1007 Acc: 0.3360\n",
      "test Loss: 1.1014 Acc: 0.3560\n",
      "Epoch 6/1499\n",
      "----------\n",
      "train Loss: 1.1018 Acc: 0.3409\n",
      "val Loss: 1.0997 Acc: 0.3360\n",
      "test Loss: 1.0997 Acc: 0.3640\n",
      "Epoch 7/1499\n",
      "----------\n",
      "train Loss: 1.1013 Acc: 0.3480\n",
      "val Loss: 1.0992 Acc: 0.3480\n",
      "test Loss: 1.0999 Acc: 0.3560\n",
      "Epoch 8/1499\n",
      "----------\n",
      "train Loss: 1.1007 Acc: 0.3449\n",
      "val Loss: 1.0979 Acc: 0.3400\n",
      "test Loss: 1.0986 Acc: 0.3520\n",
      "Epoch 9/1499\n",
      "----------\n",
      "train Loss: 1.0996 Acc: 0.3549\n",
      "val Loss: 1.0981 Acc: 0.3320\n",
      "test Loss: 1.0987 Acc: 0.3720\n",
      "Epoch 10/1499\n",
      "----------\n",
      "train Loss: 1.0988 Acc: 0.3567\n",
      "val Loss: 1.0969 Acc: 0.3640\n",
      "test Loss: 1.0968 Acc: 0.3800\n",
      "Epoch 11/1499\n",
      "----------\n",
      "train Loss: 1.0982 Acc: 0.3544\n",
      "val Loss: 1.0970 Acc: 0.3280\n",
      "test Loss: 1.0972 Acc: 0.3680\n",
      "Epoch 12/1499\n",
      "----------\n",
      "train Loss: 1.0974 Acc: 0.3584\n",
      "val Loss: 1.0966 Acc: 0.3360\n",
      "test Loss: 1.0967 Acc: 0.3760\n",
      "Epoch 13/1499\n",
      "----------\n",
      "train Loss: 1.0969 Acc: 0.3567\n",
      "val Loss: 1.0955 Acc: 0.3480\n",
      "test Loss: 1.0956 Acc: 0.3720\n",
      "Epoch 14/1499\n",
      "----------\n",
      "train Loss: 1.0964 Acc: 0.3544\n",
      "val Loss: 1.0945 Acc: 0.3880\n",
      "test Loss: 1.0948 Acc: 0.3960\n",
      "Epoch 15/1499\n",
      "----------\n",
      "train Loss: 1.0956 Acc: 0.3638\n",
      "val Loss: 1.0940 Acc: 0.3520\n",
      "test Loss: 1.0938 Acc: 0.3760\n",
      "Epoch 16/1499\n",
      "----------\n",
      "train Loss: 1.0950 Acc: 0.3627\n",
      "val Loss: 1.0937 Acc: 0.3640\n",
      "test Loss: 1.0933 Acc: 0.4000\n",
      "Epoch 17/1499\n",
      "----------\n",
      "train Loss: 1.0942 Acc: 0.3656\n",
      "val Loss: 1.0926 Acc: 0.3440\n",
      "test Loss: 1.0929 Acc: 0.3920\n",
      "Epoch 18/1499\n",
      "----------\n",
      "train Loss: 1.0937 Acc: 0.3638\n",
      "val Loss: 1.0921 Acc: 0.3600\n",
      "test Loss: 1.0918 Acc: 0.3800\n",
      "Epoch 19/1499\n",
      "----------\n",
      "train Loss: 1.0930 Acc: 0.3776\n",
      "val Loss: 1.0917 Acc: 0.3800\n",
      "test Loss: 1.0912 Acc: 0.3720\n",
      "Epoch 20/1499\n",
      "----------\n",
      "train Loss: 1.0924 Acc: 0.3787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0905 Acc: 0.4160\n",
      "test Loss: 1.0900 Acc: 0.4040\n",
      "Epoch 21/1499\n",
      "----------\n",
      "train Loss: 1.0917 Acc: 0.3893\n",
      "val Loss: 1.0902 Acc: 0.4120\n",
      "test Loss: 1.0895 Acc: 0.4080\n",
      "Epoch 22/1499\n",
      "----------\n",
      "train Loss: 1.0908 Acc: 0.4013\n",
      "val Loss: 1.0892 Acc: 0.4440\n",
      "test Loss: 1.0891 Acc: 0.4040\n",
      "Epoch 23/1499\n",
      "----------\n",
      "train Loss: 1.0901 Acc: 0.4029\n",
      "val Loss: 1.0884 Acc: 0.4240\n",
      "test Loss: 1.0884 Acc: 0.4080\n",
      "Epoch 24/1499\n",
      "----------\n",
      "train Loss: 1.0895 Acc: 0.4096\n",
      "val Loss: 1.0889 Acc: 0.4320\n",
      "test Loss: 1.0871 Acc: 0.4480\n",
      "Epoch 25/1499\n",
      "----------\n",
      "train Loss: 1.0884 Acc: 0.4218\n",
      "val Loss: 1.0875 Acc: 0.4520\n",
      "test Loss: 1.0871 Acc: 0.4320\n",
      "Epoch 26/1499\n",
      "----------\n",
      "train Loss: 1.0876 Acc: 0.4213\n",
      "val Loss: 1.0872 Acc: 0.4320\n",
      "test Loss: 1.0861 Acc: 0.4440\n",
      "Epoch 27/1499\n",
      "----------\n",
      "train Loss: 1.0870 Acc: 0.4296\n",
      "val Loss: 1.0855 Acc: 0.4520\n",
      "test Loss: 1.0850 Acc: 0.4320\n",
      "Epoch 28/1499\n",
      "----------\n",
      "train Loss: 1.0861 Acc: 0.4378\n",
      "val Loss: 1.0847 Acc: 0.4920\n",
      "test Loss: 1.0848 Acc: 0.4320\n",
      "Epoch 29/1499\n",
      "----------\n",
      "train Loss: 1.0852 Acc: 0.4411\n",
      "val Loss: 1.0850 Acc: 0.4360\n",
      "test Loss: 1.0835 Acc: 0.4520\n",
      "Epoch 30/1499\n",
      "----------\n",
      "train Loss: 1.0848 Acc: 0.4396\n",
      "val Loss: 1.0839 Acc: 0.4640\n",
      "test Loss: 1.0840 Acc: 0.4840\n",
      "Epoch 31/1499\n",
      "----------\n",
      "train Loss: 1.0837 Acc: 0.4542\n",
      "val Loss: 1.0827 Acc: 0.4760\n",
      "test Loss: 1.0821 Acc: 0.5040\n",
      "Epoch 32/1499\n",
      "----------\n",
      "train Loss: 1.0831 Acc: 0.4618\n",
      "val Loss: 1.0825 Acc: 0.4760\n",
      "test Loss: 1.0814 Acc: 0.4960\n",
      "Epoch 33/1499\n",
      "----------\n",
      "train Loss: 1.0819 Acc: 0.4780\n",
      "val Loss: 1.0808 Acc: 0.4800\n",
      "test Loss: 1.0801 Acc: 0.4880\n",
      "Epoch 34/1499\n",
      "----------\n",
      "train Loss: 1.0811 Acc: 0.4722\n",
      "val Loss: 1.0799 Acc: 0.5000\n",
      "test Loss: 1.0788 Acc: 0.4920\n",
      "Epoch 35/1499\n",
      "----------\n",
      "train Loss: 1.0798 Acc: 0.4858\n",
      "val Loss: 1.0801 Acc: 0.4880\n",
      "test Loss: 1.0775 Acc: 0.5080\n",
      "Epoch 36/1499\n",
      "----------\n",
      "train Loss: 1.0788 Acc: 0.4942\n",
      "val Loss: 1.0784 Acc: 0.4880\n",
      "test Loss: 1.0766 Acc: 0.5000\n",
      "Epoch 37/1499\n",
      "----------\n",
      "train Loss: 1.0780 Acc: 0.4936\n",
      "val Loss: 1.0765 Acc: 0.5400\n",
      "test Loss: 1.0754 Acc: 0.5120\n",
      "Epoch 38/1499\n",
      "----------\n",
      "train Loss: 1.0770 Acc: 0.5060\n",
      "val Loss: 1.0751 Acc: 0.5320\n",
      "test Loss: 1.0741 Acc: 0.5440\n",
      "Epoch 39/1499\n",
      "----------\n",
      "train Loss: 1.0757 Acc: 0.5064\n",
      "val Loss: 1.0737 Acc: 0.5600\n",
      "test Loss: 1.0734 Acc: 0.5280\n",
      "Epoch 40/1499\n",
      "----------\n",
      "train Loss: 1.0747 Acc: 0.5149\n",
      "val Loss: 1.0742 Acc: 0.5440\n",
      "test Loss: 1.0722 Acc: 0.5520\n",
      "Epoch 41/1499\n",
      "----------\n",
      "train Loss: 1.0735 Acc: 0.5242\n",
      "val Loss: 1.0731 Acc: 0.5360\n",
      "test Loss: 1.0705 Acc: 0.5480\n",
      "Epoch 42/1499\n",
      "----------\n",
      "train Loss: 1.0726 Acc: 0.5227\n",
      "val Loss: 1.0715 Acc: 0.5480\n",
      "test Loss: 1.0708 Acc: 0.5720\n",
      "Epoch 43/1499\n",
      "----------\n",
      "train Loss: 1.0709 Acc: 0.5402\n",
      "val Loss: 1.0717 Acc: 0.5560\n",
      "test Loss: 1.0686 Acc: 0.5880\n",
      "Epoch 44/1499\n",
      "----------\n",
      "train Loss: 1.0695 Acc: 0.5547\n",
      "val Loss: 1.0687 Acc: 0.5800\n",
      "test Loss: 1.0677 Acc: 0.6040\n",
      "Epoch 45/1499\n",
      "----------\n",
      "train Loss: 1.0685 Acc: 0.5689\n",
      "val Loss: 1.0670 Acc: 0.6200\n",
      "test Loss: 1.0652 Acc: 0.6480\n",
      "Epoch 46/1499\n",
      "----------\n",
      "train Loss: 1.0669 Acc: 0.5836\n",
      "val Loss: 1.0656 Acc: 0.6040\n",
      "test Loss: 1.0642 Acc: 0.6560\n",
      "Epoch 47/1499\n",
      "----------\n",
      "train Loss: 1.0656 Acc: 0.6040\n",
      "val Loss: 1.0646 Acc: 0.6360\n",
      "test Loss: 1.0633 Acc: 0.6160\n",
      "Epoch 48/1499\n",
      "----------\n",
      "train Loss: 1.0641 Acc: 0.6160\n",
      "val Loss: 1.0624 Acc: 0.6240\n",
      "test Loss: 1.0620 Acc: 0.6320\n",
      "Epoch 49/1499\n",
      "----------\n",
      "train Loss: 1.0621 Acc: 0.6200\n",
      "val Loss: 1.0621 Acc: 0.6480\n",
      "test Loss: 1.0604 Acc: 0.6920\n",
      "Epoch 50/1499\n",
      "----------\n",
      "train Loss: 1.0611 Acc: 0.6291\n",
      "val Loss: 1.0602 Acc: 0.6280\n",
      "test Loss: 1.0565 Acc: 0.6880\n",
      "Epoch 51/1499\n",
      "----------\n",
      "train Loss: 1.0591 Acc: 0.6273\n",
      "val Loss: 1.0570 Acc: 0.6440\n",
      "test Loss: 1.0555 Acc: 0.6840\n",
      "Epoch 52/1499\n",
      "----------\n",
      "train Loss: 1.0573 Acc: 0.6449\n",
      "val Loss: 1.0568 Acc: 0.6520\n",
      "test Loss: 1.0530 Acc: 0.7000\n",
      "Epoch 53/1499\n",
      "----------\n",
      "train Loss: 1.0551 Acc: 0.6544\n",
      "val Loss: 1.0542 Acc: 0.6640\n",
      "test Loss: 1.0512 Acc: 0.6920\n",
      "Epoch 54/1499\n",
      "----------\n",
      "train Loss: 1.0539 Acc: 0.6598\n",
      "val Loss: 1.0531 Acc: 0.6680\n",
      "test Loss: 1.0520 Acc: 0.6720\n",
      "Epoch 55/1499\n",
      "----------\n",
      "train Loss: 1.0520 Acc: 0.6742\n",
      "val Loss: 1.0500 Acc: 0.6760\n",
      "test Loss: 1.0474 Acc: 0.7000\n",
      "Epoch 56/1499\n",
      "----------\n",
      "train Loss: 1.0495 Acc: 0.6771\n",
      "val Loss: 1.0478 Acc: 0.6920\n",
      "test Loss: 1.0449 Acc: 0.7200\n",
      "Epoch 57/1499\n",
      "----------\n",
      "train Loss: 1.0480 Acc: 0.6862\n",
      "val Loss: 1.0460 Acc: 0.6760\n",
      "test Loss: 1.0463 Acc: 0.7160\n",
      "Epoch 58/1499\n",
      "----------\n",
      "train Loss: 1.0458 Acc: 0.6933\n",
      "val Loss: 1.0433 Acc: 0.6880\n",
      "test Loss: 1.0419 Acc: 0.7080\n",
      "Epoch 59/1499\n",
      "----------\n",
      "train Loss: 1.0435 Acc: 0.6998\n",
      "val Loss: 1.0418 Acc: 0.6800\n",
      "test Loss: 1.0381 Acc: 0.7560\n",
      "Epoch 60/1499\n",
      "----------\n",
      "train Loss: 1.0418 Acc: 0.7027\n",
      "val Loss: 1.0394 Acc: 0.7160\n",
      "test Loss: 1.0352 Acc: 0.7520\n",
      "Epoch 61/1499\n",
      "----------\n",
      "train Loss: 1.0387 Acc: 0.7113\n",
      "val Loss: 1.0408 Acc: 0.6840\n",
      "test Loss: 1.0361 Acc: 0.7280\n",
      "Epoch 62/1499\n",
      "----------\n",
      "train Loss: 1.0366 Acc: 0.7080\n",
      "val Loss: 1.0351 Acc: 0.7000\n",
      "test Loss: 1.0292 Acc: 0.7600\n",
      "Epoch 63/1499\n",
      "----------\n",
      "train Loss: 1.0346 Acc: 0.7196\n",
      "val Loss: 1.0321 Acc: 0.7040\n",
      "test Loss: 1.0283 Acc: 0.7440\n",
      "Epoch 64/1499\n",
      "----------\n",
      "train Loss: 1.0322 Acc: 0.7233\n",
      "val Loss: 1.0301 Acc: 0.7120\n",
      "test Loss: 1.0258 Acc: 0.7760\n",
      "Epoch 65/1499\n",
      "----------\n",
      "train Loss: 1.0293 Acc: 0.7200\n",
      "val Loss: 1.0278 Acc: 0.7040\n",
      "test Loss: 1.0231 Acc: 0.7520\n",
      "Epoch 66/1499\n",
      "----------\n",
      "train Loss: 1.0271 Acc: 0.7260\n",
      "val Loss: 1.0240 Acc: 0.7120\n",
      "test Loss: 1.0199 Acc: 0.7600\n",
      "Epoch 67/1499\n",
      "----------\n",
      "train Loss: 1.0248 Acc: 0.7336\n",
      "val Loss: 1.0250 Acc: 0.6960\n",
      "test Loss: 1.0169 Acc: 0.7400\n",
      "Epoch 68/1499\n",
      "----------\n",
      "train Loss: 1.0226 Acc: 0.7251\n",
      "val Loss: 1.0196 Acc: 0.7080\n",
      "test Loss: 1.0164 Acc: 0.7360\n",
      "Epoch 69/1499\n",
      "----------\n",
      "train Loss: 1.0190 Acc: 0.7331\n",
      "val Loss: 1.0164 Acc: 0.7240\n",
      "test Loss: 1.0124 Acc: 0.7600\n",
      "Epoch 70/1499\n",
      "----------\n",
      "train Loss: 1.0169 Acc: 0.7391\n",
      "val Loss: 1.0158 Acc: 0.7080\n",
      "test Loss: 1.0095 Acc: 0.7600\n",
      "Epoch 71/1499\n",
      "----------\n",
      "train Loss: 1.0142 Acc: 0.7331\n",
      "val Loss: 1.0114 Acc: 0.7480\n",
      "test Loss: 1.0072 Acc: 0.7480\n",
      "Epoch 72/1499\n",
      "----------\n",
      "train Loss: 1.0112 Acc: 0.7371\n",
      "val Loss: 1.0113 Acc: 0.7240\n",
      "test Loss: 1.0075 Acc: 0.7560\n",
      "Epoch 73/1499\n",
      "----------\n",
      "train Loss: 1.0079 Acc: 0.7387\n",
      "val Loss: 1.0087 Acc: 0.7240\n",
      "test Loss: 0.9996 Acc: 0.7560\n",
      "Epoch 74/1499\n",
      "----------\n",
      "train Loss: 1.0057 Acc: 0.7349\n",
      "val Loss: 1.0084 Acc: 0.7080\n",
      "test Loss: 0.9990 Acc: 0.7520\n",
      "Epoch 75/1499\n",
      "----------\n",
      "train Loss: 1.0022 Acc: 0.7460\n",
      "val Loss: 1.0009 Acc: 0.7320\n",
      "test Loss: 0.9984 Acc: 0.7520\n",
      "Epoch 76/1499\n",
      "----------\n",
      "train Loss: 0.9994 Acc: 0.7438\n",
      "val Loss: 0.9992 Acc: 0.7400\n",
      "test Loss: 0.9890 Acc: 0.7640\n",
      "Epoch 77/1499\n",
      "----------\n",
      "train Loss: 0.9970 Acc: 0.7431\n",
      "val Loss: 0.9963 Acc: 0.7280\n",
      "test Loss: 0.9863 Acc: 0.7560\n",
      "Epoch 78/1499\n",
      "----------\n",
      "train Loss: 0.9933 Acc: 0.7480\n",
      "val Loss: 0.9934 Acc: 0.7120\n",
      "test Loss: 0.9833 Acc: 0.7640\n",
      "Epoch 79/1499\n",
      "----------\n",
      "train Loss: 0.9905 Acc: 0.7533\n",
      "val Loss: 0.9939 Acc: 0.6880\n",
      "test Loss: 0.9811 Acc: 0.7760\n",
      "Epoch 80/1499\n",
      "----------\n",
      "train Loss: 0.9870 Acc: 0.7544\n",
      "val Loss: 0.9885 Acc: 0.7480\n",
      "test Loss: 0.9808 Acc: 0.7760\n",
      "Epoch 81/1499\n",
      "----------\n",
      "train Loss: 0.9843 Acc: 0.7556\n",
      "val Loss: 0.9841 Acc: 0.7440\n",
      "test Loss: 0.9785 Acc: 0.7760\n",
      "Epoch 82/1499\n",
      "----------\n",
      "train Loss: 0.9815 Acc: 0.7529\n",
      "val Loss: 0.9829 Acc: 0.7240\n",
      "test Loss: 0.9702 Acc: 0.7720\n",
      "Epoch 83/1499\n",
      "----------\n",
      "train Loss: 0.9777 Acc: 0.7562\n",
      "val Loss: 0.9813 Acc: 0.7080\n",
      "test Loss: 0.9690 Acc: 0.7840\n",
      "Epoch 84/1499\n",
      "----------\n",
      "train Loss: 0.9740 Acc: 0.7584\n",
      "val Loss: 0.9748 Acc: 0.7160\n",
      "test Loss: 0.9686 Acc: 0.7280\n",
      "Epoch 85/1499\n",
      "----------\n",
      "train Loss: 0.9726 Acc: 0.7520\n",
      "val Loss: 0.9737 Acc: 0.7040\n",
      "test Loss: 0.9598 Acc: 0.7880\n",
      "Epoch 86/1499\n",
      "----------\n",
      "train Loss: 0.9674 Acc: 0.7616\n",
      "val Loss: 0.9706 Acc: 0.7120\n",
      "test Loss: 0.9601 Acc: 0.7520\n",
      "Epoch 87/1499\n",
      "----------\n",
      "train Loss: 0.9648 Acc: 0.7600\n",
      "val Loss: 0.9696 Acc: 0.7120\n",
      "test Loss: 0.9560 Acc: 0.7840\n",
      "Epoch 88/1499\n",
      "----------\n",
      "train Loss: 0.9616 Acc: 0.7638\n",
      "val Loss: 0.9612 Acc: 0.7120\n",
      "test Loss: 0.9481 Acc: 0.7800\n",
      "Epoch 89/1499\n",
      "----------\n",
      "train Loss: 0.9584 Acc: 0.7613\n",
      "val Loss: 0.9544 Acc: 0.7560\n",
      "test Loss: 0.9453 Acc: 0.7560\n",
      "Epoch 90/1499\n",
      "----------\n",
      "train Loss: 0.9542 Acc: 0.7642\n",
      "val Loss: 0.9562 Acc: 0.7360\n",
      "test Loss: 0.9423 Acc: 0.7920\n",
      "Epoch 91/1499\n",
      "----------\n",
      "train Loss: 0.9512 Acc: 0.7627\n",
      "val Loss: 0.9522 Acc: 0.7280\n",
      "test Loss: 0.9393 Acc: 0.8000\n",
      "Epoch 92/1499\n",
      "----------\n",
      "train Loss: 0.9488 Acc: 0.7651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.9528 Acc: 0.7280\n",
      "test Loss: 0.9379 Acc: 0.7960\n",
      "Epoch 93/1499\n",
      "----------\n",
      "train Loss: 0.9462 Acc: 0.7622\n",
      "val Loss: 0.9474 Acc: 0.7120\n",
      "test Loss: 0.9323 Acc: 0.7840\n",
      "Epoch 94/1499\n",
      "----------\n",
      "train Loss: 0.9403 Acc: 0.7644\n",
      "val Loss: 0.9427 Acc: 0.7440\n",
      "test Loss: 0.9301 Acc: 0.7880\n",
      "Epoch 95/1499\n",
      "----------\n",
      "train Loss: 0.9382 Acc: 0.7667\n",
      "val Loss: 0.9408 Acc: 0.7160\n",
      "test Loss: 0.9301 Acc: 0.7720\n",
      "Epoch 96/1499\n",
      "----------\n",
      "train Loss: 0.9351 Acc: 0.7756\n",
      "val Loss: 0.9389 Acc: 0.7280\n",
      "test Loss: 0.9190 Acc: 0.8040\n",
      "Epoch 97/1499\n",
      "----------\n",
      "train Loss: 0.9324 Acc: 0.7682\n",
      "val Loss: 0.9337 Acc: 0.7480\n",
      "test Loss: 0.9218 Acc: 0.7880\n",
      "Epoch 98/1499\n",
      "----------\n",
      "train Loss: 0.9285 Acc: 0.7727\n",
      "val Loss: 0.9307 Acc: 0.7400\n",
      "test Loss: 0.9151 Acc: 0.7960\n",
      "Epoch 99/1499\n",
      "----------\n",
      "train Loss: 0.9256 Acc: 0.7718\n",
      "val Loss: 0.9302 Acc: 0.7120\n",
      "test Loss: 0.9148 Acc: 0.7920\n",
      "Epoch 100/1499\n",
      "----------\n",
      "train Loss: 0.9213 Acc: 0.7711\n",
      "val Loss: 0.9319 Acc: 0.7320\n",
      "test Loss: 0.9078 Acc: 0.7760\n",
      "Epoch 101/1499\n",
      "----------\n",
      "train Loss: 0.9187 Acc: 0.7738\n",
      "val Loss: 0.9234 Acc: 0.7200\n",
      "test Loss: 0.9040 Acc: 0.8000\n",
      "Epoch 102/1499\n",
      "----------\n",
      "train Loss: 0.9151 Acc: 0.7778\n",
      "val Loss: 0.9241 Acc: 0.7160\n",
      "test Loss: 0.9040 Acc: 0.7880\n",
      "Epoch 103/1499\n",
      "----------\n",
      "train Loss: 0.9124 Acc: 0.7742\n",
      "val Loss: 0.9179 Acc: 0.7160\n",
      "test Loss: 0.8999 Acc: 0.8000\n",
      "Epoch 104/1499\n",
      "----------\n",
      "train Loss: 0.9089 Acc: 0.7771\n",
      "val Loss: 0.9093 Acc: 0.7280\n",
      "test Loss: 0.8934 Acc: 0.8040\n",
      "Epoch 105/1499\n",
      "----------\n",
      "train Loss: 0.9062 Acc: 0.7751\n",
      "val Loss: 0.9083 Acc: 0.7320\n",
      "test Loss: 0.8917 Acc: 0.8000\n",
      "Epoch 106/1499\n",
      "----------\n",
      "train Loss: 0.9023 Acc: 0.7802\n",
      "val Loss: 0.9089 Acc: 0.7080\n",
      "test Loss: 0.8900 Acc: 0.8000\n",
      "Epoch 107/1499\n",
      "----------\n",
      "train Loss: 0.9002 Acc: 0.7804\n",
      "val Loss: 0.9110 Acc: 0.7360\n",
      "test Loss: 0.8872 Acc: 0.7880\n",
      "Epoch 108/1499\n",
      "----------\n",
      "train Loss: 0.8948 Acc: 0.7811\n",
      "val Loss: 0.9061 Acc: 0.7360\n",
      "test Loss: 0.8803 Acc: 0.8160\n",
      "Epoch 109/1499\n",
      "----------\n",
      "train Loss: 0.8932 Acc: 0.7813\n",
      "val Loss: 0.8988 Acc: 0.7360\n",
      "test Loss: 0.8762 Acc: 0.8000\n",
      "Epoch 110/1499\n",
      "----------\n",
      "train Loss: 0.8897 Acc: 0.7802\n",
      "val Loss: 0.8962 Acc: 0.7280\n",
      "test Loss: 0.8799 Acc: 0.7960\n",
      "Epoch 111/1499\n",
      "----------\n",
      "train Loss: 0.8866 Acc: 0.7789\n",
      "val Loss: 0.8934 Acc: 0.7200\n",
      "test Loss: 0.8668 Acc: 0.8120\n",
      "Epoch 112/1499\n",
      "----------\n",
      "train Loss: 0.8842 Acc: 0.7818\n",
      "val Loss: 0.8950 Acc: 0.7400\n",
      "test Loss: 0.8697 Acc: 0.8040\n",
      "Epoch 113/1499\n",
      "----------\n",
      "train Loss: 0.8811 Acc: 0.7853\n",
      "val Loss: 0.8884 Acc: 0.7320\n",
      "test Loss: 0.8628 Acc: 0.8080\n",
      "Epoch 114/1499\n",
      "----------\n",
      "train Loss: 0.8776 Acc: 0.7802\n",
      "val Loss: 0.8836 Acc: 0.7440\n",
      "test Loss: 0.8707 Acc: 0.7880\n",
      "Epoch 115/1499\n",
      "----------\n",
      "train Loss: 0.8757 Acc: 0.7789\n",
      "val Loss: 0.8868 Acc: 0.7520\n",
      "test Loss: 0.8630 Acc: 0.7960\n",
      "Epoch 116/1499\n",
      "----------\n",
      "train Loss: 0.8725 Acc: 0.7838\n",
      "val Loss: 0.8812 Acc: 0.7360\n",
      "test Loss: 0.8593 Acc: 0.8120\n",
      "Epoch 117/1499\n",
      "----------\n",
      "train Loss: 0.8698 Acc: 0.7822\n",
      "val Loss: 0.8783 Acc: 0.7440\n",
      "test Loss: 0.8555 Acc: 0.8080\n",
      "Epoch 118/1499\n",
      "----------\n",
      "train Loss: 0.8667 Acc: 0.7842\n",
      "val Loss: 0.8742 Acc: 0.7400\n",
      "test Loss: 0.8571 Acc: 0.8000\n",
      "Epoch 119/1499\n",
      "----------\n",
      "train Loss: 0.8644 Acc: 0.7842\n",
      "val Loss: 0.8708 Acc: 0.7600\n",
      "test Loss: 0.8499 Acc: 0.8120\n",
      "Epoch 120/1499\n",
      "----------\n",
      "train Loss: 0.8615 Acc: 0.7884\n",
      "val Loss: 0.8658 Acc: 0.7720\n",
      "test Loss: 0.8503 Acc: 0.8000\n",
      "Epoch 121/1499\n",
      "----------\n",
      "train Loss: 0.8592 Acc: 0.7849\n",
      "val Loss: 0.8696 Acc: 0.7520\n",
      "test Loss: 0.8450 Acc: 0.7920\n",
      "Epoch 122/1499\n",
      "----------\n",
      "train Loss: 0.8565 Acc: 0.7858\n",
      "val Loss: 0.8693 Acc: 0.7560\n",
      "test Loss: 0.8391 Acc: 0.8160\n",
      "Epoch 123/1499\n",
      "----------\n",
      "train Loss: 0.8532 Acc: 0.7880\n",
      "val Loss: 0.8657 Acc: 0.7240\n",
      "test Loss: 0.8352 Acc: 0.7920\n",
      "Epoch 124/1499\n",
      "----------\n",
      "train Loss: 0.8512 Acc: 0.7884\n",
      "val Loss: 0.8589 Acc: 0.7320\n",
      "test Loss: 0.8313 Acc: 0.8120\n",
      "Epoch 125/1499\n",
      "----------\n",
      "train Loss: 0.8482 Acc: 0.7909\n",
      "val Loss: 0.8635 Acc: 0.7360\n",
      "test Loss: 0.8334 Acc: 0.8040\n",
      "Epoch 126/1499\n",
      "----------\n",
      "train Loss: 0.8455 Acc: 0.7931\n",
      "val Loss: 0.8595 Acc: 0.7520\n",
      "test Loss: 0.8257 Acc: 0.8080\n",
      "Epoch 127/1499\n",
      "----------\n",
      "train Loss: 0.8431 Acc: 0.7942\n",
      "val Loss: 0.8595 Acc: 0.7480\n",
      "test Loss: 0.8325 Acc: 0.8160\n",
      "Epoch 128/1499\n",
      "----------\n",
      "train Loss: 0.8411 Acc: 0.7938\n",
      "val Loss: 0.8528 Acc: 0.7520\n",
      "test Loss: 0.8225 Acc: 0.8240\n",
      "Epoch 129/1499\n",
      "----------\n",
      "train Loss: 0.8383 Acc: 0.7953\n",
      "val Loss: 0.8553 Acc: 0.7640\n",
      "test Loss: 0.8282 Acc: 0.8120\n",
      "Epoch 130/1499\n",
      "----------\n",
      "train Loss: 0.8371 Acc: 0.7922\n",
      "val Loss: 0.8518 Acc: 0.7400\n",
      "test Loss: 0.8219 Acc: 0.8040\n",
      "Epoch 131/1499\n",
      "----------\n",
      "train Loss: 0.8342 Acc: 0.7947\n",
      "val Loss: 0.8499 Acc: 0.7560\n",
      "test Loss: 0.8106 Acc: 0.8280\n",
      "Epoch 132/1499\n",
      "----------\n",
      "train Loss: 0.8324 Acc: 0.7931\n",
      "val Loss: 0.8460 Acc: 0.7360\n",
      "test Loss: 0.8128 Acc: 0.8160\n",
      "Epoch 133/1499\n",
      "----------\n",
      "train Loss: 0.8303 Acc: 0.7907\n",
      "val Loss: 0.8356 Acc: 0.7800\n",
      "test Loss: 0.8113 Acc: 0.8160\n",
      "Epoch 134/1499\n",
      "----------\n",
      "train Loss: 0.8284 Acc: 0.7924\n",
      "val Loss: 0.8408 Acc: 0.7720\n",
      "test Loss: 0.8063 Acc: 0.8200\n",
      "Epoch 135/1499\n",
      "----------\n",
      "train Loss: 0.8254 Acc: 0.7953\n",
      "val Loss: 0.8439 Acc: 0.7360\n",
      "test Loss: 0.8130 Acc: 0.7960\n",
      "Epoch 136/1499\n",
      "----------\n",
      "train Loss: 0.8236 Acc: 0.7898\n",
      "val Loss: 0.8378 Acc: 0.7640\n",
      "test Loss: 0.8029 Acc: 0.8240\n",
      "Epoch 137/1499\n",
      "----------\n",
      "train Loss: 0.8234 Acc: 0.7902\n",
      "val Loss: 0.8302 Acc: 0.7760\n",
      "test Loss: 0.8053 Acc: 0.8080\n",
      "Epoch 138/1499\n",
      "----------\n",
      "train Loss: 0.8193 Acc: 0.7989\n",
      "val Loss: 0.8363 Acc: 0.7760\n",
      "test Loss: 0.8030 Acc: 0.8160\n",
      "Epoch 139/1499\n",
      "----------\n",
      "train Loss: 0.8182 Acc: 0.7962\n",
      "val Loss: 0.8296 Acc: 0.7640\n",
      "test Loss: 0.7989 Acc: 0.8240\n",
      "Epoch 140/1499\n",
      "----------\n",
      "train Loss: 0.8175 Acc: 0.7933\n",
      "val Loss: 0.8308 Acc: 0.7560\n",
      "test Loss: 0.7937 Acc: 0.8280\n",
      "Epoch 141/1499\n",
      "----------\n",
      "train Loss: 0.8137 Acc: 0.7958\n",
      "val Loss: 0.8283 Acc: 0.7760\n",
      "test Loss: 0.7969 Acc: 0.8120\n",
      "Epoch 142/1499\n",
      "----------\n",
      "train Loss: 0.8130 Acc: 0.7962\n",
      "val Loss: 0.8237 Acc: 0.7800\n",
      "test Loss: 0.7932 Acc: 0.8120\n",
      "Epoch 143/1499\n",
      "----------\n",
      "train Loss: 0.8109 Acc: 0.7982\n",
      "val Loss: 0.8260 Acc: 0.7560\n",
      "test Loss: 0.7933 Acc: 0.8040\n",
      "Epoch 144/1499\n",
      "----------\n",
      "train Loss: 0.8087 Acc: 0.8007\n",
      "val Loss: 0.8166 Acc: 0.7720\n",
      "test Loss: 0.7933 Acc: 0.8160\n",
      "Epoch 145/1499\n",
      "----------\n",
      "train Loss: 0.8077 Acc: 0.7976\n",
      "val Loss: 0.8170 Acc: 0.7760\n",
      "test Loss: 0.7906 Acc: 0.8200\n",
      "Epoch 146/1499\n",
      "----------\n",
      "train Loss: 0.8063 Acc: 0.7944\n",
      "val Loss: 0.8217 Acc: 0.7880\n",
      "test Loss: 0.7831 Acc: 0.8280\n",
      "Epoch 147/1499\n",
      "----------\n",
      "train Loss: 0.8048 Acc: 0.7933\n",
      "val Loss: 0.8133 Acc: 0.7680\n",
      "test Loss: 0.7835 Acc: 0.8240\n",
      "Epoch 148/1499\n",
      "----------\n",
      "train Loss: 0.8032 Acc: 0.7956\n",
      "val Loss: 0.8165 Acc: 0.7800\n",
      "test Loss: 0.7811 Acc: 0.8200\n",
      "Epoch 149/1499\n",
      "----------\n",
      "train Loss: 0.8026 Acc: 0.7967\n",
      "val Loss: 0.8113 Acc: 0.7760\n",
      "test Loss: 0.7799 Acc: 0.8240\n",
      "Epoch 150/1499\n",
      "----------\n",
      "train Loss: 0.7981 Acc: 0.7989\n",
      "val Loss: 0.8125 Acc: 0.7680\n",
      "test Loss: 0.7856 Acc: 0.8320\n",
      "Epoch 151/1499\n",
      "----------\n",
      "train Loss: 0.7967 Acc: 0.8007\n",
      "val Loss: 0.8156 Acc: 0.7720\n",
      "test Loss: 0.7805 Acc: 0.8200\n",
      "Epoch 152/1499\n",
      "----------\n",
      "train Loss: 0.7963 Acc: 0.7971\n",
      "val Loss: 0.8127 Acc: 0.7680\n",
      "test Loss: 0.7778 Acc: 0.8040\n",
      "Epoch 153/1499\n",
      "----------\n",
      "train Loss: 0.7946 Acc: 0.7971\n",
      "val Loss: 0.8085 Acc: 0.7640\n",
      "test Loss: 0.7788 Acc: 0.8240\n",
      "Epoch 154/1499\n",
      "----------\n",
      "train Loss: 0.7937 Acc: 0.8051\n",
      "val Loss: 0.8067 Acc: 0.7760\n",
      "test Loss: 0.7724 Acc: 0.8160\n",
      "Epoch 155/1499\n",
      "----------\n",
      "train Loss: 0.7931 Acc: 0.7980\n",
      "val Loss: 0.8088 Acc: 0.7600\n",
      "test Loss: 0.7712 Acc: 0.8160\n",
      "Epoch 156/1499\n",
      "----------\n",
      "train Loss: 0.7921 Acc: 0.7947\n",
      "val Loss: 0.8064 Acc: 0.7760\n",
      "test Loss: 0.7650 Acc: 0.8240\n",
      "Epoch 157/1499\n",
      "----------\n",
      "train Loss: 0.7881 Acc: 0.8047\n",
      "val Loss: 0.8162 Acc: 0.7440\n",
      "test Loss: 0.7689 Acc: 0.8320\n",
      "Epoch 158/1499\n",
      "----------\n",
      "train Loss: 0.7887 Acc: 0.7989\n",
      "val Loss: 0.8054 Acc: 0.7640\n",
      "test Loss: 0.7626 Acc: 0.8280\n",
      "Epoch 159/1499\n",
      "----------\n",
      "train Loss: 0.7860 Acc: 0.8020\n",
      "val Loss: 0.8081 Acc: 0.7560\n",
      "test Loss: 0.7716 Acc: 0.8160\n",
      "Epoch 160/1499\n",
      "----------\n",
      "train Loss: 0.7861 Acc: 0.7960\n",
      "val Loss: 0.7910 Acc: 0.7760\n",
      "test Loss: 0.7650 Acc: 0.8160\n",
      "Epoch 161/1499\n",
      "----------\n",
      "train Loss: 0.7823 Acc: 0.8064\n",
      "val Loss: 0.8025 Acc: 0.7760\n",
      "test Loss: 0.7675 Acc: 0.8240\n",
      "Epoch 162/1499\n",
      "----------\n",
      "train Loss: 0.7828 Acc: 0.8058\n",
      "val Loss: 0.7965 Acc: 0.7840\n",
      "test Loss: 0.7605 Acc: 0.8120\n",
      "Epoch 163/1499\n",
      "----------\n",
      "train Loss: 0.7820 Acc: 0.8000\n",
      "val Loss: 0.8049 Acc: 0.7480\n",
      "test Loss: 0.7610 Acc: 0.8240\n",
      "Epoch 164/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.7810 Acc: 0.8047\n",
      "val Loss: 0.7957 Acc: 0.7720\n",
      "test Loss: 0.7703 Acc: 0.8240\n",
      "Epoch 165/1499\n",
      "----------\n",
      "train Loss: 0.7780 Acc: 0.8087\n",
      "val Loss: 0.7884 Acc: 0.7840\n",
      "test Loss: 0.7605 Acc: 0.8280\n",
      "Epoch 166/1499\n",
      "----------\n",
      "train Loss: 0.7789 Acc: 0.8056\n",
      "val Loss: 0.7929 Acc: 0.7920\n",
      "test Loss: 0.7622 Acc: 0.8320\n",
      "Epoch 167/1499\n",
      "----------\n",
      "train Loss: 0.7773 Acc: 0.8049\n",
      "val Loss: 0.7932 Acc: 0.8000\n",
      "test Loss: 0.7600 Acc: 0.8400\n",
      "Epoch 168/1499\n",
      "----------\n",
      "train Loss: 0.7763 Acc: 0.8027\n",
      "val Loss: 0.7947 Acc: 0.7760\n",
      "test Loss: 0.7518 Acc: 0.8480\n",
      "Epoch 169/1499\n",
      "----------\n",
      "train Loss: 0.7769 Acc: 0.8038\n",
      "val Loss: 0.7890 Acc: 0.7880\n",
      "test Loss: 0.7555 Acc: 0.8280\n",
      "Epoch 170/1499\n",
      "----------\n",
      "train Loss: 0.7747 Acc: 0.8069\n",
      "val Loss: 0.7866 Acc: 0.7920\n",
      "test Loss: 0.7561 Acc: 0.8280\n",
      "Epoch 171/1499\n",
      "----------\n",
      "train Loss: 0.7735 Acc: 0.8087\n",
      "val Loss: 0.7875 Acc: 0.7800\n",
      "test Loss: 0.7500 Acc: 0.8360\n",
      "Epoch 172/1499\n",
      "----------\n",
      "train Loss: 0.7724 Acc: 0.8049\n",
      "val Loss: 0.7850 Acc: 0.7760\n",
      "test Loss: 0.7581 Acc: 0.8240\n",
      "Epoch 173/1499\n",
      "----------\n",
      "train Loss: 0.7708 Acc: 0.8071\n",
      "val Loss: 0.7809 Acc: 0.7840\n",
      "test Loss: 0.7612 Acc: 0.8400\n",
      "Epoch 174/1499\n",
      "----------\n",
      "train Loss: 0.7708 Acc: 0.8080\n",
      "val Loss: 0.7875 Acc: 0.7800\n",
      "test Loss: 0.7491 Acc: 0.8400\n",
      "Epoch 175/1499\n",
      "----------\n",
      "train Loss: 0.7688 Acc: 0.8056\n",
      "val Loss: 0.7829 Acc: 0.7800\n",
      "test Loss: 0.7493 Acc: 0.8240\n",
      "Epoch 176/1499\n",
      "----------\n",
      "train Loss: 0.7672 Acc: 0.8078\n",
      "val Loss: 0.7841 Acc: 0.7840\n",
      "test Loss: 0.7533 Acc: 0.8320\n",
      "Epoch 177/1499\n",
      "----------\n",
      "train Loss: 0.7678 Acc: 0.8100\n",
      "val Loss: 0.7824 Acc: 0.7920\n",
      "test Loss: 0.7513 Acc: 0.8400\n",
      "Epoch 178/1499\n",
      "----------\n",
      "train Loss: 0.7668 Acc: 0.8107\n",
      "val Loss: 0.7731 Acc: 0.7880\n",
      "test Loss: 0.7469 Acc: 0.8320\n",
      "Epoch 179/1499\n",
      "----------\n",
      "train Loss: 0.7640 Acc: 0.8111\n",
      "val Loss: 0.7751 Acc: 0.7880\n",
      "test Loss: 0.7386 Acc: 0.8480\n",
      "Epoch 180/1499\n",
      "----------\n",
      "train Loss: 0.7664 Acc: 0.8104\n",
      "val Loss: 0.7802 Acc: 0.7680\n",
      "test Loss: 0.7478 Acc: 0.8360\n",
      "Epoch 181/1499\n",
      "----------\n",
      "train Loss: 0.7630 Acc: 0.8096\n",
      "val Loss: 0.7809 Acc: 0.7800\n",
      "test Loss: 0.7503 Acc: 0.8240\n",
      "Epoch 182/1499\n",
      "----------\n",
      "train Loss: 0.7619 Acc: 0.8093\n",
      "val Loss: 0.7743 Acc: 0.7960\n",
      "test Loss: 0.7426 Acc: 0.8360\n",
      "Epoch 183/1499\n",
      "----------\n",
      "train Loss: 0.7605 Acc: 0.8107\n",
      "val Loss: 0.7808 Acc: 0.7840\n",
      "test Loss: 0.7477 Acc: 0.8240\n",
      "Epoch 184/1499\n",
      "----------\n",
      "train Loss: 0.7598 Acc: 0.8140\n",
      "val Loss: 0.7728 Acc: 0.8040\n",
      "test Loss: 0.7448 Acc: 0.8200\n",
      "Epoch 185/1499\n",
      "----------\n",
      "train Loss: 0.7609 Acc: 0.8064\n",
      "val Loss: 0.7834 Acc: 0.7640\n",
      "test Loss: 0.7427 Acc: 0.8200\n",
      "Epoch 186/1499\n",
      "----------\n",
      "train Loss: 0.7584 Acc: 0.8091\n",
      "val Loss: 0.7738 Acc: 0.7840\n",
      "test Loss: 0.7406 Acc: 0.8480\n",
      "Epoch 187/1499\n",
      "----------\n",
      "train Loss: 0.7576 Acc: 0.8158\n",
      "val Loss: 0.7689 Acc: 0.8000\n",
      "test Loss: 0.7405 Acc: 0.8360\n",
      "Epoch 188/1499\n",
      "----------\n",
      "train Loss: 0.7587 Acc: 0.8098\n",
      "val Loss: 0.7754 Acc: 0.7880\n",
      "test Loss: 0.7395 Acc: 0.8360\n",
      "Epoch 189/1499\n",
      "----------\n",
      "train Loss: 0.7583 Acc: 0.8073\n",
      "val Loss: 0.7701 Acc: 0.7880\n",
      "test Loss: 0.7413 Acc: 0.8320\n",
      "Epoch 190/1499\n",
      "----------\n",
      "train Loss: 0.7565 Acc: 0.8076\n",
      "val Loss: 0.7767 Acc: 0.7920\n",
      "test Loss: 0.7381 Acc: 0.8280\n",
      "Epoch 191/1499\n",
      "----------\n",
      "train Loss: 0.7553 Acc: 0.8122\n",
      "val Loss: 0.7687 Acc: 0.8080\n",
      "test Loss: 0.7341 Acc: 0.8440\n",
      "Epoch 192/1499\n",
      "----------\n",
      "train Loss: 0.7565 Acc: 0.8113\n",
      "val Loss: 0.7672 Acc: 0.8040\n",
      "test Loss: 0.7393 Acc: 0.8400\n",
      "Epoch 193/1499\n",
      "----------\n",
      "train Loss: 0.7536 Acc: 0.8096\n",
      "val Loss: 0.7706 Acc: 0.7760\n",
      "test Loss: 0.7365 Acc: 0.8440\n",
      "Epoch 194/1499\n",
      "----------\n",
      "train Loss: 0.7523 Acc: 0.8162\n",
      "val Loss: 0.7659 Acc: 0.7840\n",
      "test Loss: 0.7385 Acc: 0.8440\n",
      "Epoch 195/1499\n",
      "----------\n",
      "train Loss: 0.7519 Acc: 0.8129\n",
      "val Loss: 0.7692 Acc: 0.7880\n",
      "test Loss: 0.7358 Acc: 0.8480\n",
      "Epoch 196/1499\n",
      "----------\n",
      "train Loss: 0.7511 Acc: 0.8144\n",
      "val Loss: 0.7698 Acc: 0.7720\n",
      "test Loss: 0.7349 Acc: 0.8520\n",
      "Epoch 197/1499\n",
      "----------\n",
      "train Loss: 0.7511 Acc: 0.8138\n",
      "val Loss: 0.7695 Acc: 0.7960\n",
      "test Loss: 0.7394 Acc: 0.8320\n",
      "Epoch 198/1499\n",
      "----------\n",
      "train Loss: 0.7506 Acc: 0.8158\n",
      "val Loss: 0.7562 Acc: 0.8120\n",
      "test Loss: 0.7400 Acc: 0.8320\n",
      "Epoch 199/1499\n",
      "----------\n",
      "train Loss: 0.7480 Acc: 0.8160\n",
      "val Loss: 0.7689 Acc: 0.7920\n",
      "test Loss: 0.7336 Acc: 0.8320\n",
      "Epoch 200/1499\n",
      "----------\n",
      "train Loss: 0.7493 Acc: 0.8176\n",
      "val Loss: 0.7631 Acc: 0.8040\n",
      "test Loss: 0.7282 Acc: 0.8400\n",
      "Epoch 201/1499\n",
      "----------\n",
      "train Loss: 0.7486 Acc: 0.8176\n",
      "val Loss: 0.7600 Acc: 0.7880\n",
      "test Loss: 0.7327 Acc: 0.8400\n",
      "Epoch 202/1499\n",
      "----------\n",
      "train Loss: 0.7486 Acc: 0.8162\n",
      "val Loss: 0.7643 Acc: 0.7960\n",
      "test Loss: 0.7327 Acc: 0.8240\n",
      "Epoch 203/1499\n",
      "----------\n",
      "train Loss: 0.7474 Acc: 0.8182\n",
      "val Loss: 0.7562 Acc: 0.7960\n",
      "test Loss: 0.7362 Acc: 0.8480\n",
      "Epoch 204/1499\n",
      "----------\n",
      "train Loss: 0.7463 Acc: 0.8187\n",
      "val Loss: 0.7583 Acc: 0.8080\n",
      "test Loss: 0.7268 Acc: 0.8440\n",
      "Epoch 205/1499\n",
      "----------\n",
      "train Loss: 0.7464 Acc: 0.8176\n",
      "val Loss: 0.7569 Acc: 0.8040\n",
      "test Loss: 0.7313 Acc: 0.8400\n",
      "Epoch 206/1499\n",
      "----------\n",
      "train Loss: 0.7465 Acc: 0.8176\n",
      "val Loss: 0.7666 Acc: 0.8040\n",
      "test Loss: 0.7316 Acc: 0.8360\n",
      "Epoch 207/1499\n",
      "----------\n",
      "train Loss: 0.7455 Acc: 0.8164\n",
      "val Loss: 0.7604 Acc: 0.8080\n",
      "test Loss: 0.7299 Acc: 0.8400\n",
      "Epoch 208/1499\n",
      "----------\n",
      "train Loss: 0.7443 Acc: 0.8180\n",
      "val Loss: 0.7594 Acc: 0.8200\n",
      "test Loss: 0.7313 Acc: 0.8440\n",
      "Epoch 209/1499\n",
      "----------\n",
      "train Loss: 0.7439 Acc: 0.8202\n",
      "val Loss: 0.7618 Acc: 0.8000\n",
      "test Loss: 0.7308 Acc: 0.8520\n",
      "Epoch 210/1499\n",
      "----------\n",
      "train Loss: 0.7419 Acc: 0.8238\n",
      "val Loss: 0.7512 Acc: 0.8040\n",
      "test Loss: 0.7267 Acc: 0.8600\n",
      "Epoch 211/1499\n",
      "----------\n",
      "train Loss: 0.7434 Acc: 0.8182\n",
      "val Loss: 0.7604 Acc: 0.8000\n",
      "test Loss: 0.7195 Acc: 0.8480\n",
      "Epoch 212/1499\n",
      "----------\n",
      "train Loss: 0.7418 Acc: 0.8184\n",
      "val Loss: 0.7571 Acc: 0.7920\n",
      "test Loss: 0.7270 Acc: 0.8440\n",
      "Epoch 213/1499\n",
      "----------\n",
      "train Loss: 0.7429 Acc: 0.8209\n",
      "val Loss: 0.7489 Acc: 0.8120\n",
      "test Loss: 0.7359 Acc: 0.8480\n",
      "Epoch 214/1499\n",
      "----------\n",
      "train Loss: 0.7405 Acc: 0.8191\n",
      "val Loss: 0.7458 Acc: 0.8120\n",
      "test Loss: 0.7286 Acc: 0.8640\n",
      "Epoch 215/1499\n",
      "----------\n",
      "train Loss: 0.7397 Acc: 0.8216\n",
      "val Loss: 0.7566 Acc: 0.8160\n",
      "test Loss: 0.7255 Acc: 0.8360\n",
      "Epoch 216/1499\n",
      "----------\n",
      "train Loss: 0.7398 Acc: 0.8211\n",
      "val Loss: 0.7527 Acc: 0.8000\n",
      "test Loss: 0.7224 Acc: 0.8440\n",
      "Epoch 217/1499\n",
      "----------\n",
      "train Loss: 0.7385 Acc: 0.8231\n",
      "val Loss: 0.7545 Acc: 0.8080\n",
      "test Loss: 0.7257 Acc: 0.8520\n",
      "Epoch 218/1499\n",
      "----------\n",
      "train Loss: 0.7392 Acc: 0.8198\n",
      "val Loss: 0.7458 Acc: 0.8120\n",
      "test Loss: 0.7188 Acc: 0.8520\n",
      "Epoch 219/1499\n",
      "----------\n",
      "train Loss: 0.7371 Acc: 0.8240\n",
      "val Loss: 0.7445 Acc: 0.8160\n",
      "test Loss: 0.7253 Acc: 0.8440\n",
      "Epoch 220/1499\n",
      "----------\n",
      "train Loss: 0.7378 Acc: 0.8249\n",
      "val Loss: 0.7503 Acc: 0.8040\n",
      "test Loss: 0.7161 Acc: 0.8440\n",
      "Epoch 221/1499\n",
      "----------\n",
      "train Loss: 0.7361 Acc: 0.8236\n",
      "val Loss: 0.7510 Acc: 0.7960\n",
      "test Loss: 0.7204 Acc: 0.8600\n",
      "Epoch 222/1499\n",
      "----------\n",
      "train Loss: 0.7370 Acc: 0.8238\n",
      "val Loss: 0.7432 Acc: 0.8240\n",
      "test Loss: 0.7205 Acc: 0.8480\n",
      "Epoch 223/1499\n",
      "----------\n",
      "train Loss: 0.7347 Acc: 0.8278\n",
      "val Loss: 0.7505 Acc: 0.8200\n",
      "test Loss: 0.7111 Acc: 0.8560\n",
      "Epoch 224/1499\n",
      "----------\n",
      "train Loss: 0.7353 Acc: 0.8233\n",
      "val Loss: 0.7417 Acc: 0.8160\n",
      "test Loss: 0.7229 Acc: 0.8400\n",
      "Epoch 225/1499\n",
      "----------\n",
      "train Loss: 0.7348 Acc: 0.8269\n",
      "val Loss: 0.7436 Acc: 0.8040\n",
      "test Loss: 0.7159 Acc: 0.8400\n",
      "Epoch 226/1499\n",
      "----------\n",
      "train Loss: 0.7339 Acc: 0.8238\n",
      "val Loss: 0.7443 Acc: 0.8080\n",
      "test Loss: 0.7105 Acc: 0.8560\n",
      "Epoch 227/1499\n",
      "----------\n",
      "train Loss: 0.7327 Acc: 0.8269\n",
      "val Loss: 0.7449 Acc: 0.8160\n",
      "test Loss: 0.7168 Acc: 0.8440\n",
      "Epoch 228/1499\n",
      "----------\n",
      "train Loss: 0.7334 Acc: 0.8260\n",
      "val Loss: 0.7387 Acc: 0.8160\n",
      "test Loss: 0.7121 Acc: 0.8560\n",
      "Epoch 229/1499\n",
      "----------\n",
      "train Loss: 0.7337 Acc: 0.8253\n",
      "val Loss: 0.7503 Acc: 0.8040\n",
      "test Loss: 0.7175 Acc: 0.8440\n",
      "Epoch 230/1499\n",
      "----------\n",
      "train Loss: 0.7311 Acc: 0.8269\n",
      "val Loss: 0.7404 Acc: 0.8120\n",
      "test Loss: 0.7203 Acc: 0.8440\n",
      "Epoch 231/1499\n",
      "----------\n",
      "train Loss: 0.7305 Acc: 0.8280\n",
      "val Loss: 0.7404 Acc: 0.8320\n",
      "test Loss: 0.7159 Acc: 0.8480\n",
      "Epoch 232/1499\n",
      "----------\n",
      "train Loss: 0.7312 Acc: 0.8267\n",
      "val Loss: 0.7459 Acc: 0.8160\n",
      "test Loss: 0.7258 Acc: 0.8400\n",
      "Epoch 233/1499\n",
      "----------\n",
      "train Loss: 0.7308 Acc: 0.8287\n",
      "val Loss: 0.7386 Acc: 0.8160\n",
      "test Loss: 0.7222 Acc: 0.8520\n",
      "Epoch 234/1499\n",
      "----------\n",
      "train Loss: 0.7306 Acc: 0.8280\n",
      "val Loss: 0.7458 Acc: 0.8240\n",
      "test Loss: 0.7149 Acc: 0.8400\n",
      "Epoch 235/1499\n",
      "----------\n",
      "train Loss: 0.7293 Acc: 0.8313\n",
      "val Loss: 0.7395 Acc: 0.8080\n",
      "test Loss: 0.7086 Acc: 0.8480\n",
      "Epoch 236/1499\n",
      "----------\n",
      "train Loss: 0.7284 Acc: 0.8302\n",
      "val Loss: 0.7498 Acc: 0.8120\n",
      "test Loss: 0.7105 Acc: 0.8480\n",
      "Epoch 237/1499\n",
      "----------\n",
      "train Loss: 0.7285 Acc: 0.8311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.7421 Acc: 0.8080\n",
      "test Loss: 0.7154 Acc: 0.8480\n",
      "Epoch 238/1499\n",
      "----------\n",
      "train Loss: 0.7280 Acc: 0.8329\n",
      "val Loss: 0.7366 Acc: 0.8320\n",
      "test Loss: 0.7131 Acc: 0.8600\n",
      "Epoch 239/1499\n",
      "----------\n",
      "train Loss: 0.7274 Acc: 0.8353\n",
      "val Loss: 0.7362 Acc: 0.8240\n",
      "test Loss: 0.7186 Acc: 0.8400\n",
      "Epoch 240/1499\n",
      "----------\n",
      "train Loss: 0.7276 Acc: 0.8307\n",
      "val Loss: 0.7383 Acc: 0.8160\n",
      "test Loss: 0.7138 Acc: 0.8480\n",
      "Epoch 241/1499\n",
      "----------\n",
      "train Loss: 0.7271 Acc: 0.8318\n",
      "val Loss: 0.7332 Acc: 0.8240\n",
      "test Loss: 0.7108 Acc: 0.8480\n",
      "Epoch 242/1499\n",
      "----------\n",
      "train Loss: 0.7262 Acc: 0.8329\n",
      "val Loss: 0.7373 Acc: 0.8160\n",
      "test Loss: 0.7121 Acc: 0.8600\n",
      "Epoch 243/1499\n",
      "----------\n",
      "train Loss: 0.7262 Acc: 0.8342\n",
      "val Loss: 0.7386 Acc: 0.8240\n",
      "test Loss: 0.7085 Acc: 0.8560\n",
      "Epoch 244/1499\n",
      "----------\n",
      "train Loss: 0.7259 Acc: 0.8342\n",
      "val Loss: 0.7410 Acc: 0.8240\n",
      "test Loss: 0.7121 Acc: 0.8440\n",
      "Epoch 245/1499\n",
      "----------\n",
      "train Loss: 0.7255 Acc: 0.8336\n",
      "val Loss: 0.7412 Acc: 0.8200\n",
      "test Loss: 0.7141 Acc: 0.8600\n",
      "Epoch 246/1499\n",
      "----------\n",
      "train Loss: 0.7249 Acc: 0.8307\n",
      "val Loss: 0.7371 Acc: 0.8200\n",
      "test Loss: 0.7120 Acc: 0.8560\n",
      "Epoch 247/1499\n",
      "----------\n",
      "train Loss: 0.7225 Acc: 0.8338\n",
      "val Loss: 0.7312 Acc: 0.8080\n",
      "test Loss: 0.7078 Acc: 0.8560\n",
      "Epoch 248/1499\n",
      "----------\n",
      "train Loss: 0.7251 Acc: 0.8336\n",
      "val Loss: 0.7333 Acc: 0.8240\n",
      "test Loss: 0.7079 Acc: 0.8600\n",
      "Epoch 249/1499\n",
      "----------\n",
      "train Loss: 0.7218 Acc: 0.8364\n",
      "val Loss: 0.7394 Acc: 0.8200\n",
      "test Loss: 0.7120 Acc: 0.8520\n",
      "Epoch 250/1499\n",
      "----------\n",
      "train Loss: 0.7232 Acc: 0.8336\n",
      "val Loss: 0.7344 Acc: 0.8200\n",
      "test Loss: 0.7190 Acc: 0.8440\n",
      "Epoch 251/1499\n",
      "----------\n",
      "train Loss: 0.7223 Acc: 0.8353\n",
      "val Loss: 0.7350 Acc: 0.8280\n",
      "test Loss: 0.7094 Acc: 0.8480\n",
      "Epoch 252/1499\n",
      "----------\n",
      "train Loss: 0.7225 Acc: 0.8353\n",
      "val Loss: 0.7329 Acc: 0.8120\n",
      "test Loss: 0.7119 Acc: 0.8520\n",
      "Epoch 253/1499\n",
      "----------\n",
      "train Loss: 0.7225 Acc: 0.8329\n",
      "val Loss: 0.7340 Acc: 0.8120\n",
      "test Loss: 0.7136 Acc: 0.8480\n",
      "Epoch 254/1499\n",
      "----------\n",
      "train Loss: 0.7222 Acc: 0.8347\n",
      "val Loss: 0.7373 Acc: 0.8120\n",
      "test Loss: 0.7103 Acc: 0.8480\n",
      "Epoch 255/1499\n",
      "----------\n",
      "train Loss: 0.7215 Acc: 0.8320\n",
      "val Loss: 0.7330 Acc: 0.8320\n",
      "test Loss: 0.7168 Acc: 0.8440\n",
      "Epoch 256/1499\n",
      "----------\n",
      "train Loss: 0.7190 Acc: 0.8404\n",
      "val Loss: 0.7294 Acc: 0.8200\n",
      "test Loss: 0.7075 Acc: 0.8480\n",
      "Epoch 257/1499\n",
      "----------\n",
      "train Loss: 0.7202 Acc: 0.8360\n",
      "val Loss: 0.7328 Acc: 0.8360\n",
      "test Loss: 0.7042 Acc: 0.8480\n",
      "Epoch 258/1499\n",
      "----------\n",
      "train Loss: 0.7195 Acc: 0.8380\n",
      "val Loss: 0.7274 Acc: 0.8240\n",
      "test Loss: 0.7066 Acc: 0.8520\n",
      "Epoch 259/1499\n",
      "----------\n",
      "train Loss: 0.7193 Acc: 0.8362\n",
      "val Loss: 0.7316 Acc: 0.8200\n",
      "test Loss: 0.7097 Acc: 0.8560\n",
      "Epoch 260/1499\n",
      "----------\n",
      "train Loss: 0.7193 Acc: 0.8384\n",
      "val Loss: 0.7289 Acc: 0.8200\n",
      "test Loss: 0.7047 Acc: 0.8600\n",
      "Epoch 261/1499\n",
      "----------\n",
      "train Loss: 0.7184 Acc: 0.8404\n",
      "val Loss: 0.7358 Acc: 0.8320\n",
      "test Loss: 0.7082 Acc: 0.8560\n",
      "Epoch 262/1499\n",
      "----------\n",
      "train Loss: 0.7181 Acc: 0.8367\n",
      "val Loss: 0.7374 Acc: 0.7960\n",
      "test Loss: 0.7025 Acc: 0.8520\n",
      "Epoch 263/1499\n",
      "----------\n",
      "train Loss: 0.7182 Acc: 0.8369\n",
      "val Loss: 0.7297 Acc: 0.8240\n",
      "test Loss: 0.7102 Acc: 0.8480\n",
      "Epoch 264/1499\n",
      "----------\n",
      "train Loss: 0.7181 Acc: 0.8353\n",
      "val Loss: 0.7308 Acc: 0.8120\n",
      "test Loss: 0.7047 Acc: 0.8520\n",
      "Epoch 265/1499\n",
      "----------\n",
      "train Loss: 0.7182 Acc: 0.8391\n",
      "val Loss: 0.7300 Acc: 0.8240\n",
      "test Loss: 0.6998 Acc: 0.8800\n",
      "Epoch 266/1499\n",
      "----------\n",
      "train Loss: 0.7181 Acc: 0.8391\n",
      "val Loss: 0.7273 Acc: 0.8360\n",
      "test Loss: 0.7019 Acc: 0.8520\n",
      "Epoch 267/1499\n",
      "----------\n",
      "train Loss: 0.7174 Acc: 0.8391\n",
      "val Loss: 0.7262 Acc: 0.8240\n",
      "test Loss: 0.7134 Acc: 0.8480\n",
      "Epoch 268/1499\n",
      "----------\n",
      "train Loss: 0.7184 Acc: 0.8342\n",
      "val Loss: 0.7295 Acc: 0.8160\n",
      "test Loss: 0.7043 Acc: 0.8480\n",
      "Epoch 269/1499\n",
      "----------\n",
      "train Loss: 0.7155 Acc: 0.8402\n",
      "val Loss: 0.7220 Acc: 0.8240\n",
      "test Loss: 0.6985 Acc: 0.8680\n",
      "Epoch 270/1499\n",
      "----------\n",
      "train Loss: 0.7148 Acc: 0.8404\n",
      "val Loss: 0.7373 Acc: 0.8240\n",
      "test Loss: 0.7082 Acc: 0.8520\n",
      "Epoch 271/1499\n",
      "----------\n",
      "train Loss: 0.7166 Acc: 0.8400\n",
      "val Loss: 0.7266 Acc: 0.8240\n",
      "test Loss: 0.7069 Acc: 0.8400\n",
      "Epoch 272/1499\n",
      "----------\n",
      "train Loss: 0.7160 Acc: 0.8404\n",
      "val Loss: 0.7248 Acc: 0.8360\n",
      "test Loss: 0.7044 Acc: 0.8400\n",
      "Epoch 273/1499\n",
      "----------\n",
      "train Loss: 0.7147 Acc: 0.8404\n",
      "val Loss: 0.7290 Acc: 0.8400\n",
      "test Loss: 0.6996 Acc: 0.8560\n",
      "Epoch 274/1499\n",
      "----------\n",
      "train Loss: 0.7132 Acc: 0.8420\n",
      "val Loss: 0.7236 Acc: 0.8320\n",
      "test Loss: 0.7011 Acc: 0.8560\n",
      "Epoch 275/1499\n",
      "----------\n",
      "train Loss: 0.7129 Acc: 0.8438\n",
      "val Loss: 0.7244 Acc: 0.8200\n",
      "test Loss: 0.7056 Acc: 0.8440\n",
      "Epoch 276/1499\n",
      "----------\n",
      "train Loss: 0.7155 Acc: 0.8387\n",
      "val Loss: 0.7292 Acc: 0.8160\n",
      "test Loss: 0.7077 Acc: 0.8440\n",
      "Epoch 277/1499\n",
      "----------\n",
      "train Loss: 0.7141 Acc: 0.8416\n",
      "val Loss: 0.7287 Acc: 0.8360\n",
      "test Loss: 0.7085 Acc: 0.8360\n",
      "Epoch 278/1499\n",
      "----------\n",
      "train Loss: 0.7126 Acc: 0.8438\n",
      "val Loss: 0.7210 Acc: 0.8280\n",
      "test Loss: 0.6963 Acc: 0.8520\n",
      "Epoch 279/1499\n",
      "----------\n",
      "train Loss: 0.7124 Acc: 0.8418\n",
      "val Loss: 0.7258 Acc: 0.8240\n",
      "test Loss: 0.7008 Acc: 0.8560\n",
      "Epoch 280/1499\n",
      "----------\n",
      "train Loss: 0.7120 Acc: 0.8407\n",
      "val Loss: 0.7265 Acc: 0.8280\n",
      "test Loss: 0.7003 Acc: 0.8640\n",
      "Epoch 281/1499\n",
      "----------\n",
      "train Loss: 0.7112 Acc: 0.8447\n",
      "val Loss: 0.7230 Acc: 0.8360\n",
      "test Loss: 0.6985 Acc: 0.8680\n",
      "Epoch 282/1499\n",
      "----------\n",
      "train Loss: 0.7128 Acc: 0.8413\n",
      "val Loss: 0.7233 Acc: 0.8200\n",
      "test Loss: 0.7046 Acc: 0.8680\n",
      "Epoch 283/1499\n",
      "----------\n",
      "train Loss: 0.7124 Acc: 0.8416\n",
      "val Loss: 0.7207 Acc: 0.8280\n",
      "test Loss: 0.6998 Acc: 0.8600\n",
      "Epoch 284/1499\n",
      "----------\n",
      "train Loss: 0.7116 Acc: 0.8429\n",
      "val Loss: 0.7198 Acc: 0.8280\n",
      "test Loss: 0.7030 Acc: 0.8560\n",
      "Epoch 285/1499\n",
      "----------\n",
      "train Loss: 0.7105 Acc: 0.8456\n",
      "val Loss: 0.7185 Acc: 0.8320\n",
      "test Loss: 0.6961 Acc: 0.8560\n",
      "Epoch 286/1499\n",
      "----------\n",
      "train Loss: 0.7118 Acc: 0.8422\n",
      "val Loss: 0.7246 Acc: 0.8240\n",
      "test Loss: 0.7035 Acc: 0.8480\n",
      "Epoch 287/1499\n",
      "----------\n",
      "train Loss: 0.7096 Acc: 0.8460\n",
      "val Loss: 0.7219 Acc: 0.8280\n",
      "test Loss: 0.7018 Acc: 0.8640\n",
      "Epoch 288/1499\n",
      "----------\n",
      "train Loss: 0.7093 Acc: 0.8473\n",
      "val Loss: 0.7232 Acc: 0.8120\n",
      "test Loss: 0.6955 Acc: 0.8680\n",
      "Epoch 289/1499\n",
      "----------\n",
      "train Loss: 0.7101 Acc: 0.8449\n",
      "val Loss: 0.7209 Acc: 0.8360\n",
      "test Loss: 0.7002 Acc: 0.8640\n",
      "Epoch 290/1499\n",
      "----------\n",
      "train Loss: 0.7087 Acc: 0.8438\n",
      "val Loss: 0.7250 Acc: 0.8240\n",
      "test Loss: 0.6937 Acc: 0.8680\n",
      "Epoch 291/1499\n",
      "----------\n",
      "train Loss: 0.7085 Acc: 0.8464\n",
      "val Loss: 0.7157 Acc: 0.8480\n",
      "test Loss: 0.7040 Acc: 0.8480\n",
      "Epoch 292/1499\n",
      "----------\n",
      "train Loss: 0.7092 Acc: 0.8462\n",
      "val Loss: 0.7247 Acc: 0.8320\n",
      "test Loss: 0.6948 Acc: 0.8680\n",
      "Epoch 293/1499\n",
      "----------\n",
      "train Loss: 0.7081 Acc: 0.8498\n",
      "val Loss: 0.7195 Acc: 0.8440\n",
      "test Loss: 0.6980 Acc: 0.8680\n",
      "Epoch 294/1499\n",
      "----------\n",
      "train Loss: 0.7098 Acc: 0.8433\n",
      "val Loss: 0.7189 Acc: 0.8440\n",
      "test Loss: 0.7008 Acc: 0.8600\n",
      "Epoch 295/1499\n",
      "----------\n",
      "train Loss: 0.7090 Acc: 0.8478\n",
      "val Loss: 0.7189 Acc: 0.8400\n",
      "test Loss: 0.6982 Acc: 0.8560\n",
      "Epoch 296/1499\n",
      "----------\n",
      "train Loss: 0.7076 Acc: 0.8476\n",
      "val Loss: 0.7218 Acc: 0.8360\n",
      "test Loss: 0.6977 Acc: 0.8680\n",
      "Epoch 297/1499\n",
      "----------\n",
      "train Loss: 0.7060 Acc: 0.8500\n",
      "val Loss: 0.7225 Acc: 0.8280\n",
      "test Loss: 0.6978 Acc: 0.8680\n",
      "Epoch 298/1499\n",
      "----------\n",
      "train Loss: 0.7063 Acc: 0.8480\n",
      "val Loss: 0.7182 Acc: 0.8520\n",
      "test Loss: 0.7000 Acc: 0.8640\n",
      "Epoch 299/1499\n",
      "----------\n",
      "train Loss: 0.7072 Acc: 0.8449\n",
      "val Loss: 0.7180 Acc: 0.8480\n",
      "test Loss: 0.7037 Acc: 0.8560\n",
      "Epoch 300/1499\n",
      "----------\n",
      "train Loss: 0.7061 Acc: 0.8464\n",
      "val Loss: 0.7115 Acc: 0.8600\n",
      "test Loss: 0.7032 Acc: 0.8600\n",
      "Epoch 301/1499\n",
      "----------\n",
      "train Loss: 0.7054 Acc: 0.8507\n",
      "val Loss: 0.7151 Acc: 0.8480\n",
      "test Loss: 0.6991 Acc: 0.8560\n",
      "Epoch 302/1499\n",
      "----------\n",
      "train Loss: 0.7045 Acc: 0.8507\n",
      "val Loss: 0.7114 Acc: 0.8560\n",
      "test Loss: 0.6943 Acc: 0.8760\n",
      "Epoch 303/1499\n",
      "----------\n",
      "train Loss: 0.7059 Acc: 0.8484\n",
      "val Loss: 0.7151 Acc: 0.8600\n",
      "test Loss: 0.6965 Acc: 0.8640\n",
      "Epoch 304/1499\n",
      "----------\n",
      "train Loss: 0.7049 Acc: 0.8471\n",
      "val Loss: 0.7123 Acc: 0.8560\n",
      "test Loss: 0.6977 Acc: 0.8680\n",
      "Epoch 305/1499\n",
      "----------\n",
      "train Loss: 0.7051 Acc: 0.8500\n",
      "val Loss: 0.7211 Acc: 0.8480\n",
      "test Loss: 0.6943 Acc: 0.8760\n",
      "Epoch 306/1499\n",
      "----------\n",
      "train Loss: 0.7056 Acc: 0.8527\n",
      "val Loss: 0.7174 Acc: 0.8480\n",
      "test Loss: 0.6931 Acc: 0.8680\n",
      "Epoch 307/1499\n",
      "----------\n",
      "train Loss: 0.7036 Acc: 0.8511\n",
      "val Loss: 0.7180 Acc: 0.8560\n",
      "test Loss: 0.6940 Acc: 0.8680\n",
      "Epoch 308/1499\n",
      "----------\n",
      "train Loss: 0.7043 Acc: 0.8498\n",
      "val Loss: 0.7098 Acc: 0.8520\n",
      "test Loss: 0.6953 Acc: 0.8680\n",
      "Epoch 309/1499\n",
      "----------\n",
      "train Loss: 0.7026 Acc: 0.8536\n",
      "val Loss: 0.7100 Acc: 0.8640\n",
      "test Loss: 0.6954 Acc: 0.8680\n",
      "Epoch 310/1499\n",
      "----------\n",
      "train Loss: 0.7027 Acc: 0.8500\n",
      "val Loss: 0.7051 Acc: 0.8720\n",
      "test Loss: 0.6966 Acc: 0.8760\n",
      "Epoch 311/1499\n",
      "----------\n",
      "train Loss: 0.7025 Acc: 0.8524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.7124 Acc: 0.8520\n",
      "test Loss: 0.6915 Acc: 0.8760\n",
      "Epoch 312/1499\n",
      "----------\n",
      "train Loss: 0.7036 Acc: 0.8516\n",
      "val Loss: 0.7108 Acc: 0.8480\n",
      "test Loss: 0.6969 Acc: 0.8720\n",
      "Epoch 313/1499\n",
      "----------\n",
      "train Loss: 0.7029 Acc: 0.8496\n",
      "val Loss: 0.7134 Acc: 0.8480\n",
      "test Loss: 0.6967 Acc: 0.8680\n",
      "Epoch 314/1499\n",
      "----------\n",
      "train Loss: 0.7023 Acc: 0.8531\n",
      "val Loss: 0.7168 Acc: 0.8480\n",
      "test Loss: 0.6967 Acc: 0.8720\n",
      "Epoch 315/1499\n",
      "----------\n",
      "train Loss: 0.7039 Acc: 0.8518\n",
      "val Loss: 0.7148 Acc: 0.8440\n",
      "test Loss: 0.6932 Acc: 0.8800\n",
      "Epoch 316/1499\n",
      "----------\n",
      "train Loss: 0.7026 Acc: 0.8502\n",
      "val Loss: 0.7073 Acc: 0.8600\n",
      "test Loss: 0.6941 Acc: 0.8720\n",
      "Epoch 317/1499\n",
      "----------\n",
      "train Loss: 0.7010 Acc: 0.8527\n",
      "val Loss: 0.7008 Acc: 0.8560\n",
      "test Loss: 0.6939 Acc: 0.8680\n",
      "Epoch 318/1499\n",
      "----------\n",
      "train Loss: 0.7017 Acc: 0.8547\n",
      "val Loss: 0.7157 Acc: 0.8360\n",
      "test Loss: 0.6967 Acc: 0.8680\n",
      "Epoch 319/1499\n",
      "----------\n",
      "train Loss: 0.7022 Acc: 0.8529\n",
      "val Loss: 0.7092 Acc: 0.8520\n",
      "test Loss: 0.6991 Acc: 0.8560\n",
      "Epoch 320/1499\n",
      "----------\n",
      "train Loss: 0.7009 Acc: 0.8529\n",
      "val Loss: 0.7107 Acc: 0.8440\n",
      "test Loss: 0.6928 Acc: 0.8720\n",
      "Epoch 321/1499\n",
      "----------\n",
      "train Loss: 0.7004 Acc: 0.8536\n",
      "val Loss: 0.7104 Acc: 0.8520\n",
      "test Loss: 0.6899 Acc: 0.8760\n",
      "Epoch 322/1499\n",
      "----------\n",
      "train Loss: 0.6998 Acc: 0.8547\n",
      "val Loss: 0.7093 Acc: 0.8440\n",
      "test Loss: 0.6943 Acc: 0.8640\n",
      "Epoch 323/1499\n",
      "----------\n",
      "train Loss: 0.6998 Acc: 0.8560\n",
      "val Loss: 0.7085 Acc: 0.8520\n",
      "test Loss: 0.6938 Acc: 0.8720\n",
      "Epoch 324/1499\n",
      "----------\n",
      "train Loss: 0.6995 Acc: 0.8527\n",
      "val Loss: 0.7139 Acc: 0.8320\n",
      "test Loss: 0.6870 Acc: 0.8880\n",
      "Epoch 325/1499\n",
      "----------\n",
      "train Loss: 0.6986 Acc: 0.8571\n",
      "val Loss: 0.7044 Acc: 0.8480\n",
      "test Loss: 0.6959 Acc: 0.8640\n",
      "Epoch 326/1499\n",
      "----------\n",
      "train Loss: 0.6985 Acc: 0.8558\n",
      "val Loss: 0.7094 Acc: 0.8560\n",
      "test Loss: 0.6928 Acc: 0.8640\n",
      "Epoch 327/1499\n",
      "----------\n",
      "train Loss: 0.6980 Acc: 0.8571\n",
      "val Loss: 0.7045 Acc: 0.8520\n",
      "test Loss: 0.6889 Acc: 0.8800\n",
      "Epoch 328/1499\n",
      "----------\n",
      "train Loss: 0.6979 Acc: 0.8598\n",
      "val Loss: 0.7112 Acc: 0.8320\n",
      "test Loss: 0.6935 Acc: 0.8640\n",
      "Epoch 329/1499\n",
      "----------\n",
      "train Loss: 0.6984 Acc: 0.8578\n",
      "val Loss: 0.7085 Acc: 0.8320\n",
      "test Loss: 0.6932 Acc: 0.8720\n",
      "Epoch 330/1499\n",
      "----------\n",
      "train Loss: 0.6974 Acc: 0.8562\n",
      "val Loss: 0.7074 Acc: 0.8520\n",
      "test Loss: 0.6920 Acc: 0.8760\n",
      "Epoch 331/1499\n",
      "----------\n",
      "train Loss: 0.6981 Acc: 0.8520\n",
      "val Loss: 0.7063 Acc: 0.8560\n",
      "test Loss: 0.6913 Acc: 0.8720\n",
      "Epoch 332/1499\n",
      "----------\n",
      "train Loss: 0.6973 Acc: 0.8562\n",
      "val Loss: 0.7091 Acc: 0.8520\n",
      "test Loss: 0.6872 Acc: 0.8720\n",
      "Epoch 333/1499\n",
      "----------\n",
      "train Loss: 0.6984 Acc: 0.8518\n",
      "val Loss: 0.7092 Acc: 0.8440\n",
      "test Loss: 0.6891 Acc: 0.8720\n",
      "Epoch 334/1499\n",
      "----------\n",
      "train Loss: 0.6975 Acc: 0.8573\n",
      "val Loss: 0.7022 Acc: 0.8640\n",
      "test Loss: 0.6919 Acc: 0.8560\n",
      "Epoch 335/1499\n",
      "----------\n",
      "train Loss: 0.6966 Acc: 0.8549\n",
      "val Loss: 0.7087 Acc: 0.8520\n",
      "test Loss: 0.6950 Acc: 0.8680\n",
      "Epoch 336/1499\n",
      "----------\n",
      "train Loss: 0.6957 Acc: 0.8558\n",
      "val Loss: 0.7004 Acc: 0.8560\n",
      "test Loss: 0.6860 Acc: 0.8760\n",
      "Epoch 337/1499\n",
      "----------\n",
      "train Loss: 0.6962 Acc: 0.8553\n",
      "val Loss: 0.7029 Acc: 0.8600\n",
      "test Loss: 0.6905 Acc: 0.8680\n",
      "Epoch 338/1499\n",
      "----------\n",
      "train Loss: 0.6965 Acc: 0.8558\n",
      "val Loss: 0.7032 Acc: 0.8480\n",
      "test Loss: 0.6851 Acc: 0.8840\n",
      "Epoch 339/1499\n",
      "----------\n",
      "train Loss: 0.6939 Acc: 0.8569\n",
      "val Loss: 0.7015 Acc: 0.8480\n",
      "test Loss: 0.6874 Acc: 0.8800\n",
      "Epoch 340/1499\n",
      "----------\n",
      "train Loss: 0.6942 Acc: 0.8578\n",
      "val Loss: 0.7033 Acc: 0.8600\n",
      "test Loss: 0.6909 Acc: 0.8720\n",
      "Epoch 341/1499\n",
      "----------\n",
      "train Loss: 0.6944 Acc: 0.8582\n",
      "val Loss: 0.7031 Acc: 0.8600\n",
      "test Loss: 0.6907 Acc: 0.8720\n",
      "Epoch 342/1499\n",
      "----------\n",
      "train Loss: 0.6946 Acc: 0.8591\n",
      "val Loss: 0.7019 Acc: 0.8600\n",
      "test Loss: 0.6882 Acc: 0.8680\n",
      "Epoch 343/1499\n",
      "----------\n",
      "train Loss: 0.6953 Acc: 0.8602\n",
      "val Loss: 0.6966 Acc: 0.8640\n",
      "test Loss: 0.6848 Acc: 0.8800\n",
      "Epoch 344/1499\n",
      "----------\n",
      "train Loss: 0.6935 Acc: 0.8593\n",
      "val Loss: 0.7020 Acc: 0.8560\n",
      "test Loss: 0.6884 Acc: 0.8760\n",
      "Epoch 345/1499\n",
      "----------\n",
      "train Loss: 0.6933 Acc: 0.8627\n",
      "val Loss: 0.7007 Acc: 0.8560\n",
      "test Loss: 0.6920 Acc: 0.8680\n",
      "Epoch 346/1499\n",
      "----------\n",
      "train Loss: 0.6938 Acc: 0.8602\n",
      "val Loss: 0.6980 Acc: 0.8560\n",
      "test Loss: 0.6863 Acc: 0.8640\n",
      "Epoch 347/1499\n",
      "----------\n",
      "train Loss: 0.6935 Acc: 0.8607\n",
      "val Loss: 0.7061 Acc: 0.8480\n",
      "test Loss: 0.6947 Acc: 0.8680\n",
      "Epoch 348/1499\n",
      "----------\n",
      "train Loss: 0.6940 Acc: 0.8620\n",
      "val Loss: 0.6959 Acc: 0.8600\n",
      "test Loss: 0.6884 Acc: 0.8760\n",
      "Epoch 349/1499\n",
      "----------\n",
      "train Loss: 0.6939 Acc: 0.8629\n",
      "val Loss: 0.6970 Acc: 0.8520\n",
      "test Loss: 0.6838 Acc: 0.8720\n",
      "Epoch 350/1499\n",
      "----------\n",
      "train Loss: 0.6937 Acc: 0.8604\n",
      "val Loss: 0.6915 Acc: 0.8640\n",
      "test Loss: 0.6846 Acc: 0.8800\n",
      "Epoch 351/1499\n",
      "----------\n",
      "train Loss: 0.6925 Acc: 0.8616\n",
      "val Loss: 0.6962 Acc: 0.8600\n",
      "test Loss: 0.6857 Acc: 0.8760\n",
      "Epoch 352/1499\n",
      "----------\n",
      "train Loss: 0.6908 Acc: 0.8624\n",
      "val Loss: 0.7004 Acc: 0.8520\n",
      "test Loss: 0.6892 Acc: 0.8680\n",
      "Epoch 353/1499\n",
      "----------\n",
      "train Loss: 0.6929 Acc: 0.8647\n",
      "val Loss: 0.7014 Acc: 0.8640\n",
      "test Loss: 0.6889 Acc: 0.8720\n",
      "Epoch 354/1499\n",
      "----------\n",
      "train Loss: 0.6926 Acc: 0.8624\n",
      "val Loss: 0.7011 Acc: 0.8680\n",
      "test Loss: 0.6917 Acc: 0.8760\n",
      "Epoch 355/1499\n",
      "----------\n",
      "train Loss: 0.6917 Acc: 0.8622\n",
      "val Loss: 0.6981 Acc: 0.8720\n",
      "test Loss: 0.6860 Acc: 0.8760\n",
      "Epoch 356/1499\n",
      "----------\n",
      "train Loss: 0.6916 Acc: 0.8667\n",
      "val Loss: 0.6978 Acc: 0.8600\n",
      "test Loss: 0.6854 Acc: 0.8800\n",
      "Epoch 357/1499\n",
      "----------\n",
      "train Loss: 0.6929 Acc: 0.8613\n",
      "val Loss: 0.7028 Acc: 0.8640\n",
      "test Loss: 0.6867 Acc: 0.8800\n",
      "Epoch 358/1499\n",
      "----------\n",
      "train Loss: 0.6900 Acc: 0.8647\n",
      "val Loss: 0.6955 Acc: 0.8520\n",
      "test Loss: 0.6889 Acc: 0.8760\n",
      "Epoch 359/1499\n",
      "----------\n",
      "train Loss: 0.6914 Acc: 0.8636\n",
      "val Loss: 0.6982 Acc: 0.8600\n",
      "test Loss: 0.6937 Acc: 0.8640\n",
      "Epoch 360/1499\n",
      "----------\n",
      "train Loss: 0.6897 Acc: 0.8656\n",
      "val Loss: 0.6957 Acc: 0.8680\n",
      "test Loss: 0.6821 Acc: 0.8720\n",
      "Epoch 361/1499\n",
      "----------\n",
      "train Loss: 0.6892 Acc: 0.8647\n",
      "val Loss: 0.6889 Acc: 0.8640\n",
      "test Loss: 0.6867 Acc: 0.8720\n",
      "Epoch 362/1499\n",
      "----------\n",
      "train Loss: 0.6894 Acc: 0.8638\n",
      "val Loss: 0.7057 Acc: 0.8560\n",
      "test Loss: 0.6803 Acc: 0.8840\n",
      "Epoch 363/1499\n",
      "----------\n",
      "train Loss: 0.6897 Acc: 0.8676\n",
      "val Loss: 0.7078 Acc: 0.8600\n",
      "test Loss: 0.6784 Acc: 0.8800\n",
      "Epoch 364/1499\n",
      "----------\n",
      "train Loss: 0.6883 Acc: 0.8662\n",
      "val Loss: 0.6933 Acc: 0.8560\n",
      "test Loss: 0.6863 Acc: 0.8760\n",
      "Epoch 365/1499\n",
      "----------\n",
      "train Loss: 0.6896 Acc: 0.8636\n",
      "val Loss: 0.6949 Acc: 0.8640\n",
      "test Loss: 0.6861 Acc: 0.8800\n",
      "Epoch 366/1499\n",
      "----------\n",
      "train Loss: 0.6889 Acc: 0.8660\n",
      "val Loss: 0.6910 Acc: 0.8560\n",
      "test Loss: 0.6869 Acc: 0.8800\n",
      "Epoch 367/1499\n",
      "----------\n",
      "train Loss: 0.6883 Acc: 0.8676\n",
      "val Loss: 0.6954 Acc: 0.8520\n",
      "test Loss: 0.6845 Acc: 0.8720\n",
      "Epoch 368/1499\n",
      "----------\n",
      "train Loss: 0.6888 Acc: 0.8644\n",
      "val Loss: 0.6961 Acc: 0.8480\n",
      "test Loss: 0.6876 Acc: 0.8720\n",
      "Epoch 369/1499\n",
      "----------\n",
      "train Loss: 0.6887 Acc: 0.8658\n",
      "val Loss: 0.6898 Acc: 0.8680\n",
      "test Loss: 0.6857 Acc: 0.8800\n",
      "Epoch 370/1499\n",
      "----------\n",
      "train Loss: 0.6880 Acc: 0.8693\n",
      "val Loss: 0.6923 Acc: 0.8680\n",
      "test Loss: 0.6867 Acc: 0.8720\n",
      "Epoch 371/1499\n",
      "----------\n",
      "train Loss: 0.6904 Acc: 0.8642\n",
      "val Loss: 0.6908 Acc: 0.8760\n",
      "test Loss: 0.6791 Acc: 0.8840\n",
      "Epoch 372/1499\n",
      "----------\n",
      "train Loss: 0.6885 Acc: 0.8669\n",
      "val Loss: 0.6907 Acc: 0.8600\n",
      "test Loss: 0.6823 Acc: 0.8880\n",
      "Epoch 373/1499\n",
      "----------\n",
      "train Loss: 0.6875 Acc: 0.8680\n",
      "val Loss: 0.6920 Acc: 0.8680\n",
      "test Loss: 0.6819 Acc: 0.8800\n",
      "Epoch 374/1499\n",
      "----------\n",
      "train Loss: 0.6875 Acc: 0.8684\n",
      "val Loss: 0.6952 Acc: 0.8600\n",
      "test Loss: 0.6790 Acc: 0.8800\n",
      "Epoch 375/1499\n",
      "----------\n",
      "train Loss: 0.6873 Acc: 0.8667\n",
      "val Loss: 0.6963 Acc: 0.8760\n",
      "test Loss: 0.6837 Acc: 0.8880\n",
      "Epoch 376/1499\n",
      "----------\n",
      "train Loss: 0.6846 Acc: 0.8707\n",
      "val Loss: 0.6895 Acc: 0.8680\n",
      "test Loss: 0.6822 Acc: 0.8760\n",
      "Epoch 377/1499\n",
      "----------\n",
      "train Loss: 0.6863 Acc: 0.8687\n",
      "val Loss: 0.6860 Acc: 0.8760\n",
      "test Loss: 0.6832 Acc: 0.8760\n",
      "Epoch 378/1499\n",
      "----------\n",
      "train Loss: 0.6855 Acc: 0.8682\n",
      "val Loss: 0.6918 Acc: 0.8640\n",
      "test Loss: 0.6796 Acc: 0.8800\n",
      "Epoch 379/1499\n",
      "----------\n",
      "train Loss: 0.6867 Acc: 0.8700\n",
      "val Loss: 0.6882 Acc: 0.8640\n",
      "test Loss: 0.6829 Acc: 0.8840\n",
      "Epoch 380/1499\n",
      "----------\n",
      "train Loss: 0.6856 Acc: 0.8680\n",
      "val Loss: 0.6895 Acc: 0.8520\n",
      "test Loss: 0.6843 Acc: 0.8720\n",
      "Epoch 381/1499\n",
      "----------\n",
      "train Loss: 0.6865 Acc: 0.8651\n",
      "val Loss: 0.6852 Acc: 0.8760\n",
      "test Loss: 0.6828 Acc: 0.8760\n",
      "Epoch 382/1499\n",
      "----------\n",
      "train Loss: 0.6847 Acc: 0.8693\n",
      "val Loss: 0.6884 Acc: 0.8600\n",
      "test Loss: 0.6810 Acc: 0.8800\n",
      "Epoch 383/1499\n",
      "----------\n",
      "train Loss: 0.6849 Acc: 0.8716\n",
      "val Loss: 0.6874 Acc: 0.8720\n",
      "test Loss: 0.6810 Acc: 0.8800\n",
      "Epoch 384/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6844 Acc: 0.8707\n",
      "val Loss: 0.6885 Acc: 0.8640\n",
      "test Loss: 0.6770 Acc: 0.8840\n",
      "Epoch 385/1499\n",
      "----------\n",
      "train Loss: 0.6835 Acc: 0.8747\n",
      "val Loss: 0.6891 Acc: 0.8480\n",
      "test Loss: 0.6786 Acc: 0.8880\n",
      "Epoch 386/1499\n",
      "----------\n",
      "train Loss: 0.6861 Acc: 0.8671\n",
      "val Loss: 0.6889 Acc: 0.8560\n",
      "test Loss: 0.6847 Acc: 0.8760\n",
      "Epoch 387/1499\n",
      "----------\n",
      "train Loss: 0.6842 Acc: 0.8702\n",
      "val Loss: 0.6892 Acc: 0.8720\n",
      "test Loss: 0.6773 Acc: 0.8840\n",
      "Epoch 388/1499\n",
      "----------\n",
      "train Loss: 0.6837 Acc: 0.8722\n",
      "val Loss: 0.6875 Acc: 0.8760\n",
      "test Loss: 0.6859 Acc: 0.8720\n",
      "Epoch 389/1499\n",
      "----------\n",
      "train Loss: 0.6835 Acc: 0.8736\n",
      "val Loss: 0.6910 Acc: 0.8520\n",
      "test Loss: 0.6822 Acc: 0.8760\n",
      "Epoch 390/1499\n",
      "----------\n",
      "train Loss: 0.6839 Acc: 0.8696\n",
      "val Loss: 0.6883 Acc: 0.8720\n",
      "test Loss: 0.6808 Acc: 0.8800\n",
      "Epoch 391/1499\n",
      "----------\n",
      "train Loss: 0.6837 Acc: 0.8709\n",
      "val Loss: 0.6857 Acc: 0.8760\n",
      "test Loss: 0.6792 Acc: 0.8840\n",
      "Epoch 392/1499\n",
      "----------\n",
      "train Loss: 0.6834 Acc: 0.8720\n",
      "val Loss: 0.6866 Acc: 0.8600\n",
      "test Loss: 0.6802 Acc: 0.8840\n",
      "Epoch 393/1499\n",
      "----------\n",
      "train Loss: 0.6838 Acc: 0.8700\n",
      "val Loss: 0.6921 Acc: 0.8600\n",
      "test Loss: 0.6774 Acc: 0.8920\n",
      "Epoch 394/1499\n",
      "----------\n",
      "train Loss: 0.6826 Acc: 0.8693\n",
      "val Loss: 0.6870 Acc: 0.8600\n",
      "test Loss: 0.6768 Acc: 0.8880\n",
      "Epoch 395/1499\n",
      "----------\n",
      "train Loss: 0.6812 Acc: 0.8713\n",
      "val Loss: 0.6929 Acc: 0.8560\n",
      "test Loss: 0.6820 Acc: 0.8800\n",
      "Epoch 396/1499\n",
      "----------\n",
      "train Loss: 0.6810 Acc: 0.8729\n",
      "val Loss: 0.6893 Acc: 0.8480\n",
      "test Loss: 0.6812 Acc: 0.8800\n",
      "Epoch 397/1499\n",
      "----------\n",
      "train Loss: 0.6815 Acc: 0.8718\n",
      "val Loss: 0.6866 Acc: 0.8680\n",
      "test Loss: 0.6698 Acc: 0.8880\n",
      "Epoch 398/1499\n",
      "----------\n",
      "train Loss: 0.6808 Acc: 0.8704\n",
      "val Loss: 0.6847 Acc: 0.8760\n",
      "test Loss: 0.6741 Acc: 0.8880\n",
      "Epoch 399/1499\n",
      "----------\n",
      "train Loss: 0.6820 Acc: 0.8702\n",
      "val Loss: 0.6883 Acc: 0.8600\n",
      "test Loss: 0.6806 Acc: 0.8840\n",
      "Epoch 400/1499\n",
      "----------\n",
      "train Loss: 0.6813 Acc: 0.8700\n",
      "val Loss: 0.6832 Acc: 0.8640\n",
      "test Loss: 0.6792 Acc: 0.8800\n",
      "Epoch 401/1499\n",
      "----------\n",
      "train Loss: 0.6808 Acc: 0.8733\n",
      "val Loss: 0.6883 Acc: 0.8640\n",
      "test Loss: 0.6805 Acc: 0.8720\n",
      "Epoch 402/1499\n",
      "----------\n",
      "train Loss: 0.6816 Acc: 0.8684\n",
      "val Loss: 0.6848 Acc: 0.8560\n",
      "test Loss: 0.6843 Acc: 0.8640\n",
      "Epoch 403/1499\n",
      "----------\n",
      "train Loss: 0.6801 Acc: 0.8742\n",
      "val Loss: 0.6889 Acc: 0.8680\n",
      "test Loss: 0.6818 Acc: 0.8680\n",
      "Epoch 404/1499\n",
      "----------\n",
      "train Loss: 0.6800 Acc: 0.8736\n",
      "val Loss: 0.6778 Acc: 0.8680\n",
      "test Loss: 0.6768 Acc: 0.8880\n",
      "Epoch 405/1499\n",
      "----------\n",
      "train Loss: 0.6809 Acc: 0.8713\n",
      "val Loss: 0.6832 Acc: 0.8640\n",
      "test Loss: 0.6760 Acc: 0.8800\n",
      "Epoch 406/1499\n",
      "----------\n",
      "train Loss: 0.6792 Acc: 0.8736\n",
      "val Loss: 0.6853 Acc: 0.8720\n",
      "test Loss: 0.6756 Acc: 0.8840\n",
      "Epoch 407/1499\n",
      "----------\n",
      "train Loss: 0.6791 Acc: 0.8724\n",
      "val Loss: 0.6852 Acc: 0.8600\n",
      "test Loss: 0.6787 Acc: 0.8800\n",
      "Epoch 408/1499\n",
      "----------\n",
      "train Loss: 0.6783 Acc: 0.8764\n",
      "val Loss: 0.6853 Acc: 0.8680\n",
      "test Loss: 0.6765 Acc: 0.8880\n",
      "Epoch 409/1499\n",
      "----------\n",
      "train Loss: 0.6800 Acc: 0.8727\n",
      "val Loss: 0.6887 Acc: 0.8600\n",
      "test Loss: 0.6796 Acc: 0.8760\n",
      "Epoch 410/1499\n",
      "----------\n",
      "train Loss: 0.6787 Acc: 0.8764\n",
      "val Loss: 0.6830 Acc: 0.8680\n",
      "test Loss: 0.6744 Acc: 0.8840\n",
      "Epoch 411/1499\n",
      "----------\n",
      "train Loss: 0.6770 Acc: 0.8791\n",
      "val Loss: 0.6809 Acc: 0.8680\n",
      "test Loss: 0.6771 Acc: 0.8880\n",
      "Epoch 412/1499\n",
      "----------\n",
      "train Loss: 0.6786 Acc: 0.8767\n",
      "val Loss: 0.6805 Acc: 0.8720\n",
      "test Loss: 0.6785 Acc: 0.8800\n",
      "Epoch 413/1499\n",
      "----------\n",
      "train Loss: 0.6797 Acc: 0.8760\n",
      "val Loss: 0.6848 Acc: 0.8600\n",
      "test Loss: 0.6777 Acc: 0.8960\n",
      "Epoch 414/1499\n",
      "----------\n",
      "train Loss: 0.6779 Acc: 0.8769\n",
      "val Loss: 0.6861 Acc: 0.8680\n",
      "test Loss: 0.6832 Acc: 0.8760\n",
      "Epoch 415/1499\n",
      "----------\n",
      "train Loss: 0.6796 Acc: 0.8742\n",
      "val Loss: 0.6824 Acc: 0.8640\n",
      "test Loss: 0.6768 Acc: 0.8880\n",
      "Epoch 416/1499\n",
      "----------\n",
      "train Loss: 0.6785 Acc: 0.8756\n",
      "val Loss: 0.6831 Acc: 0.8560\n",
      "test Loss: 0.6782 Acc: 0.8840\n",
      "Epoch 417/1499\n",
      "----------\n",
      "train Loss: 0.6773 Acc: 0.8800\n",
      "val Loss: 0.6807 Acc: 0.8560\n",
      "test Loss: 0.6787 Acc: 0.8800\n",
      "Epoch 418/1499\n",
      "----------\n",
      "train Loss: 0.6775 Acc: 0.8760\n",
      "val Loss: 0.6789 Acc: 0.8680\n",
      "test Loss: 0.6771 Acc: 0.8840\n",
      "Epoch 419/1499\n",
      "----------\n",
      "train Loss: 0.6774 Acc: 0.8778\n",
      "val Loss: 0.6835 Acc: 0.8560\n",
      "test Loss: 0.6768 Acc: 0.8760\n",
      "Epoch 420/1499\n",
      "----------\n",
      "train Loss: 0.6785 Acc: 0.8742\n",
      "val Loss: 0.6805 Acc: 0.8720\n",
      "test Loss: 0.6767 Acc: 0.8800\n",
      "Epoch 421/1499\n",
      "----------\n",
      "train Loss: 0.6776 Acc: 0.8784\n",
      "val Loss: 0.6792 Acc: 0.8680\n",
      "test Loss: 0.6768 Acc: 0.8760\n",
      "Epoch 422/1499\n",
      "----------\n",
      "train Loss: 0.6755 Acc: 0.8773\n",
      "val Loss: 0.6849 Acc: 0.8640\n",
      "test Loss: 0.6719 Acc: 0.8880\n",
      "Epoch 423/1499\n",
      "----------\n",
      "train Loss: 0.6765 Acc: 0.8789\n",
      "val Loss: 0.6781 Acc: 0.8680\n",
      "test Loss: 0.6795 Acc: 0.8800\n",
      "Epoch 424/1499\n",
      "----------\n",
      "train Loss: 0.6770 Acc: 0.8760\n",
      "val Loss: 0.6733 Acc: 0.8800\n",
      "test Loss: 0.6773 Acc: 0.8760\n",
      "Epoch 425/1499\n",
      "----------\n",
      "train Loss: 0.6770 Acc: 0.8762\n",
      "val Loss: 0.6756 Acc: 0.8560\n",
      "test Loss: 0.6813 Acc: 0.8760\n",
      "Epoch 426/1499\n",
      "----------\n",
      "train Loss: 0.6770 Acc: 0.8767\n",
      "val Loss: 0.6793 Acc: 0.8800\n",
      "test Loss: 0.6762 Acc: 0.8800\n",
      "Epoch 427/1499\n",
      "----------\n",
      "train Loss: 0.6766 Acc: 0.8764\n",
      "val Loss: 0.6884 Acc: 0.8520\n",
      "test Loss: 0.6686 Acc: 0.8840\n",
      "Epoch 428/1499\n",
      "----------\n",
      "train Loss: 0.6758 Acc: 0.8758\n",
      "val Loss: 0.6812 Acc: 0.8760\n",
      "test Loss: 0.6799 Acc: 0.8800\n",
      "Epoch 429/1499\n",
      "----------\n",
      "train Loss: 0.6756 Acc: 0.8780\n",
      "val Loss: 0.6758 Acc: 0.8880\n",
      "test Loss: 0.6712 Acc: 0.8800\n",
      "Epoch 430/1499\n",
      "----------\n",
      "train Loss: 0.6765 Acc: 0.8764\n",
      "val Loss: 0.6807 Acc: 0.8600\n",
      "test Loss: 0.6718 Acc: 0.8800\n",
      "Epoch 431/1499\n",
      "----------\n",
      "train Loss: 0.6754 Acc: 0.8776\n",
      "val Loss: 0.6763 Acc: 0.8760\n",
      "test Loss: 0.6764 Acc: 0.8800\n",
      "Epoch 432/1499\n",
      "----------\n",
      "train Loss: 0.6749 Acc: 0.8762\n",
      "val Loss: 0.6762 Acc: 0.8720\n",
      "test Loss: 0.6802 Acc: 0.8720\n",
      "Epoch 433/1499\n",
      "----------\n",
      "train Loss: 0.6754 Acc: 0.8782\n",
      "val Loss: 0.6818 Acc: 0.8560\n",
      "test Loss: 0.6724 Acc: 0.8840\n",
      "Epoch 434/1499\n",
      "----------\n",
      "train Loss: 0.6753 Acc: 0.8809\n",
      "val Loss: 0.6833 Acc: 0.8800\n",
      "test Loss: 0.6731 Acc: 0.8920\n",
      "Epoch 435/1499\n",
      "----------\n",
      "train Loss: 0.6741 Acc: 0.8778\n",
      "val Loss: 0.6805 Acc: 0.8640\n",
      "test Loss: 0.6737 Acc: 0.8840\n",
      "Epoch 436/1499\n",
      "----------\n",
      "train Loss: 0.6747 Acc: 0.8791\n",
      "val Loss: 0.6819 Acc: 0.8600\n",
      "test Loss: 0.6771 Acc: 0.8880\n",
      "Epoch 437/1499\n",
      "----------\n",
      "train Loss: 0.6740 Acc: 0.8798\n",
      "val Loss: 0.6789 Acc: 0.8760\n",
      "test Loss: 0.6777 Acc: 0.8760\n",
      "Epoch 438/1499\n",
      "----------\n",
      "train Loss: 0.6729 Acc: 0.8829\n",
      "val Loss: 0.6819 Acc: 0.8560\n",
      "test Loss: 0.6727 Acc: 0.8800\n",
      "Epoch 439/1499\n",
      "----------\n",
      "train Loss: 0.6736 Acc: 0.8771\n",
      "val Loss: 0.6801 Acc: 0.8680\n",
      "test Loss: 0.6712 Acc: 0.8920\n",
      "Epoch 440/1499\n",
      "----------\n",
      "train Loss: 0.6731 Acc: 0.8778\n",
      "val Loss: 0.6716 Acc: 0.8880\n",
      "test Loss: 0.6690 Acc: 0.8880\n",
      "Epoch 441/1499\n",
      "----------\n",
      "train Loss: 0.6745 Acc: 0.8753\n",
      "val Loss: 0.6765 Acc: 0.8720\n",
      "test Loss: 0.6694 Acc: 0.8960\n",
      "Epoch 442/1499\n",
      "----------\n",
      "train Loss: 0.6734 Acc: 0.8800\n",
      "val Loss: 0.6784 Acc: 0.8600\n",
      "test Loss: 0.6778 Acc: 0.8800\n",
      "Epoch 443/1499\n",
      "----------\n",
      "train Loss: 0.6741 Acc: 0.8762\n",
      "val Loss: 0.6764 Acc: 0.8640\n",
      "test Loss: 0.6762 Acc: 0.8760\n",
      "Epoch 444/1499\n",
      "----------\n",
      "train Loss: 0.6738 Acc: 0.8802\n",
      "val Loss: 0.6719 Acc: 0.8760\n",
      "test Loss: 0.6722 Acc: 0.8880\n",
      "Epoch 445/1499\n",
      "----------\n",
      "train Loss: 0.6729 Acc: 0.8798\n",
      "val Loss: 0.6813 Acc: 0.8680\n",
      "test Loss: 0.6700 Acc: 0.8880\n",
      "Epoch 446/1499\n",
      "----------\n",
      "train Loss: 0.6725 Acc: 0.8773\n",
      "val Loss: 0.6736 Acc: 0.8720\n",
      "test Loss: 0.6767 Acc: 0.8760\n",
      "Epoch 447/1499\n",
      "----------\n",
      "train Loss: 0.6722 Acc: 0.8800\n",
      "val Loss: 0.6790 Acc: 0.8680\n",
      "test Loss: 0.6735 Acc: 0.8840\n",
      "Epoch 448/1499\n",
      "----------\n",
      "train Loss: 0.6724 Acc: 0.8804\n",
      "val Loss: 0.6683 Acc: 0.8920\n",
      "test Loss: 0.6765 Acc: 0.8760\n",
      "Epoch 449/1499\n",
      "----------\n",
      "train Loss: 0.6727 Acc: 0.8829\n",
      "val Loss: 0.6741 Acc: 0.8760\n",
      "test Loss: 0.6761 Acc: 0.8720\n",
      "Epoch 450/1499\n",
      "----------\n",
      "train Loss: 0.6722 Acc: 0.8784\n",
      "val Loss: 0.6775 Acc: 0.8720\n",
      "test Loss: 0.6751 Acc: 0.8800\n",
      "Epoch 451/1499\n",
      "----------\n",
      "train Loss: 0.6731 Acc: 0.8778\n",
      "val Loss: 0.6752 Acc: 0.8720\n",
      "test Loss: 0.6702 Acc: 0.8800\n",
      "Epoch 452/1499\n",
      "----------\n",
      "train Loss: 0.6725 Acc: 0.8793\n",
      "val Loss: 0.6720 Acc: 0.8760\n",
      "test Loss: 0.6733 Acc: 0.8920\n",
      "Epoch 453/1499\n",
      "----------\n",
      "train Loss: 0.6724 Acc: 0.8824\n",
      "val Loss: 0.6773 Acc: 0.8800\n",
      "test Loss: 0.6734 Acc: 0.8840\n",
      "Epoch 454/1499\n",
      "----------\n",
      "train Loss: 0.6721 Acc: 0.8809\n",
      "val Loss: 0.6751 Acc: 0.8560\n",
      "test Loss: 0.6697 Acc: 0.8840\n",
      "Epoch 455/1499\n",
      "----------\n",
      "train Loss: 0.6716 Acc: 0.8784\n",
      "val Loss: 0.6679 Acc: 0.8760\n",
      "test Loss: 0.6707 Acc: 0.8760\n",
      "Epoch 456/1499\n",
      "----------\n",
      "train Loss: 0.6711 Acc: 0.8800\n",
      "val Loss: 0.6735 Acc: 0.8760\n",
      "test Loss: 0.6711 Acc: 0.8800\n",
      "Epoch 457/1499\n",
      "----------\n",
      "train Loss: 0.6698 Acc: 0.8813\n",
      "val Loss: 0.6706 Acc: 0.8920\n",
      "test Loss: 0.6719 Acc: 0.8760\n",
      "Epoch 458/1499\n",
      "----------\n",
      "train Loss: 0.6715 Acc: 0.8787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.6728 Acc: 0.8880\n",
      "test Loss: 0.6724 Acc: 0.8880\n",
      "Epoch 459/1499\n",
      "----------\n",
      "train Loss: 0.6712 Acc: 0.8820\n",
      "val Loss: 0.6765 Acc: 0.8800\n",
      "test Loss: 0.6725 Acc: 0.8840\n",
      "Epoch 460/1499\n",
      "----------\n",
      "train Loss: 0.6699 Acc: 0.8827\n",
      "val Loss: 0.6792 Acc: 0.8640\n",
      "test Loss: 0.6745 Acc: 0.8840\n",
      "Epoch 461/1499\n",
      "----------\n",
      "train Loss: 0.6725 Acc: 0.8802\n",
      "val Loss: 0.6773 Acc: 0.8680\n",
      "test Loss: 0.6649 Acc: 0.8960\n",
      "Epoch 462/1499\n",
      "----------\n",
      "train Loss: 0.6715 Acc: 0.8784\n",
      "val Loss: 0.6696 Acc: 0.8800\n",
      "test Loss: 0.6713 Acc: 0.8800\n",
      "Epoch 463/1499\n",
      "----------\n",
      "train Loss: 0.6718 Acc: 0.8780\n",
      "val Loss: 0.6766 Acc: 0.8720\n",
      "test Loss: 0.6736 Acc: 0.8880\n",
      "Epoch 464/1499\n",
      "----------\n",
      "train Loss: 0.6722 Acc: 0.8780\n",
      "val Loss: 0.6771 Acc: 0.8640\n",
      "test Loss: 0.6717 Acc: 0.8880\n",
      "Epoch 465/1499\n",
      "----------\n",
      "train Loss: 0.6714 Acc: 0.8800\n",
      "val Loss: 0.6798 Acc: 0.8600\n",
      "test Loss: 0.6706 Acc: 0.8880\n",
      "Epoch 466/1499\n",
      "----------\n",
      "train Loss: 0.6710 Acc: 0.8791\n",
      "val Loss: 0.6724 Acc: 0.8880\n",
      "test Loss: 0.6690 Acc: 0.8840\n",
      "Epoch 467/1499\n",
      "----------\n",
      "train Loss: 0.6693 Acc: 0.8807\n",
      "val Loss: 0.6781 Acc: 0.8640\n",
      "test Loss: 0.6721 Acc: 0.8800\n",
      "Epoch 468/1499\n",
      "----------\n",
      "train Loss: 0.6691 Acc: 0.8818\n",
      "val Loss: 0.6819 Acc: 0.8520\n",
      "test Loss: 0.6698 Acc: 0.8920\n",
      "Epoch 469/1499\n",
      "----------\n",
      "train Loss: 0.6718 Acc: 0.8784\n",
      "val Loss: 0.6785 Acc: 0.8760\n",
      "test Loss: 0.6678 Acc: 0.8880\n",
      "Epoch 470/1499\n",
      "----------\n",
      "train Loss: 0.6699 Acc: 0.8824\n",
      "val Loss: 0.6754 Acc: 0.8680\n",
      "test Loss: 0.6649 Acc: 0.8840\n",
      "Epoch 471/1499\n",
      "----------\n",
      "train Loss: 0.6697 Acc: 0.8827\n",
      "val Loss: 0.6740 Acc: 0.8800\n",
      "test Loss: 0.6698 Acc: 0.8880\n",
      "Epoch 472/1499\n",
      "----------\n",
      "train Loss: 0.6712 Acc: 0.8793\n",
      "val Loss: 0.6711 Acc: 0.8800\n",
      "test Loss: 0.6706 Acc: 0.8800\n",
      "Epoch 473/1499\n",
      "----------\n",
      "train Loss: 0.6700 Acc: 0.8796\n",
      "val Loss: 0.6738 Acc: 0.8880\n",
      "test Loss: 0.6652 Acc: 0.8920\n",
      "Epoch 474/1499\n",
      "----------\n",
      "train Loss: 0.6699 Acc: 0.8787\n",
      "val Loss: 0.6729 Acc: 0.8720\n",
      "test Loss: 0.6678 Acc: 0.8880\n",
      "Epoch 475/1499\n",
      "----------\n",
      "train Loss: 0.6697 Acc: 0.8818\n",
      "val Loss: 0.6767 Acc: 0.8720\n",
      "test Loss: 0.6725 Acc: 0.8840\n",
      "Epoch 476/1499\n",
      "----------\n",
      "train Loss: 0.6698 Acc: 0.8836\n",
      "val Loss: 0.6673 Acc: 0.8880\n",
      "test Loss: 0.6695 Acc: 0.8880\n",
      "Epoch 477/1499\n",
      "----------\n",
      "train Loss: 0.6679 Acc: 0.8851\n",
      "val Loss: 0.6704 Acc: 0.8720\n",
      "test Loss: 0.6683 Acc: 0.8840\n",
      "Epoch 478/1499\n",
      "----------\n",
      "train Loss: 0.6689 Acc: 0.8824\n",
      "val Loss: 0.6733 Acc: 0.8800\n",
      "test Loss: 0.6712 Acc: 0.8880\n",
      "Epoch 479/1499\n",
      "----------\n",
      "train Loss: 0.6698 Acc: 0.8809\n",
      "val Loss: 0.6725 Acc: 0.8720\n",
      "test Loss: 0.6650 Acc: 0.8920\n",
      "Epoch 480/1499\n",
      "----------\n",
      "train Loss: 0.6685 Acc: 0.8849\n",
      "val Loss: 0.6713 Acc: 0.8760\n",
      "test Loss: 0.6705 Acc: 0.8840\n",
      "Epoch 481/1499\n",
      "----------\n",
      "train Loss: 0.6684 Acc: 0.8818\n",
      "val Loss: 0.6768 Acc: 0.8720\n",
      "test Loss: 0.6677 Acc: 0.8840\n",
      "Epoch 482/1499\n",
      "----------\n",
      "train Loss: 0.6675 Acc: 0.8827\n",
      "val Loss: 0.6731 Acc: 0.8720\n",
      "test Loss: 0.6702 Acc: 0.8840\n",
      "Epoch 483/1499\n",
      "----------\n",
      "train Loss: 0.6673 Acc: 0.8849\n",
      "val Loss: 0.6739 Acc: 0.8760\n",
      "test Loss: 0.6701 Acc: 0.8840\n",
      "Epoch 484/1499\n",
      "----------\n",
      "train Loss: 0.6666 Acc: 0.8827\n",
      "val Loss: 0.6684 Acc: 0.8800\n",
      "test Loss: 0.6676 Acc: 0.8840\n",
      "Epoch 485/1499\n",
      "----------\n",
      "train Loss: 0.6684 Acc: 0.8833\n",
      "val Loss: 0.6702 Acc: 0.8760\n",
      "test Loss: 0.6664 Acc: 0.8880\n",
      "Epoch 486/1499\n",
      "----------\n",
      "train Loss: 0.6689 Acc: 0.8816\n",
      "val Loss: 0.6743 Acc: 0.8840\n",
      "test Loss: 0.6653 Acc: 0.8880\n",
      "Epoch 487/1499\n",
      "----------\n",
      "train Loss: 0.6681 Acc: 0.8824\n",
      "val Loss: 0.6733 Acc: 0.8760\n",
      "test Loss: 0.6711 Acc: 0.8920\n",
      "Epoch 488/1499\n",
      "----------\n",
      "train Loss: 0.6682 Acc: 0.8816\n",
      "val Loss: 0.6709 Acc: 0.8800\n",
      "test Loss: 0.6674 Acc: 0.8880\n",
      "Epoch 489/1499\n",
      "----------\n",
      "train Loss: 0.6672 Acc: 0.8833\n",
      "val Loss: 0.6739 Acc: 0.8760\n",
      "test Loss: 0.6680 Acc: 0.8920\n",
      "Epoch 490/1499\n",
      "----------\n",
      "train Loss: 0.6672 Acc: 0.8829\n",
      "val Loss: 0.6758 Acc: 0.8800\n",
      "test Loss: 0.6665 Acc: 0.8880\n",
      "Epoch 491/1499\n",
      "----------\n",
      "train Loss: 0.6682 Acc: 0.8822\n",
      "val Loss: 0.6736 Acc: 0.8640\n",
      "test Loss: 0.6688 Acc: 0.8840\n",
      "Epoch 492/1499\n",
      "----------\n",
      "train Loss: 0.6678 Acc: 0.8849\n",
      "val Loss: 0.6719 Acc: 0.8720\n",
      "test Loss: 0.6671 Acc: 0.8920\n",
      "Epoch 493/1499\n",
      "----------\n",
      "train Loss: 0.6680 Acc: 0.8833\n",
      "val Loss: 0.6731 Acc: 0.8840\n",
      "test Loss: 0.6748 Acc: 0.8800\n",
      "Epoch 494/1499\n",
      "----------\n",
      "train Loss: 0.6685 Acc: 0.8818\n",
      "val Loss: 0.6713 Acc: 0.8800\n",
      "test Loss: 0.6712 Acc: 0.8840\n",
      "Epoch 495/1499\n",
      "----------\n",
      "train Loss: 0.6678 Acc: 0.8833\n",
      "val Loss: 0.6677 Acc: 0.8880\n",
      "test Loss: 0.6698 Acc: 0.8880\n",
      "Epoch 496/1499\n",
      "----------\n",
      "train Loss: 0.6670 Acc: 0.8873\n",
      "val Loss: 0.6734 Acc: 0.8760\n",
      "test Loss: 0.6632 Acc: 0.8880\n",
      "Epoch 497/1499\n",
      "----------\n",
      "train Loss: 0.6681 Acc: 0.8820\n",
      "val Loss: 0.6693 Acc: 0.8760\n",
      "test Loss: 0.6669 Acc: 0.8800\n",
      "Epoch 498/1499\n",
      "----------\n",
      "train Loss: 0.6675 Acc: 0.8824\n",
      "val Loss: 0.6712 Acc: 0.8800\n",
      "test Loss: 0.6746 Acc: 0.8840\n",
      "Epoch 499/1499\n",
      "----------\n",
      "train Loss: 0.6669 Acc: 0.8824\n",
      "val Loss: 0.6754 Acc: 0.8760\n",
      "test Loss: 0.6677 Acc: 0.8880\n",
      "Epoch 500/1499\n",
      "----------\n",
      "train Loss: 0.6654 Acc: 0.8876\n",
      "val Loss: 0.6707 Acc: 0.8760\n",
      "test Loss: 0.6720 Acc: 0.8880\n",
      "Epoch 501/1499\n",
      "----------\n",
      "train Loss: 0.6672 Acc: 0.8858\n",
      "val Loss: 0.6697 Acc: 0.8880\n",
      "test Loss: 0.6681 Acc: 0.8840\n",
      "Epoch 502/1499\n",
      "----------\n",
      "train Loss: 0.6679 Acc: 0.8820\n",
      "val Loss: 0.6658 Acc: 0.8800\n",
      "test Loss: 0.6653 Acc: 0.8920\n",
      "Epoch 503/1499\n",
      "----------\n",
      "train Loss: 0.6659 Acc: 0.8873\n",
      "val Loss: 0.6758 Acc: 0.8800\n",
      "test Loss: 0.6671 Acc: 0.8880\n",
      "Epoch 504/1499\n",
      "----------\n",
      "train Loss: 0.6664 Acc: 0.8831\n",
      "val Loss: 0.6682 Acc: 0.8920\n",
      "test Loss: 0.6677 Acc: 0.8760\n",
      "Epoch 505/1499\n",
      "----------\n",
      "train Loss: 0.6660 Acc: 0.8838\n",
      "val Loss: 0.6684 Acc: 0.8720\n",
      "test Loss: 0.6698 Acc: 0.8840\n",
      "Epoch 506/1499\n",
      "----------\n",
      "train Loss: 0.6657 Acc: 0.8853\n",
      "val Loss: 0.6687 Acc: 0.8920\n",
      "test Loss: 0.6652 Acc: 0.8880\n",
      "Epoch 507/1499\n",
      "----------\n",
      "train Loss: 0.6670 Acc: 0.8836\n",
      "val Loss: 0.6736 Acc: 0.8840\n",
      "test Loss: 0.6649 Acc: 0.8920\n",
      "Epoch 508/1499\n",
      "----------\n",
      "train Loss: 0.6656 Acc: 0.8838\n",
      "val Loss: 0.6668 Acc: 0.8800\n",
      "test Loss: 0.6671 Acc: 0.8880\n",
      "Epoch 509/1499\n",
      "----------\n",
      "train Loss: 0.6655 Acc: 0.8862\n",
      "val Loss: 0.6673 Acc: 0.8840\n",
      "test Loss: 0.6653 Acc: 0.8960\n",
      "Epoch 510/1499\n",
      "----------\n",
      "train Loss: 0.6660 Acc: 0.8842\n",
      "val Loss: 0.6679 Acc: 0.8840\n",
      "test Loss: 0.6627 Acc: 0.8880\n",
      "Epoch 511/1499\n",
      "----------\n",
      "train Loss: 0.6651 Acc: 0.8864\n",
      "val Loss: 0.6727 Acc: 0.8800\n",
      "test Loss: 0.6719 Acc: 0.8800\n",
      "Epoch 512/1499\n",
      "----------\n",
      "train Loss: 0.6651 Acc: 0.8820\n",
      "val Loss: 0.6719 Acc: 0.8760\n",
      "test Loss: 0.6648 Acc: 0.8880\n",
      "Epoch 513/1499\n",
      "----------\n",
      "train Loss: 0.6646 Acc: 0.8842\n",
      "val Loss: 0.6682 Acc: 0.8880\n",
      "test Loss: 0.6658 Acc: 0.8960\n",
      "Epoch 514/1499\n",
      "----------\n",
      "train Loss: 0.6647 Acc: 0.8878\n",
      "val Loss: 0.6692 Acc: 0.8880\n",
      "test Loss: 0.6713 Acc: 0.8840\n",
      "Epoch 515/1499\n",
      "----------\n",
      "train Loss: 0.6654 Acc: 0.8864\n",
      "val Loss: 0.6669 Acc: 0.8840\n",
      "test Loss: 0.6640 Acc: 0.8920\n",
      "Epoch 516/1499\n",
      "----------\n",
      "train Loss: 0.6648 Acc: 0.8860\n",
      "val Loss: 0.6673 Acc: 0.8800\n",
      "test Loss: 0.6674 Acc: 0.8920\n",
      "Epoch 517/1499\n",
      "----------\n",
      "train Loss: 0.6660 Acc: 0.8856\n",
      "val Loss: 0.6663 Acc: 0.8800\n",
      "test Loss: 0.6693 Acc: 0.8840\n",
      "Epoch 518/1499\n",
      "----------\n",
      "train Loss: 0.6646 Acc: 0.8853\n",
      "val Loss: 0.6623 Acc: 0.8880\n",
      "test Loss: 0.6633 Acc: 0.8840\n",
      "Epoch 519/1499\n",
      "----------\n",
      "train Loss: 0.6641 Acc: 0.8882\n",
      "val Loss: 0.6714 Acc: 0.8840\n",
      "test Loss: 0.6652 Acc: 0.8880\n",
      "Epoch 520/1499\n",
      "----------\n",
      "train Loss: 0.6641 Acc: 0.8862\n",
      "val Loss: 0.6647 Acc: 0.8800\n",
      "test Loss: 0.6659 Acc: 0.8920\n",
      "Epoch 521/1499\n",
      "----------\n",
      "train Loss: 0.6642 Acc: 0.8849\n",
      "val Loss: 0.6643 Acc: 0.8760\n",
      "test Loss: 0.6633 Acc: 0.8920\n",
      "Epoch 522/1499\n",
      "----------\n",
      "train Loss: 0.6640 Acc: 0.8862\n",
      "val Loss: 0.6703 Acc: 0.8800\n",
      "test Loss: 0.6667 Acc: 0.8880\n",
      "Epoch 523/1499\n",
      "----------\n",
      "train Loss: 0.6633 Acc: 0.8882\n",
      "val Loss: 0.6712 Acc: 0.8840\n",
      "test Loss: 0.6654 Acc: 0.9000\n",
      "Epoch 524/1499\n",
      "----------\n",
      "train Loss: 0.6651 Acc: 0.8836\n",
      "val Loss: 0.6643 Acc: 0.8960\n",
      "test Loss: 0.6653 Acc: 0.8880\n",
      "Epoch 525/1499\n",
      "----------\n",
      "train Loss: 0.6640 Acc: 0.8856\n",
      "val Loss: 0.6722 Acc: 0.8720\n",
      "test Loss: 0.6642 Acc: 0.8880\n",
      "Epoch 526/1499\n",
      "----------\n",
      "train Loss: 0.6650 Acc: 0.8856\n",
      "val Loss: 0.6697 Acc: 0.8760\n",
      "test Loss: 0.6668 Acc: 0.8920\n",
      "Epoch 527/1499\n",
      "----------\n",
      "train Loss: 0.6640 Acc: 0.8873\n",
      "val Loss: 0.6695 Acc: 0.8760\n",
      "test Loss: 0.6690 Acc: 0.8840\n",
      "Epoch 528/1499\n",
      "----------\n",
      "train Loss: 0.6643 Acc: 0.8849\n",
      "val Loss: 0.6679 Acc: 0.8680\n",
      "test Loss: 0.6653 Acc: 0.8920\n",
      "Epoch 529/1499\n",
      "----------\n",
      "train Loss: 0.6629 Acc: 0.8876\n",
      "val Loss: 0.6728 Acc: 0.8760\n",
      "test Loss: 0.6620 Acc: 0.9000\n",
      "Epoch 530/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6644 Acc: 0.8840\n",
      "val Loss: 0.6678 Acc: 0.8840\n",
      "test Loss: 0.6680 Acc: 0.8840\n",
      "Epoch 531/1499\n",
      "----------\n",
      "train Loss: 0.6638 Acc: 0.8889\n",
      "val Loss: 0.6658 Acc: 0.8840\n",
      "test Loss: 0.6694 Acc: 0.8880\n",
      "Epoch 532/1499\n",
      "----------\n",
      "train Loss: 0.6632 Acc: 0.8876\n",
      "val Loss: 0.6652 Acc: 0.8840\n",
      "test Loss: 0.6698 Acc: 0.8840\n",
      "Epoch 533/1499\n",
      "----------\n",
      "train Loss: 0.6633 Acc: 0.8862\n",
      "val Loss: 0.6691 Acc: 0.8760\n",
      "test Loss: 0.6678 Acc: 0.8880\n",
      "Epoch 534/1499\n",
      "----------\n",
      "train Loss: 0.6644 Acc: 0.8858\n",
      "val Loss: 0.6701 Acc: 0.8800\n",
      "test Loss: 0.6635 Acc: 0.8920\n",
      "Epoch 535/1499\n",
      "----------\n",
      "train Loss: 0.6642 Acc: 0.8867\n",
      "val Loss: 0.6651 Acc: 0.8840\n",
      "test Loss: 0.6687 Acc: 0.8880\n",
      "Epoch 536/1499\n",
      "----------\n",
      "train Loss: 0.6642 Acc: 0.8864\n",
      "val Loss: 0.6638 Acc: 0.8880\n",
      "test Loss: 0.6663 Acc: 0.8840\n",
      "Epoch 537/1499\n",
      "----------\n",
      "train Loss: 0.6640 Acc: 0.8860\n",
      "val Loss: 0.6626 Acc: 0.8880\n",
      "test Loss: 0.6679 Acc: 0.8920\n",
      "Epoch 538/1499\n",
      "----------\n",
      "train Loss: 0.6648 Acc: 0.8856\n",
      "val Loss: 0.6655 Acc: 0.8880\n",
      "test Loss: 0.6662 Acc: 0.8880\n",
      "Epoch 539/1499\n",
      "----------\n",
      "train Loss: 0.6636 Acc: 0.8867\n",
      "val Loss: 0.6666 Acc: 0.8800\n",
      "test Loss: 0.6667 Acc: 0.8880\n",
      "Epoch 540/1499\n",
      "----------\n",
      "train Loss: 0.6644 Acc: 0.8869\n",
      "val Loss: 0.6669 Acc: 0.8800\n",
      "test Loss: 0.6683 Acc: 0.8840\n",
      "Epoch 541/1499\n",
      "----------\n",
      "train Loss: 0.6635 Acc: 0.8880\n",
      "val Loss: 0.6637 Acc: 0.8880\n",
      "test Loss: 0.6606 Acc: 0.8880\n",
      "Epoch 542/1499\n",
      "----------\n",
      "train Loss: 0.6631 Acc: 0.8862\n",
      "val Loss: 0.6668 Acc: 0.8800\n",
      "test Loss: 0.6653 Acc: 0.8880\n",
      "Epoch 543/1499\n",
      "----------\n",
      "train Loss: 0.6636 Acc: 0.8858\n",
      "val Loss: 0.6694 Acc: 0.8760\n",
      "test Loss: 0.6621 Acc: 0.8960\n",
      "Epoch 544/1499\n",
      "----------\n",
      "train Loss: 0.6620 Acc: 0.8864\n",
      "val Loss: 0.6689 Acc: 0.8720\n",
      "test Loss: 0.6634 Acc: 0.8920\n",
      "Epoch 545/1499\n",
      "----------\n",
      "train Loss: 0.6637 Acc: 0.8867\n",
      "val Loss: 0.6687 Acc: 0.8720\n",
      "test Loss: 0.6663 Acc: 0.8840\n",
      "Epoch 546/1499\n",
      "----------\n",
      "train Loss: 0.6615 Acc: 0.8878\n",
      "val Loss: 0.6694 Acc: 0.8680\n",
      "test Loss: 0.6655 Acc: 0.8840\n",
      "Epoch 547/1499\n",
      "----------\n",
      "train Loss: 0.6629 Acc: 0.8856\n",
      "val Loss: 0.6662 Acc: 0.8760\n",
      "test Loss: 0.6639 Acc: 0.8840\n",
      "Epoch 548/1499\n",
      "----------\n",
      "train Loss: 0.6629 Acc: 0.8882\n",
      "val Loss: 0.6656 Acc: 0.8840\n",
      "test Loss: 0.6635 Acc: 0.8920\n",
      "Epoch 549/1499\n",
      "----------\n",
      "train Loss: 0.6630 Acc: 0.8860\n",
      "val Loss: 0.6680 Acc: 0.8880\n",
      "test Loss: 0.6644 Acc: 0.8920\n",
      "Epoch 550/1499\n",
      "----------\n",
      "train Loss: 0.6637 Acc: 0.8833\n",
      "val Loss: 0.6709 Acc: 0.8840\n",
      "test Loss: 0.6650 Acc: 0.8880\n",
      "Epoch 551/1499\n",
      "----------\n",
      "train Loss: 0.6624 Acc: 0.8864\n",
      "val Loss: 0.6643 Acc: 0.8800\n",
      "test Loss: 0.6673 Acc: 0.8840\n",
      "Epoch 552/1499\n",
      "----------\n",
      "train Loss: 0.6622 Acc: 0.8896\n",
      "val Loss: 0.6675 Acc: 0.8720\n",
      "test Loss: 0.6639 Acc: 0.8920\n",
      "Epoch 553/1499\n",
      "----------\n",
      "train Loss: 0.6620 Acc: 0.8898\n",
      "val Loss: 0.6688 Acc: 0.8760\n",
      "test Loss: 0.6638 Acc: 0.8840\n",
      "Epoch 554/1499\n",
      "----------\n",
      "train Loss: 0.6619 Acc: 0.8900\n",
      "val Loss: 0.6640 Acc: 0.8920\n",
      "test Loss: 0.6680 Acc: 0.8920\n",
      "Epoch 555/1499\n",
      "----------\n",
      "train Loss: 0.6622 Acc: 0.8893\n",
      "val Loss: 0.6652 Acc: 0.8880\n",
      "test Loss: 0.6661 Acc: 0.8920\n",
      "Epoch 556/1499\n",
      "----------\n",
      "train Loss: 0.6610 Acc: 0.8896\n",
      "val Loss: 0.6633 Acc: 0.8760\n",
      "test Loss: 0.6670 Acc: 0.8840\n",
      "Epoch 557/1499\n",
      "----------\n",
      "train Loss: 0.6617 Acc: 0.8900\n",
      "val Loss: 0.6664 Acc: 0.8800\n",
      "test Loss: 0.6633 Acc: 0.8880\n",
      "Epoch 558/1499\n",
      "----------\n",
      "train Loss: 0.6633 Acc: 0.8867\n",
      "val Loss: 0.6671 Acc: 0.8800\n",
      "test Loss: 0.6653 Acc: 0.8880\n",
      "Epoch 559/1499\n",
      "----------\n",
      "train Loss: 0.6612 Acc: 0.8902\n",
      "val Loss: 0.6620 Acc: 0.8960\n",
      "test Loss: 0.6661 Acc: 0.8920\n",
      "Epoch 560/1499\n",
      "----------\n",
      "train Loss: 0.6617 Acc: 0.8873\n",
      "val Loss: 0.6681 Acc: 0.8760\n",
      "test Loss: 0.6631 Acc: 0.8920\n",
      "Epoch 561/1499\n",
      "----------\n",
      "train Loss: 0.6614 Acc: 0.8893\n",
      "val Loss: 0.6597 Acc: 0.8960\n",
      "test Loss: 0.6666 Acc: 0.8920\n",
      "Epoch 562/1499\n",
      "----------\n",
      "train Loss: 0.6608 Acc: 0.8876\n",
      "val Loss: 0.6617 Acc: 0.8920\n",
      "test Loss: 0.6629 Acc: 0.8920\n",
      "Epoch 563/1499\n",
      "----------\n",
      "train Loss: 0.6617 Acc: 0.8907\n",
      "val Loss: 0.6650 Acc: 0.8800\n",
      "test Loss: 0.6605 Acc: 0.8920\n",
      "Epoch 564/1499\n",
      "----------\n",
      "train Loss: 0.6624 Acc: 0.8864\n",
      "val Loss: 0.6637 Acc: 0.8920\n",
      "test Loss: 0.6617 Acc: 0.8880\n",
      "Epoch 565/1499\n",
      "----------\n",
      "train Loss: 0.6628 Acc: 0.8871\n",
      "val Loss: 0.6610 Acc: 0.8880\n",
      "test Loss: 0.6679 Acc: 0.8880\n",
      "Epoch 566/1499\n",
      "----------\n",
      "train Loss: 0.6624 Acc: 0.8864\n",
      "val Loss: 0.6621 Acc: 0.8880\n",
      "test Loss: 0.6655 Acc: 0.8920\n",
      "Epoch 567/1499\n",
      "----------\n",
      "train Loss: 0.6611 Acc: 0.8871\n",
      "val Loss: 0.6632 Acc: 0.8840\n",
      "test Loss: 0.6675 Acc: 0.8880\n",
      "Epoch 568/1499\n",
      "----------\n",
      "train Loss: 0.6615 Acc: 0.8907\n",
      "val Loss: 0.6650 Acc: 0.8800\n",
      "test Loss: 0.6628 Acc: 0.8800\n",
      "Epoch 569/1499\n",
      "----------\n",
      "train Loss: 0.6609 Acc: 0.8909\n",
      "val Loss: 0.6615 Acc: 0.8960\n",
      "test Loss: 0.6632 Acc: 0.8960\n",
      "Epoch 570/1499\n",
      "----------\n",
      "train Loss: 0.6627 Acc: 0.8864\n",
      "val Loss: 0.6618 Acc: 0.8840\n",
      "test Loss: 0.6657 Acc: 0.8880\n",
      "Epoch 571/1499\n",
      "----------\n",
      "train Loss: 0.6614 Acc: 0.8884\n",
      "val Loss: 0.6625 Acc: 0.8840\n",
      "test Loss: 0.6665 Acc: 0.8840\n",
      "Epoch 572/1499\n",
      "----------\n",
      "train Loss: 0.6606 Acc: 0.8884\n",
      "val Loss: 0.6670 Acc: 0.8840\n",
      "test Loss: 0.6632 Acc: 0.8920\n",
      "Epoch 573/1499\n",
      "----------\n",
      "train Loss: 0.6614 Acc: 0.8880\n",
      "val Loss: 0.6629 Acc: 0.8880\n",
      "test Loss: 0.6644 Acc: 0.8920\n",
      "Epoch 574/1499\n",
      "----------\n",
      "train Loss: 0.6603 Acc: 0.8887\n",
      "val Loss: 0.6723 Acc: 0.8760\n",
      "test Loss: 0.6630 Acc: 0.8920\n",
      "Epoch 575/1499\n",
      "----------\n",
      "train Loss: 0.6616 Acc: 0.8887\n",
      "val Loss: 0.6661 Acc: 0.8680\n",
      "test Loss: 0.6617 Acc: 0.8920\n",
      "Epoch 576/1499\n",
      "----------\n",
      "train Loss: 0.6602 Acc: 0.8913\n",
      "val Loss: 0.6611 Acc: 0.8800\n",
      "test Loss: 0.6628 Acc: 0.8880\n",
      "Epoch 577/1499\n",
      "----------\n",
      "train Loss: 0.6604 Acc: 0.8904\n",
      "val Loss: 0.6716 Acc: 0.8800\n",
      "test Loss: 0.6630 Acc: 0.8920\n",
      "Epoch 578/1499\n",
      "----------\n",
      "train Loss: 0.6609 Acc: 0.8873\n",
      "val Loss: 0.6642 Acc: 0.8840\n",
      "test Loss: 0.6615 Acc: 0.8880\n",
      "Epoch 579/1499\n",
      "----------\n",
      "train Loss: 0.6597 Acc: 0.8924\n",
      "val Loss: 0.6623 Acc: 0.8800\n",
      "test Loss: 0.6624 Acc: 0.8880\n",
      "Epoch 580/1499\n",
      "----------\n",
      "train Loss: 0.6610 Acc: 0.8862\n",
      "val Loss: 0.6612 Acc: 0.8880\n",
      "test Loss: 0.6610 Acc: 0.8920\n",
      "Epoch 581/1499\n",
      "----------\n",
      "train Loss: 0.6609 Acc: 0.8898\n",
      "val Loss: 0.6662 Acc: 0.8840\n",
      "test Loss: 0.6648 Acc: 0.8800\n",
      "Epoch 582/1499\n",
      "----------\n",
      "train Loss: 0.6606 Acc: 0.8902\n",
      "val Loss: 0.6656 Acc: 0.8840\n",
      "test Loss: 0.6601 Acc: 0.8960\n",
      "Epoch 583/1499\n",
      "----------\n",
      "train Loss: 0.6604 Acc: 0.8918\n",
      "val Loss: 0.6619 Acc: 0.8840\n",
      "test Loss: 0.6587 Acc: 0.8920\n",
      "Epoch 584/1499\n",
      "----------\n",
      "train Loss: 0.6601 Acc: 0.8904\n",
      "val Loss: 0.6686 Acc: 0.8800\n",
      "test Loss: 0.6640 Acc: 0.8880\n",
      "Epoch 585/1499\n",
      "----------\n",
      "train Loss: 0.6604 Acc: 0.8902\n",
      "val Loss: 0.6726 Acc: 0.8760\n",
      "test Loss: 0.6638 Acc: 0.8920\n",
      "Epoch 586/1499\n",
      "----------\n",
      "train Loss: 0.6593 Acc: 0.8913\n",
      "val Loss: 0.6638 Acc: 0.8840\n",
      "test Loss: 0.6637 Acc: 0.8920\n",
      "Epoch 587/1499\n",
      "----------\n",
      "train Loss: 0.6597 Acc: 0.8909\n",
      "val Loss: 0.6648 Acc: 0.8760\n",
      "test Loss: 0.6606 Acc: 0.8960\n",
      "Epoch 588/1499\n",
      "----------\n",
      "train Loss: 0.6596 Acc: 0.8927\n",
      "val Loss: 0.6608 Acc: 0.8880\n",
      "test Loss: 0.6628 Acc: 0.8920\n",
      "Epoch 589/1499\n",
      "----------\n",
      "train Loss: 0.6597 Acc: 0.8933\n",
      "val Loss: 0.6678 Acc: 0.8760\n",
      "test Loss: 0.6623 Acc: 0.8880\n",
      "Epoch 590/1499\n",
      "----------\n",
      "train Loss: 0.6598 Acc: 0.8893\n",
      "val Loss: 0.6602 Acc: 0.8960\n",
      "test Loss: 0.6595 Acc: 0.8880\n",
      "Epoch 591/1499\n",
      "----------\n",
      "train Loss: 0.6600 Acc: 0.8896\n",
      "val Loss: 0.6599 Acc: 0.8920\n",
      "test Loss: 0.6640 Acc: 0.8880\n",
      "Epoch 592/1499\n",
      "----------\n",
      "train Loss: 0.6594 Acc: 0.8907\n",
      "val Loss: 0.6636 Acc: 0.8920\n",
      "test Loss: 0.6660 Acc: 0.8920\n",
      "Epoch 593/1499\n",
      "----------\n",
      "train Loss: 0.6599 Acc: 0.8913\n",
      "val Loss: 0.6582 Acc: 0.8880\n",
      "test Loss: 0.6668 Acc: 0.8880\n",
      "Epoch 594/1499\n",
      "----------\n",
      "train Loss: 0.6599 Acc: 0.8887\n",
      "val Loss: 0.6614 Acc: 0.8800\n",
      "test Loss: 0.6651 Acc: 0.8920\n",
      "Epoch 595/1499\n",
      "----------\n",
      "train Loss: 0.6597 Acc: 0.8900\n",
      "val Loss: 0.6658 Acc: 0.8680\n",
      "test Loss: 0.6628 Acc: 0.8880\n",
      "Epoch 596/1499\n",
      "----------\n",
      "train Loss: 0.6585 Acc: 0.8884\n",
      "val Loss: 0.6623 Acc: 0.8840\n",
      "test Loss: 0.6633 Acc: 0.8840\n",
      "Epoch 597/1499\n",
      "----------\n",
      "train Loss: 0.6600 Acc: 0.8887\n",
      "val Loss: 0.6603 Acc: 0.8880\n",
      "test Loss: 0.6647 Acc: 0.8920\n",
      "Epoch 598/1499\n",
      "----------\n",
      "train Loss: 0.6591 Acc: 0.8898\n",
      "val Loss: 0.6648 Acc: 0.8840\n",
      "test Loss: 0.6598 Acc: 0.8960\n",
      "Epoch 599/1499\n",
      "----------\n",
      "train Loss: 0.6585 Acc: 0.8920\n",
      "val Loss: 0.6642 Acc: 0.8840\n",
      "test Loss: 0.6615 Acc: 0.8920\n",
      "Epoch 600/1499\n",
      "----------\n",
      "train Loss: 0.6589 Acc: 0.8896\n",
      "val Loss: 0.6640 Acc: 0.8800\n",
      "test Loss: 0.6639 Acc: 0.8880\n",
      "Epoch 601/1499\n",
      "----------\n",
      "train Loss: 0.6581 Acc: 0.8922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.6627 Acc: 0.8880\n",
      "test Loss: 0.6666 Acc: 0.8880\n",
      "Epoch 602/1499\n",
      "----------\n",
      "train Loss: 0.6591 Acc: 0.8924\n",
      "val Loss: 0.6642 Acc: 0.8880\n",
      "test Loss: 0.6645 Acc: 0.8920\n",
      "Epoch 603/1499\n",
      "----------\n",
      "train Loss: 0.6589 Acc: 0.8904\n",
      "val Loss: 0.6613 Acc: 0.8800\n",
      "test Loss: 0.6581 Acc: 0.9000\n",
      "Epoch 604/1499\n",
      "----------\n",
      "train Loss: 0.6584 Acc: 0.8924\n",
      "val Loss: 0.6606 Acc: 0.8880\n",
      "test Loss: 0.6574 Acc: 0.8920\n",
      "Epoch 605/1499\n",
      "----------\n",
      "train Loss: 0.6584 Acc: 0.8902\n",
      "val Loss: 0.6638 Acc: 0.8800\n",
      "test Loss: 0.6609 Acc: 0.8920\n",
      "Epoch 606/1499\n",
      "----------\n",
      "train Loss: 0.6592 Acc: 0.8873\n",
      "val Loss: 0.6612 Acc: 0.8840\n",
      "test Loss: 0.6605 Acc: 0.8840\n",
      "Epoch 607/1499\n",
      "----------\n",
      "train Loss: 0.6591 Acc: 0.8909\n",
      "val Loss: 0.6621 Acc: 0.8880\n",
      "test Loss: 0.6614 Acc: 0.8920\n",
      "Epoch 608/1499\n",
      "----------\n",
      "train Loss: 0.6582 Acc: 0.8920\n",
      "val Loss: 0.6627 Acc: 0.8800\n",
      "test Loss: 0.6631 Acc: 0.8920\n",
      "Epoch 609/1499\n",
      "----------\n",
      "train Loss: 0.6577 Acc: 0.8938\n",
      "val Loss: 0.6606 Acc: 0.8920\n",
      "test Loss: 0.6637 Acc: 0.8920\n",
      "Epoch 610/1499\n",
      "----------\n",
      "train Loss: 0.6589 Acc: 0.8911\n",
      "val Loss: 0.6643 Acc: 0.8800\n",
      "test Loss: 0.6610 Acc: 0.8920\n",
      "Epoch 611/1499\n",
      "----------\n",
      "train Loss: 0.6581 Acc: 0.8909\n",
      "val Loss: 0.6623 Acc: 0.8720\n",
      "test Loss: 0.6613 Acc: 0.8920\n",
      "Epoch 612/1499\n",
      "----------\n",
      "train Loss: 0.6579 Acc: 0.8944\n",
      "val Loss: 0.6606 Acc: 0.8840\n",
      "test Loss: 0.6640 Acc: 0.8920\n",
      "Epoch 613/1499\n",
      "----------\n",
      "train Loss: 0.6578 Acc: 0.8893\n",
      "val Loss: 0.6659 Acc: 0.8800\n",
      "test Loss: 0.6595 Acc: 0.8840\n",
      "Epoch 614/1499\n",
      "----------\n",
      "train Loss: 0.6585 Acc: 0.8924\n",
      "val Loss: 0.6581 Acc: 0.8800\n",
      "test Loss: 0.6634 Acc: 0.8920\n",
      "Epoch 615/1499\n",
      "----------\n",
      "train Loss: 0.6579 Acc: 0.8938\n",
      "val Loss: 0.6607 Acc: 0.8840\n",
      "test Loss: 0.6650 Acc: 0.8840\n",
      "Epoch 616/1499\n",
      "----------\n",
      "train Loss: 0.6572 Acc: 0.8924\n",
      "val Loss: 0.6624 Acc: 0.8760\n",
      "test Loss: 0.6608 Acc: 0.9000\n",
      "Epoch 617/1499\n",
      "----------\n",
      "train Loss: 0.6586 Acc: 0.8884\n",
      "val Loss: 0.6597 Acc: 0.8920\n",
      "test Loss: 0.6647 Acc: 0.8880\n",
      "Epoch 618/1499\n",
      "----------\n",
      "train Loss: 0.6576 Acc: 0.8893\n",
      "val Loss: 0.6610 Acc: 0.8840\n",
      "test Loss: 0.6629 Acc: 0.8880\n",
      "Epoch 619/1499\n",
      "----------\n",
      "train Loss: 0.6575 Acc: 0.8942\n",
      "val Loss: 0.6618 Acc: 0.8880\n",
      "test Loss: 0.6603 Acc: 0.8960\n",
      "Epoch 620/1499\n",
      "----------\n",
      "train Loss: 0.6575 Acc: 0.8911\n",
      "val Loss: 0.6617 Acc: 0.8840\n",
      "test Loss: 0.6581 Acc: 0.8960\n",
      "Epoch 621/1499\n",
      "----------\n",
      "train Loss: 0.6581 Acc: 0.8911\n",
      "val Loss: 0.6658 Acc: 0.8760\n",
      "test Loss: 0.6619 Acc: 0.8960\n",
      "Epoch 622/1499\n",
      "----------\n",
      "train Loss: 0.6577 Acc: 0.8942\n",
      "val Loss: 0.6649 Acc: 0.8720\n",
      "test Loss: 0.6621 Acc: 0.8920\n",
      "Epoch 623/1499\n",
      "----------\n",
      "train Loss: 0.6568 Acc: 0.8940\n",
      "val Loss: 0.6593 Acc: 0.8960\n",
      "test Loss: 0.6682 Acc: 0.8880\n",
      "Epoch 624/1499\n",
      "----------\n",
      "train Loss: 0.6577 Acc: 0.8918\n",
      "val Loss: 0.6607 Acc: 0.8800\n",
      "test Loss: 0.6653 Acc: 0.8880\n",
      "Epoch 625/1499\n",
      "----------\n",
      "train Loss: 0.6578 Acc: 0.8929\n",
      "val Loss: 0.6661 Acc: 0.8840\n",
      "test Loss: 0.6600 Acc: 0.8960\n",
      "Epoch 626/1499\n",
      "----------\n",
      "train Loss: 0.6587 Acc: 0.8896\n",
      "val Loss: 0.6643 Acc: 0.8880\n",
      "test Loss: 0.6598 Acc: 0.8920\n",
      "Epoch 627/1499\n",
      "----------\n",
      "train Loss: 0.6582 Acc: 0.8911\n",
      "val Loss: 0.6569 Acc: 0.8880\n",
      "test Loss: 0.6594 Acc: 0.8960\n",
      "Epoch 628/1499\n",
      "----------\n",
      "train Loss: 0.6577 Acc: 0.8918\n",
      "val Loss: 0.6587 Acc: 0.8840\n",
      "test Loss: 0.6598 Acc: 0.8920\n",
      "Epoch 629/1499\n",
      "----------\n",
      "train Loss: 0.6561 Acc: 0.8929\n",
      "val Loss: 0.6591 Acc: 0.8960\n",
      "test Loss: 0.6669 Acc: 0.8840\n",
      "Epoch 630/1499\n",
      "----------\n",
      "train Loss: 0.6578 Acc: 0.8916\n",
      "val Loss: 0.6590 Acc: 0.8920\n",
      "test Loss: 0.6631 Acc: 0.8920\n",
      "Epoch 631/1499\n",
      "----------\n",
      "train Loss: 0.6579 Acc: 0.8936\n",
      "val Loss: 0.6637 Acc: 0.8720\n",
      "test Loss: 0.6641 Acc: 0.8760\n",
      "Epoch 632/1499\n",
      "----------\n",
      "train Loss: 0.6559 Acc: 0.8931\n",
      "val Loss: 0.6601 Acc: 0.8800\n",
      "test Loss: 0.6612 Acc: 0.8880\n",
      "Epoch 633/1499\n",
      "----------\n",
      "train Loss: 0.6578 Acc: 0.8913\n",
      "val Loss: 0.6588 Acc: 0.8840\n",
      "test Loss: 0.6625 Acc: 0.8880\n",
      "Epoch 634/1499\n",
      "----------\n",
      "train Loss: 0.6564 Acc: 0.8931\n",
      "val Loss: 0.6600 Acc: 0.8720\n",
      "test Loss: 0.6648 Acc: 0.8880\n",
      "Epoch 635/1499\n",
      "----------\n",
      "train Loss: 0.6568 Acc: 0.8929\n",
      "val Loss: 0.6622 Acc: 0.8880\n",
      "test Loss: 0.6584 Acc: 0.9000\n",
      "Epoch 636/1499\n",
      "----------\n",
      "train Loss: 0.6575 Acc: 0.8916\n",
      "val Loss: 0.6623 Acc: 0.8800\n",
      "test Loss: 0.6641 Acc: 0.8880\n",
      "Epoch 637/1499\n",
      "----------\n",
      "train Loss: 0.6570 Acc: 0.8927\n",
      "val Loss: 0.6565 Acc: 0.8880\n",
      "test Loss: 0.6645 Acc: 0.8920\n",
      "Epoch 638/1499\n",
      "----------\n",
      "train Loss: 0.6576 Acc: 0.8927\n",
      "val Loss: 0.6624 Acc: 0.8760\n",
      "test Loss: 0.6624 Acc: 0.8920\n",
      "Epoch 639/1499\n",
      "----------\n",
      "train Loss: 0.6574 Acc: 0.8913\n",
      "val Loss: 0.6616 Acc: 0.8840\n",
      "test Loss: 0.6617 Acc: 0.8960\n",
      "Epoch 640/1499\n",
      "----------\n",
      "train Loss: 0.6572 Acc: 0.8904\n",
      "val Loss: 0.6566 Acc: 0.8840\n",
      "test Loss: 0.6603 Acc: 0.8880\n",
      "Epoch 641/1499\n",
      "----------\n",
      "train Loss: 0.6558 Acc: 0.8918\n",
      "val Loss: 0.6706 Acc: 0.8760\n",
      "test Loss: 0.6582 Acc: 0.8960\n",
      "Epoch 642/1499\n",
      "----------\n",
      "train Loss: 0.6562 Acc: 0.8929\n",
      "val Loss: 0.6606 Acc: 0.8920\n",
      "test Loss: 0.6592 Acc: 0.8960\n",
      "Epoch 643/1499\n",
      "----------\n",
      "train Loss: 0.6559 Acc: 0.8951\n",
      "val Loss: 0.6604 Acc: 0.8840\n",
      "test Loss: 0.6626 Acc: 0.8920\n",
      "Epoch 644/1499\n",
      "----------\n",
      "train Loss: 0.6568 Acc: 0.8924\n",
      "val Loss: 0.6569 Acc: 0.8960\n",
      "test Loss: 0.6601 Acc: 0.8960\n",
      "Epoch 645/1499\n",
      "----------\n",
      "train Loss: 0.6573 Acc: 0.8920\n",
      "val Loss: 0.6606 Acc: 0.8840\n",
      "test Loss: 0.6587 Acc: 0.9000\n",
      "Epoch 646/1499\n",
      "----------\n",
      "train Loss: 0.6570 Acc: 0.8924\n",
      "val Loss: 0.6626 Acc: 0.8800\n",
      "test Loss: 0.6608 Acc: 0.8960\n",
      "Epoch 647/1499\n",
      "----------\n",
      "train Loss: 0.6571 Acc: 0.8936\n",
      "val Loss: 0.6635 Acc: 0.8720\n",
      "test Loss: 0.6580 Acc: 0.8920\n",
      "Epoch 648/1499\n",
      "----------\n",
      "train Loss: 0.6562 Acc: 0.8911\n",
      "val Loss: 0.6595 Acc: 0.8840\n",
      "test Loss: 0.6608 Acc: 0.8920\n",
      "Epoch 649/1499\n",
      "----------\n",
      "train Loss: 0.6565 Acc: 0.8929\n",
      "val Loss: 0.6634 Acc: 0.8840\n",
      "test Loss: 0.6647 Acc: 0.8880\n",
      "Epoch 650/1499\n",
      "----------\n",
      "train Loss: 0.6568 Acc: 0.8924\n",
      "val Loss: 0.6598 Acc: 0.8840\n",
      "test Loss: 0.6542 Acc: 0.9000\n",
      "Epoch 651/1499\n",
      "----------\n",
      "train Loss: 0.6552 Acc: 0.8971\n",
      "val Loss: 0.6618 Acc: 0.8800\n",
      "test Loss: 0.6614 Acc: 0.8960\n",
      "Epoch 652/1499\n",
      "----------\n",
      "train Loss: 0.6550 Acc: 0.8953\n",
      "val Loss: 0.6614 Acc: 0.8920\n",
      "test Loss: 0.6584 Acc: 0.9000\n",
      "Epoch 653/1499\n",
      "----------\n",
      "train Loss: 0.6546 Acc: 0.8949\n",
      "val Loss: 0.6618 Acc: 0.8880\n",
      "test Loss: 0.6615 Acc: 0.8960\n",
      "Epoch 654/1499\n",
      "----------\n",
      "train Loss: 0.6552 Acc: 0.8949\n",
      "val Loss: 0.6657 Acc: 0.8920\n",
      "test Loss: 0.6601 Acc: 0.8920\n",
      "Epoch 655/1499\n",
      "----------\n",
      "train Loss: 0.6568 Acc: 0.8911\n",
      "val Loss: 0.6588 Acc: 0.8840\n",
      "test Loss: 0.6622 Acc: 0.8920\n",
      "Epoch 656/1499\n",
      "----------\n",
      "train Loss: 0.6558 Acc: 0.8944\n",
      "val Loss: 0.6634 Acc: 0.8800\n",
      "test Loss: 0.6630 Acc: 0.8960\n",
      "Epoch 657/1499\n",
      "----------\n",
      "train Loss: 0.6541 Acc: 0.8969\n",
      "val Loss: 0.6602 Acc: 0.8840\n",
      "test Loss: 0.6620 Acc: 0.8920\n",
      "Epoch 658/1499\n",
      "----------\n",
      "train Loss: 0.6555 Acc: 0.8940\n",
      "val Loss: 0.6605 Acc: 0.8760\n",
      "test Loss: 0.6602 Acc: 0.8960\n",
      "Epoch 659/1499\n",
      "----------\n",
      "train Loss: 0.6556 Acc: 0.8913\n",
      "val Loss: 0.6612 Acc: 0.8800\n",
      "test Loss: 0.6593 Acc: 0.8920\n",
      "Epoch 660/1499\n",
      "----------\n",
      "train Loss: 0.6542 Acc: 0.8969\n",
      "val Loss: 0.6604 Acc: 0.8800\n",
      "test Loss: 0.6611 Acc: 0.8920\n",
      "Epoch 661/1499\n",
      "----------\n",
      "train Loss: 0.6559 Acc: 0.8944\n",
      "val Loss: 0.6608 Acc: 0.8840\n",
      "test Loss: 0.6592 Acc: 0.9000\n",
      "Epoch 662/1499\n",
      "----------\n",
      "train Loss: 0.6553 Acc: 0.8956\n",
      "val Loss: 0.6617 Acc: 0.8840\n",
      "test Loss: 0.6591 Acc: 0.8920\n",
      "Epoch 663/1499\n",
      "----------\n",
      "train Loss: 0.6555 Acc: 0.8951\n",
      "val Loss: 0.6620 Acc: 0.8840\n",
      "test Loss: 0.6655 Acc: 0.8920\n",
      "Epoch 664/1499\n",
      "----------\n",
      "train Loss: 0.6562 Acc: 0.8953\n",
      "val Loss: 0.6594 Acc: 0.8840\n",
      "test Loss: 0.6607 Acc: 0.8920\n",
      "Epoch 665/1499\n",
      "----------\n",
      "train Loss: 0.6549 Acc: 0.8940\n",
      "val Loss: 0.6547 Acc: 0.8880\n",
      "test Loss: 0.6610 Acc: 0.8840\n",
      "Epoch 666/1499\n",
      "----------\n",
      "train Loss: 0.6543 Acc: 0.8953\n",
      "val Loss: 0.6625 Acc: 0.8840\n",
      "test Loss: 0.6606 Acc: 0.8960\n",
      "Epoch 667/1499\n",
      "----------\n",
      "train Loss: 0.6550 Acc: 0.8969\n",
      "val Loss: 0.6605 Acc: 0.8920\n",
      "test Loss: 0.6645 Acc: 0.8920\n",
      "Epoch 668/1499\n",
      "----------\n",
      "train Loss: 0.6556 Acc: 0.8940\n",
      "val Loss: 0.6528 Acc: 0.8920\n",
      "test Loss: 0.6608 Acc: 0.8960\n",
      "Epoch 669/1499\n",
      "----------\n",
      "train Loss: 0.6548 Acc: 0.8953\n",
      "val Loss: 0.6618 Acc: 0.8920\n",
      "test Loss: 0.6590 Acc: 0.9000\n",
      "Epoch 670/1499\n",
      "----------\n",
      "train Loss: 0.6558 Acc: 0.8916\n",
      "val Loss: 0.6639 Acc: 0.8760\n",
      "test Loss: 0.6601 Acc: 0.8960\n",
      "Epoch 671/1499\n",
      "----------\n",
      "train Loss: 0.6546 Acc: 0.8940\n",
      "val Loss: 0.6644 Acc: 0.8760\n",
      "test Loss: 0.6605 Acc: 0.8880\n",
      "Epoch 672/1499\n",
      "----------\n",
      "train Loss: 0.6546 Acc: 0.8956\n",
      "val Loss: 0.6609 Acc: 0.8760\n",
      "test Loss: 0.6572 Acc: 0.8960\n",
      "Epoch 673/1499\n",
      "----------\n",
      "train Loss: 0.6545 Acc: 0.8944\n",
      "val Loss: 0.6608 Acc: 0.8840\n",
      "test Loss: 0.6649 Acc: 0.8800\n",
      "Epoch 674/1499\n",
      "----------\n",
      "train Loss: 0.6537 Acc: 0.8951\n",
      "val Loss: 0.6603 Acc: 0.8920\n",
      "test Loss: 0.6631 Acc: 0.8880\n",
      "Epoch 675/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6550 Acc: 0.8947\n",
      "val Loss: 0.6611 Acc: 0.8920\n",
      "test Loss: 0.6594 Acc: 0.8920\n",
      "Epoch 676/1499\n",
      "----------\n",
      "train Loss: 0.6545 Acc: 0.8940\n",
      "val Loss: 0.6585 Acc: 0.9000\n",
      "test Loss: 0.6625 Acc: 0.8960\n",
      "Epoch 677/1499\n",
      "----------\n",
      "train Loss: 0.6554 Acc: 0.8942\n",
      "val Loss: 0.6554 Acc: 0.9000\n",
      "test Loss: 0.6604 Acc: 0.8960\n",
      "Epoch 678/1499\n",
      "----------\n",
      "train Loss: 0.6551 Acc: 0.8940\n",
      "val Loss: 0.6633 Acc: 0.8800\n",
      "test Loss: 0.6598 Acc: 0.9000\n",
      "Epoch 679/1499\n",
      "----------\n",
      "train Loss: 0.6559 Acc: 0.8920\n",
      "val Loss: 0.6624 Acc: 0.8840\n",
      "test Loss: 0.6572 Acc: 0.9000\n",
      "Epoch 680/1499\n",
      "----------\n",
      "train Loss: 0.6543 Acc: 0.8978\n",
      "val Loss: 0.6597 Acc: 0.8920\n",
      "test Loss: 0.6613 Acc: 0.8920\n",
      "Epoch 681/1499\n",
      "----------\n",
      "train Loss: 0.6553 Acc: 0.8911\n",
      "val Loss: 0.6559 Acc: 0.8960\n",
      "test Loss: 0.6556 Acc: 0.9000\n",
      "Epoch 682/1499\n",
      "----------\n",
      "train Loss: 0.6545 Acc: 0.8978\n",
      "val Loss: 0.6619 Acc: 0.8920\n",
      "test Loss: 0.6614 Acc: 0.8960\n",
      "Epoch 683/1499\n",
      "----------\n",
      "train Loss: 0.6548 Acc: 0.8929\n",
      "val Loss: 0.6609 Acc: 0.8840\n",
      "test Loss: 0.6610 Acc: 0.8880\n",
      "Epoch 684/1499\n",
      "----------\n",
      "train Loss: 0.6540 Acc: 0.8980\n",
      "val Loss: 0.6611 Acc: 0.8920\n",
      "test Loss: 0.6600 Acc: 0.8880\n",
      "Epoch 685/1499\n",
      "----------\n",
      "train Loss: 0.6556 Acc: 0.8931\n",
      "val Loss: 0.6591 Acc: 0.8840\n",
      "test Loss: 0.6578 Acc: 0.8960\n",
      "Epoch 686/1499\n",
      "----------\n",
      "train Loss: 0.6541 Acc: 0.8962\n",
      "val Loss: 0.6609 Acc: 0.8880\n",
      "test Loss: 0.6559 Acc: 0.9000\n",
      "Epoch 687/1499\n",
      "----------\n",
      "train Loss: 0.6542 Acc: 0.8969\n",
      "val Loss: 0.6606 Acc: 0.8880\n",
      "test Loss: 0.6597 Acc: 0.8920\n",
      "Epoch 688/1499\n",
      "----------\n",
      "train Loss: 0.6540 Acc: 0.8964\n",
      "val Loss: 0.6551 Acc: 0.9000\n",
      "test Loss: 0.6562 Acc: 0.8960\n",
      "Epoch 689/1499\n",
      "----------\n",
      "train Loss: 0.6544 Acc: 0.8938\n",
      "val Loss: 0.6629 Acc: 0.8840\n",
      "test Loss: 0.6593 Acc: 0.8960\n",
      "Epoch 690/1499\n",
      "----------\n",
      "train Loss: 0.6547 Acc: 0.8933\n",
      "val Loss: 0.6589 Acc: 0.8920\n",
      "test Loss: 0.6621 Acc: 0.8960\n",
      "Epoch 691/1499\n",
      "----------\n",
      "train Loss: 0.6538 Acc: 0.8944\n",
      "val Loss: 0.6552 Acc: 0.8960\n",
      "test Loss: 0.6584 Acc: 0.9000\n",
      "Epoch 692/1499\n",
      "----------\n",
      "train Loss: 0.6540 Acc: 0.8958\n",
      "val Loss: 0.6595 Acc: 0.9040\n",
      "test Loss: 0.6588 Acc: 0.8960\n",
      "Epoch 693/1499\n",
      "----------\n",
      "train Loss: 0.6540 Acc: 0.8967\n",
      "val Loss: 0.6619 Acc: 0.8880\n",
      "test Loss: 0.6608 Acc: 0.8840\n",
      "Epoch 694/1499\n",
      "----------\n",
      "train Loss: 0.6552 Acc: 0.8924\n",
      "val Loss: 0.6555 Acc: 0.8960\n",
      "test Loss: 0.6593 Acc: 0.8960\n",
      "Epoch 695/1499\n",
      "----------\n",
      "train Loss: 0.6539 Acc: 0.8949\n",
      "val Loss: 0.6586 Acc: 0.8880\n",
      "test Loss: 0.6601 Acc: 0.8840\n",
      "Epoch 696/1499\n",
      "----------\n",
      "train Loss: 0.6535 Acc: 0.8969\n",
      "val Loss: 0.6581 Acc: 0.8880\n",
      "test Loss: 0.6634 Acc: 0.8920\n",
      "Epoch 697/1499\n",
      "----------\n",
      "train Loss: 0.6545 Acc: 0.8956\n",
      "val Loss: 0.6529 Acc: 0.9040\n",
      "test Loss: 0.6585 Acc: 0.8920\n",
      "Epoch 698/1499\n",
      "----------\n",
      "train Loss: 0.6529 Acc: 0.8956\n",
      "val Loss: 0.6639 Acc: 0.8800\n",
      "test Loss: 0.6604 Acc: 0.8920\n",
      "Epoch 699/1499\n",
      "----------\n",
      "train Loss: 0.6532 Acc: 0.8944\n",
      "val Loss: 0.6558 Acc: 0.8880\n",
      "test Loss: 0.6604 Acc: 0.8960\n",
      "Epoch 700/1499\n",
      "----------\n",
      "train Loss: 0.6543 Acc: 0.8962\n",
      "val Loss: 0.6632 Acc: 0.8760\n",
      "test Loss: 0.6625 Acc: 0.8880\n",
      "Epoch 701/1499\n",
      "----------\n",
      "train Loss: 0.6529 Acc: 0.8976\n",
      "val Loss: 0.6592 Acc: 0.9000\n",
      "test Loss: 0.6585 Acc: 0.9000\n",
      "Epoch 702/1499\n",
      "----------\n",
      "train Loss: 0.6537 Acc: 0.8969\n",
      "val Loss: 0.6636 Acc: 0.8840\n",
      "test Loss: 0.6599 Acc: 0.9000\n",
      "Epoch 703/1499\n",
      "----------\n",
      "train Loss: 0.6537 Acc: 0.8980\n",
      "val Loss: 0.6566 Acc: 0.8840\n",
      "test Loss: 0.6589 Acc: 0.8960\n",
      "Epoch 704/1499\n",
      "----------\n",
      "train Loss: 0.6533 Acc: 0.8951\n",
      "val Loss: 0.6587 Acc: 0.8800\n",
      "test Loss: 0.6596 Acc: 0.8960\n",
      "Epoch 705/1499\n",
      "----------\n",
      "train Loss: 0.6524 Acc: 0.8971\n",
      "val Loss: 0.6565 Acc: 0.8880\n",
      "test Loss: 0.6603 Acc: 0.9000\n",
      "Epoch 706/1499\n",
      "----------\n",
      "train Loss: 0.6531 Acc: 0.8978\n",
      "val Loss: 0.6602 Acc: 0.8880\n",
      "test Loss: 0.6563 Acc: 0.9000\n",
      "Epoch 707/1499\n",
      "----------\n",
      "train Loss: 0.6539 Acc: 0.8960\n",
      "val Loss: 0.6619 Acc: 0.8920\n",
      "test Loss: 0.6635 Acc: 0.8960\n",
      "Epoch 708/1499\n",
      "----------\n",
      "train Loss: 0.6532 Acc: 0.8953\n",
      "val Loss: 0.6628 Acc: 0.8960\n",
      "test Loss: 0.6572 Acc: 0.9000\n",
      "Epoch 709/1499\n",
      "----------\n",
      "train Loss: 0.6523 Acc: 0.8978\n",
      "val Loss: 0.6569 Acc: 0.8960\n",
      "test Loss: 0.6587 Acc: 0.8960\n",
      "Epoch 710/1499\n",
      "----------\n",
      "train Loss: 0.6529 Acc: 0.8971\n",
      "val Loss: 0.6584 Acc: 0.8960\n",
      "test Loss: 0.6622 Acc: 0.8840\n",
      "Epoch 711/1499\n",
      "----------\n",
      "train Loss: 0.6538 Acc: 0.8969\n",
      "val Loss: 0.6588 Acc: 0.8920\n",
      "test Loss: 0.6574 Acc: 0.9000\n",
      "Epoch 712/1499\n",
      "----------\n",
      "train Loss: 0.6528 Acc: 0.8980\n",
      "val Loss: 0.6593 Acc: 0.8800\n",
      "test Loss: 0.6627 Acc: 0.9000\n",
      "Epoch 713/1499\n",
      "----------\n",
      "train Loss: 0.6531 Acc: 0.8958\n",
      "val Loss: 0.6624 Acc: 0.8800\n",
      "test Loss: 0.6611 Acc: 0.8960\n",
      "Epoch 714/1499\n",
      "----------\n",
      "train Loss: 0.6530 Acc: 0.8971\n",
      "val Loss: 0.6574 Acc: 0.9000\n",
      "test Loss: 0.6585 Acc: 0.8920\n",
      "Epoch 715/1499\n",
      "----------\n",
      "train Loss: 0.6528 Acc: 0.9007\n",
      "val Loss: 0.6545 Acc: 0.8800\n",
      "test Loss: 0.6594 Acc: 0.8920\n",
      "Epoch 716/1499\n",
      "----------\n",
      "train Loss: 0.6524 Acc: 0.8953\n",
      "val Loss: 0.6584 Acc: 0.8920\n",
      "test Loss: 0.6611 Acc: 0.8960\n",
      "Epoch 717/1499\n",
      "----------\n",
      "train Loss: 0.6511 Acc: 0.9011\n",
      "val Loss: 0.6558 Acc: 0.8880\n",
      "test Loss: 0.6616 Acc: 0.9000\n",
      "Epoch 718/1499\n",
      "----------\n",
      "train Loss: 0.6523 Acc: 0.8956\n",
      "val Loss: 0.6586 Acc: 0.8880\n",
      "test Loss: 0.6622 Acc: 0.8880\n",
      "Epoch 719/1499\n",
      "----------\n",
      "train Loss: 0.6525 Acc: 0.8987\n",
      "val Loss: 0.6597 Acc: 0.8880\n",
      "test Loss: 0.6570 Acc: 0.9000\n",
      "Epoch 720/1499\n",
      "----------\n",
      "train Loss: 0.6519 Acc: 0.8971\n",
      "val Loss: 0.6594 Acc: 0.8840\n",
      "test Loss: 0.6623 Acc: 0.8960\n",
      "Epoch 721/1499\n",
      "----------\n",
      "train Loss: 0.6517 Acc: 0.9009\n",
      "val Loss: 0.6574 Acc: 0.8840\n",
      "test Loss: 0.6582 Acc: 0.8920\n",
      "Epoch 722/1499\n",
      "----------\n",
      "train Loss: 0.6536 Acc: 0.8978\n",
      "val Loss: 0.6613 Acc: 0.8920\n",
      "test Loss: 0.6574 Acc: 0.9000\n",
      "Epoch 723/1499\n",
      "----------\n",
      "train Loss: 0.6534 Acc: 0.8962\n",
      "val Loss: 0.6588 Acc: 0.8880\n",
      "test Loss: 0.6592 Acc: 0.8960\n",
      "Epoch 724/1499\n",
      "----------\n",
      "train Loss: 0.6527 Acc: 0.8998\n",
      "val Loss: 0.6556 Acc: 0.8960\n",
      "test Loss: 0.6599 Acc: 0.9000\n",
      "Epoch 725/1499\n",
      "----------\n",
      "train Loss: 0.6535 Acc: 0.8951\n",
      "val Loss: 0.6608 Acc: 0.8920\n",
      "test Loss: 0.6595 Acc: 0.8960\n",
      "Epoch 726/1499\n",
      "----------\n",
      "train Loss: 0.6535 Acc: 0.8964\n",
      "val Loss: 0.6593 Acc: 0.8880\n",
      "test Loss: 0.6582 Acc: 0.9000\n",
      "Epoch 727/1499\n",
      "----------\n",
      "train Loss: 0.6528 Acc: 0.8962\n",
      "val Loss: 0.6583 Acc: 0.8960\n",
      "test Loss: 0.6595 Acc: 0.8920\n",
      "Epoch 728/1499\n",
      "----------\n",
      "train Loss: 0.6529 Acc: 0.8960\n",
      "val Loss: 0.6601 Acc: 0.8840\n",
      "test Loss: 0.6593 Acc: 0.8880\n",
      "Epoch 729/1499\n",
      "----------\n",
      "train Loss: 0.6527 Acc: 0.8964\n",
      "val Loss: 0.6616 Acc: 0.8800\n",
      "test Loss: 0.6604 Acc: 0.8880\n",
      "Epoch 730/1499\n",
      "----------\n",
      "train Loss: 0.6512 Acc: 0.8973\n",
      "val Loss: 0.6538 Acc: 0.8960\n",
      "test Loss: 0.6577 Acc: 0.9040\n",
      "Epoch 731/1499\n",
      "----------\n",
      "train Loss: 0.6513 Acc: 0.8973\n",
      "val Loss: 0.6601 Acc: 0.8960\n",
      "test Loss: 0.6605 Acc: 0.8880\n",
      "Epoch 732/1499\n",
      "----------\n",
      "train Loss: 0.6522 Acc: 0.8980\n",
      "val Loss: 0.6588 Acc: 0.8880\n",
      "test Loss: 0.6600 Acc: 0.8920\n",
      "Epoch 733/1499\n",
      "----------\n",
      "train Loss: 0.6522 Acc: 0.8967\n",
      "val Loss: 0.6617 Acc: 0.8920\n",
      "test Loss: 0.6587 Acc: 0.8920\n",
      "Epoch 734/1499\n",
      "----------\n",
      "train Loss: 0.6523 Acc: 0.8973\n",
      "val Loss: 0.6549 Acc: 0.8840\n",
      "test Loss: 0.6565 Acc: 0.9000\n",
      "Epoch 735/1499\n",
      "----------\n",
      "train Loss: 0.6509 Acc: 0.9002\n",
      "val Loss: 0.6629 Acc: 0.8800\n",
      "test Loss: 0.6575 Acc: 0.8960\n",
      "Epoch 736/1499\n",
      "----------\n",
      "train Loss: 0.6523 Acc: 0.8987\n",
      "val Loss: 0.6566 Acc: 0.8960\n",
      "test Loss: 0.6593 Acc: 0.8960\n",
      "Epoch 737/1499\n",
      "----------\n",
      "train Loss: 0.6531 Acc: 0.8971\n",
      "val Loss: 0.6532 Acc: 0.8960\n",
      "test Loss: 0.6584 Acc: 0.8920\n",
      "Epoch 738/1499\n",
      "----------\n",
      "train Loss: 0.6520 Acc: 0.8958\n",
      "val Loss: 0.6588 Acc: 0.8920\n",
      "test Loss: 0.6559 Acc: 0.8960\n",
      "Epoch 739/1499\n",
      "----------\n",
      "train Loss: 0.6520 Acc: 0.8976\n",
      "val Loss: 0.6585 Acc: 0.8880\n",
      "test Loss: 0.6613 Acc: 0.8960\n",
      "Epoch 740/1499\n",
      "----------\n",
      "train Loss: 0.6523 Acc: 0.8989\n",
      "val Loss: 0.6579 Acc: 0.8920\n",
      "test Loss: 0.6595 Acc: 0.8960\n",
      "Epoch 741/1499\n",
      "----------\n",
      "train Loss: 0.6510 Acc: 0.9016\n",
      "val Loss: 0.6549 Acc: 0.8960\n",
      "test Loss: 0.6643 Acc: 0.8880\n",
      "Epoch 742/1499\n",
      "----------\n",
      "train Loss: 0.6519 Acc: 0.8951\n",
      "val Loss: 0.6647 Acc: 0.8760\n",
      "test Loss: 0.6547 Acc: 0.8920\n",
      "Epoch 743/1499\n",
      "----------\n",
      "train Loss: 0.6517 Acc: 0.8973\n",
      "val Loss: 0.6536 Acc: 0.9040\n",
      "test Loss: 0.6565 Acc: 0.8960\n",
      "Epoch 744/1499\n",
      "----------\n",
      "train Loss: 0.6519 Acc: 0.8987\n",
      "val Loss: 0.6536 Acc: 0.8800\n",
      "test Loss: 0.6591 Acc: 0.8960\n",
      "Epoch 745/1499\n",
      "----------\n",
      "train Loss: 0.6520 Acc: 0.8973\n",
      "val Loss: 0.6582 Acc: 0.8880\n",
      "test Loss: 0.6576 Acc: 0.8920\n",
      "Epoch 746/1499\n",
      "----------\n",
      "train Loss: 0.6515 Acc: 0.8987\n",
      "val Loss: 0.6608 Acc: 0.8760\n",
      "test Loss: 0.6564 Acc: 0.9000\n",
      "Epoch 747/1499\n",
      "----------\n",
      "train Loss: 0.6514 Acc: 0.8958\n",
      "val Loss: 0.6579 Acc: 0.8960\n",
      "test Loss: 0.6604 Acc: 0.8920\n",
      "Epoch 748/1499\n",
      "----------\n",
      "train Loss: 0.6520 Acc: 0.8984\n",
      "val Loss: 0.6578 Acc: 0.8880\n",
      "test Loss: 0.6539 Acc: 0.9040\n",
      "Epoch 749/1499\n",
      "----------\n",
      "train Loss: 0.6520 Acc: 0.8976\n",
      "val Loss: 0.6577 Acc: 0.9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6578 Acc: 0.8960\n",
      "Epoch 750/1499\n",
      "----------\n",
      "train Loss: 0.6511 Acc: 0.8969\n",
      "val Loss: 0.6568 Acc: 0.8840\n",
      "test Loss: 0.6560 Acc: 0.8960\n",
      "Epoch 751/1499\n",
      "----------\n",
      "train Loss: 0.6507 Acc: 0.8993\n",
      "val Loss: 0.6598 Acc: 0.9000\n",
      "test Loss: 0.6568 Acc: 0.9000\n",
      "Epoch 752/1499\n",
      "----------\n",
      "train Loss: 0.6511 Acc: 0.8964\n",
      "val Loss: 0.6565 Acc: 0.9000\n",
      "test Loss: 0.6596 Acc: 0.9000\n",
      "Epoch 753/1499\n",
      "----------\n",
      "train Loss: 0.6515 Acc: 0.8973\n",
      "val Loss: 0.6617 Acc: 0.8800\n",
      "test Loss: 0.6630 Acc: 0.8960\n",
      "Epoch 754/1499\n",
      "----------\n",
      "train Loss: 0.6521 Acc: 0.8976\n",
      "val Loss: 0.6581 Acc: 0.8800\n",
      "test Loss: 0.6555 Acc: 0.8960\n",
      "Epoch 755/1499\n",
      "----------\n",
      "train Loss: 0.6504 Acc: 0.9011\n",
      "val Loss: 0.6574 Acc: 0.8880\n",
      "test Loss: 0.6572 Acc: 0.9000\n",
      "Epoch 756/1499\n",
      "----------\n",
      "train Loss: 0.6507 Acc: 0.8998\n",
      "val Loss: 0.6544 Acc: 0.9000\n",
      "test Loss: 0.6598 Acc: 0.8880\n",
      "Epoch 757/1499\n",
      "----------\n",
      "train Loss: 0.6509 Acc: 0.8971\n",
      "val Loss: 0.6624 Acc: 0.8760\n",
      "test Loss: 0.6628 Acc: 0.8880\n",
      "Epoch 758/1499\n",
      "----------\n",
      "train Loss: 0.6507 Acc: 0.9016\n",
      "val Loss: 0.6533 Acc: 0.9040\n",
      "test Loss: 0.6588 Acc: 0.9000\n",
      "Epoch 759/1499\n",
      "----------\n",
      "train Loss: 0.6513 Acc: 0.8989\n",
      "val Loss: 0.6533 Acc: 0.9040\n",
      "test Loss: 0.6583 Acc: 0.8960\n",
      "Epoch 760/1499\n",
      "----------\n",
      "train Loss: 0.6526 Acc: 0.8962\n",
      "val Loss: 0.6589 Acc: 0.8880\n",
      "test Loss: 0.6550 Acc: 0.8960\n",
      "Epoch 761/1499\n",
      "----------\n",
      "train Loss: 0.6512 Acc: 0.8991\n",
      "val Loss: 0.6546 Acc: 0.9000\n",
      "test Loss: 0.6571 Acc: 0.9000\n",
      "Epoch 762/1499\n",
      "----------\n",
      "train Loss: 0.6511 Acc: 0.8982\n",
      "val Loss: 0.6574 Acc: 0.8840\n",
      "test Loss: 0.6593 Acc: 0.9000\n",
      "Epoch 763/1499\n",
      "----------\n",
      "train Loss: 0.6516 Acc: 0.8998\n",
      "val Loss: 0.6511 Acc: 0.9080\n",
      "test Loss: 0.6570 Acc: 0.9000\n",
      "Epoch 764/1499\n",
      "----------\n",
      "train Loss: 0.6517 Acc: 0.8964\n",
      "val Loss: 0.6576 Acc: 0.8880\n",
      "test Loss: 0.6575 Acc: 0.9000\n",
      "Epoch 765/1499\n",
      "----------\n",
      "train Loss: 0.6512 Acc: 0.8980\n",
      "val Loss: 0.6561 Acc: 0.8920\n",
      "test Loss: 0.6595 Acc: 0.8960\n",
      "Epoch 766/1499\n",
      "----------\n",
      "train Loss: 0.6503 Acc: 0.8987\n",
      "val Loss: 0.6590 Acc: 0.8880\n",
      "test Loss: 0.6586 Acc: 0.8880\n",
      "Epoch 767/1499\n",
      "----------\n",
      "train Loss: 0.6502 Acc: 0.8996\n",
      "val Loss: 0.6576 Acc: 0.8960\n",
      "test Loss: 0.6583 Acc: 0.8960\n",
      "Epoch 768/1499\n",
      "----------\n",
      "train Loss: 0.6495 Acc: 0.9007\n",
      "val Loss: 0.6558 Acc: 0.8880\n",
      "test Loss: 0.6567 Acc: 0.9000\n",
      "Epoch 769/1499\n",
      "----------\n",
      "train Loss: 0.6504 Acc: 0.8996\n",
      "val Loss: 0.6593 Acc: 0.8920\n",
      "test Loss: 0.6555 Acc: 0.9000\n",
      "Epoch 770/1499\n",
      "----------\n",
      "train Loss: 0.6491 Acc: 0.9033\n",
      "val Loss: 0.6587 Acc: 0.8880\n",
      "test Loss: 0.6617 Acc: 0.8960\n",
      "Epoch 771/1499\n",
      "----------\n",
      "train Loss: 0.6513 Acc: 0.9016\n",
      "val Loss: 0.6533 Acc: 0.9000\n",
      "test Loss: 0.6614 Acc: 0.8960\n",
      "Epoch 772/1499\n",
      "----------\n",
      "train Loss: 0.6518 Acc: 0.8980\n",
      "val Loss: 0.6535 Acc: 0.9000\n",
      "test Loss: 0.6531 Acc: 0.9000\n",
      "Epoch 773/1499\n",
      "----------\n",
      "train Loss: 0.6510 Acc: 0.8993\n",
      "val Loss: 0.6573 Acc: 0.8840\n",
      "test Loss: 0.6585 Acc: 0.8920\n",
      "Epoch 774/1499\n",
      "----------\n",
      "train Loss: 0.6501 Acc: 0.8989\n",
      "val Loss: 0.6575 Acc: 0.8960\n",
      "test Loss: 0.6585 Acc: 0.8880\n",
      "Epoch 775/1499\n",
      "----------\n",
      "train Loss: 0.6510 Acc: 0.8991\n",
      "val Loss: 0.6528 Acc: 0.9000\n",
      "test Loss: 0.6548 Acc: 0.9040\n",
      "Epoch 776/1499\n",
      "----------\n",
      "train Loss: 0.6514 Acc: 0.8989\n",
      "val Loss: 0.6594 Acc: 0.8880\n",
      "test Loss: 0.6583 Acc: 0.8920\n",
      "Epoch 777/1499\n",
      "----------\n",
      "train Loss: 0.6514 Acc: 0.9009\n",
      "val Loss: 0.6621 Acc: 0.8840\n",
      "test Loss: 0.6595 Acc: 0.8960\n",
      "Epoch 778/1499\n",
      "----------\n",
      "train Loss: 0.6486 Acc: 0.9040\n",
      "val Loss: 0.6577 Acc: 0.8880\n",
      "test Loss: 0.6607 Acc: 0.8920\n",
      "Epoch 779/1499\n",
      "----------\n",
      "train Loss: 0.6510 Acc: 0.8998\n",
      "val Loss: 0.6606 Acc: 0.8880\n",
      "test Loss: 0.6581 Acc: 0.8960\n",
      "Epoch 780/1499\n",
      "----------\n",
      "train Loss: 0.6496 Acc: 0.9009\n",
      "val Loss: 0.6532 Acc: 0.9000\n",
      "test Loss: 0.6575 Acc: 0.9000\n",
      "Epoch 781/1499\n",
      "----------\n",
      "train Loss: 0.6494 Acc: 0.9018\n",
      "val Loss: 0.6530 Acc: 0.9040\n",
      "test Loss: 0.6604 Acc: 0.8920\n",
      "Epoch 782/1499\n",
      "----------\n",
      "train Loss: 0.6508 Acc: 0.8976\n",
      "val Loss: 0.6543 Acc: 0.9000\n",
      "test Loss: 0.6564 Acc: 0.9040\n",
      "Epoch 783/1499\n",
      "----------\n",
      "train Loss: 0.6491 Acc: 0.9009\n",
      "val Loss: 0.6584 Acc: 0.8840\n",
      "test Loss: 0.6586 Acc: 0.9040\n",
      "Epoch 784/1499\n",
      "----------\n",
      "train Loss: 0.6497 Acc: 0.9004\n",
      "val Loss: 0.6536 Acc: 0.9000\n",
      "test Loss: 0.6555 Acc: 0.8960\n",
      "Epoch 785/1499\n",
      "----------\n",
      "train Loss: 0.6506 Acc: 0.8993\n",
      "val Loss: 0.6573 Acc: 0.8920\n",
      "test Loss: 0.6574 Acc: 0.9040\n",
      "Epoch 786/1499\n",
      "----------\n",
      "train Loss: 0.6498 Acc: 0.9016\n",
      "val Loss: 0.6584 Acc: 0.8880\n",
      "test Loss: 0.6587 Acc: 0.9000\n",
      "Epoch 787/1499\n",
      "----------\n",
      "train Loss: 0.6497 Acc: 0.9007\n",
      "val Loss: 0.6547 Acc: 0.8920\n",
      "test Loss: 0.6555 Acc: 0.8960\n",
      "Epoch 788/1499\n",
      "----------\n",
      "train Loss: 0.6507 Acc: 0.8984\n",
      "val Loss: 0.6553 Acc: 0.8960\n",
      "test Loss: 0.6569 Acc: 0.9000\n",
      "Epoch 789/1499\n",
      "----------\n",
      "train Loss: 0.6502 Acc: 0.9016\n",
      "val Loss: 0.6582 Acc: 0.8880\n",
      "test Loss: 0.6583 Acc: 0.8960\n",
      "Epoch 790/1499\n",
      "----------\n",
      "train Loss: 0.6499 Acc: 0.9011\n",
      "val Loss: 0.6563 Acc: 0.8920\n",
      "test Loss: 0.6557 Acc: 0.9000\n",
      "Epoch 791/1499\n",
      "----------\n",
      "train Loss: 0.6497 Acc: 0.9000\n",
      "val Loss: 0.6631 Acc: 0.8840\n",
      "test Loss: 0.6545 Acc: 0.9040\n",
      "Epoch 792/1499\n",
      "----------\n",
      "train Loss: 0.6496 Acc: 0.8996\n",
      "val Loss: 0.6559 Acc: 0.9000\n",
      "test Loss: 0.6576 Acc: 0.8960\n",
      "Epoch 793/1499\n",
      "----------\n",
      "train Loss: 0.6502 Acc: 0.8993\n",
      "val Loss: 0.6541 Acc: 0.8960\n",
      "test Loss: 0.6602 Acc: 0.8920\n",
      "Epoch 794/1499\n",
      "----------\n",
      "train Loss: 0.6496 Acc: 0.9000\n",
      "val Loss: 0.6538 Acc: 0.9000\n",
      "test Loss: 0.6605 Acc: 0.8960\n",
      "Epoch 795/1499\n",
      "----------\n",
      "train Loss: 0.6504 Acc: 0.9016\n",
      "val Loss: 0.6564 Acc: 0.8960\n",
      "test Loss: 0.6518 Acc: 0.9040\n",
      "Epoch 796/1499\n",
      "----------\n",
      "train Loss: 0.6490 Acc: 0.9002\n",
      "val Loss: 0.6534 Acc: 0.8960\n",
      "test Loss: 0.6568 Acc: 0.9000\n",
      "Epoch 797/1499\n",
      "----------\n",
      "train Loss: 0.6490 Acc: 0.9027\n",
      "val Loss: 0.6590 Acc: 0.8880\n",
      "test Loss: 0.6573 Acc: 0.9040\n",
      "Epoch 798/1499\n",
      "----------\n",
      "train Loss: 0.6497 Acc: 0.9013\n",
      "val Loss: 0.6510 Acc: 0.9040\n",
      "test Loss: 0.6600 Acc: 0.9000\n",
      "Epoch 799/1499\n",
      "----------\n",
      "train Loss: 0.6497 Acc: 0.9020\n",
      "val Loss: 0.6582 Acc: 0.8920\n",
      "test Loss: 0.6578 Acc: 0.8880\n",
      "Epoch 800/1499\n",
      "----------\n",
      "train Loss: 0.6508 Acc: 0.8980\n",
      "val Loss: 0.6474 Acc: 0.9120\n",
      "test Loss: 0.6577 Acc: 0.9040\n",
      "Epoch 801/1499\n",
      "----------\n",
      "train Loss: 0.6500 Acc: 0.9009\n",
      "val Loss: 0.6540 Acc: 0.8960\n",
      "test Loss: 0.6564 Acc: 0.9000\n",
      "Epoch 802/1499\n",
      "----------\n",
      "train Loss: 0.6486 Acc: 0.9020\n",
      "val Loss: 0.6508 Acc: 0.9000\n",
      "test Loss: 0.6565 Acc: 0.9000\n",
      "Epoch 803/1499\n",
      "----------\n",
      "train Loss: 0.6487 Acc: 0.9007\n",
      "val Loss: 0.6601 Acc: 0.8960\n",
      "test Loss: 0.6583 Acc: 0.8960\n",
      "Epoch 804/1499\n",
      "----------\n",
      "train Loss: 0.6504 Acc: 0.8978\n",
      "val Loss: 0.6541 Acc: 0.8960\n",
      "test Loss: 0.6616 Acc: 0.8920\n",
      "Epoch 805/1499\n",
      "----------\n",
      "train Loss: 0.6495 Acc: 0.9007\n",
      "val Loss: 0.6558 Acc: 0.9040\n",
      "test Loss: 0.6545 Acc: 0.9000\n",
      "Epoch 806/1499\n",
      "----------\n",
      "train Loss: 0.6496 Acc: 0.9016\n",
      "val Loss: 0.6540 Acc: 0.8920\n",
      "test Loss: 0.6526 Acc: 0.9000\n",
      "Epoch 807/1499\n",
      "----------\n",
      "train Loss: 0.6495 Acc: 0.9009\n",
      "val Loss: 0.6535 Acc: 0.8960\n",
      "test Loss: 0.6576 Acc: 0.8960\n",
      "Epoch 808/1499\n",
      "----------\n",
      "train Loss: 0.6489 Acc: 0.9009\n",
      "val Loss: 0.6585 Acc: 0.8880\n",
      "test Loss: 0.6567 Acc: 0.8960\n",
      "Epoch 809/1499\n",
      "----------\n",
      "train Loss: 0.6495 Acc: 0.9009\n",
      "val Loss: 0.6526 Acc: 0.9040\n",
      "test Loss: 0.6528 Acc: 0.9000\n",
      "Epoch 810/1499\n",
      "----------\n",
      "train Loss: 0.6489 Acc: 0.9018\n",
      "val Loss: 0.6543 Acc: 0.9000\n",
      "test Loss: 0.6568 Acc: 0.9040\n",
      "Epoch 811/1499\n",
      "----------\n",
      "train Loss: 0.6502 Acc: 0.9024\n",
      "val Loss: 0.6593 Acc: 0.8960\n",
      "test Loss: 0.6555 Acc: 0.9000\n",
      "Epoch 812/1499\n",
      "----------\n",
      "train Loss: 0.6499 Acc: 0.8982\n",
      "val Loss: 0.6603 Acc: 0.8920\n",
      "test Loss: 0.6572 Acc: 0.9000\n",
      "Epoch 813/1499\n",
      "----------\n",
      "train Loss: 0.6492 Acc: 0.9024\n",
      "val Loss: 0.6519 Acc: 0.9000\n",
      "test Loss: 0.6578 Acc: 0.9000\n",
      "Epoch 814/1499\n",
      "----------\n",
      "train Loss: 0.6486 Acc: 0.9024\n",
      "val Loss: 0.6560 Acc: 0.8960\n",
      "test Loss: 0.6535 Acc: 0.8960\n",
      "Epoch 815/1499\n",
      "----------\n",
      "train Loss: 0.6511 Acc: 0.8962\n",
      "val Loss: 0.6577 Acc: 0.8920\n",
      "test Loss: 0.6549 Acc: 0.9000\n",
      "Epoch 816/1499\n",
      "----------\n",
      "train Loss: 0.6482 Acc: 0.9027\n",
      "val Loss: 0.6583 Acc: 0.8960\n",
      "test Loss: 0.6602 Acc: 0.8960\n",
      "Epoch 817/1499\n",
      "----------\n",
      "train Loss: 0.6491 Acc: 0.9013\n",
      "val Loss: 0.6579 Acc: 0.8920\n",
      "test Loss: 0.6567 Acc: 0.9000\n",
      "Epoch 818/1499\n",
      "----------\n",
      "train Loss: 0.6486 Acc: 0.9038\n",
      "val Loss: 0.6601 Acc: 0.8880\n",
      "test Loss: 0.6564 Acc: 0.9040\n",
      "Epoch 819/1499\n",
      "----------\n",
      "train Loss: 0.6487 Acc: 0.9033\n",
      "val Loss: 0.6623 Acc: 0.8840\n",
      "test Loss: 0.6547 Acc: 0.9000\n",
      "Epoch 820/1499\n",
      "----------\n",
      "train Loss: 0.6504 Acc: 0.8971\n",
      "val Loss: 0.6550 Acc: 0.8920\n",
      "test Loss: 0.6602 Acc: 0.8960\n",
      "Epoch 821/1499\n",
      "----------\n",
      "train Loss: 0.6483 Acc: 0.9009\n",
      "val Loss: 0.6562 Acc: 0.9000\n",
      "test Loss: 0.6576 Acc: 0.8960\n",
      "Epoch 822/1499\n",
      "----------\n",
      "train Loss: 0.6484 Acc: 0.9022\n",
      "val Loss: 0.6575 Acc: 0.9000\n",
      "test Loss: 0.6550 Acc: 0.8960\n",
      "Epoch 823/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6498 Acc: 0.8998\n",
      "val Loss: 0.6555 Acc: 0.8960\n",
      "test Loss: 0.6559 Acc: 0.9000\n",
      "Epoch 824/1499\n",
      "----------\n",
      "train Loss: 0.6481 Acc: 0.9040\n",
      "val Loss: 0.6611 Acc: 0.8880\n",
      "test Loss: 0.6584 Acc: 0.8960\n",
      "Epoch 825/1499\n",
      "----------\n",
      "train Loss: 0.6481 Acc: 0.9024\n",
      "val Loss: 0.6545 Acc: 0.9040\n",
      "test Loss: 0.6599 Acc: 0.8920\n",
      "Epoch 826/1499\n",
      "----------\n",
      "train Loss: 0.6492 Acc: 0.9002\n",
      "val Loss: 0.6599 Acc: 0.8960\n",
      "test Loss: 0.6592 Acc: 0.8880\n",
      "Epoch 827/1499\n",
      "----------\n",
      "train Loss: 0.6486 Acc: 0.9011\n",
      "val Loss: 0.6506 Acc: 0.9000\n",
      "test Loss: 0.6597 Acc: 0.9000\n",
      "Epoch 828/1499\n",
      "----------\n",
      "train Loss: 0.6487 Acc: 0.9040\n",
      "val Loss: 0.6540 Acc: 0.8920\n",
      "test Loss: 0.6551 Acc: 0.9040\n",
      "Epoch 829/1499\n",
      "----------\n",
      "train Loss: 0.6486 Acc: 0.9016\n",
      "val Loss: 0.6578 Acc: 0.8840\n",
      "test Loss: 0.6576 Acc: 0.8960\n",
      "Epoch 830/1499\n",
      "----------\n",
      "train Loss: 0.6481 Acc: 0.9016\n",
      "val Loss: 0.6565 Acc: 0.8880\n",
      "test Loss: 0.6579 Acc: 0.8960\n",
      "Epoch 831/1499\n",
      "----------\n",
      "train Loss: 0.6487 Acc: 0.9024\n",
      "val Loss: 0.6534 Acc: 0.9040\n",
      "test Loss: 0.6582 Acc: 0.8960\n",
      "Epoch 832/1499\n",
      "----------\n",
      "train Loss: 0.6477 Acc: 0.9022\n",
      "val Loss: 0.6576 Acc: 0.8920\n",
      "test Loss: 0.6579 Acc: 0.9000\n",
      "Epoch 833/1499\n",
      "----------\n",
      "train Loss: 0.6481 Acc: 0.9018\n",
      "val Loss: 0.6568 Acc: 0.8880\n",
      "test Loss: 0.6587 Acc: 0.9000\n",
      "Epoch 834/1499\n",
      "----------\n",
      "train Loss: 0.6467 Acc: 0.9038\n",
      "val Loss: 0.6624 Acc: 0.8800\n",
      "test Loss: 0.6571 Acc: 0.9000\n",
      "Epoch 835/1499\n",
      "----------\n",
      "train Loss: 0.6479 Acc: 0.9027\n",
      "val Loss: 0.6570 Acc: 0.9000\n",
      "test Loss: 0.6555 Acc: 0.9000\n",
      "Epoch 836/1499\n",
      "----------\n",
      "train Loss: 0.6477 Acc: 0.9022\n",
      "val Loss: 0.6547 Acc: 0.8960\n",
      "test Loss: 0.6562 Acc: 0.9040\n",
      "Epoch 837/1499\n",
      "----------\n",
      "train Loss: 0.6483 Acc: 0.9018\n",
      "val Loss: 0.6610 Acc: 0.8840\n",
      "test Loss: 0.6559 Acc: 0.9000\n",
      "Epoch 838/1499\n",
      "----------\n",
      "train Loss: 0.6497 Acc: 0.9004\n",
      "val Loss: 0.6560 Acc: 0.8920\n",
      "test Loss: 0.6576 Acc: 0.9000\n",
      "Epoch 839/1499\n",
      "----------\n",
      "train Loss: 0.6488 Acc: 0.9000\n",
      "val Loss: 0.6572 Acc: 0.8880\n",
      "test Loss: 0.6547 Acc: 0.9040\n",
      "Epoch 840/1499\n",
      "----------\n",
      "train Loss: 0.6472 Acc: 0.9044\n",
      "val Loss: 0.6567 Acc: 0.8880\n",
      "test Loss: 0.6573 Acc: 0.8960\n",
      "Epoch 841/1499\n",
      "----------\n",
      "train Loss: 0.6485 Acc: 0.9004\n",
      "val Loss: 0.6507 Acc: 0.9000\n",
      "test Loss: 0.6573 Acc: 0.9000\n",
      "Epoch 842/1499\n",
      "----------\n",
      "train Loss: 0.6479 Acc: 0.9024\n",
      "val Loss: 0.6581 Acc: 0.8920\n",
      "test Loss: 0.6549 Acc: 0.9000\n",
      "Epoch 843/1499\n",
      "----------\n",
      "train Loss: 0.6485 Acc: 0.9022\n",
      "val Loss: 0.6533 Acc: 0.9000\n",
      "test Loss: 0.6546 Acc: 0.9000\n",
      "Epoch 844/1499\n",
      "----------\n",
      "train Loss: 0.6490 Acc: 0.9002\n",
      "val Loss: 0.6545 Acc: 0.9000\n",
      "test Loss: 0.6590 Acc: 0.9000\n",
      "Epoch 845/1499\n",
      "----------\n",
      "train Loss: 0.6474 Acc: 0.9044\n",
      "val Loss: 0.6556 Acc: 0.8920\n",
      "test Loss: 0.6570 Acc: 0.9000\n",
      "Epoch 846/1499\n",
      "----------\n",
      "train Loss: 0.6481 Acc: 0.9044\n",
      "val Loss: 0.6541 Acc: 0.8960\n",
      "test Loss: 0.6547 Acc: 0.9000\n",
      "Epoch 847/1499\n",
      "----------\n",
      "train Loss: 0.6478 Acc: 0.9024\n",
      "val Loss: 0.6576 Acc: 0.8920\n",
      "test Loss: 0.6540 Acc: 0.9040\n",
      "Epoch 848/1499\n",
      "----------\n",
      "train Loss: 0.6468 Acc: 0.9036\n",
      "val Loss: 0.6571 Acc: 0.8880\n",
      "test Loss: 0.6577 Acc: 0.9000\n",
      "Epoch 849/1499\n",
      "----------\n",
      "train Loss: 0.6479 Acc: 0.9027\n",
      "val Loss: 0.6513 Acc: 0.9000\n",
      "test Loss: 0.6526 Acc: 0.9040\n",
      "Epoch 850/1499\n",
      "----------\n",
      "train Loss: 0.6472 Acc: 0.9020\n",
      "val Loss: 0.6579 Acc: 0.8920\n",
      "test Loss: 0.6577 Acc: 0.9000\n",
      "Epoch 851/1499\n",
      "----------\n",
      "train Loss: 0.6477 Acc: 0.9029\n",
      "val Loss: 0.6506 Acc: 0.8920\n",
      "test Loss: 0.6582 Acc: 0.9000\n",
      "Epoch 852/1499\n",
      "----------\n",
      "train Loss: 0.6482 Acc: 0.9022\n",
      "val Loss: 0.6510 Acc: 0.8960\n",
      "test Loss: 0.6571 Acc: 0.8920\n",
      "Epoch 853/1499\n",
      "----------\n",
      "train Loss: 0.6494 Acc: 0.9004\n",
      "val Loss: 0.6535 Acc: 0.9000\n",
      "test Loss: 0.6544 Acc: 0.9000\n",
      "Epoch 854/1499\n",
      "----------\n",
      "train Loss: 0.6482 Acc: 0.9022\n",
      "val Loss: 0.6539 Acc: 0.8920\n",
      "test Loss: 0.6576 Acc: 0.9000\n",
      "Epoch 855/1499\n",
      "----------\n",
      "train Loss: 0.6467 Acc: 0.9029\n",
      "val Loss: 0.6552 Acc: 0.8960\n",
      "test Loss: 0.6557 Acc: 0.9040\n",
      "Epoch 856/1499\n",
      "----------\n",
      "train Loss: 0.6473 Acc: 0.9029\n",
      "val Loss: 0.6568 Acc: 0.8880\n",
      "test Loss: 0.6580 Acc: 0.8920\n",
      "Epoch 857/1499\n",
      "----------\n",
      "train Loss: 0.6466 Acc: 0.9044\n",
      "val Loss: 0.6573 Acc: 0.9000\n",
      "test Loss: 0.6554 Acc: 0.9000\n",
      "Epoch 858/1499\n",
      "----------\n",
      "train Loss: 0.6479 Acc: 0.9031\n",
      "val Loss: 0.6509 Acc: 0.9000\n",
      "test Loss: 0.6562 Acc: 0.9000\n",
      "Epoch 859/1499\n",
      "----------\n",
      "train Loss: 0.6485 Acc: 0.9020\n",
      "val Loss: 0.6539 Acc: 0.8920\n",
      "test Loss: 0.6568 Acc: 0.9000\n",
      "Epoch 860/1499\n",
      "----------\n",
      "train Loss: 0.6477 Acc: 0.9022\n",
      "val Loss: 0.6499 Acc: 0.9040\n",
      "test Loss: 0.6542 Acc: 0.9000\n",
      "Epoch 861/1499\n",
      "----------\n",
      "train Loss: 0.6478 Acc: 0.9024\n",
      "val Loss: 0.6545 Acc: 0.8960\n",
      "test Loss: 0.6572 Acc: 0.9000\n",
      "Epoch 862/1499\n",
      "----------\n",
      "train Loss: 0.6481 Acc: 0.9033\n",
      "val Loss: 0.6502 Acc: 0.9000\n",
      "test Loss: 0.6559 Acc: 0.8920\n",
      "Epoch 863/1499\n",
      "----------\n",
      "train Loss: 0.6477 Acc: 0.9024\n",
      "val Loss: 0.6467 Acc: 0.9080\n",
      "test Loss: 0.6543 Acc: 0.9000\n",
      "Epoch 864/1499\n",
      "----------\n",
      "train Loss: 0.6484 Acc: 0.9024\n",
      "val Loss: 0.6534 Acc: 0.9040\n",
      "test Loss: 0.6532 Acc: 0.9040\n",
      "Epoch 865/1499\n",
      "----------\n",
      "train Loss: 0.6472 Acc: 0.9018\n",
      "val Loss: 0.6550 Acc: 0.8960\n",
      "test Loss: 0.6553 Acc: 0.9000\n",
      "Epoch 866/1499\n",
      "----------\n",
      "train Loss: 0.6478 Acc: 0.9022\n",
      "val Loss: 0.6551 Acc: 0.8840\n",
      "test Loss: 0.6551 Acc: 0.9000\n",
      "Epoch 867/1499\n",
      "----------\n",
      "train Loss: 0.6471 Acc: 0.9007\n",
      "val Loss: 0.6544 Acc: 0.9000\n",
      "test Loss: 0.6566 Acc: 0.8960\n",
      "Epoch 868/1499\n",
      "----------\n",
      "train Loss: 0.6472 Acc: 0.9002\n",
      "val Loss: 0.6557 Acc: 0.8920\n",
      "test Loss: 0.6539 Acc: 0.9000\n",
      "Epoch 869/1499\n",
      "----------\n",
      "train Loss: 0.6475 Acc: 0.9022\n",
      "val Loss: 0.6546 Acc: 0.8880\n",
      "test Loss: 0.6559 Acc: 0.9000\n",
      "Epoch 870/1499\n",
      "----------\n",
      "train Loss: 0.6479 Acc: 0.9013\n",
      "val Loss: 0.6539 Acc: 0.9000\n",
      "test Loss: 0.6569 Acc: 0.9000\n",
      "Epoch 871/1499\n",
      "----------\n",
      "train Loss: 0.6488 Acc: 0.9013\n",
      "val Loss: 0.6605 Acc: 0.8920\n",
      "test Loss: 0.6532 Acc: 0.9000\n",
      "Epoch 872/1499\n",
      "----------\n",
      "train Loss: 0.6470 Acc: 0.9036\n",
      "val Loss: 0.6559 Acc: 0.9000\n",
      "test Loss: 0.6555 Acc: 0.8920\n",
      "Epoch 873/1499\n",
      "----------\n",
      "train Loss: 0.6469 Acc: 0.9058\n",
      "val Loss: 0.6523 Acc: 0.9000\n",
      "test Loss: 0.6579 Acc: 0.9000\n",
      "Epoch 874/1499\n",
      "----------\n",
      "train Loss: 0.6471 Acc: 0.9016\n",
      "val Loss: 0.6544 Acc: 0.8920\n",
      "test Loss: 0.6551 Acc: 0.9000\n",
      "Epoch 875/1499\n",
      "----------\n",
      "train Loss: 0.6474 Acc: 0.9018\n",
      "val Loss: 0.6549 Acc: 0.8920\n",
      "test Loss: 0.6553 Acc: 0.8960\n",
      "Epoch 876/1499\n",
      "----------\n",
      "train Loss: 0.6461 Acc: 0.9064\n",
      "val Loss: 0.6527 Acc: 0.9040\n",
      "test Loss: 0.6535 Acc: 0.9000\n",
      "Epoch 877/1499\n",
      "----------\n",
      "train Loss: 0.6474 Acc: 0.9031\n",
      "val Loss: 0.6541 Acc: 0.9000\n",
      "test Loss: 0.6580 Acc: 0.8960\n",
      "Epoch 878/1499\n",
      "----------\n",
      "train Loss: 0.6472 Acc: 0.9018\n",
      "val Loss: 0.6488 Acc: 0.9040\n",
      "test Loss: 0.6566 Acc: 0.8960\n",
      "Epoch 879/1499\n",
      "----------\n",
      "train Loss: 0.6482 Acc: 0.9020\n",
      "val Loss: 0.6540 Acc: 0.9000\n",
      "test Loss: 0.6543 Acc: 0.8960\n",
      "Epoch 880/1499\n",
      "----------\n",
      "train Loss: 0.6477 Acc: 0.9000\n",
      "val Loss: 0.6517 Acc: 0.9080\n",
      "test Loss: 0.6552 Acc: 0.9000\n",
      "Epoch 881/1499\n",
      "----------\n",
      "train Loss: 0.6468 Acc: 0.9040\n",
      "val Loss: 0.6568 Acc: 0.8920\n",
      "test Loss: 0.6577 Acc: 0.9040\n",
      "Epoch 882/1499\n",
      "----------\n",
      "train Loss: 0.6463 Acc: 0.9036\n",
      "val Loss: 0.6534 Acc: 0.9000\n",
      "test Loss: 0.6521 Acc: 0.9040\n",
      "Epoch 883/1499\n",
      "----------\n",
      "train Loss: 0.6465 Acc: 0.9038\n",
      "val Loss: 0.6548 Acc: 0.9000\n",
      "test Loss: 0.6550 Acc: 0.8920\n",
      "Epoch 884/1499\n",
      "----------\n",
      "train Loss: 0.6467 Acc: 0.9044\n",
      "val Loss: 0.6528 Acc: 0.9080\n",
      "test Loss: 0.6554 Acc: 0.9000\n",
      "Epoch 885/1499\n",
      "----------\n",
      "train Loss: 0.6475 Acc: 0.9040\n",
      "val Loss: 0.6519 Acc: 0.8920\n",
      "test Loss: 0.6518 Acc: 0.9040\n",
      "Epoch 886/1499\n",
      "----------\n",
      "train Loss: 0.6464 Acc: 0.9040\n",
      "val Loss: 0.6542 Acc: 0.8880\n",
      "test Loss: 0.6567 Acc: 0.8960\n",
      "Epoch 887/1499\n",
      "----------\n",
      "train Loss: 0.6466 Acc: 0.9040\n",
      "val Loss: 0.6541 Acc: 0.8920\n",
      "test Loss: 0.6556 Acc: 0.9000\n",
      "Epoch 888/1499\n",
      "----------\n",
      "train Loss: 0.6468 Acc: 0.9051\n",
      "val Loss: 0.6543 Acc: 0.8960\n",
      "test Loss: 0.6534 Acc: 0.9040\n",
      "Epoch 889/1499\n",
      "----------\n",
      "train Loss: 0.6471 Acc: 0.9033\n",
      "val Loss: 0.6531 Acc: 0.8960\n",
      "test Loss: 0.6560 Acc: 0.9000\n",
      "Epoch 890/1499\n",
      "----------\n",
      "train Loss: 0.6467 Acc: 0.9049\n",
      "val Loss: 0.6558 Acc: 0.9000\n",
      "test Loss: 0.6557 Acc: 0.9000\n",
      "Epoch 891/1499\n",
      "----------\n",
      "train Loss: 0.6464 Acc: 0.9038\n",
      "val Loss: 0.6523 Acc: 0.8960\n",
      "test Loss: 0.6532 Acc: 0.9000\n",
      "Epoch 892/1499\n",
      "----------\n",
      "train Loss: 0.6468 Acc: 0.9040\n",
      "val Loss: 0.6488 Acc: 0.9040\n",
      "test Loss: 0.6518 Acc: 0.9040\n",
      "Epoch 893/1499\n",
      "----------\n",
      "train Loss: 0.6467 Acc: 0.9029\n",
      "val Loss: 0.6585 Acc: 0.8880\n",
      "test Loss: 0.6613 Acc: 0.8840\n",
      "Epoch 894/1499\n",
      "----------\n",
      "train Loss: 0.6466 Acc: 0.9036\n",
      "val Loss: 0.6525 Acc: 0.8960\n",
      "test Loss: 0.6556 Acc: 0.8960\n",
      "Epoch 895/1499\n",
      "----------\n",
      "train Loss: 0.6470 Acc: 0.9007\n",
      "val Loss: 0.6554 Acc: 0.9000\n",
      "test Loss: 0.6590 Acc: 0.8920\n",
      "Epoch 896/1499\n",
      "----------\n",
      "train Loss: 0.6464 Acc: 0.9042\n",
      "val Loss: 0.6533 Acc: 0.9000\n",
      "test Loss: 0.6529 Acc: 0.9000\n",
      "Epoch 897/1499\n",
      "----------\n",
      "train Loss: 0.6451 Acc: 0.9062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.6535 Acc: 0.8960\n",
      "test Loss: 0.6521 Acc: 0.9040\n",
      "Epoch 898/1499\n",
      "----------\n",
      "train Loss: 0.6475 Acc: 0.9040\n",
      "val Loss: 0.6554 Acc: 0.8920\n",
      "test Loss: 0.6593 Acc: 0.9000\n",
      "Epoch 899/1499\n",
      "----------\n",
      "train Loss: 0.6474 Acc: 0.9009\n",
      "val Loss: 0.6556 Acc: 0.8880\n",
      "test Loss: 0.6508 Acc: 0.9040\n",
      "Epoch 900/1499\n",
      "----------\n",
      "train Loss: 0.6467 Acc: 0.9042\n",
      "val Loss: 0.6520 Acc: 0.9000\n",
      "test Loss: 0.6533 Acc: 0.9000\n",
      "Epoch 901/1499\n",
      "----------\n",
      "train Loss: 0.6456 Acc: 0.9049\n",
      "val Loss: 0.6555 Acc: 0.9000\n",
      "test Loss: 0.6537 Acc: 0.8960\n",
      "Epoch 902/1499\n",
      "----------\n",
      "train Loss: 0.6458 Acc: 0.9040\n",
      "val Loss: 0.6572 Acc: 0.9000\n",
      "test Loss: 0.6543 Acc: 0.9040\n",
      "Epoch 903/1499\n",
      "----------\n",
      "train Loss: 0.6450 Acc: 0.9067\n",
      "val Loss: 0.6532 Acc: 0.8960\n",
      "test Loss: 0.6569 Acc: 0.8960\n",
      "Epoch 904/1499\n",
      "----------\n",
      "train Loss: 0.6464 Acc: 0.9018\n",
      "val Loss: 0.6537 Acc: 0.8880\n",
      "test Loss: 0.6550 Acc: 0.9000\n",
      "Epoch 905/1499\n",
      "----------\n",
      "train Loss: 0.6465 Acc: 0.9029\n",
      "val Loss: 0.6539 Acc: 0.8960\n",
      "test Loss: 0.6599 Acc: 0.8880\n",
      "Epoch 906/1499\n",
      "----------\n",
      "train Loss: 0.6453 Acc: 0.9049\n",
      "val Loss: 0.6507 Acc: 0.9000\n",
      "test Loss: 0.6576 Acc: 0.9000\n",
      "Epoch 907/1499\n",
      "----------\n",
      "train Loss: 0.6457 Acc: 0.9053\n",
      "val Loss: 0.6506 Acc: 0.9040\n",
      "test Loss: 0.6523 Acc: 0.9040\n",
      "Epoch 908/1499\n",
      "----------\n",
      "train Loss: 0.6459 Acc: 0.9029\n",
      "val Loss: 0.6529 Acc: 0.9000\n",
      "test Loss: 0.6511 Acc: 0.9000\n",
      "Epoch 909/1499\n",
      "----------\n",
      "train Loss: 0.6447 Acc: 0.9071\n",
      "val Loss: 0.6549 Acc: 0.8920\n",
      "test Loss: 0.6530 Acc: 0.9000\n",
      "Epoch 910/1499\n",
      "----------\n",
      "train Loss: 0.6463 Acc: 0.9044\n",
      "val Loss: 0.6509 Acc: 0.8960\n",
      "test Loss: 0.6588 Acc: 0.8920\n",
      "Epoch 911/1499\n",
      "----------\n",
      "train Loss: 0.6465 Acc: 0.9047\n",
      "val Loss: 0.6518 Acc: 0.8960\n",
      "test Loss: 0.6548 Acc: 0.9000\n",
      "Epoch 912/1499\n",
      "----------\n",
      "train Loss: 0.6461 Acc: 0.9069\n",
      "val Loss: 0.6507 Acc: 0.9000\n",
      "test Loss: 0.6563 Acc: 0.8960\n",
      "Epoch 913/1499\n",
      "----------\n",
      "train Loss: 0.6468 Acc: 0.9042\n",
      "val Loss: 0.6519 Acc: 0.8960\n",
      "test Loss: 0.6558 Acc: 0.9000\n",
      "Epoch 914/1499\n",
      "----------\n",
      "train Loss: 0.6464 Acc: 0.9024\n",
      "val Loss: 0.6566 Acc: 0.9000\n",
      "test Loss: 0.6558 Acc: 0.8960\n",
      "Epoch 915/1499\n",
      "----------\n",
      "train Loss: 0.6459 Acc: 0.9051\n",
      "val Loss: 0.6529 Acc: 0.8920\n",
      "test Loss: 0.6496 Acc: 0.9000\n",
      "Epoch 916/1499\n",
      "----------\n",
      "train Loss: 0.6457 Acc: 0.9042\n",
      "val Loss: 0.6499 Acc: 0.9000\n",
      "test Loss: 0.6543 Acc: 0.9000\n",
      "Epoch 917/1499\n",
      "----------\n",
      "train Loss: 0.6453 Acc: 0.9082\n",
      "val Loss: 0.6541 Acc: 0.8960\n",
      "test Loss: 0.6541 Acc: 0.9000\n",
      "Epoch 918/1499\n",
      "----------\n",
      "train Loss: 0.6457 Acc: 0.9056\n",
      "val Loss: 0.6529 Acc: 0.8960\n",
      "test Loss: 0.6560 Acc: 0.9000\n",
      "Epoch 919/1499\n",
      "----------\n",
      "train Loss: 0.6464 Acc: 0.9036\n",
      "val Loss: 0.6537 Acc: 0.9000\n",
      "test Loss: 0.6565 Acc: 0.9040\n",
      "Epoch 920/1499\n",
      "----------\n",
      "train Loss: 0.6459 Acc: 0.9062\n",
      "val Loss: 0.6523 Acc: 0.8960\n",
      "test Loss: 0.6526 Acc: 0.9040\n",
      "Epoch 921/1499\n",
      "----------\n",
      "train Loss: 0.6450 Acc: 0.9073\n",
      "val Loss: 0.6537 Acc: 0.8880\n",
      "test Loss: 0.6574 Acc: 0.8960\n",
      "Epoch 922/1499\n",
      "----------\n",
      "train Loss: 0.6467 Acc: 0.9040\n",
      "val Loss: 0.6519 Acc: 0.9000\n",
      "test Loss: 0.6529 Acc: 0.9000\n",
      "Epoch 923/1499\n",
      "----------\n",
      "train Loss: 0.6456 Acc: 0.9056\n",
      "val Loss: 0.6461 Acc: 0.9080\n",
      "test Loss: 0.6541 Acc: 0.8960\n",
      "Epoch 924/1499\n",
      "----------\n",
      "train Loss: 0.6460 Acc: 0.9049\n",
      "val Loss: 0.6553 Acc: 0.8960\n",
      "test Loss: 0.6520 Acc: 0.9000\n",
      "Epoch 925/1499\n",
      "----------\n",
      "train Loss: 0.6449 Acc: 0.9049\n",
      "val Loss: 0.6540 Acc: 0.9000\n",
      "test Loss: 0.6533 Acc: 0.9040\n",
      "Epoch 926/1499\n",
      "----------\n",
      "train Loss: 0.6457 Acc: 0.9056\n",
      "val Loss: 0.6518 Acc: 0.9000\n",
      "test Loss: 0.6556 Acc: 0.8960\n",
      "Epoch 927/1499\n",
      "----------\n",
      "train Loss: 0.6449 Acc: 0.9082\n",
      "val Loss: 0.6507 Acc: 0.9000\n",
      "test Loss: 0.6586 Acc: 0.8920\n",
      "Epoch 928/1499\n",
      "----------\n",
      "train Loss: 0.6451 Acc: 0.9044\n",
      "val Loss: 0.6504 Acc: 0.9040\n",
      "test Loss: 0.6571 Acc: 0.8960\n",
      "Epoch 929/1499\n",
      "----------\n",
      "train Loss: 0.6447 Acc: 0.9056\n",
      "val Loss: 0.6491 Acc: 0.8920\n",
      "test Loss: 0.6568 Acc: 0.8920\n",
      "Epoch 930/1499\n",
      "----------\n",
      "train Loss: 0.6449 Acc: 0.9062\n",
      "val Loss: 0.6559 Acc: 0.8880\n",
      "test Loss: 0.6545 Acc: 0.9000\n",
      "Epoch 931/1499\n",
      "----------\n",
      "train Loss: 0.6453 Acc: 0.9060\n",
      "val Loss: 0.6534 Acc: 0.9040\n",
      "test Loss: 0.6559 Acc: 0.8960\n",
      "Epoch 932/1499\n",
      "----------\n",
      "train Loss: 0.6474 Acc: 0.9013\n",
      "val Loss: 0.6499 Acc: 0.9000\n",
      "test Loss: 0.6517 Acc: 0.9000\n",
      "Epoch 933/1499\n",
      "----------\n",
      "train Loss: 0.6461 Acc: 0.9053\n",
      "val Loss: 0.6549 Acc: 0.8960\n",
      "test Loss: 0.6515 Acc: 0.9000\n",
      "Epoch 934/1499\n",
      "----------\n",
      "train Loss: 0.6451 Acc: 0.9058\n",
      "val Loss: 0.6517 Acc: 0.9040\n",
      "test Loss: 0.6540 Acc: 0.9040\n",
      "Epoch 935/1499\n",
      "----------\n",
      "train Loss: 0.6445 Acc: 0.9071\n",
      "val Loss: 0.6540 Acc: 0.8920\n",
      "test Loss: 0.6540 Acc: 0.9000\n",
      "Epoch 936/1499\n",
      "----------\n",
      "train Loss: 0.6463 Acc: 0.9058\n",
      "val Loss: 0.6505 Acc: 0.8960\n",
      "test Loss: 0.6522 Acc: 0.9080\n",
      "Epoch 937/1499\n",
      "----------\n",
      "train Loss: 0.6433 Acc: 0.9084\n",
      "val Loss: 0.6501 Acc: 0.9040\n",
      "test Loss: 0.6562 Acc: 0.9000\n",
      "Epoch 938/1499\n",
      "----------\n",
      "train Loss: 0.6458 Acc: 0.9042\n",
      "val Loss: 0.6519 Acc: 0.9000\n",
      "test Loss: 0.6602 Acc: 0.8960\n",
      "Epoch 939/1499\n",
      "----------\n",
      "train Loss: 0.6454 Acc: 0.9044\n",
      "val Loss: 0.6548 Acc: 0.8920\n",
      "test Loss: 0.6552 Acc: 0.9000\n",
      "Epoch 940/1499\n",
      "----------\n",
      "train Loss: 0.6450 Acc: 0.9042\n",
      "val Loss: 0.6523 Acc: 0.8840\n",
      "test Loss: 0.6524 Acc: 0.8960\n",
      "Epoch 941/1499\n",
      "----------\n",
      "train Loss: 0.6454 Acc: 0.9056\n",
      "val Loss: 0.6524 Acc: 0.8920\n",
      "test Loss: 0.6511 Acc: 0.9000\n",
      "Epoch 942/1499\n",
      "----------\n",
      "train Loss: 0.6435 Acc: 0.9073\n",
      "val Loss: 0.6507 Acc: 0.9000\n",
      "test Loss: 0.6518 Acc: 0.9000\n",
      "Epoch 943/1499\n",
      "----------\n",
      "train Loss: 0.6453 Acc: 0.9062\n",
      "val Loss: 0.6531 Acc: 0.8880\n",
      "test Loss: 0.6532 Acc: 0.9000\n",
      "Epoch 944/1499\n",
      "----------\n",
      "train Loss: 0.6443 Acc: 0.9056\n",
      "val Loss: 0.6509 Acc: 0.8960\n",
      "test Loss: 0.6574 Acc: 0.8960\n",
      "Epoch 945/1499\n",
      "----------\n",
      "train Loss: 0.6461 Acc: 0.9022\n",
      "val Loss: 0.6543 Acc: 0.8920\n",
      "test Loss: 0.6538 Acc: 0.8960\n",
      "Epoch 946/1499\n",
      "----------\n",
      "train Loss: 0.6443 Acc: 0.9084\n",
      "val Loss: 0.6531 Acc: 0.8920\n",
      "test Loss: 0.6562 Acc: 0.8920\n",
      "Epoch 947/1499\n",
      "----------\n",
      "train Loss: 0.6444 Acc: 0.9067\n",
      "val Loss: 0.6490 Acc: 0.9000\n",
      "test Loss: 0.6538 Acc: 0.8960\n",
      "Epoch 948/1499\n",
      "----------\n",
      "train Loss: 0.6454 Acc: 0.9071\n",
      "val Loss: 0.6506 Acc: 0.8880\n",
      "test Loss: 0.6546 Acc: 0.8960\n",
      "Epoch 949/1499\n",
      "----------\n",
      "train Loss: 0.6452 Acc: 0.9047\n",
      "val Loss: 0.6550 Acc: 0.8920\n",
      "test Loss: 0.6537 Acc: 0.8920\n",
      "Epoch 950/1499\n",
      "----------\n",
      "train Loss: 0.6445 Acc: 0.9049\n",
      "val Loss: 0.6473 Acc: 0.8960\n",
      "test Loss: 0.6542 Acc: 0.9040\n",
      "Epoch 951/1499\n",
      "----------\n",
      "train Loss: 0.6447 Acc: 0.9058\n",
      "val Loss: 0.6506 Acc: 0.9040\n",
      "test Loss: 0.6573 Acc: 0.9000\n",
      "Epoch 952/1499\n",
      "----------\n",
      "train Loss: 0.6455 Acc: 0.9047\n",
      "val Loss: 0.6514 Acc: 0.9040\n",
      "test Loss: 0.6529 Acc: 0.9040\n",
      "Epoch 953/1499\n",
      "----------\n",
      "train Loss: 0.6464 Acc: 0.9027\n",
      "val Loss: 0.6517 Acc: 0.8960\n",
      "test Loss: 0.6569 Acc: 0.8920\n",
      "Epoch 954/1499\n",
      "----------\n",
      "train Loss: 0.6453 Acc: 0.9049\n",
      "val Loss: 0.6535 Acc: 0.9000\n",
      "test Loss: 0.6565 Acc: 0.8960\n",
      "Epoch 955/1499\n",
      "----------\n",
      "train Loss: 0.6433 Acc: 0.9078\n",
      "val Loss: 0.6490 Acc: 0.8960\n",
      "test Loss: 0.6544 Acc: 0.8960\n",
      "Epoch 956/1499\n",
      "----------\n",
      "train Loss: 0.6439 Acc: 0.9073\n",
      "val Loss: 0.6517 Acc: 0.9000\n",
      "test Loss: 0.6540 Acc: 0.9000\n",
      "Epoch 957/1499\n",
      "----------\n",
      "train Loss: 0.6444 Acc: 0.9062\n",
      "val Loss: 0.6499 Acc: 0.9000\n",
      "test Loss: 0.6535 Acc: 0.9000\n",
      "Epoch 958/1499\n",
      "----------\n",
      "train Loss: 0.6451 Acc: 0.9051\n",
      "val Loss: 0.6527 Acc: 0.9000\n",
      "test Loss: 0.6516 Acc: 0.9040\n",
      "Epoch 959/1499\n",
      "----------\n",
      "train Loss: 0.6456 Acc: 0.9033\n",
      "val Loss: 0.6515 Acc: 0.9000\n",
      "test Loss: 0.6502 Acc: 0.9080\n",
      "Epoch 960/1499\n",
      "----------\n",
      "train Loss: 0.6447 Acc: 0.9062\n",
      "val Loss: 0.6495 Acc: 0.9120\n",
      "test Loss: 0.6515 Acc: 0.9000\n",
      "Epoch 961/1499\n",
      "----------\n",
      "train Loss: 0.6440 Acc: 0.9058\n",
      "val Loss: 0.6518 Acc: 0.8960\n",
      "test Loss: 0.6545 Acc: 0.8960\n",
      "Epoch 962/1499\n",
      "----------\n",
      "train Loss: 0.6446 Acc: 0.9062\n",
      "val Loss: 0.6493 Acc: 0.9040\n",
      "test Loss: 0.6512 Acc: 0.9040\n",
      "Epoch 963/1499\n",
      "----------\n",
      "train Loss: 0.6452 Acc: 0.9067\n",
      "val Loss: 0.6537 Acc: 0.9000\n",
      "test Loss: 0.6574 Acc: 0.8960\n",
      "Epoch 964/1499\n",
      "----------\n",
      "train Loss: 0.6442 Acc: 0.9067\n",
      "val Loss: 0.6517 Acc: 0.9000\n",
      "test Loss: 0.6523 Acc: 0.8960\n",
      "Epoch 965/1499\n",
      "----------\n",
      "train Loss: 0.6447 Acc: 0.9038\n",
      "val Loss: 0.6514 Acc: 0.9000\n",
      "test Loss: 0.6520 Acc: 0.9000\n",
      "Epoch 966/1499\n",
      "----------\n",
      "train Loss: 0.6448 Acc: 0.9047\n",
      "val Loss: 0.6530 Acc: 0.8920\n",
      "test Loss: 0.6569 Acc: 0.9000\n",
      "Epoch 967/1499\n",
      "----------\n",
      "train Loss: 0.6438 Acc: 0.9076\n",
      "val Loss: 0.6479 Acc: 0.9040\n",
      "test Loss: 0.6552 Acc: 0.9000\n",
      "Epoch 968/1499\n",
      "----------\n",
      "train Loss: 0.6450 Acc: 0.9060\n",
      "val Loss: 0.6530 Acc: 0.8920\n",
      "test Loss: 0.6514 Acc: 0.9000\n",
      "Epoch 969/1499\n",
      "----------\n",
      "train Loss: 0.6442 Acc: 0.9082\n",
      "val Loss: 0.6479 Acc: 0.9080\n",
      "test Loss: 0.6532 Acc: 0.9000\n",
      "Epoch 970/1499\n",
      "----------\n",
      "train Loss: 0.6437 Acc: 0.9084\n",
      "val Loss: 0.6489 Acc: 0.9000\n",
      "test Loss: 0.6524 Acc: 0.9000\n",
      "Epoch 971/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6448 Acc: 0.9062\n",
      "val Loss: 0.6501 Acc: 0.9080\n",
      "test Loss: 0.6531 Acc: 0.9000\n",
      "Epoch 972/1499\n",
      "----------\n",
      "train Loss: 0.6449 Acc: 0.9040\n",
      "val Loss: 0.6517 Acc: 0.8960\n",
      "test Loss: 0.6529 Acc: 0.9000\n",
      "Epoch 973/1499\n",
      "----------\n",
      "train Loss: 0.6440 Acc: 0.9042\n",
      "val Loss: 0.6468 Acc: 0.9080\n",
      "test Loss: 0.6551 Acc: 0.8960\n",
      "Epoch 974/1499\n",
      "----------\n",
      "train Loss: 0.6443 Acc: 0.9029\n",
      "val Loss: 0.6505 Acc: 0.8960\n",
      "test Loss: 0.6548 Acc: 0.8960\n",
      "Epoch 975/1499\n",
      "----------\n",
      "train Loss: 0.6439 Acc: 0.9071\n",
      "val Loss: 0.6468 Acc: 0.9000\n",
      "test Loss: 0.6492 Acc: 0.9040\n",
      "Epoch 976/1499\n",
      "----------\n",
      "train Loss: 0.6436 Acc: 0.9058\n",
      "val Loss: 0.6511 Acc: 0.8920\n",
      "test Loss: 0.6540 Acc: 0.9000\n",
      "Epoch 977/1499\n",
      "----------\n",
      "train Loss: 0.6448 Acc: 0.9042\n",
      "val Loss: 0.6496 Acc: 0.9000\n",
      "test Loss: 0.6520 Acc: 0.9040\n",
      "Epoch 978/1499\n",
      "----------\n",
      "train Loss: 0.6447 Acc: 0.9060\n",
      "val Loss: 0.6480 Acc: 0.9000\n",
      "test Loss: 0.6502 Acc: 0.9040\n",
      "Epoch 979/1499\n",
      "----------\n",
      "train Loss: 0.6437 Acc: 0.9058\n",
      "val Loss: 0.6521 Acc: 0.9000\n",
      "test Loss: 0.6517 Acc: 0.9040\n",
      "Epoch 980/1499\n",
      "----------\n",
      "train Loss: 0.6435 Acc: 0.9067\n",
      "val Loss: 0.6494 Acc: 0.9000\n",
      "test Loss: 0.6542 Acc: 0.9000\n",
      "Epoch 981/1499\n",
      "----------\n",
      "train Loss: 0.6437 Acc: 0.9078\n",
      "val Loss: 0.6516 Acc: 0.8960\n",
      "test Loss: 0.6578 Acc: 0.9000\n",
      "Epoch 982/1499\n",
      "----------\n",
      "train Loss: 0.6452 Acc: 0.9033\n",
      "val Loss: 0.6485 Acc: 0.9000\n",
      "test Loss: 0.6564 Acc: 0.8960\n",
      "Epoch 983/1499\n",
      "----------\n",
      "train Loss: 0.6440 Acc: 0.9069\n",
      "val Loss: 0.6498 Acc: 0.9000\n",
      "test Loss: 0.6500 Acc: 0.9000\n",
      "Epoch 984/1499\n",
      "----------\n",
      "train Loss: 0.6431 Acc: 0.9067\n",
      "val Loss: 0.6496 Acc: 0.9040\n",
      "test Loss: 0.6584 Acc: 0.8960\n",
      "Epoch 985/1499\n",
      "----------\n",
      "train Loss: 0.6447 Acc: 0.9031\n",
      "val Loss: 0.6498 Acc: 0.9000\n",
      "test Loss: 0.6564 Acc: 0.9040\n",
      "Epoch 986/1499\n",
      "----------\n",
      "train Loss: 0.6442 Acc: 0.9053\n",
      "val Loss: 0.6489 Acc: 0.9040\n",
      "test Loss: 0.6516 Acc: 0.9000\n",
      "Epoch 987/1499\n",
      "----------\n",
      "train Loss: 0.6437 Acc: 0.9053\n",
      "val Loss: 0.6505 Acc: 0.9040\n",
      "test Loss: 0.6543 Acc: 0.8960\n",
      "Epoch 988/1499\n",
      "----------\n",
      "train Loss: 0.6437 Acc: 0.9044\n",
      "val Loss: 0.6522 Acc: 0.9000\n",
      "test Loss: 0.6506 Acc: 0.9000\n",
      "Epoch 989/1499\n",
      "----------\n",
      "train Loss: 0.6434 Acc: 0.9069\n",
      "val Loss: 0.6512 Acc: 0.9040\n",
      "test Loss: 0.6542 Acc: 0.9040\n",
      "Epoch 990/1499\n",
      "----------\n",
      "train Loss: 0.6438 Acc: 0.9042\n",
      "val Loss: 0.6492 Acc: 0.9040\n",
      "test Loss: 0.6551 Acc: 0.9000\n",
      "Epoch 991/1499\n",
      "----------\n",
      "train Loss: 0.6437 Acc: 0.9040\n",
      "val Loss: 0.6512 Acc: 0.9040\n",
      "test Loss: 0.6530 Acc: 0.9000\n",
      "Epoch 992/1499\n",
      "----------\n",
      "train Loss: 0.6442 Acc: 0.9076\n",
      "val Loss: 0.6498 Acc: 0.9040\n",
      "test Loss: 0.6539 Acc: 0.9000\n",
      "Epoch 993/1499\n",
      "----------\n",
      "train Loss: 0.6426 Acc: 0.9067\n",
      "val Loss: 0.6488 Acc: 0.9040\n",
      "test Loss: 0.6520 Acc: 0.9000\n",
      "Epoch 994/1499\n",
      "----------\n",
      "train Loss: 0.6439 Acc: 0.9058\n",
      "val Loss: 0.6513 Acc: 0.9000\n",
      "test Loss: 0.6510 Acc: 0.9000\n",
      "Epoch 995/1499\n",
      "----------\n",
      "train Loss: 0.6443 Acc: 0.9064\n",
      "val Loss: 0.6481 Acc: 0.9040\n",
      "test Loss: 0.6566 Acc: 0.9000\n",
      "Epoch 996/1499\n",
      "----------\n",
      "train Loss: 0.6431 Acc: 0.9087\n",
      "val Loss: 0.6492 Acc: 0.9000\n",
      "test Loss: 0.6525 Acc: 0.9040\n",
      "Epoch 997/1499\n",
      "----------\n",
      "train Loss: 0.6435 Acc: 0.9071\n",
      "val Loss: 0.6464 Acc: 0.9120\n",
      "test Loss: 0.6497 Acc: 0.9080\n",
      "Epoch 998/1499\n",
      "----------\n",
      "train Loss: 0.6419 Acc: 0.9082\n",
      "val Loss: 0.6451 Acc: 0.9040\n",
      "test Loss: 0.6533 Acc: 0.8920\n",
      "Epoch 999/1499\n",
      "----------\n",
      "train Loss: 0.6435 Acc: 0.9069\n",
      "val Loss: 0.6502 Acc: 0.9080\n",
      "test Loss: 0.6528 Acc: 0.9000\n",
      "Epoch 1000/1499\n",
      "----------\n",
      "train Loss: 0.6436 Acc: 0.9073\n",
      "val Loss: 0.6504 Acc: 0.8960\n",
      "test Loss: 0.6537 Acc: 0.9000\n",
      "Epoch 1001/1499\n",
      "----------\n",
      "train Loss: 0.6436 Acc: 0.9062\n",
      "val Loss: 0.6463 Acc: 0.9040\n",
      "test Loss: 0.6516 Acc: 0.9000\n",
      "Epoch 1002/1499\n",
      "----------\n",
      "train Loss: 0.6430 Acc: 0.9093\n",
      "val Loss: 0.6463 Acc: 0.9040\n",
      "test Loss: 0.6594 Acc: 0.8960\n",
      "Epoch 1003/1499\n",
      "----------\n",
      "train Loss: 0.6441 Acc: 0.9062\n",
      "val Loss: 0.6448 Acc: 0.9040\n",
      "test Loss: 0.6538 Acc: 0.9040\n",
      "Epoch 1004/1499\n",
      "----------\n",
      "train Loss: 0.6432 Acc: 0.9071\n",
      "val Loss: 0.6474 Acc: 0.9000\n",
      "test Loss: 0.6530 Acc: 0.9000\n",
      "Epoch 1005/1499\n",
      "----------\n",
      "train Loss: 0.6429 Acc: 0.9093\n",
      "val Loss: 0.6514 Acc: 0.8960\n",
      "test Loss: 0.6553 Acc: 0.8960\n",
      "Epoch 1006/1499\n",
      "----------\n",
      "train Loss: 0.6432 Acc: 0.9076\n",
      "val Loss: 0.6506 Acc: 0.9000\n",
      "test Loss: 0.6521 Acc: 0.9000\n",
      "Epoch 1007/1499\n",
      "----------\n",
      "train Loss: 0.6440 Acc: 0.9058\n",
      "val Loss: 0.6486 Acc: 0.9000\n",
      "test Loss: 0.6575 Acc: 0.8920\n",
      "Epoch 1008/1499\n",
      "----------\n",
      "train Loss: 0.6427 Acc: 0.9089\n",
      "val Loss: 0.6499 Acc: 0.9040\n",
      "test Loss: 0.6553 Acc: 0.9000\n",
      "Epoch 1009/1499\n",
      "----------\n",
      "train Loss: 0.6429 Acc: 0.9076\n",
      "val Loss: 0.6510 Acc: 0.9000\n",
      "test Loss: 0.6537 Acc: 0.8960\n",
      "Epoch 1010/1499\n",
      "----------\n",
      "train Loss: 0.6435 Acc: 0.9062\n",
      "val Loss: 0.6485 Acc: 0.9000\n",
      "test Loss: 0.6524 Acc: 0.9040\n",
      "Epoch 1011/1499\n",
      "----------\n",
      "train Loss: 0.6434 Acc: 0.9053\n",
      "val Loss: 0.6515 Acc: 0.8960\n",
      "test Loss: 0.6507 Acc: 0.9040\n",
      "Epoch 1012/1499\n",
      "----------\n",
      "train Loss: 0.6419 Acc: 0.9096\n",
      "val Loss: 0.6489 Acc: 0.9040\n",
      "test Loss: 0.6534 Acc: 0.8960\n",
      "Epoch 1013/1499\n",
      "----------\n",
      "train Loss: 0.6434 Acc: 0.9056\n",
      "val Loss: 0.6479 Acc: 0.8960\n",
      "test Loss: 0.6523 Acc: 0.9000\n",
      "Epoch 1014/1499\n",
      "----------\n",
      "train Loss: 0.6431 Acc: 0.9073\n",
      "val Loss: 0.6510 Acc: 0.8920\n",
      "test Loss: 0.6490 Acc: 0.9040\n",
      "Epoch 1015/1499\n",
      "----------\n",
      "train Loss: 0.6421 Acc: 0.9089\n",
      "val Loss: 0.6489 Acc: 0.9040\n",
      "test Loss: 0.6511 Acc: 0.9000\n",
      "Epoch 1016/1499\n",
      "----------\n",
      "train Loss: 0.6415 Acc: 0.9093\n",
      "val Loss: 0.6491 Acc: 0.9000\n",
      "test Loss: 0.6547 Acc: 0.9040\n",
      "Epoch 1017/1499\n",
      "----------\n",
      "train Loss: 0.6433 Acc: 0.9060\n",
      "val Loss: 0.6458 Acc: 0.9040\n",
      "test Loss: 0.6530 Acc: 0.8960\n",
      "Epoch 1018/1499\n",
      "----------\n",
      "train Loss: 0.6423 Acc: 0.9084\n",
      "val Loss: 0.6493 Acc: 0.9000\n",
      "test Loss: 0.6511 Acc: 0.9000\n",
      "Epoch 1019/1499\n",
      "----------\n",
      "train Loss: 0.6433 Acc: 0.9091\n",
      "val Loss: 0.6520 Acc: 0.8920\n",
      "test Loss: 0.6551 Acc: 0.9000\n",
      "Epoch 1020/1499\n",
      "----------\n",
      "train Loss: 0.6431 Acc: 0.9076\n",
      "val Loss: 0.6473 Acc: 0.9000\n",
      "test Loss: 0.6557 Acc: 0.9000\n",
      "Epoch 1021/1499\n",
      "----------\n",
      "train Loss: 0.6425 Acc: 0.9091\n",
      "val Loss: 0.6491 Acc: 0.9000\n",
      "test Loss: 0.6497 Acc: 0.9040\n",
      "Epoch 1022/1499\n",
      "----------\n",
      "train Loss: 0.6428 Acc: 0.9071\n",
      "val Loss: 0.6504 Acc: 0.8920\n",
      "test Loss: 0.6500 Acc: 0.9000\n",
      "Epoch 1023/1499\n",
      "----------\n",
      "train Loss: 0.6428 Acc: 0.9078\n",
      "val Loss: 0.6519 Acc: 0.8960\n",
      "test Loss: 0.6511 Acc: 0.9000\n",
      "Epoch 1024/1499\n",
      "----------\n",
      "train Loss: 0.6442 Acc: 0.9053\n",
      "val Loss: 0.6512 Acc: 0.9000\n",
      "test Loss: 0.6536 Acc: 0.9000\n",
      "Epoch 1025/1499\n",
      "----------\n",
      "train Loss: 0.6430 Acc: 0.9060\n",
      "val Loss: 0.6525 Acc: 0.8960\n",
      "test Loss: 0.6554 Acc: 0.9040\n",
      "Epoch 1026/1499\n",
      "----------\n",
      "train Loss: 0.6433 Acc: 0.9067\n",
      "val Loss: 0.6489 Acc: 0.9000\n",
      "test Loss: 0.6512 Acc: 0.9000\n",
      "Epoch 1027/1499\n",
      "----------\n",
      "train Loss: 0.6426 Acc: 0.9062\n",
      "val Loss: 0.6491 Acc: 0.8960\n",
      "test Loss: 0.6531 Acc: 0.9000\n",
      "Epoch 1028/1499\n",
      "----------\n",
      "train Loss: 0.6431 Acc: 0.9040\n",
      "val Loss: 0.6503 Acc: 0.9080\n",
      "test Loss: 0.6565 Acc: 0.9000\n",
      "Epoch 1029/1499\n",
      "----------\n",
      "train Loss: 0.6427 Acc: 0.9084\n",
      "val Loss: 0.6488 Acc: 0.9000\n",
      "test Loss: 0.6527 Acc: 0.9000\n",
      "Epoch 1030/1499\n",
      "----------\n",
      "train Loss: 0.6427 Acc: 0.9071\n",
      "val Loss: 0.6457 Acc: 0.9000\n",
      "test Loss: 0.6531 Acc: 0.9000\n",
      "Epoch 1031/1499\n",
      "----------\n",
      "train Loss: 0.6423 Acc: 0.9104\n",
      "val Loss: 0.6488 Acc: 0.9040\n",
      "test Loss: 0.6543 Acc: 0.8960\n",
      "Epoch 1032/1499\n",
      "----------\n",
      "train Loss: 0.6432 Acc: 0.9071\n",
      "val Loss: 0.6474 Acc: 0.9160\n",
      "test Loss: 0.6548 Acc: 0.8960\n",
      "Epoch 1033/1499\n",
      "----------\n",
      "train Loss: 0.6425 Acc: 0.9073\n",
      "val Loss: 0.6499 Acc: 0.9080\n",
      "test Loss: 0.6496 Acc: 0.9000\n",
      "Epoch 1034/1499\n",
      "----------\n",
      "train Loss: 0.6424 Acc: 0.9087\n",
      "val Loss: 0.6470 Acc: 0.9080\n",
      "test Loss: 0.6510 Acc: 0.9040\n",
      "Epoch 1035/1499\n",
      "----------\n",
      "train Loss: 0.6418 Acc: 0.9104\n",
      "val Loss: 0.6505 Acc: 0.9040\n",
      "test Loss: 0.6562 Acc: 0.8960\n",
      "Epoch 1036/1499\n",
      "----------\n",
      "train Loss: 0.6437 Acc: 0.9051\n",
      "val Loss: 0.6492 Acc: 0.9000\n",
      "test Loss: 0.6541 Acc: 0.9000\n",
      "Epoch 1037/1499\n",
      "----------\n",
      "train Loss: 0.6432 Acc: 0.9080\n",
      "val Loss: 0.6503 Acc: 0.9000\n",
      "test Loss: 0.6506 Acc: 0.8960\n",
      "Epoch 1038/1499\n",
      "----------\n",
      "train Loss: 0.6429 Acc: 0.9087\n",
      "val Loss: 0.6462 Acc: 0.9080\n",
      "test Loss: 0.6537 Acc: 0.8880\n",
      "Epoch 1039/1499\n",
      "----------\n",
      "train Loss: 0.6441 Acc: 0.9020\n",
      "val Loss: 0.6435 Acc: 0.9080\n",
      "test Loss: 0.6526 Acc: 0.8960\n",
      "Epoch 1040/1499\n",
      "----------\n",
      "train Loss: 0.6431 Acc: 0.9067\n",
      "val Loss: 0.6505 Acc: 0.9000\n",
      "test Loss: 0.6526 Acc: 0.9000\n",
      "Epoch 1041/1499\n",
      "----------\n",
      "train Loss: 0.6429 Acc: 0.9047\n",
      "val Loss: 0.6509 Acc: 0.8960\n",
      "test Loss: 0.6522 Acc: 0.9040\n",
      "Epoch 1042/1499\n",
      "----------\n",
      "train Loss: 0.6423 Acc: 0.9078\n",
      "val Loss: 0.6469 Acc: 0.9040\n",
      "test Loss: 0.6530 Acc: 0.9000\n",
      "Epoch 1043/1499\n",
      "----------\n",
      "train Loss: 0.6419 Acc: 0.9107\n",
      "val Loss: 0.6500 Acc: 0.8920\n",
      "test Loss: 0.6553 Acc: 0.8960\n",
      "Epoch 1044/1499\n",
      "----------\n",
      "train Loss: 0.6431 Acc: 0.9062\n",
      "val Loss: 0.6493 Acc: 0.9080\n",
      "test Loss: 0.6561 Acc: 0.8920\n",
      "Epoch 1045/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6441 Acc: 0.9062\n",
      "val Loss: 0.6461 Acc: 0.9040\n",
      "test Loss: 0.6486 Acc: 0.9040\n",
      "Epoch 1046/1499\n",
      "----------\n",
      "train Loss: 0.6420 Acc: 0.9091\n",
      "val Loss: 0.6473 Acc: 0.9040\n",
      "test Loss: 0.6551 Acc: 0.8920\n",
      "Epoch 1047/1499\n",
      "----------\n",
      "train Loss: 0.6427 Acc: 0.9076\n",
      "val Loss: 0.6501 Acc: 0.9040\n",
      "test Loss: 0.6556 Acc: 0.8960\n",
      "Epoch 1048/1499\n",
      "----------\n",
      "train Loss: 0.6432 Acc: 0.9051\n",
      "val Loss: 0.6418 Acc: 0.9080\n",
      "test Loss: 0.6509 Acc: 0.9000\n",
      "Epoch 1049/1499\n",
      "----------\n",
      "train Loss: 0.6420 Acc: 0.9073\n",
      "val Loss: 0.6455 Acc: 0.9120\n",
      "test Loss: 0.6521 Acc: 0.9040\n",
      "Epoch 1050/1499\n",
      "----------\n",
      "train Loss: 0.6428 Acc: 0.9096\n",
      "val Loss: 0.6485 Acc: 0.9080\n",
      "test Loss: 0.6538 Acc: 0.9000\n",
      "Epoch 1051/1499\n",
      "----------\n",
      "train Loss: 0.6431 Acc: 0.9073\n",
      "val Loss: 0.6460 Acc: 0.9040\n",
      "test Loss: 0.6508 Acc: 0.9000\n",
      "Epoch 1052/1499\n",
      "----------\n",
      "train Loss: 0.6422 Acc: 0.9040\n",
      "val Loss: 0.6517 Acc: 0.8920\n",
      "test Loss: 0.6516 Acc: 0.9000\n",
      "Epoch 1053/1499\n",
      "----------\n",
      "train Loss: 0.6418 Acc: 0.9078\n",
      "val Loss: 0.6441 Acc: 0.9120\n",
      "test Loss: 0.6552 Acc: 0.8960\n",
      "Epoch 1054/1499\n",
      "----------\n",
      "train Loss: 0.6425 Acc: 0.9082\n",
      "val Loss: 0.6485 Acc: 0.9080\n",
      "test Loss: 0.6524 Acc: 0.8960\n",
      "Epoch 1055/1499\n",
      "----------\n",
      "train Loss: 0.6415 Acc: 0.9084\n",
      "val Loss: 0.6459 Acc: 0.9120\n",
      "test Loss: 0.6504 Acc: 0.9040\n",
      "Epoch 1056/1499\n",
      "----------\n",
      "train Loss: 0.6416 Acc: 0.9076\n",
      "val Loss: 0.6458 Acc: 0.9000\n",
      "test Loss: 0.6543 Acc: 0.8960\n",
      "Epoch 1057/1499\n",
      "----------\n",
      "train Loss: 0.6414 Acc: 0.9100\n",
      "val Loss: 0.6502 Acc: 0.9000\n",
      "test Loss: 0.6514 Acc: 0.9000\n",
      "Epoch 1058/1499\n",
      "----------\n",
      "train Loss: 0.6404 Acc: 0.9093\n",
      "val Loss: 0.6469 Acc: 0.9040\n",
      "test Loss: 0.6562 Acc: 0.8960\n",
      "Epoch 1059/1499\n",
      "----------\n",
      "train Loss: 0.6423 Acc: 0.9071\n",
      "val Loss: 0.6533 Acc: 0.8960\n",
      "test Loss: 0.6515 Acc: 0.9000\n",
      "Epoch 1060/1499\n",
      "----------\n",
      "train Loss: 0.6427 Acc: 0.9069\n",
      "val Loss: 0.6480 Acc: 0.9040\n",
      "test Loss: 0.6497 Acc: 0.8960\n",
      "Epoch 1061/1499\n",
      "----------\n",
      "train Loss: 0.6409 Acc: 0.9067\n",
      "val Loss: 0.6474 Acc: 0.9040\n",
      "test Loss: 0.6530 Acc: 0.8960\n",
      "Epoch 1062/1499\n",
      "----------\n",
      "train Loss: 0.6428 Acc: 0.9058\n",
      "val Loss: 0.6516 Acc: 0.8960\n",
      "test Loss: 0.6542 Acc: 0.9000\n",
      "Epoch 1063/1499\n",
      "----------\n",
      "train Loss: 0.6416 Acc: 0.9087\n",
      "val Loss: 0.6519 Acc: 0.8960\n",
      "test Loss: 0.6530 Acc: 0.9000\n",
      "Epoch 1064/1499\n",
      "----------\n",
      "train Loss: 0.6425 Acc: 0.9071\n",
      "val Loss: 0.6481 Acc: 0.9120\n",
      "test Loss: 0.6507 Acc: 0.9040\n",
      "Epoch 1065/1499\n",
      "----------\n",
      "train Loss: 0.6418 Acc: 0.9087\n",
      "val Loss: 0.6502 Acc: 0.9000\n",
      "test Loss: 0.6556 Acc: 0.8960\n",
      "Epoch 1066/1499\n",
      "----------\n",
      "train Loss: 0.6418 Acc: 0.9080\n",
      "val Loss: 0.6484 Acc: 0.9040\n",
      "test Loss: 0.6495 Acc: 0.9080\n",
      "Epoch 1067/1499\n",
      "----------\n",
      "train Loss: 0.6419 Acc: 0.9098\n",
      "val Loss: 0.6461 Acc: 0.9040\n",
      "test Loss: 0.6517 Acc: 0.9000\n",
      "Epoch 1068/1499\n",
      "----------\n",
      "train Loss: 0.6413 Acc: 0.9098\n",
      "val Loss: 0.6515 Acc: 0.9000\n",
      "test Loss: 0.6514 Acc: 0.9000\n",
      "Epoch 1069/1499\n",
      "----------\n",
      "train Loss: 0.6418 Acc: 0.9089\n",
      "val Loss: 0.6543 Acc: 0.8880\n",
      "test Loss: 0.6502 Acc: 0.9040\n",
      "Epoch 1070/1499\n",
      "----------\n",
      "train Loss: 0.6406 Acc: 0.9107\n",
      "val Loss: 0.6476 Acc: 0.9080\n",
      "test Loss: 0.6522 Acc: 0.8960\n",
      "Epoch 1071/1499\n",
      "----------\n",
      "train Loss: 0.6419 Acc: 0.9076\n",
      "val Loss: 0.6482 Acc: 0.9040\n",
      "test Loss: 0.6500 Acc: 0.9000\n",
      "Epoch 1072/1499\n",
      "----------\n",
      "train Loss: 0.6413 Acc: 0.9091\n",
      "val Loss: 0.6471 Acc: 0.8960\n",
      "test Loss: 0.6528 Acc: 0.8960\n",
      "Epoch 1073/1499\n",
      "----------\n",
      "train Loss: 0.6399 Acc: 0.9122\n",
      "val Loss: 0.6485 Acc: 0.8960\n",
      "test Loss: 0.6547 Acc: 0.9000\n",
      "Epoch 1074/1499\n",
      "----------\n",
      "train Loss: 0.6424 Acc: 0.9071\n",
      "val Loss: 0.6475 Acc: 0.9000\n",
      "test Loss: 0.6545 Acc: 0.9000\n",
      "Epoch 1075/1499\n",
      "----------\n",
      "train Loss: 0.6400 Acc: 0.9104\n",
      "val Loss: 0.6469 Acc: 0.9040\n",
      "test Loss: 0.6544 Acc: 0.9000\n",
      "Epoch 1076/1499\n",
      "----------\n",
      "train Loss: 0.6411 Acc: 0.9089\n",
      "val Loss: 0.6446 Acc: 0.9040\n",
      "test Loss: 0.6544 Acc: 0.9000\n",
      "Epoch 1077/1499\n",
      "----------\n",
      "train Loss: 0.6415 Acc: 0.9078\n",
      "val Loss: 0.6427 Acc: 0.9080\n",
      "test Loss: 0.6526 Acc: 0.9000\n",
      "Epoch 1078/1499\n",
      "----------\n",
      "train Loss: 0.6422 Acc: 0.9087\n",
      "val Loss: 0.6505 Acc: 0.9000\n",
      "test Loss: 0.6530 Acc: 0.8960\n",
      "Epoch 1079/1499\n",
      "----------\n",
      "train Loss: 0.6419 Acc: 0.9091\n",
      "val Loss: 0.6514 Acc: 0.9040\n",
      "test Loss: 0.6502 Acc: 0.9000\n",
      "Epoch 1080/1499\n",
      "----------\n",
      "train Loss: 0.6409 Acc: 0.9098\n",
      "val Loss: 0.6463 Acc: 0.9080\n",
      "test Loss: 0.6545 Acc: 0.9000\n",
      "Epoch 1081/1499\n",
      "----------\n",
      "train Loss: 0.6409 Acc: 0.9100\n",
      "val Loss: 0.6447 Acc: 0.9080\n",
      "test Loss: 0.6534 Acc: 0.9000\n",
      "Epoch 1082/1499\n",
      "----------\n",
      "train Loss: 0.6410 Acc: 0.9096\n",
      "val Loss: 0.6465 Acc: 0.9160\n",
      "test Loss: 0.6511 Acc: 0.9000\n",
      "Epoch 1083/1499\n",
      "----------\n",
      "train Loss: 0.6414 Acc: 0.9089\n",
      "val Loss: 0.6459 Acc: 0.9080\n",
      "test Loss: 0.6476 Acc: 0.9040\n",
      "Epoch 1084/1499\n",
      "----------\n",
      "train Loss: 0.6409 Acc: 0.9091\n",
      "val Loss: 0.6537 Acc: 0.8960\n",
      "test Loss: 0.6521 Acc: 0.9000\n",
      "Epoch 1085/1499\n",
      "----------\n",
      "train Loss: 0.6411 Acc: 0.9087\n",
      "val Loss: 0.6501 Acc: 0.9000\n",
      "test Loss: 0.6501 Acc: 0.8960\n",
      "Epoch 1086/1499\n",
      "----------\n",
      "train Loss: 0.6407 Acc: 0.9104\n",
      "val Loss: 0.6508 Acc: 0.9000\n",
      "test Loss: 0.6500 Acc: 0.9000\n",
      "Epoch 1087/1499\n",
      "----------\n",
      "train Loss: 0.6413 Acc: 0.9100\n",
      "val Loss: 0.6445 Acc: 0.9120\n",
      "test Loss: 0.6521 Acc: 0.8960\n",
      "Epoch 1088/1499\n",
      "----------\n",
      "train Loss: 0.6429 Acc: 0.9069\n",
      "val Loss: 0.6443 Acc: 0.9040\n",
      "test Loss: 0.6535 Acc: 0.9000\n",
      "Epoch 1089/1499\n",
      "----------\n",
      "train Loss: 0.6418 Acc: 0.9082\n",
      "val Loss: 0.6489 Acc: 0.8960\n",
      "test Loss: 0.6508 Acc: 0.9040\n",
      "Epoch 1090/1499\n",
      "----------\n",
      "train Loss: 0.6420 Acc: 0.9073\n",
      "val Loss: 0.6482 Acc: 0.9120\n",
      "test Loss: 0.6493 Acc: 0.9040\n",
      "Epoch 1091/1499\n",
      "----------\n",
      "train Loss: 0.6414 Acc: 0.9098\n",
      "val Loss: 0.6508 Acc: 0.9040\n",
      "test Loss: 0.6534 Acc: 0.9000\n",
      "Epoch 1092/1499\n",
      "----------\n",
      "train Loss: 0.6424 Acc: 0.9082\n",
      "val Loss: 0.6466 Acc: 0.9040\n",
      "test Loss: 0.6540 Acc: 0.8960\n",
      "Epoch 1093/1499\n",
      "----------\n",
      "train Loss: 0.6413 Acc: 0.9073\n",
      "val Loss: 0.6504 Acc: 0.9040\n",
      "test Loss: 0.6527 Acc: 0.9000\n",
      "Epoch 1094/1499\n",
      "----------\n",
      "train Loss: 0.6405 Acc: 0.9089\n",
      "val Loss: 0.6473 Acc: 0.9000\n",
      "test Loss: 0.6492 Acc: 0.8960\n",
      "Epoch 1095/1499\n",
      "----------\n",
      "train Loss: 0.6411 Acc: 0.9073\n",
      "val Loss: 0.6526 Acc: 0.9000\n",
      "test Loss: 0.6518 Acc: 0.9000\n",
      "Epoch 1096/1499\n",
      "----------\n",
      "train Loss: 0.6400 Acc: 0.9104\n",
      "val Loss: 0.6463 Acc: 0.9080\n",
      "test Loss: 0.6501 Acc: 0.8960\n",
      "Epoch 1097/1499\n",
      "----------\n",
      "train Loss: 0.6399 Acc: 0.9109\n",
      "val Loss: 0.6508 Acc: 0.9000\n",
      "test Loss: 0.6529 Acc: 0.8960\n",
      "Epoch 1098/1499\n",
      "----------\n",
      "train Loss: 0.6407 Acc: 0.9089\n",
      "val Loss: 0.6467 Acc: 0.8960\n",
      "test Loss: 0.6516 Acc: 0.9000\n",
      "Epoch 1099/1499\n",
      "----------\n",
      "train Loss: 0.6410 Acc: 0.9080\n",
      "val Loss: 0.6438 Acc: 0.9080\n",
      "test Loss: 0.6518 Acc: 0.9000\n",
      "Epoch 1100/1499\n",
      "----------\n",
      "train Loss: 0.6406 Acc: 0.9118\n",
      "val Loss: 0.6480 Acc: 0.9040\n",
      "test Loss: 0.6532 Acc: 0.8960\n",
      "Epoch 1101/1499\n",
      "----------\n",
      "train Loss: 0.6403 Acc: 0.9078\n",
      "val Loss: 0.6531 Acc: 0.8920\n",
      "test Loss: 0.6517 Acc: 0.9000\n",
      "Epoch 1102/1499\n",
      "----------\n",
      "train Loss: 0.6405 Acc: 0.9069\n",
      "val Loss: 0.6486 Acc: 0.9000\n",
      "test Loss: 0.6528 Acc: 0.8960\n",
      "Epoch 1103/1499\n",
      "----------\n",
      "train Loss: 0.6413 Acc: 0.9091\n",
      "val Loss: 0.6468 Acc: 0.9000\n",
      "test Loss: 0.6530 Acc: 0.9000\n",
      "Epoch 1104/1499\n",
      "----------\n",
      "train Loss: 0.6407 Acc: 0.9067\n",
      "val Loss: 0.6451 Acc: 0.9000\n",
      "test Loss: 0.6511 Acc: 0.9000\n",
      "Epoch 1105/1499\n",
      "----------\n",
      "train Loss: 0.6406 Acc: 0.9096\n",
      "val Loss: 0.6441 Acc: 0.9120\n",
      "test Loss: 0.6539 Acc: 0.8960\n",
      "Epoch 1106/1499\n",
      "----------\n",
      "train Loss: 0.6406 Acc: 0.9102\n",
      "val Loss: 0.6474 Acc: 0.9080\n",
      "test Loss: 0.6529 Acc: 0.9000\n",
      "Epoch 1107/1499\n",
      "----------\n",
      "train Loss: 0.6411 Acc: 0.9089\n",
      "val Loss: 0.6472 Acc: 0.9040\n",
      "test Loss: 0.6545 Acc: 0.8960\n",
      "Epoch 1108/1499\n",
      "----------\n",
      "train Loss: 0.6416 Acc: 0.9069\n",
      "val Loss: 0.6467 Acc: 0.9000\n",
      "test Loss: 0.6493 Acc: 0.9000\n",
      "Epoch 1109/1499\n",
      "----------\n",
      "train Loss: 0.6410 Acc: 0.9084\n",
      "val Loss: 0.6455 Acc: 0.9080\n",
      "test Loss: 0.6537 Acc: 0.9040\n",
      "Epoch 1110/1499\n",
      "----------\n",
      "train Loss: 0.6409 Acc: 0.9073\n",
      "val Loss: 0.6504 Acc: 0.8960\n",
      "test Loss: 0.6474 Acc: 0.9000\n",
      "Epoch 1111/1499\n",
      "----------\n",
      "train Loss: 0.6406 Acc: 0.9069\n",
      "val Loss: 0.6446 Acc: 0.9000\n",
      "test Loss: 0.6496 Acc: 0.9000\n",
      "Epoch 1112/1499\n",
      "----------\n",
      "train Loss: 0.6412 Acc: 0.9062\n",
      "val Loss: 0.6415 Acc: 0.9080\n",
      "test Loss: 0.6532 Acc: 0.8960\n",
      "Epoch 1113/1499\n",
      "----------\n",
      "train Loss: 0.6403 Acc: 0.9118\n",
      "val Loss: 0.6502 Acc: 0.9080\n",
      "test Loss: 0.6520 Acc: 0.9040\n",
      "Epoch 1114/1499\n",
      "----------\n",
      "train Loss: 0.6407 Acc: 0.9091\n",
      "val Loss: 0.6486 Acc: 0.9000\n",
      "test Loss: 0.6477 Acc: 0.9000\n",
      "Epoch 1115/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6414 Acc: 0.9084\n",
      "val Loss: 0.6451 Acc: 0.9040\n",
      "test Loss: 0.6507 Acc: 0.9000\n",
      "Epoch 1116/1499\n",
      "----------\n",
      "train Loss: 0.6417 Acc: 0.9071\n",
      "val Loss: 0.6479 Acc: 0.9120\n",
      "test Loss: 0.6517 Acc: 0.8960\n",
      "Epoch 1117/1499\n",
      "----------\n",
      "train Loss: 0.6400 Acc: 0.9084\n",
      "val Loss: 0.6518 Acc: 0.8960\n",
      "test Loss: 0.6535 Acc: 0.9000\n",
      "Epoch 1118/1499\n",
      "----------\n",
      "train Loss: 0.6415 Acc: 0.9093\n",
      "val Loss: 0.6470 Acc: 0.9000\n",
      "test Loss: 0.6486 Acc: 0.9040\n",
      "Epoch 1119/1499\n",
      "----------\n",
      "train Loss: 0.6395 Acc: 0.9104\n",
      "val Loss: 0.6479 Acc: 0.9040\n",
      "test Loss: 0.6507 Acc: 0.9040\n",
      "Epoch 1120/1499\n",
      "----------\n",
      "train Loss: 0.6416 Acc: 0.9084\n",
      "val Loss: 0.6455 Acc: 0.9040\n",
      "test Loss: 0.6508 Acc: 0.9040\n",
      "Epoch 1121/1499\n",
      "----------\n",
      "train Loss: 0.6400 Acc: 0.9091\n",
      "val Loss: 0.6499 Acc: 0.9040\n",
      "test Loss: 0.6489 Acc: 0.9040\n",
      "Epoch 1122/1499\n",
      "----------\n",
      "train Loss: 0.6407 Acc: 0.9082\n",
      "val Loss: 0.6465 Acc: 0.9040\n",
      "test Loss: 0.6517 Acc: 0.9000\n",
      "Epoch 1123/1499\n",
      "----------\n",
      "train Loss: 0.6404 Acc: 0.9102\n",
      "val Loss: 0.6467 Acc: 0.9000\n",
      "test Loss: 0.6503 Acc: 0.9040\n",
      "Epoch 1124/1499\n",
      "----------\n",
      "train Loss: 0.6400 Acc: 0.9113\n",
      "val Loss: 0.6492 Acc: 0.9080\n",
      "test Loss: 0.6533 Acc: 0.9040\n",
      "Epoch 1125/1499\n",
      "----------\n",
      "train Loss: 0.6394 Acc: 0.9091\n",
      "val Loss: 0.6470 Acc: 0.9080\n",
      "test Loss: 0.6501 Acc: 0.9040\n",
      "Epoch 1126/1499\n",
      "----------\n",
      "train Loss: 0.6397 Acc: 0.9098\n",
      "val Loss: 0.6520 Acc: 0.9040\n",
      "test Loss: 0.6530 Acc: 0.8960\n",
      "Epoch 1127/1499\n",
      "----------\n",
      "train Loss: 0.6400 Acc: 0.9109\n",
      "val Loss: 0.6481 Acc: 0.9080\n",
      "test Loss: 0.6525 Acc: 0.9000\n",
      "Epoch 1128/1499\n",
      "----------\n",
      "train Loss: 0.6404 Acc: 0.9102\n",
      "val Loss: 0.6465 Acc: 0.9040\n",
      "test Loss: 0.6501 Acc: 0.9040\n",
      "Epoch 1129/1499\n",
      "----------\n",
      "train Loss: 0.6391 Acc: 0.9087\n",
      "val Loss: 0.6449 Acc: 0.9080\n",
      "test Loss: 0.6553 Acc: 0.9000\n",
      "Epoch 1130/1499\n",
      "----------\n",
      "train Loss: 0.6404 Acc: 0.9087\n",
      "val Loss: 0.6485 Acc: 0.9040\n",
      "test Loss: 0.6507 Acc: 0.9000\n",
      "Epoch 1131/1499\n",
      "----------\n",
      "train Loss: 0.6406 Acc: 0.9091\n",
      "val Loss: 0.6465 Acc: 0.9120\n",
      "test Loss: 0.6508 Acc: 0.9000\n",
      "Epoch 1132/1499\n",
      "----------\n",
      "train Loss: 0.6405 Acc: 0.9107\n",
      "val Loss: 0.6460 Acc: 0.9000\n",
      "test Loss: 0.6514 Acc: 0.9000\n",
      "Epoch 1133/1499\n",
      "----------\n",
      "train Loss: 0.6404 Acc: 0.9096\n",
      "val Loss: 0.6485 Acc: 0.9040\n",
      "test Loss: 0.6503 Acc: 0.8960\n",
      "Epoch 1134/1499\n",
      "----------\n",
      "train Loss: 0.6394 Acc: 0.9113\n",
      "val Loss: 0.6462 Acc: 0.9000\n",
      "test Loss: 0.6515 Acc: 0.9000\n",
      "Epoch 1135/1499\n",
      "----------\n",
      "train Loss: 0.6405 Acc: 0.9093\n",
      "val Loss: 0.6440 Acc: 0.9080\n",
      "test Loss: 0.6551 Acc: 0.8920\n",
      "Epoch 1136/1499\n",
      "----------\n",
      "train Loss: 0.6398 Acc: 0.9096\n",
      "val Loss: 0.6534 Acc: 0.8920\n",
      "test Loss: 0.6517 Acc: 0.9000\n",
      "Epoch 1137/1499\n",
      "----------\n",
      "train Loss: 0.6389 Acc: 0.9109\n",
      "val Loss: 0.6483 Acc: 0.9000\n",
      "test Loss: 0.6497 Acc: 0.9040\n",
      "Epoch 1138/1499\n",
      "----------\n",
      "train Loss: 0.6398 Acc: 0.9089\n",
      "val Loss: 0.6508 Acc: 0.9000\n",
      "test Loss: 0.6548 Acc: 0.8960\n",
      "Epoch 1139/1499\n",
      "----------\n",
      "train Loss: 0.6405 Acc: 0.9098\n",
      "val Loss: 0.6452 Acc: 0.9040\n",
      "test Loss: 0.6469 Acc: 0.9040\n",
      "Epoch 1140/1499\n",
      "----------\n",
      "train Loss: 0.6399 Acc: 0.9109\n",
      "val Loss: 0.6468 Acc: 0.9120\n",
      "test Loss: 0.6524 Acc: 0.9000\n",
      "Epoch 1141/1499\n",
      "----------\n",
      "train Loss: 0.6399 Acc: 0.9096\n",
      "val Loss: 0.6505 Acc: 0.9040\n",
      "test Loss: 0.6521 Acc: 0.9040\n",
      "Epoch 1142/1499\n",
      "----------\n",
      "train Loss: 0.6391 Acc: 0.9104\n",
      "val Loss: 0.6485 Acc: 0.9040\n",
      "test Loss: 0.6526 Acc: 0.8920\n",
      "Epoch 1143/1499\n",
      "----------\n",
      "train Loss: 0.6403 Acc: 0.9091\n",
      "val Loss: 0.6449 Acc: 0.9080\n",
      "test Loss: 0.6562 Acc: 0.8960\n",
      "Epoch 1144/1499\n",
      "----------\n",
      "train Loss: 0.6403 Acc: 0.9078\n",
      "val Loss: 0.6473 Acc: 0.9120\n",
      "test Loss: 0.6476 Acc: 0.9040\n",
      "Epoch 1145/1499\n",
      "----------\n",
      "train Loss: 0.6391 Acc: 0.9100\n",
      "val Loss: 0.6425 Acc: 0.9120\n",
      "test Loss: 0.6500 Acc: 0.9000\n",
      "Epoch 1146/1499\n",
      "----------\n",
      "train Loss: 0.6395 Acc: 0.9089\n",
      "val Loss: 0.6433 Acc: 0.9040\n",
      "test Loss: 0.6538 Acc: 0.9000\n",
      "Epoch 1147/1499\n",
      "----------\n",
      "train Loss: 0.6398 Acc: 0.9120\n",
      "val Loss: 0.6502 Acc: 0.8960\n",
      "test Loss: 0.6480 Acc: 0.9000\n",
      "Epoch 1148/1499\n",
      "----------\n",
      "train Loss: 0.6401 Acc: 0.9102\n",
      "val Loss: 0.6464 Acc: 0.9040\n",
      "test Loss: 0.6503 Acc: 0.9000\n",
      "Epoch 1149/1499\n",
      "----------\n",
      "train Loss: 0.6397 Acc: 0.9096\n",
      "val Loss: 0.6459 Acc: 0.9040\n",
      "test Loss: 0.6528 Acc: 0.9040\n",
      "Epoch 1150/1499\n",
      "----------\n",
      "train Loss: 0.6403 Acc: 0.9091\n",
      "val Loss: 0.6478 Acc: 0.8960\n",
      "test Loss: 0.6494 Acc: 0.9040\n",
      "Epoch 1151/1499\n",
      "----------\n",
      "train Loss: 0.6398 Acc: 0.9084\n",
      "val Loss: 0.6513 Acc: 0.8960\n",
      "test Loss: 0.6500 Acc: 0.9000\n",
      "Epoch 1152/1499\n",
      "----------\n",
      "train Loss: 0.6404 Acc: 0.9084\n",
      "val Loss: 0.6437 Acc: 0.9080\n",
      "test Loss: 0.6516 Acc: 0.9000\n",
      "Epoch 1153/1499\n",
      "----------\n",
      "train Loss: 0.6402 Acc: 0.9091\n",
      "val Loss: 0.6464 Acc: 0.9040\n",
      "test Loss: 0.6533 Acc: 0.8920\n",
      "Epoch 1154/1499\n",
      "----------\n",
      "train Loss: 0.6393 Acc: 0.9116\n",
      "val Loss: 0.6499 Acc: 0.8960\n",
      "test Loss: 0.6554 Acc: 0.8920\n",
      "Epoch 1155/1499\n",
      "----------\n",
      "train Loss: 0.6399 Acc: 0.9107\n",
      "val Loss: 0.6526 Acc: 0.9000\n",
      "test Loss: 0.6530 Acc: 0.9000\n",
      "Epoch 1156/1499\n",
      "----------\n",
      "train Loss: 0.6408 Acc: 0.9084\n",
      "val Loss: 0.6494 Acc: 0.8960\n",
      "test Loss: 0.6531 Acc: 0.9040\n",
      "Epoch 1157/1499\n",
      "----------\n",
      "train Loss: 0.6395 Acc: 0.9107\n",
      "val Loss: 0.6430 Acc: 0.9040\n",
      "test Loss: 0.6464 Acc: 0.9040\n",
      "Epoch 1158/1499\n",
      "----------\n",
      "train Loss: 0.6402 Acc: 0.9102\n",
      "val Loss: 0.6466 Acc: 0.9040\n",
      "test Loss: 0.6516 Acc: 0.8920\n",
      "Epoch 1159/1499\n",
      "----------\n",
      "train Loss: 0.6387 Acc: 0.9098\n",
      "val Loss: 0.6441 Acc: 0.9080\n",
      "test Loss: 0.6516 Acc: 0.9000\n",
      "Epoch 1160/1499\n",
      "----------\n",
      "train Loss: 0.6403 Acc: 0.9104\n",
      "val Loss: 0.6501 Acc: 0.9040\n",
      "test Loss: 0.6525 Acc: 0.9000\n",
      "Epoch 1161/1499\n",
      "----------\n",
      "train Loss: 0.6389 Acc: 0.9100\n",
      "val Loss: 0.6452 Acc: 0.9000\n",
      "test Loss: 0.6524 Acc: 0.9000\n",
      "Epoch 1162/1499\n",
      "----------\n",
      "train Loss: 0.6399 Acc: 0.9073\n",
      "val Loss: 0.6436 Acc: 0.9120\n",
      "test Loss: 0.6499 Acc: 0.9000\n",
      "Epoch 1163/1499\n",
      "----------\n",
      "train Loss: 0.6394 Acc: 0.9096\n",
      "val Loss: 0.6466 Acc: 0.9080\n",
      "test Loss: 0.6483 Acc: 0.9040\n",
      "Epoch 1164/1499\n",
      "----------\n",
      "train Loss: 0.6397 Acc: 0.9091\n",
      "val Loss: 0.6485 Acc: 0.9040\n",
      "test Loss: 0.6549 Acc: 0.8960\n",
      "Epoch 1165/1499\n",
      "----------\n",
      "train Loss: 0.6386 Acc: 0.9113\n",
      "val Loss: 0.6507 Acc: 0.9000\n",
      "test Loss: 0.6522 Acc: 0.8960\n",
      "Epoch 1166/1499\n",
      "----------\n",
      "train Loss: 0.6404 Acc: 0.9096\n",
      "val Loss: 0.6443 Acc: 0.9040\n",
      "test Loss: 0.6519 Acc: 0.9000\n",
      "Epoch 1167/1499\n",
      "----------\n",
      "train Loss: 0.6392 Acc: 0.9107\n",
      "val Loss: 0.6504 Acc: 0.8920\n",
      "test Loss: 0.6542 Acc: 0.8920\n",
      "Epoch 1168/1499\n",
      "----------\n",
      "train Loss: 0.6397 Acc: 0.9104\n",
      "val Loss: 0.6439 Acc: 0.9080\n",
      "test Loss: 0.6492 Acc: 0.9000\n",
      "Epoch 1169/1499\n",
      "----------\n",
      "train Loss: 0.6397 Acc: 0.9091\n",
      "val Loss: 0.6487 Acc: 0.8960\n",
      "test Loss: 0.6527 Acc: 0.8960\n",
      "Epoch 1170/1499\n",
      "----------\n",
      "train Loss: 0.6401 Acc: 0.9071\n",
      "val Loss: 0.6488 Acc: 0.9000\n",
      "test Loss: 0.6477 Acc: 0.9000\n",
      "Epoch 1171/1499\n",
      "----------\n",
      "train Loss: 0.6393 Acc: 0.9091\n",
      "val Loss: 0.6447 Acc: 0.9080\n",
      "test Loss: 0.6486 Acc: 0.9000\n",
      "Epoch 1172/1499\n",
      "----------\n",
      "train Loss: 0.6397 Acc: 0.9093\n",
      "val Loss: 0.6465 Acc: 0.9040\n",
      "test Loss: 0.6544 Acc: 0.8960\n",
      "Epoch 1173/1499\n",
      "----------\n",
      "train Loss: 0.6396 Acc: 0.9089\n",
      "val Loss: 0.6483 Acc: 0.8960\n",
      "test Loss: 0.6488 Acc: 0.9000\n",
      "Epoch 1174/1499\n",
      "----------\n",
      "train Loss: 0.6401 Acc: 0.9082\n",
      "val Loss: 0.6474 Acc: 0.9000\n",
      "test Loss: 0.6476 Acc: 0.9040\n",
      "Epoch 1175/1499\n",
      "----------\n",
      "train Loss: 0.6392 Acc: 0.9091\n",
      "val Loss: 0.6480 Acc: 0.9000\n",
      "test Loss: 0.6532 Acc: 0.8960\n",
      "Epoch 1176/1499\n",
      "----------\n",
      "train Loss: 0.6392 Acc: 0.9120\n",
      "val Loss: 0.6460 Acc: 0.9000\n",
      "test Loss: 0.6506 Acc: 0.9040\n",
      "Epoch 1177/1499\n",
      "----------\n",
      "train Loss: 0.6391 Acc: 0.9089\n",
      "val Loss: 0.6489 Acc: 0.9040\n",
      "test Loss: 0.6505 Acc: 0.9000\n",
      "Epoch 1178/1499\n",
      "----------\n",
      "train Loss: 0.6384 Acc: 0.9098\n",
      "val Loss: 0.6503 Acc: 0.9040\n",
      "test Loss: 0.6492 Acc: 0.9040\n",
      "Epoch 1179/1499\n",
      "----------\n",
      "train Loss: 0.6388 Acc: 0.9102\n",
      "val Loss: 0.6467 Acc: 0.8960\n",
      "test Loss: 0.6523 Acc: 0.9000\n",
      "Epoch 1180/1499\n",
      "----------\n",
      "train Loss: 0.6406 Acc: 0.9089\n",
      "val Loss: 0.6439 Acc: 0.9000\n",
      "test Loss: 0.6524 Acc: 0.8960\n",
      "Epoch 1181/1499\n",
      "----------\n",
      "train Loss: 0.6384 Acc: 0.9118\n",
      "val Loss: 0.6448 Acc: 0.9120\n",
      "test Loss: 0.6535 Acc: 0.8960\n",
      "Epoch 1182/1499\n",
      "----------\n",
      "train Loss: 0.6396 Acc: 0.9100\n",
      "val Loss: 0.6399 Acc: 0.9160\n",
      "test Loss: 0.6515 Acc: 0.8960\n",
      "Epoch 1183/1499\n",
      "----------\n",
      "train Loss: 0.6386 Acc: 0.9100\n",
      "val Loss: 0.6506 Acc: 0.9040\n",
      "test Loss: 0.6492 Acc: 0.9040\n",
      "Epoch 1184/1499\n",
      "----------\n",
      "train Loss: 0.6386 Acc: 0.9116\n",
      "val Loss: 0.6439 Acc: 0.9080\n",
      "test Loss: 0.6516 Acc: 0.9000\n",
      "Epoch 1185/1499\n",
      "----------\n",
      "train Loss: 0.6388 Acc: 0.9113\n",
      "val Loss: 0.6472 Acc: 0.8960\n",
      "test Loss: 0.6505 Acc: 0.9000\n",
      "Epoch 1186/1499\n",
      "----------\n",
      "train Loss: 0.6403 Acc: 0.9084\n",
      "val Loss: 0.6411 Acc: 0.9120\n",
      "test Loss: 0.6481 Acc: 0.9040\n",
      "Epoch 1187/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6402 Acc: 0.9080\n",
      "val Loss: 0.6448 Acc: 0.9040\n",
      "test Loss: 0.6521 Acc: 0.8960\n",
      "Epoch 1188/1499\n",
      "----------\n",
      "train Loss: 0.6388 Acc: 0.9109\n",
      "val Loss: 0.6476 Acc: 0.8960\n",
      "test Loss: 0.6499 Acc: 0.8960\n",
      "Epoch 1189/1499\n",
      "----------\n",
      "train Loss: 0.6387 Acc: 0.9116\n",
      "val Loss: 0.6468 Acc: 0.9040\n",
      "test Loss: 0.6496 Acc: 0.9040\n",
      "Epoch 1190/1499\n",
      "----------\n",
      "train Loss: 0.6379 Acc: 0.9129\n",
      "val Loss: 0.6457 Acc: 0.9040\n",
      "test Loss: 0.6502 Acc: 0.9000\n",
      "Epoch 1191/1499\n",
      "----------\n",
      "train Loss: 0.6396 Acc: 0.9091\n",
      "val Loss: 0.6494 Acc: 0.8960\n",
      "test Loss: 0.6488 Acc: 0.9000\n",
      "Epoch 1192/1499\n",
      "----------\n",
      "train Loss: 0.6387 Acc: 0.9116\n",
      "val Loss: 0.6473 Acc: 0.9000\n",
      "test Loss: 0.6502 Acc: 0.9000\n",
      "Epoch 1193/1499\n",
      "----------\n",
      "train Loss: 0.6383 Acc: 0.9104\n",
      "val Loss: 0.6436 Acc: 0.9080\n",
      "test Loss: 0.6487 Acc: 0.9040\n",
      "Epoch 1194/1499\n",
      "----------\n",
      "train Loss: 0.6399 Acc: 0.9089\n",
      "val Loss: 0.6451 Acc: 0.9040\n",
      "test Loss: 0.6509 Acc: 0.8960\n",
      "Epoch 1195/1499\n",
      "----------\n",
      "train Loss: 0.6385 Acc: 0.9124\n",
      "val Loss: 0.6438 Acc: 0.9040\n",
      "test Loss: 0.6479 Acc: 0.9040\n",
      "Epoch 1196/1499\n",
      "----------\n",
      "train Loss: 0.6397 Acc: 0.9111\n",
      "val Loss: 0.6429 Acc: 0.9160\n",
      "test Loss: 0.6532 Acc: 0.8960\n",
      "Epoch 1197/1499\n",
      "----------\n",
      "train Loss: 0.6394 Acc: 0.9104\n",
      "val Loss: 0.6426 Acc: 0.9000\n",
      "test Loss: 0.6512 Acc: 0.9000\n",
      "Epoch 1198/1499\n",
      "----------\n",
      "train Loss: 0.6385 Acc: 0.9100\n",
      "val Loss: 0.6465 Acc: 0.8960\n",
      "test Loss: 0.6516 Acc: 0.8960\n",
      "Epoch 1199/1499\n",
      "----------\n",
      "train Loss: 0.6389 Acc: 0.9093\n",
      "val Loss: 0.6471 Acc: 0.9040\n",
      "test Loss: 0.6466 Acc: 0.9040\n",
      "Epoch 1200/1499\n",
      "----------\n",
      "train Loss: 0.6394 Acc: 0.9120\n",
      "val Loss: 0.6465 Acc: 0.9040\n",
      "test Loss: 0.6488 Acc: 0.9040\n",
      "Epoch 1201/1499\n",
      "----------\n",
      "train Loss: 0.6393 Acc: 0.9109\n",
      "val Loss: 0.6473 Acc: 0.9040\n",
      "test Loss: 0.6533 Acc: 0.8880\n",
      "Epoch 1202/1499\n",
      "----------\n",
      "train Loss: 0.6386 Acc: 0.9111\n",
      "val Loss: 0.6438 Acc: 0.9000\n",
      "test Loss: 0.6521 Acc: 0.9000\n",
      "Epoch 1203/1499\n",
      "----------\n",
      "train Loss: 0.6391 Acc: 0.9116\n",
      "val Loss: 0.6449 Acc: 0.8960\n",
      "test Loss: 0.6525 Acc: 0.8960\n",
      "Epoch 1204/1499\n",
      "----------\n",
      "train Loss: 0.6395 Acc: 0.9102\n",
      "val Loss: 0.6419 Acc: 0.9080\n",
      "test Loss: 0.6523 Acc: 0.8960\n",
      "Epoch 1205/1499\n",
      "----------\n",
      "train Loss: 0.6391 Acc: 0.9093\n",
      "val Loss: 0.6460 Acc: 0.9040\n",
      "test Loss: 0.6507 Acc: 0.9040\n",
      "Epoch 1206/1499\n",
      "----------\n",
      "train Loss: 0.6381 Acc: 0.9082\n",
      "val Loss: 0.6436 Acc: 0.9040\n",
      "test Loss: 0.6468 Acc: 0.9040\n",
      "Epoch 1207/1499\n",
      "----------\n",
      "train Loss: 0.6382 Acc: 0.9122\n",
      "val Loss: 0.6455 Acc: 0.9040\n",
      "test Loss: 0.6516 Acc: 0.8960\n",
      "Epoch 1208/1499\n",
      "----------\n",
      "train Loss: 0.6379 Acc: 0.9116\n",
      "val Loss: 0.6442 Acc: 0.9040\n",
      "test Loss: 0.6511 Acc: 0.9000\n",
      "Epoch 1209/1499\n",
      "----------\n",
      "train Loss: 0.6386 Acc: 0.9102\n",
      "val Loss: 0.6473 Acc: 0.9040\n",
      "test Loss: 0.6495 Acc: 0.9000\n",
      "Epoch 1210/1499\n",
      "----------\n",
      "train Loss: 0.6384 Acc: 0.9102\n",
      "val Loss: 0.6441 Acc: 0.9040\n",
      "test Loss: 0.6504 Acc: 0.9040\n",
      "Epoch 1211/1499\n",
      "----------\n",
      "train Loss: 0.6398 Acc: 0.9087\n",
      "val Loss: 0.6439 Acc: 0.9120\n",
      "test Loss: 0.6559 Acc: 0.9000\n",
      "Epoch 1212/1499\n",
      "----------\n",
      "train Loss: 0.6385 Acc: 0.9116\n",
      "val Loss: 0.6451 Acc: 0.9040\n",
      "test Loss: 0.6481 Acc: 0.9040\n",
      "Epoch 1213/1499\n",
      "----------\n",
      "train Loss: 0.6385 Acc: 0.9098\n",
      "val Loss: 0.6456 Acc: 0.9040\n",
      "test Loss: 0.6517 Acc: 0.9000\n",
      "Epoch 1214/1499\n",
      "----------\n",
      "train Loss: 0.6393 Acc: 0.9113\n",
      "val Loss: 0.6479 Acc: 0.9040\n",
      "test Loss: 0.6497 Acc: 0.9040\n",
      "Epoch 1215/1499\n",
      "----------\n",
      "train Loss: 0.6381 Acc: 0.9102\n",
      "val Loss: 0.6454 Acc: 0.9000\n",
      "test Loss: 0.6507 Acc: 0.9000\n",
      "Epoch 1216/1499\n",
      "----------\n",
      "train Loss: 0.6386 Acc: 0.9096\n",
      "val Loss: 0.6459 Acc: 0.9040\n",
      "test Loss: 0.6477 Acc: 0.9000\n",
      "Epoch 1217/1499\n",
      "----------\n",
      "train Loss: 0.6388 Acc: 0.9116\n",
      "val Loss: 0.6421 Acc: 0.9120\n",
      "test Loss: 0.6538 Acc: 0.8920\n",
      "Epoch 1218/1499\n",
      "----------\n",
      "train Loss: 0.6381 Acc: 0.9122\n",
      "val Loss: 0.6429 Acc: 0.9120\n",
      "test Loss: 0.6519 Acc: 0.8960\n",
      "Epoch 1219/1499\n",
      "----------\n",
      "train Loss: 0.6385 Acc: 0.9104\n",
      "val Loss: 0.6452 Acc: 0.9040\n",
      "test Loss: 0.6486 Acc: 0.9000\n",
      "Epoch 1220/1499\n",
      "----------\n",
      "train Loss: 0.6385 Acc: 0.9116\n",
      "val Loss: 0.6435 Acc: 0.9200\n",
      "test Loss: 0.6495 Acc: 0.8960\n",
      "Epoch 1221/1499\n",
      "----------\n",
      "train Loss: 0.6378 Acc: 0.9107\n",
      "val Loss: 0.6471 Acc: 0.9000\n",
      "test Loss: 0.6550 Acc: 0.9000\n",
      "Epoch 1222/1499\n",
      "----------\n",
      "train Loss: 0.6381 Acc: 0.9078\n",
      "val Loss: 0.6458 Acc: 0.9080\n",
      "test Loss: 0.6515 Acc: 0.9000\n",
      "Epoch 1223/1499\n",
      "----------\n",
      "train Loss: 0.6391 Acc: 0.9096\n",
      "val Loss: 0.6423 Acc: 0.9080\n",
      "test Loss: 0.6512 Acc: 0.8960\n",
      "Epoch 1224/1499\n",
      "----------\n",
      "train Loss: 0.6385 Acc: 0.9100\n",
      "val Loss: 0.6485 Acc: 0.9000\n",
      "test Loss: 0.6515 Acc: 0.8960\n",
      "Epoch 1225/1499\n",
      "----------\n",
      "train Loss: 0.6384 Acc: 0.9120\n",
      "val Loss: 0.6428 Acc: 0.9040\n",
      "test Loss: 0.6480 Acc: 0.9000\n",
      "Epoch 1226/1499\n",
      "----------\n",
      "train Loss: 0.6382 Acc: 0.9109\n",
      "val Loss: 0.6418 Acc: 0.9040\n",
      "test Loss: 0.6494 Acc: 0.9000\n",
      "Epoch 1227/1499\n",
      "----------\n",
      "train Loss: 0.6389 Acc: 0.9118\n",
      "val Loss: 0.6491 Acc: 0.9000\n",
      "test Loss: 0.6526 Acc: 0.8960\n",
      "Epoch 1228/1499\n",
      "----------\n",
      "train Loss: 0.6385 Acc: 0.9111\n",
      "val Loss: 0.6472 Acc: 0.9080\n",
      "test Loss: 0.6460 Acc: 0.9040\n",
      "Epoch 1229/1499\n",
      "----------\n",
      "train Loss: 0.6378 Acc: 0.9098\n",
      "val Loss: 0.6433 Acc: 0.9080\n",
      "test Loss: 0.6473 Acc: 0.9040\n",
      "Epoch 1230/1499\n",
      "----------\n",
      "train Loss: 0.6371 Acc: 0.9131\n",
      "val Loss: 0.6438 Acc: 0.9120\n",
      "test Loss: 0.6471 Acc: 0.9000\n",
      "Epoch 1231/1499\n",
      "----------\n",
      "train Loss: 0.6388 Acc: 0.9096\n",
      "val Loss: 0.6481 Acc: 0.9120\n",
      "test Loss: 0.6521 Acc: 0.9000\n",
      "Epoch 1232/1499\n",
      "----------\n",
      "train Loss: 0.6380 Acc: 0.9091\n",
      "val Loss: 0.6469 Acc: 0.9000\n",
      "test Loss: 0.6517 Acc: 0.9040\n",
      "Epoch 1233/1499\n",
      "----------\n",
      "train Loss: 0.6378 Acc: 0.9096\n",
      "val Loss: 0.6411 Acc: 0.9120\n",
      "test Loss: 0.6504 Acc: 0.9000\n",
      "Epoch 1234/1499\n",
      "----------\n",
      "train Loss: 0.6378 Acc: 0.9127\n",
      "val Loss: 0.6414 Acc: 0.9040\n",
      "test Loss: 0.6525 Acc: 0.8960\n",
      "Epoch 1235/1499\n",
      "----------\n",
      "train Loss: 0.6386 Acc: 0.9093\n",
      "val Loss: 0.6434 Acc: 0.9080\n",
      "test Loss: 0.6518 Acc: 0.9000\n",
      "Epoch 1236/1499\n",
      "----------\n",
      "train Loss: 0.6378 Acc: 0.9104\n",
      "val Loss: 0.6418 Acc: 0.9120\n",
      "test Loss: 0.6513 Acc: 0.9000\n",
      "Epoch 1237/1499\n",
      "----------\n",
      "train Loss: 0.6401 Acc: 0.9093\n",
      "val Loss: 0.6420 Acc: 0.9160\n",
      "test Loss: 0.6509 Acc: 0.9000\n",
      "Epoch 1238/1499\n",
      "----------\n",
      "train Loss: 0.6385 Acc: 0.9093\n",
      "val Loss: 0.6437 Acc: 0.9080\n",
      "test Loss: 0.6486 Acc: 0.8960\n",
      "Epoch 1239/1499\n",
      "----------\n",
      "train Loss: 0.6380 Acc: 0.9113\n",
      "val Loss: 0.6385 Acc: 0.9160\n",
      "test Loss: 0.6510 Acc: 0.9000\n",
      "Epoch 1240/1499\n",
      "----------\n",
      "train Loss: 0.6370 Acc: 0.9129\n",
      "val Loss: 0.6454 Acc: 0.9040\n",
      "test Loss: 0.6507 Acc: 0.9040\n",
      "Epoch 1241/1499\n",
      "----------\n",
      "train Loss: 0.6378 Acc: 0.9102\n",
      "val Loss: 0.6444 Acc: 0.9080\n",
      "test Loss: 0.6491 Acc: 0.8960\n",
      "Epoch 1242/1499\n",
      "----------\n",
      "train Loss: 0.6381 Acc: 0.9133\n",
      "val Loss: 0.6441 Acc: 0.9040\n",
      "test Loss: 0.6514 Acc: 0.8960\n",
      "Epoch 1243/1499\n",
      "----------\n",
      "train Loss: 0.6385 Acc: 0.9102\n",
      "val Loss: 0.6458 Acc: 0.9000\n",
      "test Loss: 0.6546 Acc: 0.8920\n",
      "Epoch 1244/1499\n",
      "----------\n",
      "train Loss: 0.6379 Acc: 0.9124\n",
      "val Loss: 0.6421 Acc: 0.9080\n",
      "test Loss: 0.6478 Acc: 0.9040\n",
      "Epoch 1245/1499\n",
      "----------\n",
      "train Loss: 0.6388 Acc: 0.9084\n",
      "val Loss: 0.6454 Acc: 0.9000\n",
      "test Loss: 0.6529 Acc: 0.8960\n",
      "Epoch 1246/1499\n",
      "----------\n",
      "train Loss: 0.6375 Acc: 0.9102\n",
      "val Loss: 0.6473 Acc: 0.9040\n",
      "test Loss: 0.6529 Acc: 0.9000\n",
      "Epoch 1247/1499\n",
      "----------\n",
      "train Loss: 0.6380 Acc: 0.9098\n",
      "val Loss: 0.6464 Acc: 0.9040\n",
      "test Loss: 0.6475 Acc: 0.9040\n",
      "Epoch 1248/1499\n",
      "----------\n",
      "train Loss: 0.6381 Acc: 0.9102\n",
      "val Loss: 0.6436 Acc: 0.9120\n",
      "test Loss: 0.6517 Acc: 0.9000\n",
      "Epoch 1249/1499\n",
      "----------\n",
      "train Loss: 0.6381 Acc: 0.9111\n",
      "val Loss: 0.6471 Acc: 0.9080\n",
      "test Loss: 0.6497 Acc: 0.9000\n",
      "Epoch 1250/1499\n",
      "----------\n",
      "train Loss: 0.6366 Acc: 0.9116\n",
      "val Loss: 0.6468 Acc: 0.9080\n",
      "test Loss: 0.6502 Acc: 0.9000\n",
      "Epoch 1251/1499\n",
      "----------\n",
      "train Loss: 0.6373 Acc: 0.9109\n",
      "val Loss: 0.6429 Acc: 0.9120\n",
      "test Loss: 0.6517 Acc: 0.9000\n",
      "Epoch 1252/1499\n",
      "----------\n",
      "train Loss: 0.6380 Acc: 0.9109\n",
      "val Loss: 0.6483 Acc: 0.9080\n",
      "test Loss: 0.6484 Acc: 0.8960\n",
      "Epoch 1253/1499\n",
      "----------\n",
      "train Loss: 0.6375 Acc: 0.9116\n",
      "val Loss: 0.6436 Acc: 0.9080\n",
      "test Loss: 0.6497 Acc: 0.9040\n",
      "Epoch 1254/1499\n",
      "----------\n",
      "train Loss: 0.6377 Acc: 0.9091\n",
      "val Loss: 0.6450 Acc: 0.9040\n",
      "test Loss: 0.6484 Acc: 0.9040\n",
      "Epoch 1255/1499\n",
      "----------\n",
      "train Loss: 0.6369 Acc: 0.9122\n",
      "val Loss: 0.6420 Acc: 0.9160\n",
      "test Loss: 0.6494 Acc: 0.8960\n",
      "Epoch 1256/1499\n",
      "----------\n",
      "train Loss: 0.6377 Acc: 0.9124\n",
      "val Loss: 0.6470 Acc: 0.9080\n",
      "test Loss: 0.6528 Acc: 0.8960\n",
      "Epoch 1257/1499\n",
      "----------\n",
      "train Loss: 0.6380 Acc: 0.9116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.6452 Acc: 0.9080\n",
      "test Loss: 0.6513 Acc: 0.9000\n",
      "Epoch 1258/1499\n",
      "----------\n",
      "train Loss: 0.6383 Acc: 0.9118\n",
      "val Loss: 0.6414 Acc: 0.9040\n",
      "test Loss: 0.6510 Acc: 0.9000\n",
      "Epoch 1259/1499\n",
      "----------\n",
      "train Loss: 0.6377 Acc: 0.9120\n",
      "val Loss: 0.6432 Acc: 0.9080\n",
      "test Loss: 0.6484 Acc: 0.9000\n",
      "Epoch 1260/1499\n",
      "----------\n",
      "train Loss: 0.6379 Acc: 0.9087\n",
      "val Loss: 0.6426 Acc: 0.9000\n",
      "test Loss: 0.6501 Acc: 0.9080\n",
      "Epoch 1261/1499\n",
      "----------\n",
      "train Loss: 0.6376 Acc: 0.9111\n",
      "val Loss: 0.6435 Acc: 0.9080\n",
      "test Loss: 0.6522 Acc: 0.8960\n",
      "Epoch 1262/1499\n",
      "----------\n",
      "train Loss: 0.6387 Acc: 0.9093\n",
      "val Loss: 0.6394 Acc: 0.9160\n",
      "test Loss: 0.6477 Acc: 0.9000\n",
      "Epoch 1263/1499\n",
      "----------\n",
      "train Loss: 0.6364 Acc: 0.9111\n",
      "val Loss: 0.6452 Acc: 0.9080\n",
      "test Loss: 0.6504 Acc: 0.9000\n",
      "Epoch 1264/1499\n",
      "----------\n",
      "train Loss: 0.6373 Acc: 0.9129\n",
      "val Loss: 0.6464 Acc: 0.9080\n",
      "test Loss: 0.6494 Acc: 0.9040\n",
      "Epoch 1265/1499\n",
      "----------\n",
      "train Loss: 0.6380 Acc: 0.9111\n",
      "val Loss: 0.6459 Acc: 0.9120\n",
      "test Loss: 0.6484 Acc: 0.9040\n",
      "Epoch 1266/1499\n",
      "----------\n",
      "train Loss: 0.6384 Acc: 0.9096\n",
      "val Loss: 0.6453 Acc: 0.9000\n",
      "test Loss: 0.6516 Acc: 0.8960\n",
      "Epoch 1267/1499\n",
      "----------\n",
      "train Loss: 0.6377 Acc: 0.9120\n",
      "val Loss: 0.6473 Acc: 0.9000\n",
      "test Loss: 0.6516 Acc: 0.9000\n",
      "Epoch 1268/1499\n",
      "----------\n",
      "train Loss: 0.6375 Acc: 0.9111\n",
      "val Loss: 0.6461 Acc: 0.9040\n",
      "test Loss: 0.6508 Acc: 0.9000\n",
      "Epoch 1269/1499\n",
      "----------\n",
      "train Loss: 0.6377 Acc: 0.9104\n",
      "val Loss: 0.6440 Acc: 0.9080\n",
      "test Loss: 0.6471 Acc: 0.9000\n",
      "Epoch 1270/1499\n",
      "----------\n",
      "train Loss: 0.6377 Acc: 0.9104\n",
      "val Loss: 0.6436 Acc: 0.9040\n",
      "test Loss: 0.6481 Acc: 0.9000\n",
      "Epoch 1271/1499\n",
      "----------\n",
      "train Loss: 0.6376 Acc: 0.9136\n",
      "val Loss: 0.6472 Acc: 0.9000\n",
      "test Loss: 0.6537 Acc: 0.8960\n",
      "Epoch 1272/1499\n",
      "----------\n",
      "train Loss: 0.6372 Acc: 0.9113\n",
      "val Loss: 0.6440 Acc: 0.9080\n",
      "test Loss: 0.6488 Acc: 0.9040\n",
      "Epoch 1273/1499\n",
      "----------\n",
      "train Loss: 0.6370 Acc: 0.9122\n",
      "val Loss: 0.6477 Acc: 0.9040\n",
      "test Loss: 0.6497 Acc: 0.9040\n",
      "Epoch 1274/1499\n",
      "----------\n",
      "train Loss: 0.6363 Acc: 0.9129\n",
      "val Loss: 0.6487 Acc: 0.9000\n",
      "test Loss: 0.6497 Acc: 0.9000\n",
      "Epoch 1275/1499\n",
      "----------\n",
      "train Loss: 0.6378 Acc: 0.9091\n",
      "val Loss: 0.6434 Acc: 0.9120\n",
      "test Loss: 0.6525 Acc: 0.9040\n",
      "Epoch 1276/1499\n",
      "----------\n",
      "train Loss: 0.6375 Acc: 0.9116\n",
      "val Loss: 0.6467 Acc: 0.9040\n",
      "test Loss: 0.6516 Acc: 0.8960\n",
      "Epoch 1277/1499\n",
      "----------\n",
      "train Loss: 0.6380 Acc: 0.9116\n",
      "val Loss: 0.6454 Acc: 0.9040\n",
      "test Loss: 0.6529 Acc: 0.9000\n",
      "Epoch 1278/1499\n",
      "----------\n",
      "train Loss: 0.6377 Acc: 0.9124\n",
      "val Loss: 0.6437 Acc: 0.9120\n",
      "test Loss: 0.6518 Acc: 0.9000\n",
      "Epoch 1279/1499\n",
      "----------\n",
      "train Loss: 0.6374 Acc: 0.9102\n",
      "val Loss: 0.6471 Acc: 0.9040\n",
      "test Loss: 0.6527 Acc: 0.9000\n",
      "Epoch 1280/1499\n",
      "----------\n",
      "train Loss: 0.6372 Acc: 0.9124\n",
      "val Loss: 0.6479 Acc: 0.9080\n",
      "test Loss: 0.6485 Acc: 0.9000\n",
      "Epoch 1281/1499\n",
      "----------\n",
      "train Loss: 0.6374 Acc: 0.9109\n",
      "val Loss: 0.6436 Acc: 0.9160\n",
      "test Loss: 0.6545 Acc: 0.9000\n",
      "Epoch 1282/1499\n",
      "----------\n",
      "train Loss: 0.6373 Acc: 0.9138\n",
      "val Loss: 0.6448 Acc: 0.9080\n",
      "test Loss: 0.6484 Acc: 0.9040\n",
      "Epoch 1283/1499\n",
      "----------\n",
      "train Loss: 0.6357 Acc: 0.9120\n",
      "val Loss: 0.6427 Acc: 0.9080\n",
      "test Loss: 0.6503 Acc: 0.8960\n",
      "Epoch 1284/1499\n",
      "----------\n",
      "train Loss: 0.6373 Acc: 0.9127\n",
      "val Loss: 0.6449 Acc: 0.9040\n",
      "test Loss: 0.6466 Acc: 0.9000\n",
      "Epoch 1285/1499\n",
      "----------\n",
      "train Loss: 0.6371 Acc: 0.9098\n",
      "val Loss: 0.6437 Acc: 0.9120\n",
      "test Loss: 0.6505 Acc: 0.9000\n",
      "Epoch 1286/1499\n",
      "----------\n",
      "train Loss: 0.6361 Acc: 0.9131\n",
      "val Loss: 0.6457 Acc: 0.9120\n",
      "test Loss: 0.6468 Acc: 0.9040\n",
      "Epoch 1287/1499\n",
      "----------\n",
      "train Loss: 0.6370 Acc: 0.9129\n",
      "val Loss: 0.6460 Acc: 0.9040\n",
      "test Loss: 0.6444 Acc: 0.9000\n",
      "Epoch 1288/1499\n",
      "----------\n",
      "train Loss: 0.6374 Acc: 0.9093\n",
      "val Loss: 0.6486 Acc: 0.9000\n",
      "test Loss: 0.6532 Acc: 0.8920\n",
      "Epoch 1289/1499\n",
      "----------\n",
      "train Loss: 0.6372 Acc: 0.9124\n",
      "val Loss: 0.6423 Acc: 0.9000\n",
      "test Loss: 0.6507 Acc: 0.9040\n",
      "Epoch 1290/1499\n",
      "----------\n",
      "train Loss: 0.6357 Acc: 0.9133\n",
      "val Loss: 0.6443 Acc: 0.9040\n",
      "test Loss: 0.6481 Acc: 0.9000\n",
      "Epoch 1291/1499\n",
      "----------\n",
      "train Loss: 0.6365 Acc: 0.9140\n",
      "val Loss: 0.6452 Acc: 0.9040\n",
      "test Loss: 0.6526 Acc: 0.8920\n",
      "Epoch 1292/1499\n",
      "----------\n",
      "train Loss: 0.6367 Acc: 0.9116\n",
      "val Loss: 0.6424 Acc: 0.9080\n",
      "test Loss: 0.6485 Acc: 0.9080\n",
      "Epoch 1293/1499\n",
      "----------\n",
      "train Loss: 0.6370 Acc: 0.9118\n",
      "val Loss: 0.6432 Acc: 0.9040\n",
      "test Loss: 0.6539 Acc: 0.8960\n",
      "Epoch 1294/1499\n",
      "----------\n",
      "train Loss: 0.6382 Acc: 0.9096\n",
      "val Loss: 0.6415 Acc: 0.9080\n",
      "test Loss: 0.6476 Acc: 0.9000\n",
      "Epoch 1295/1499\n",
      "----------\n",
      "train Loss: 0.6380 Acc: 0.9104\n",
      "val Loss: 0.6455 Acc: 0.9000\n",
      "test Loss: 0.6494 Acc: 0.9040\n",
      "Epoch 1296/1499\n",
      "----------\n",
      "train Loss: 0.6376 Acc: 0.9109\n",
      "val Loss: 0.6424 Acc: 0.9000\n",
      "test Loss: 0.6519 Acc: 0.9000\n",
      "Epoch 1297/1499\n",
      "----------\n",
      "train Loss: 0.6372 Acc: 0.9111\n",
      "val Loss: 0.6481 Acc: 0.9040\n",
      "test Loss: 0.6479 Acc: 0.9000\n",
      "Epoch 1298/1499\n",
      "----------\n",
      "train Loss: 0.6366 Acc: 0.9118\n",
      "val Loss: 0.6442 Acc: 0.9080\n",
      "test Loss: 0.6516 Acc: 0.9000\n",
      "Epoch 1299/1499\n",
      "----------\n",
      "train Loss: 0.6370 Acc: 0.9131\n",
      "val Loss: 0.6424 Acc: 0.9040\n",
      "test Loss: 0.6519 Acc: 0.8960\n",
      "Epoch 1300/1499\n",
      "----------\n",
      "train Loss: 0.6375 Acc: 0.9096\n",
      "val Loss: 0.6465 Acc: 0.9080\n",
      "test Loss: 0.6518 Acc: 0.8960\n",
      "Epoch 1301/1499\n",
      "----------\n",
      "train Loss: 0.6371 Acc: 0.9116\n",
      "val Loss: 0.6397 Acc: 0.9080\n",
      "test Loss: 0.6544 Acc: 0.8960\n",
      "Epoch 1302/1499\n",
      "----------\n",
      "train Loss: 0.6362 Acc: 0.9142\n",
      "val Loss: 0.6433 Acc: 0.9120\n",
      "test Loss: 0.6477 Acc: 0.9000\n",
      "Epoch 1303/1499\n",
      "----------\n",
      "train Loss: 0.6362 Acc: 0.9136\n",
      "val Loss: 0.6453 Acc: 0.9040\n",
      "test Loss: 0.6529 Acc: 0.9040\n",
      "Epoch 1304/1499\n",
      "----------\n",
      "train Loss: 0.6380 Acc: 0.9096\n",
      "val Loss: 0.6448 Acc: 0.9040\n",
      "test Loss: 0.6496 Acc: 0.9000\n",
      "Epoch 1305/1499\n",
      "----------\n",
      "train Loss: 0.6365 Acc: 0.9118\n",
      "val Loss: 0.6474 Acc: 0.9040\n",
      "test Loss: 0.6493 Acc: 0.9000\n",
      "Epoch 1306/1499\n",
      "----------\n",
      "train Loss: 0.6372 Acc: 0.9087\n",
      "val Loss: 0.6496 Acc: 0.9040\n",
      "test Loss: 0.6508 Acc: 0.8960\n",
      "Epoch 1307/1499\n",
      "----------\n",
      "train Loss: 0.6366 Acc: 0.9129\n",
      "val Loss: 0.6463 Acc: 0.9080\n",
      "test Loss: 0.6520 Acc: 0.9000\n",
      "Epoch 1308/1499\n",
      "----------\n",
      "train Loss: 0.6367 Acc: 0.9129\n",
      "val Loss: 0.6437 Acc: 0.9000\n",
      "test Loss: 0.6517 Acc: 0.8880\n",
      "Epoch 1309/1499\n",
      "----------\n",
      "train Loss: 0.6381 Acc: 0.9113\n",
      "val Loss: 0.6449 Acc: 0.9040\n",
      "test Loss: 0.6498 Acc: 0.8960\n",
      "Epoch 1310/1499\n",
      "----------\n",
      "train Loss: 0.6364 Acc: 0.9116\n",
      "val Loss: 0.6448 Acc: 0.9080\n",
      "test Loss: 0.6508 Acc: 0.8960\n",
      "Epoch 1311/1499\n",
      "----------\n",
      "train Loss: 0.6359 Acc: 0.9140\n",
      "val Loss: 0.6425 Acc: 0.9040\n",
      "test Loss: 0.6468 Acc: 0.8960\n",
      "Epoch 1312/1499\n",
      "----------\n",
      "train Loss: 0.6367 Acc: 0.9142\n",
      "val Loss: 0.6451 Acc: 0.9120\n",
      "test Loss: 0.6511 Acc: 0.8960\n",
      "Epoch 1313/1499\n",
      "----------\n",
      "train Loss: 0.6361 Acc: 0.9124\n",
      "val Loss: 0.6488 Acc: 0.9120\n",
      "test Loss: 0.6473 Acc: 0.9000\n",
      "Epoch 1314/1499\n",
      "----------\n",
      "train Loss: 0.6368 Acc: 0.9107\n",
      "val Loss: 0.6491 Acc: 0.8960\n",
      "test Loss: 0.6484 Acc: 0.9000\n",
      "Epoch 1315/1499\n",
      "----------\n",
      "train Loss: 0.6358 Acc: 0.9136\n",
      "val Loss: 0.6454 Acc: 0.9040\n",
      "test Loss: 0.6475 Acc: 0.9040\n",
      "Epoch 1316/1499\n",
      "----------\n",
      "train Loss: 0.6369 Acc: 0.9093\n",
      "val Loss: 0.6474 Acc: 0.9080\n",
      "test Loss: 0.6492 Acc: 0.9000\n",
      "Epoch 1317/1499\n",
      "----------\n",
      "train Loss: 0.6370 Acc: 0.9142\n",
      "val Loss: 0.6463 Acc: 0.9000\n",
      "test Loss: 0.6471 Acc: 0.9040\n",
      "Epoch 1318/1499\n",
      "----------\n",
      "train Loss: 0.6357 Acc: 0.9124\n",
      "val Loss: 0.6504 Acc: 0.9040\n",
      "test Loss: 0.6505 Acc: 0.9000\n",
      "Epoch 1319/1499\n",
      "----------\n",
      "train Loss: 0.6362 Acc: 0.9124\n",
      "val Loss: 0.6441 Acc: 0.9080\n",
      "test Loss: 0.6504 Acc: 0.8920\n",
      "Epoch 1320/1499\n",
      "----------\n",
      "train Loss: 0.6361 Acc: 0.9122\n",
      "val Loss: 0.6448 Acc: 0.9080\n",
      "test Loss: 0.6467 Acc: 0.8960\n",
      "Epoch 1321/1499\n",
      "----------\n",
      "train Loss: 0.6373 Acc: 0.9113\n",
      "val Loss: 0.6457 Acc: 0.9120\n",
      "test Loss: 0.6515 Acc: 0.8920\n",
      "Epoch 1322/1499\n",
      "----------\n",
      "train Loss: 0.6364 Acc: 0.9111\n",
      "val Loss: 0.6471 Acc: 0.9040\n",
      "test Loss: 0.6444 Acc: 0.8960\n",
      "Epoch 1323/1499\n",
      "----------\n",
      "train Loss: 0.6368 Acc: 0.9136\n",
      "val Loss: 0.6435 Acc: 0.9000\n",
      "test Loss: 0.6492 Acc: 0.9040\n",
      "Epoch 1324/1499\n",
      "----------\n",
      "train Loss: 0.6377 Acc: 0.9084\n",
      "val Loss: 0.6446 Acc: 0.9120\n",
      "test Loss: 0.6471 Acc: 0.9000\n",
      "Epoch 1325/1499\n",
      "----------\n",
      "train Loss: 0.6367 Acc: 0.9144\n",
      "val Loss: 0.6489 Acc: 0.8960\n",
      "test Loss: 0.6500 Acc: 0.9040\n",
      "Epoch 1326/1499\n",
      "----------\n",
      "train Loss: 0.6373 Acc: 0.9109\n",
      "val Loss: 0.6444 Acc: 0.9000\n",
      "test Loss: 0.6492 Acc: 0.9040\n",
      "Epoch 1327/1499\n",
      "----------\n",
      "train Loss: 0.6369 Acc: 0.9140\n",
      "val Loss: 0.6437 Acc: 0.9120\n",
      "test Loss: 0.6510 Acc: 0.8960\n",
      "Epoch 1328/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6373 Acc: 0.9104\n",
      "val Loss: 0.6426 Acc: 0.9120\n",
      "test Loss: 0.6519 Acc: 0.8920\n",
      "Epoch 1329/1499\n",
      "----------\n",
      "train Loss: 0.6370 Acc: 0.9131\n",
      "val Loss: 0.6453 Acc: 0.9040\n",
      "test Loss: 0.6506 Acc: 0.9000\n",
      "Epoch 1330/1499\n",
      "----------\n",
      "train Loss: 0.6364 Acc: 0.9138\n",
      "val Loss: 0.6455 Acc: 0.9000\n",
      "test Loss: 0.6467 Acc: 0.9040\n",
      "Epoch 1331/1499\n",
      "----------\n",
      "train Loss: 0.6370 Acc: 0.9093\n",
      "val Loss: 0.6449 Acc: 0.9080\n",
      "test Loss: 0.6505 Acc: 0.8960\n",
      "Epoch 1332/1499\n",
      "----------\n",
      "train Loss: 0.6376 Acc: 0.9116\n",
      "val Loss: 0.6455 Acc: 0.9000\n",
      "test Loss: 0.6501 Acc: 0.9040\n",
      "Epoch 1333/1499\n",
      "----------\n",
      "train Loss: 0.6365 Acc: 0.9116\n",
      "val Loss: 0.6479 Acc: 0.9000\n",
      "test Loss: 0.6509 Acc: 0.8960\n",
      "Epoch 1334/1499\n",
      "----------\n",
      "train Loss: 0.6365 Acc: 0.9127\n",
      "val Loss: 0.6449 Acc: 0.9080\n",
      "test Loss: 0.6563 Acc: 0.8920\n",
      "Epoch 1335/1499\n",
      "----------\n",
      "train Loss: 0.6365 Acc: 0.9124\n",
      "val Loss: 0.6462 Acc: 0.9000\n",
      "test Loss: 0.6484 Acc: 0.9000\n",
      "Epoch 1336/1499\n",
      "----------\n",
      "train Loss: 0.6365 Acc: 0.9107\n",
      "val Loss: 0.6460 Acc: 0.9080\n",
      "test Loss: 0.6511 Acc: 0.8960\n",
      "Epoch 1337/1499\n",
      "----------\n",
      "train Loss: 0.6370 Acc: 0.9122\n",
      "val Loss: 0.6448 Acc: 0.9080\n",
      "test Loss: 0.6484 Acc: 0.9000\n",
      "Epoch 1338/1499\n",
      "----------\n",
      "train Loss: 0.6354 Acc: 0.9151\n",
      "val Loss: 0.6421 Acc: 0.9080\n",
      "test Loss: 0.6463 Acc: 0.9040\n",
      "Epoch 1339/1499\n",
      "----------\n",
      "train Loss: 0.6359 Acc: 0.9136\n",
      "val Loss: 0.6464 Acc: 0.9000\n",
      "test Loss: 0.6517 Acc: 0.8920\n",
      "Epoch 1340/1499\n",
      "----------\n",
      "train Loss: 0.6369 Acc: 0.9120\n",
      "val Loss: 0.6454 Acc: 0.9000\n",
      "test Loss: 0.6457 Acc: 0.8960\n",
      "Epoch 1341/1499\n",
      "----------\n",
      "train Loss: 0.6358 Acc: 0.9136\n",
      "val Loss: 0.6454 Acc: 0.9080\n",
      "test Loss: 0.6467 Acc: 0.9040\n",
      "Epoch 1342/1499\n",
      "----------\n",
      "train Loss: 0.6370 Acc: 0.9129\n",
      "val Loss: 0.6489 Acc: 0.9000\n",
      "test Loss: 0.6502 Acc: 0.8960\n",
      "Epoch 1343/1499\n",
      "----------\n",
      "train Loss: 0.6365 Acc: 0.9118\n",
      "val Loss: 0.6426 Acc: 0.9080\n",
      "test Loss: 0.6452 Acc: 0.8960\n",
      "Epoch 1344/1499\n",
      "----------\n",
      "train Loss: 0.6356 Acc: 0.9122\n",
      "val Loss: 0.6467 Acc: 0.9040\n",
      "test Loss: 0.6525 Acc: 0.8880\n",
      "Epoch 1345/1499\n",
      "----------\n",
      "train Loss: 0.6360 Acc: 0.9127\n",
      "val Loss: 0.6462 Acc: 0.9040\n",
      "test Loss: 0.6479 Acc: 0.9000\n",
      "Epoch 1346/1499\n",
      "----------\n",
      "train Loss: 0.6367 Acc: 0.9131\n",
      "val Loss: 0.6447 Acc: 0.9000\n",
      "test Loss: 0.6504 Acc: 0.9000\n",
      "Epoch 1347/1499\n",
      "----------\n",
      "train Loss: 0.6379 Acc: 0.9111\n",
      "val Loss: 0.6429 Acc: 0.9080\n",
      "test Loss: 0.6456 Acc: 0.9000\n",
      "Epoch 1348/1499\n",
      "----------\n",
      "train Loss: 0.6367 Acc: 0.9111\n",
      "val Loss: 0.6487 Acc: 0.9120\n",
      "test Loss: 0.6484 Acc: 0.8960\n",
      "Epoch 1349/1499\n",
      "----------\n",
      "train Loss: 0.6368 Acc: 0.9144\n",
      "val Loss: 0.6460 Acc: 0.9080\n",
      "test Loss: 0.6461 Acc: 0.9000\n",
      "Epoch 1350/1499\n",
      "----------\n",
      "train Loss: 0.6365 Acc: 0.9140\n",
      "val Loss: 0.6449 Acc: 0.9040\n",
      "test Loss: 0.6492 Acc: 0.9000\n",
      "Epoch 1351/1499\n",
      "----------\n",
      "train Loss: 0.6372 Acc: 0.9118\n",
      "val Loss: 0.6497 Acc: 0.9000\n",
      "test Loss: 0.6475 Acc: 0.9040\n",
      "Epoch 1352/1499\n",
      "----------\n",
      "train Loss: 0.6365 Acc: 0.9104\n",
      "val Loss: 0.6431 Acc: 0.9040\n",
      "test Loss: 0.6511 Acc: 0.8960\n",
      "Epoch 1353/1499\n",
      "----------\n",
      "train Loss: 0.6362 Acc: 0.9109\n",
      "val Loss: 0.6502 Acc: 0.8960\n",
      "test Loss: 0.6508 Acc: 0.9000\n",
      "Epoch 1354/1499\n",
      "----------\n",
      "train Loss: 0.6367 Acc: 0.9136\n",
      "val Loss: 0.6453 Acc: 0.9040\n",
      "test Loss: 0.6499 Acc: 0.9000\n",
      "Epoch 1355/1499\n",
      "----------\n",
      "train Loss: 0.6363 Acc: 0.9131\n",
      "val Loss: 0.6499 Acc: 0.9000\n",
      "test Loss: 0.6505 Acc: 0.8960\n",
      "Epoch 1356/1499\n",
      "----------\n",
      "train Loss: 0.6358 Acc: 0.9129\n",
      "val Loss: 0.6486 Acc: 0.9080\n",
      "test Loss: 0.6501 Acc: 0.8920\n",
      "Epoch 1357/1499\n",
      "----------\n",
      "train Loss: 0.6354 Acc: 0.9118\n",
      "val Loss: 0.6470 Acc: 0.9040\n",
      "test Loss: 0.6519 Acc: 0.8960\n",
      "Epoch 1358/1499\n",
      "----------\n",
      "train Loss: 0.6365 Acc: 0.9111\n",
      "val Loss: 0.6384 Acc: 0.9160\n",
      "test Loss: 0.6509 Acc: 0.8920\n",
      "Epoch 1359/1499\n",
      "----------\n",
      "train Loss: 0.6358 Acc: 0.9140\n",
      "val Loss: 0.6442 Acc: 0.9040\n",
      "test Loss: 0.6470 Acc: 0.8960\n",
      "Epoch 1360/1499\n",
      "----------\n",
      "train Loss: 0.6361 Acc: 0.9118\n",
      "val Loss: 0.6451 Acc: 0.9080\n",
      "test Loss: 0.6505 Acc: 0.9000\n",
      "Epoch 1361/1499\n",
      "----------\n",
      "train Loss: 0.6356 Acc: 0.9142\n",
      "val Loss: 0.6431 Acc: 0.9040\n",
      "test Loss: 0.6514 Acc: 0.9000\n",
      "Epoch 1362/1499\n",
      "----------\n",
      "train Loss: 0.6364 Acc: 0.9122\n",
      "val Loss: 0.6422 Acc: 0.9040\n",
      "test Loss: 0.6497 Acc: 0.8960\n",
      "Epoch 1363/1499\n",
      "----------\n",
      "train Loss: 0.6364 Acc: 0.9133\n",
      "val Loss: 0.6458 Acc: 0.9080\n",
      "test Loss: 0.6469 Acc: 0.9040\n",
      "Epoch 1364/1499\n",
      "----------\n",
      "train Loss: 0.6365 Acc: 0.9116\n",
      "val Loss: 0.6444 Acc: 0.9160\n",
      "test Loss: 0.6493 Acc: 0.8960\n",
      "Epoch 1365/1499\n",
      "----------\n",
      "train Loss: 0.6366 Acc: 0.9127\n",
      "val Loss: 0.6435 Acc: 0.9080\n",
      "test Loss: 0.6499 Acc: 0.8960\n",
      "Epoch 1366/1499\n",
      "----------\n",
      "train Loss: 0.6358 Acc: 0.9120\n",
      "val Loss: 0.6474 Acc: 0.8960\n",
      "test Loss: 0.6497 Acc: 0.9040\n",
      "Epoch 1367/1499\n",
      "----------\n",
      "train Loss: 0.6357 Acc: 0.9124\n",
      "val Loss: 0.6452 Acc: 0.9080\n",
      "test Loss: 0.6460 Acc: 0.9080\n",
      "Epoch 1368/1499\n",
      "----------\n",
      "train Loss: 0.6359 Acc: 0.9113\n",
      "val Loss: 0.6419 Acc: 0.9160\n",
      "test Loss: 0.6497 Acc: 0.9000\n",
      "Epoch 1369/1499\n",
      "----------\n",
      "train Loss: 0.6363 Acc: 0.9113\n",
      "val Loss: 0.6425 Acc: 0.9120\n",
      "test Loss: 0.6498 Acc: 0.9040\n",
      "Epoch 1370/1499\n",
      "----------\n",
      "train Loss: 0.6356 Acc: 0.9140\n",
      "val Loss: 0.6458 Acc: 0.9040\n",
      "test Loss: 0.6511 Acc: 0.8920\n",
      "Epoch 1371/1499\n",
      "----------\n",
      "train Loss: 0.6359 Acc: 0.9140\n",
      "val Loss: 0.6386 Acc: 0.9160\n",
      "test Loss: 0.6480 Acc: 0.9040\n",
      "Epoch 1372/1499\n",
      "----------\n",
      "train Loss: 0.6365 Acc: 0.9122\n",
      "val Loss: 0.6438 Acc: 0.9000\n",
      "test Loss: 0.6528 Acc: 0.8920\n",
      "Epoch 1373/1499\n",
      "----------\n",
      "train Loss: 0.6367 Acc: 0.9133\n",
      "val Loss: 0.6438 Acc: 0.9040\n",
      "test Loss: 0.6530 Acc: 0.8920\n",
      "Epoch 1374/1499\n",
      "----------\n",
      "train Loss: 0.6357 Acc: 0.9136\n",
      "val Loss: 0.6448 Acc: 0.9120\n",
      "test Loss: 0.6476 Acc: 0.8960\n",
      "Epoch 1375/1499\n",
      "----------\n",
      "train Loss: 0.6361 Acc: 0.9127\n",
      "val Loss: 0.6458 Acc: 0.9080\n",
      "test Loss: 0.6478 Acc: 0.9000\n",
      "Epoch 1376/1499\n",
      "----------\n",
      "train Loss: 0.6381 Acc: 0.9109\n",
      "val Loss: 0.6434 Acc: 0.9080\n",
      "test Loss: 0.6497 Acc: 0.8960\n",
      "Epoch 1377/1499\n",
      "----------\n",
      "train Loss: 0.6348 Acc: 0.9153\n",
      "val Loss: 0.6440 Acc: 0.9120\n",
      "test Loss: 0.6481 Acc: 0.9000\n",
      "Epoch 1378/1499\n",
      "----------\n",
      "train Loss: 0.6361 Acc: 0.9120\n",
      "val Loss: 0.6408 Acc: 0.9160\n",
      "test Loss: 0.6477 Acc: 0.9040\n",
      "Epoch 1379/1499\n",
      "----------\n",
      "train Loss: 0.6356 Acc: 0.9116\n",
      "val Loss: 0.6415 Acc: 0.9120\n",
      "test Loss: 0.6465 Acc: 0.9000\n",
      "Epoch 1380/1499\n",
      "----------\n",
      "train Loss: 0.6359 Acc: 0.9129\n",
      "val Loss: 0.6467 Acc: 0.9120\n",
      "test Loss: 0.6490 Acc: 0.8960\n",
      "Epoch 1381/1499\n",
      "----------\n",
      "train Loss: 0.6350 Acc: 0.9136\n",
      "val Loss: 0.6426 Acc: 0.9080\n",
      "test Loss: 0.6486 Acc: 0.8960\n",
      "Epoch 1382/1499\n",
      "----------\n",
      "train Loss: 0.6356 Acc: 0.9124\n",
      "val Loss: 0.6440 Acc: 0.9000\n",
      "test Loss: 0.6510 Acc: 0.8960\n",
      "Epoch 1383/1499\n",
      "----------\n",
      "train Loss: 0.6366 Acc: 0.9142\n",
      "val Loss: 0.6466 Acc: 0.9120\n",
      "test Loss: 0.6446 Acc: 0.9040\n",
      "Epoch 1384/1499\n",
      "----------\n",
      "train Loss: 0.6356 Acc: 0.9131\n",
      "val Loss: 0.6439 Acc: 0.9040\n",
      "test Loss: 0.6447 Acc: 0.9000\n",
      "Epoch 1385/1499\n",
      "----------\n",
      "train Loss: 0.6361 Acc: 0.9113\n",
      "val Loss: 0.6467 Acc: 0.9040\n",
      "test Loss: 0.6511 Acc: 0.9000\n",
      "Epoch 1386/1499\n",
      "----------\n",
      "train Loss: 0.6352 Acc: 0.9147\n",
      "val Loss: 0.6452 Acc: 0.9040\n",
      "test Loss: 0.6448 Acc: 0.9040\n",
      "Epoch 1387/1499\n",
      "----------\n",
      "train Loss: 0.6346 Acc: 0.9149\n",
      "val Loss: 0.6448 Acc: 0.9040\n",
      "test Loss: 0.6508 Acc: 0.8960\n",
      "Epoch 1388/1499\n",
      "----------\n",
      "train Loss: 0.6354 Acc: 0.9156\n",
      "val Loss: 0.6419 Acc: 0.9080\n",
      "test Loss: 0.6463 Acc: 0.9040\n",
      "Epoch 1389/1499\n",
      "----------\n",
      "train Loss: 0.6347 Acc: 0.9151\n",
      "val Loss: 0.6449 Acc: 0.9040\n",
      "test Loss: 0.6471 Acc: 0.9040\n",
      "Epoch 1390/1499\n",
      "----------\n",
      "train Loss: 0.6363 Acc: 0.9138\n",
      "val Loss: 0.6445 Acc: 0.9000\n",
      "test Loss: 0.6498 Acc: 0.8960\n",
      "Epoch 1391/1499\n",
      "----------\n",
      "train Loss: 0.6351 Acc: 0.9131\n",
      "val Loss: 0.6486 Acc: 0.9000\n",
      "test Loss: 0.6478 Acc: 0.9000\n",
      "Epoch 1392/1499\n",
      "----------\n",
      "train Loss: 0.6348 Acc: 0.9116\n",
      "val Loss: 0.6484 Acc: 0.9040\n",
      "test Loss: 0.6480 Acc: 0.8960\n",
      "Epoch 1393/1499\n",
      "----------\n",
      "train Loss: 0.6352 Acc: 0.9138\n",
      "val Loss: 0.6409 Acc: 0.9120\n",
      "test Loss: 0.6474 Acc: 0.8960\n",
      "Epoch 1394/1499\n",
      "----------\n",
      "train Loss: 0.6347 Acc: 0.9136\n",
      "val Loss: 0.6480 Acc: 0.8960\n",
      "test Loss: 0.6514 Acc: 0.9000\n",
      "Epoch 1395/1499\n",
      "----------\n",
      "train Loss: 0.6351 Acc: 0.9162\n",
      "val Loss: 0.6430 Acc: 0.9120\n",
      "test Loss: 0.6505 Acc: 0.8960\n",
      "Epoch 1396/1499\n",
      "----------\n",
      "train Loss: 0.6353 Acc: 0.9120\n",
      "val Loss: 0.6456 Acc: 0.9040\n",
      "test Loss: 0.6501 Acc: 0.8960\n",
      "Epoch 1397/1499\n",
      "----------\n",
      "train Loss: 0.6353 Acc: 0.9118\n",
      "val Loss: 0.6418 Acc: 0.9040\n",
      "test Loss: 0.6475 Acc: 0.8960\n",
      "Epoch 1398/1499\n",
      "----------\n",
      "train Loss: 0.6356 Acc: 0.9136\n",
      "val Loss: 0.6495 Acc: 0.8960\n",
      "test Loss: 0.6520 Acc: 0.9000\n",
      "Epoch 1399/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6362 Acc: 0.9138\n",
      "val Loss: 0.6461 Acc: 0.9080\n",
      "test Loss: 0.6508 Acc: 0.9000\n",
      "Epoch 1400/1499\n",
      "----------\n",
      "train Loss: 0.6350 Acc: 0.9144\n",
      "val Loss: 0.6451 Acc: 0.8960\n",
      "test Loss: 0.6480 Acc: 0.9000\n",
      "Epoch 1401/1499\n",
      "----------\n",
      "train Loss: 0.6353 Acc: 0.9133\n",
      "val Loss: 0.6460 Acc: 0.9040\n",
      "test Loss: 0.6476 Acc: 0.9000\n",
      "Epoch 1402/1499\n",
      "----------\n",
      "train Loss: 0.6352 Acc: 0.9147\n",
      "val Loss: 0.6472 Acc: 0.9000\n",
      "test Loss: 0.6469 Acc: 0.9000\n",
      "Epoch 1403/1499\n",
      "----------\n",
      "train Loss: 0.6351 Acc: 0.9129\n",
      "val Loss: 0.6472 Acc: 0.9080\n",
      "test Loss: 0.6481 Acc: 0.9040\n",
      "Epoch 1404/1499\n",
      "----------\n",
      "train Loss: 0.6348 Acc: 0.9129\n",
      "val Loss: 0.6462 Acc: 0.9080\n",
      "test Loss: 0.6510 Acc: 0.9000\n",
      "Epoch 1405/1499\n",
      "----------\n",
      "train Loss: 0.6349 Acc: 0.9142\n",
      "val Loss: 0.6428 Acc: 0.9040\n",
      "test Loss: 0.6425 Acc: 0.9040\n",
      "Epoch 1406/1499\n",
      "----------\n",
      "train Loss: 0.6351 Acc: 0.9142\n",
      "val Loss: 0.6467 Acc: 0.9080\n",
      "test Loss: 0.6485 Acc: 0.9040\n",
      "Epoch 1407/1499\n",
      "----------\n",
      "train Loss: 0.6360 Acc: 0.9131\n",
      "val Loss: 0.6472 Acc: 0.9040\n",
      "test Loss: 0.6488 Acc: 0.8960\n",
      "Epoch 1408/1499\n",
      "----------\n",
      "train Loss: 0.6341 Acc: 0.9160\n",
      "val Loss: 0.6452 Acc: 0.9080\n",
      "test Loss: 0.6476 Acc: 0.9040\n",
      "Epoch 1409/1499\n",
      "----------\n",
      "train Loss: 0.6352 Acc: 0.9118\n",
      "val Loss: 0.6403 Acc: 0.9080\n",
      "test Loss: 0.6481 Acc: 0.8960\n",
      "Epoch 1410/1499\n",
      "----------\n",
      "train Loss: 0.6354 Acc: 0.9124\n",
      "val Loss: 0.6446 Acc: 0.9120\n",
      "test Loss: 0.6480 Acc: 0.9000\n",
      "Epoch 1411/1499\n",
      "----------\n",
      "train Loss: 0.6360 Acc: 0.9118\n",
      "val Loss: 0.6493 Acc: 0.8960\n",
      "test Loss: 0.6488 Acc: 0.9000\n",
      "Epoch 1412/1499\n",
      "----------\n",
      "train Loss: 0.6342 Acc: 0.9138\n",
      "val Loss: 0.6439 Acc: 0.9080\n",
      "test Loss: 0.6480 Acc: 0.9000\n",
      "Epoch 1413/1499\n",
      "----------\n",
      "train Loss: 0.6346 Acc: 0.9136\n",
      "val Loss: 0.6465 Acc: 0.9080\n",
      "test Loss: 0.6466 Acc: 0.9080\n",
      "Epoch 1414/1499\n",
      "----------\n",
      "train Loss: 0.6349 Acc: 0.9138\n",
      "val Loss: 0.6447 Acc: 0.9040\n",
      "test Loss: 0.6500 Acc: 0.9040\n",
      "Epoch 1415/1499\n",
      "----------\n",
      "train Loss: 0.6365 Acc: 0.9129\n",
      "val Loss: 0.6443 Acc: 0.9000\n",
      "test Loss: 0.6473 Acc: 0.9000\n",
      "Epoch 1416/1499\n",
      "----------\n",
      "train Loss: 0.6349 Acc: 0.9153\n",
      "val Loss: 0.6462 Acc: 0.9040\n",
      "test Loss: 0.6490 Acc: 0.9000\n",
      "Epoch 1417/1499\n",
      "----------\n",
      "train Loss: 0.6350 Acc: 0.9144\n",
      "val Loss: 0.6428 Acc: 0.9040\n",
      "test Loss: 0.6446 Acc: 0.9040\n",
      "Epoch 1418/1499\n",
      "----------\n",
      "train Loss: 0.6344 Acc: 0.9122\n",
      "val Loss: 0.6434 Acc: 0.9080\n",
      "test Loss: 0.6474 Acc: 0.9000\n",
      "Epoch 1419/1499\n",
      "----------\n",
      "train Loss: 0.6340 Acc: 0.9160\n",
      "val Loss: 0.6473 Acc: 0.9000\n",
      "test Loss: 0.6489 Acc: 0.8920\n",
      "Epoch 1420/1499\n",
      "----------\n",
      "train Loss: 0.6345 Acc: 0.9136\n",
      "val Loss: 0.6422 Acc: 0.9080\n",
      "test Loss: 0.6450 Acc: 0.9000\n",
      "Epoch 1421/1499\n",
      "----------\n",
      "train Loss: 0.6355 Acc: 0.9122\n",
      "val Loss: 0.6440 Acc: 0.9000\n",
      "test Loss: 0.6447 Acc: 0.9040\n",
      "Epoch 1422/1499\n",
      "----------\n",
      "train Loss: 0.6358 Acc: 0.9142\n",
      "val Loss: 0.6409 Acc: 0.9120\n",
      "test Loss: 0.6464 Acc: 0.8960\n",
      "Epoch 1423/1499\n",
      "----------\n",
      "train Loss: 0.6341 Acc: 0.9153\n",
      "val Loss: 0.6458 Acc: 0.9080\n",
      "test Loss: 0.6479 Acc: 0.9040\n",
      "Epoch 1424/1499\n",
      "----------\n",
      "train Loss: 0.6343 Acc: 0.9136\n",
      "val Loss: 0.6438 Acc: 0.9040\n",
      "test Loss: 0.6445 Acc: 0.9000\n",
      "Epoch 1425/1499\n",
      "----------\n",
      "train Loss: 0.6348 Acc: 0.9129\n",
      "val Loss: 0.6444 Acc: 0.9040\n",
      "test Loss: 0.6493 Acc: 0.8960\n",
      "Epoch 1426/1499\n",
      "----------\n",
      "train Loss: 0.6353 Acc: 0.9131\n",
      "val Loss: 0.6512 Acc: 0.9040\n",
      "test Loss: 0.6482 Acc: 0.9040\n",
      "Epoch 1427/1499\n",
      "----------\n",
      "train Loss: 0.6350 Acc: 0.9144\n",
      "val Loss: 0.6467 Acc: 0.9000\n",
      "test Loss: 0.6494 Acc: 0.8960\n",
      "Epoch 1428/1499\n",
      "----------\n",
      "train Loss: 0.6341 Acc: 0.9142\n",
      "val Loss: 0.6435 Acc: 0.9080\n",
      "test Loss: 0.6468 Acc: 0.9040\n",
      "Epoch 1429/1499\n",
      "----------\n",
      "train Loss: 0.6345 Acc: 0.9144\n",
      "val Loss: 0.6428 Acc: 0.9120\n",
      "test Loss: 0.6464 Acc: 0.8960\n",
      "Epoch 1430/1499\n",
      "----------\n",
      "train Loss: 0.6356 Acc: 0.9147\n",
      "val Loss: 0.6460 Acc: 0.9120\n",
      "test Loss: 0.6526 Acc: 0.8920\n",
      "Epoch 1431/1499\n",
      "----------\n",
      "train Loss: 0.6351 Acc: 0.9131\n",
      "val Loss: 0.6460 Acc: 0.9000\n",
      "test Loss: 0.6476 Acc: 0.9000\n",
      "Epoch 1432/1499\n",
      "----------\n",
      "train Loss: 0.6346 Acc: 0.9149\n",
      "val Loss: 0.6458 Acc: 0.9080\n",
      "test Loss: 0.6518 Acc: 0.8920\n",
      "Epoch 1433/1499\n",
      "----------\n",
      "train Loss: 0.6350 Acc: 0.9153\n",
      "val Loss: 0.6484 Acc: 0.9000\n",
      "test Loss: 0.6487 Acc: 0.9000\n",
      "Epoch 1434/1499\n",
      "----------\n",
      "train Loss: 0.6348 Acc: 0.9124\n",
      "val Loss: 0.6450 Acc: 0.9080\n",
      "test Loss: 0.6441 Acc: 0.9040\n",
      "Epoch 1435/1499\n",
      "----------\n",
      "train Loss: 0.6348 Acc: 0.9129\n",
      "val Loss: 0.6420 Acc: 0.9080\n",
      "test Loss: 0.6478 Acc: 0.8960\n",
      "Epoch 1436/1499\n",
      "----------\n",
      "train Loss: 0.6346 Acc: 0.9149\n",
      "val Loss: 0.6442 Acc: 0.9080\n",
      "test Loss: 0.6498 Acc: 0.9000\n",
      "Epoch 1437/1499\n",
      "----------\n",
      "train Loss: 0.6359 Acc: 0.9133\n",
      "val Loss: 0.6413 Acc: 0.9120\n",
      "test Loss: 0.6494 Acc: 0.8960\n",
      "Epoch 1438/1499\n",
      "----------\n",
      "train Loss: 0.6351 Acc: 0.9147\n",
      "val Loss: 0.6437 Acc: 0.9120\n",
      "test Loss: 0.6453 Acc: 0.9040\n",
      "Epoch 1439/1499\n",
      "----------\n",
      "train Loss: 0.6349 Acc: 0.9120\n",
      "val Loss: 0.6457 Acc: 0.9040\n",
      "test Loss: 0.6476 Acc: 0.9000\n",
      "Epoch 1440/1499\n",
      "----------\n",
      "train Loss: 0.6357 Acc: 0.9118\n",
      "val Loss: 0.6444 Acc: 0.9120\n",
      "test Loss: 0.6505 Acc: 0.8960\n",
      "Epoch 1441/1499\n",
      "----------\n",
      "train Loss: 0.6346 Acc: 0.9131\n",
      "val Loss: 0.6454 Acc: 0.9120\n",
      "test Loss: 0.6503 Acc: 0.8960\n",
      "Epoch 1442/1499\n",
      "----------\n",
      "train Loss: 0.6344 Acc: 0.9116\n",
      "val Loss: 0.6447 Acc: 0.9080\n",
      "test Loss: 0.6461 Acc: 0.9040\n",
      "Epoch 1443/1499\n",
      "----------\n",
      "train Loss: 0.6352 Acc: 0.9140\n",
      "val Loss: 0.6431 Acc: 0.9040\n",
      "test Loss: 0.6470 Acc: 0.8960\n",
      "Epoch 1444/1499\n",
      "----------\n",
      "train Loss: 0.6345 Acc: 0.9133\n",
      "val Loss: 0.6452 Acc: 0.9120\n",
      "test Loss: 0.6494 Acc: 0.8960\n",
      "Epoch 1445/1499\n",
      "----------\n",
      "train Loss: 0.6348 Acc: 0.9127\n",
      "val Loss: 0.6474 Acc: 0.9040\n",
      "test Loss: 0.6494 Acc: 0.8920\n",
      "Epoch 1446/1499\n",
      "----------\n",
      "train Loss: 0.6351 Acc: 0.9120\n",
      "val Loss: 0.6386 Acc: 0.9080\n",
      "test Loss: 0.6452 Acc: 0.9000\n",
      "Epoch 1447/1499\n",
      "----------\n",
      "train Loss: 0.6336 Acc: 0.9160\n",
      "val Loss: 0.6418 Acc: 0.9120\n",
      "test Loss: 0.6490 Acc: 0.8960\n",
      "Epoch 1448/1499\n",
      "----------\n",
      "train Loss: 0.6342 Acc: 0.9158\n",
      "val Loss: 0.6437 Acc: 0.9080\n",
      "test Loss: 0.6512 Acc: 0.9000\n",
      "Epoch 1449/1499\n",
      "----------\n",
      "train Loss: 0.6339 Acc: 0.9160\n",
      "val Loss: 0.6456 Acc: 0.9000\n",
      "test Loss: 0.6449 Acc: 0.9000\n",
      "Epoch 1450/1499\n",
      "----------\n",
      "train Loss: 0.6345 Acc: 0.9140\n",
      "val Loss: 0.6480 Acc: 0.9000\n",
      "test Loss: 0.6523 Acc: 0.8960\n",
      "Epoch 1451/1499\n",
      "----------\n",
      "train Loss: 0.6340 Acc: 0.9133\n",
      "val Loss: 0.6434 Acc: 0.9080\n",
      "test Loss: 0.6482 Acc: 0.8960\n",
      "Epoch 1452/1499\n",
      "----------\n",
      "train Loss: 0.6347 Acc: 0.9129\n",
      "val Loss: 0.6400 Acc: 0.9120\n",
      "test Loss: 0.6503 Acc: 0.8960\n",
      "Epoch 1453/1499\n",
      "----------\n",
      "train Loss: 0.6345 Acc: 0.9160\n",
      "val Loss: 0.6483 Acc: 0.9000\n",
      "test Loss: 0.6516 Acc: 0.8960\n",
      "Epoch 1454/1499\n",
      "----------\n",
      "train Loss: 0.6339 Acc: 0.9136\n",
      "val Loss: 0.6494 Acc: 0.9040\n",
      "test Loss: 0.6488 Acc: 0.8960\n",
      "Epoch 1455/1499\n",
      "----------\n",
      "train Loss: 0.6352 Acc: 0.9124\n",
      "val Loss: 0.6375 Acc: 0.9120\n",
      "test Loss: 0.6465 Acc: 0.9040\n",
      "Epoch 1456/1499\n",
      "----------\n",
      "train Loss: 0.6356 Acc: 0.9158\n",
      "val Loss: 0.6487 Acc: 0.8960\n",
      "test Loss: 0.6447 Acc: 0.9000\n",
      "Epoch 1457/1499\n",
      "----------\n",
      "train Loss: 0.6333 Acc: 0.9180\n",
      "val Loss: 0.6422 Acc: 0.9000\n",
      "test Loss: 0.6487 Acc: 0.9000\n",
      "Epoch 1458/1499\n",
      "----------\n",
      "train Loss: 0.6351 Acc: 0.9151\n",
      "val Loss: 0.6515 Acc: 0.8920\n",
      "test Loss: 0.6485 Acc: 0.9000\n",
      "Epoch 1459/1499\n",
      "----------\n",
      "train Loss: 0.6344 Acc: 0.9144\n",
      "val Loss: 0.6452 Acc: 0.9000\n",
      "test Loss: 0.6534 Acc: 0.8920\n",
      "Epoch 1460/1499\n",
      "----------\n",
      "train Loss: 0.6348 Acc: 0.9151\n",
      "val Loss: 0.6433 Acc: 0.9080\n",
      "test Loss: 0.6497 Acc: 0.8960\n",
      "Epoch 1461/1499\n",
      "----------\n",
      "train Loss: 0.6339 Acc: 0.9149\n",
      "val Loss: 0.6462 Acc: 0.9040\n",
      "test Loss: 0.6498 Acc: 0.8960\n",
      "Epoch 1462/1499\n",
      "----------\n",
      "train Loss: 0.6345 Acc: 0.9144\n",
      "val Loss: 0.6398 Acc: 0.9080\n",
      "test Loss: 0.6476 Acc: 0.9040\n",
      "Epoch 1463/1499\n",
      "----------\n",
      "train Loss: 0.6349 Acc: 0.9136\n",
      "val Loss: 0.6476 Acc: 0.9040\n",
      "test Loss: 0.6449 Acc: 0.9000\n",
      "Epoch 1464/1499\n",
      "----------\n",
      "train Loss: 0.6341 Acc: 0.9153\n",
      "val Loss: 0.6475 Acc: 0.9040\n",
      "test Loss: 0.6499 Acc: 0.8960\n",
      "Epoch 1465/1499\n",
      "----------\n",
      "train Loss: 0.6338 Acc: 0.9122\n",
      "val Loss: 0.6418 Acc: 0.9120\n",
      "test Loss: 0.6443 Acc: 0.9040\n",
      "Epoch 1466/1499\n",
      "----------\n",
      "train Loss: 0.6343 Acc: 0.9164\n",
      "val Loss: 0.6435 Acc: 0.9080\n",
      "test Loss: 0.6482 Acc: 0.8960\n",
      "Epoch 1467/1499\n",
      "----------\n",
      "train Loss: 0.6348 Acc: 0.9153\n",
      "val Loss: 0.6455 Acc: 0.9040\n",
      "test Loss: 0.6474 Acc: 0.8960\n",
      "Epoch 1468/1499\n",
      "----------\n",
      "train Loss: 0.6336 Acc: 0.9144\n",
      "val Loss: 0.6487 Acc: 0.9000\n",
      "test Loss: 0.6469 Acc: 0.8960\n",
      "Epoch 1469/1499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6340 Acc: 0.9149\n",
      "val Loss: 0.6481 Acc: 0.9080\n",
      "test Loss: 0.6509 Acc: 0.8960\n",
      "Epoch 1470/1499\n",
      "----------\n",
      "train Loss: 0.6342 Acc: 0.9133\n",
      "val Loss: 0.6429 Acc: 0.9120\n",
      "test Loss: 0.6503 Acc: 0.8880\n",
      "Epoch 1471/1499\n",
      "----------\n",
      "train Loss: 0.6346 Acc: 0.9138\n",
      "val Loss: 0.6451 Acc: 0.9120\n",
      "test Loss: 0.6454 Acc: 0.8960\n",
      "Epoch 1472/1499\n",
      "----------\n",
      "train Loss: 0.6355 Acc: 0.9140\n",
      "val Loss: 0.6428 Acc: 0.9040\n",
      "test Loss: 0.6456 Acc: 0.9000\n",
      "Epoch 1473/1499\n",
      "----------\n",
      "train Loss: 0.6335 Acc: 0.9149\n",
      "val Loss: 0.6432 Acc: 0.9080\n",
      "test Loss: 0.6454 Acc: 0.8920\n",
      "Epoch 1474/1499\n",
      "----------\n",
      "train Loss: 0.6339 Acc: 0.9156\n",
      "val Loss: 0.6496 Acc: 0.9000\n",
      "test Loss: 0.6449 Acc: 0.9000\n",
      "Epoch 1475/1499\n",
      "----------\n",
      "train Loss: 0.6332 Acc: 0.9151\n",
      "val Loss: 0.6465 Acc: 0.9000\n",
      "test Loss: 0.6494 Acc: 0.8960\n",
      "Epoch 1476/1499\n",
      "----------\n",
      "train Loss: 0.6344 Acc: 0.9142\n",
      "val Loss: 0.6426 Acc: 0.9040\n",
      "test Loss: 0.6493 Acc: 0.8960\n",
      "Epoch 1477/1499\n",
      "----------\n",
      "train Loss: 0.6342 Acc: 0.9133\n",
      "val Loss: 0.6453 Acc: 0.9000\n",
      "test Loss: 0.6503 Acc: 0.8960\n",
      "Epoch 1478/1499\n",
      "----------\n",
      "train Loss: 0.6330 Acc: 0.9160\n",
      "val Loss: 0.6486 Acc: 0.9000\n",
      "test Loss: 0.6472 Acc: 0.9040\n",
      "Epoch 1479/1499\n",
      "----------\n",
      "train Loss: 0.6343 Acc: 0.9142\n",
      "val Loss: 0.6418 Acc: 0.9040\n",
      "test Loss: 0.6492 Acc: 0.8960\n",
      "Epoch 1480/1499\n",
      "----------\n",
      "train Loss: 0.6337 Acc: 0.9151\n",
      "val Loss: 0.6452 Acc: 0.9120\n",
      "test Loss: 0.6476 Acc: 0.9000\n",
      "Epoch 1481/1499\n",
      "----------\n",
      "train Loss: 0.6329 Acc: 0.9158\n",
      "val Loss: 0.6439 Acc: 0.9080\n",
      "test Loss: 0.6443 Acc: 0.9000\n",
      "Epoch 1482/1499\n",
      "----------\n",
      "train Loss: 0.6335 Acc: 0.9162\n",
      "val Loss: 0.6445 Acc: 0.9080\n",
      "test Loss: 0.6515 Acc: 0.8920\n",
      "Epoch 1483/1499\n",
      "----------\n",
      "train Loss: 0.6348 Acc: 0.9116\n",
      "val Loss: 0.6453 Acc: 0.9000\n",
      "test Loss: 0.6467 Acc: 0.8960\n",
      "Epoch 1484/1499\n",
      "----------\n",
      "train Loss: 0.6338 Acc: 0.9140\n",
      "val Loss: 0.6407 Acc: 0.9080\n",
      "test Loss: 0.6486 Acc: 0.9000\n",
      "Epoch 1485/1499\n",
      "----------\n",
      "train Loss: 0.6340 Acc: 0.9147\n",
      "val Loss: 0.6416 Acc: 0.9040\n",
      "test Loss: 0.6493 Acc: 0.8960\n",
      "Epoch 1486/1499\n",
      "----------\n",
      "train Loss: 0.6335 Acc: 0.9140\n",
      "val Loss: 0.6470 Acc: 0.9000\n",
      "test Loss: 0.6467 Acc: 0.9000\n",
      "Epoch 1487/1499\n",
      "----------\n",
      "train Loss: 0.6331 Acc: 0.9153\n",
      "val Loss: 0.6427 Acc: 0.9120\n",
      "test Loss: 0.6507 Acc: 0.9000\n",
      "Epoch 1488/1499\n",
      "----------\n",
      "train Loss: 0.6360 Acc: 0.9102\n",
      "val Loss: 0.6455 Acc: 0.9080\n",
      "test Loss: 0.6481 Acc: 0.9040\n",
      "Epoch 1489/1499\n",
      "----------\n",
      "train Loss: 0.6355 Acc: 0.9127\n",
      "val Loss: 0.6484 Acc: 0.9000\n",
      "test Loss: 0.6516 Acc: 0.8920\n",
      "Epoch 1490/1499\n",
      "----------\n",
      "train Loss: 0.6347 Acc: 0.9140\n",
      "val Loss: 0.6412 Acc: 0.9080\n",
      "test Loss: 0.6480 Acc: 0.8920\n",
      "Epoch 1491/1499\n",
      "----------\n",
      "train Loss: 0.6330 Acc: 0.9164\n",
      "val Loss: 0.6455 Acc: 0.9120\n",
      "test Loss: 0.6465 Acc: 0.9040\n",
      "Epoch 1492/1499\n",
      "----------\n",
      "train Loss: 0.6335 Acc: 0.9160\n",
      "val Loss: 0.6477 Acc: 0.9000\n",
      "test Loss: 0.6472 Acc: 0.8960\n",
      "Epoch 1493/1499\n",
      "----------\n",
      "train Loss: 0.6337 Acc: 0.9160\n",
      "val Loss: 0.6423 Acc: 0.9040\n",
      "test Loss: 0.6485 Acc: 0.8960\n",
      "Epoch 1494/1499\n",
      "----------\n",
      "train Loss: 0.6350 Acc: 0.9133\n",
      "val Loss: 0.6469 Acc: 0.9040\n",
      "test Loss: 0.6464 Acc: 0.8960\n",
      "Epoch 1495/1499\n",
      "----------\n",
      "train Loss: 0.6341 Acc: 0.9144\n",
      "val Loss: 0.6462 Acc: 0.9120\n",
      "test Loss: 0.6449 Acc: 0.9040\n",
      "Epoch 1496/1499\n",
      "----------\n",
      "train Loss: 0.6346 Acc: 0.9149\n",
      "val Loss: 0.6411 Acc: 0.9040\n",
      "test Loss: 0.6507 Acc: 0.8960\n",
      "Epoch 1497/1499\n",
      "----------\n",
      "train Loss: 0.6334 Acc: 0.9133\n",
      "val Loss: 0.6425 Acc: 0.9120\n",
      "test Loss: 0.6509 Acc: 0.9000\n",
      "Epoch 1498/1499\n",
      "----------\n",
      "train Loss: 0.6341 Acc: 0.9120\n",
      "val Loss: 0.6421 Acc: 0.9120\n",
      "test Loss: 0.6473 Acc: 0.8960\n",
      "Epoch 1499/1499\n",
      "----------\n",
      "train Loss: 0.6342 Acc: 0.9129\n",
      "val Loss: 0.6475 Acc: 0.9080\n",
      "test Loss: 0.6468 Acc: 0.9040\n",
      "Training complete in 1m 25s\n",
      "Best test Acc: 0.908000\n"
     ]
    }
   ],
   "source": [
    "# random\n",
    "num_epochs_random = 1500\n",
    "\n",
    "params_to_update310 = model_random_3_10.parameters()\n",
    "params_to_update110 = model_random_1_10.parameters()\n",
    "params_to_update510 = model_random_5_10.parameters()\n",
    "params_to_update305 = model_random_3_05.parameters()\n",
    "params_to_update315 = model_random_3_15.parameters()\n",
    "\n",
    "optimizer_ft310 = optim.Adam(params_to_update310, lr=0.001)\n",
    "optimizer_ft110 = optim.Adam(params_to_update110, lr=0.001)\n",
    "optimizer_ft510 = optim.Adam(params_to_update510, lr=0.001)\n",
    "optimizer_ft305 = optim.Adam(params_to_update305, lr=0.001)\n",
    "optimizer_ft315 = optim.Adam(params_to_update315, lr=0.001)\n",
    "\n",
    "model_ft310r, hist310r, loss310r, f1_310r = train_model(model_random_3_10, loader_random, criterion, optimizer_ft310, num_epochs=num_epochs_random)\n",
    "model_ft110r, hist110r, loss110r, f1_110r = train_model(model_random_1_10, loader_random, criterion, optimizer_ft110, num_epochs=num_epochs_random)\n",
    "model_ft510r, hist510r, loss510r, f1_510r = train_model(model_random_5_10, loader_random, criterion, optimizer_ft510, num_epochs=num_epochs_random)\n",
    "model_ft305r, hist305r, loss305r, f1_305r = train_model(model_random_3_05, loader_random, criterion, optimizer_ft305, num_epochs=num_epochs_random)\n",
    "model_ft315r, hist315r, loss315r, f1_315r = train_model(model_random_3_15, loader_random, criterion, optimizer_ft315, num_epochs=num_epochs_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_model(model, loader):\n",
    "#     model.eval()\n",
    "#     all_outputs = []\n",
    "#     with torch.no_grad():\n",
    "#         for inputs, labels in loader['test']:\n",
    "#             inputs = inputs.to(device)\n",
    "#             test_outputs = model(inputs)\n",
    "#             _, preds = torch.max(test_outputs, 1)\n",
    "#             all_outputs = np.concatenate((all_outputs, preds.cpu().numpy()))\n",
    "            \n",
    "#     return np.mean(all_outputs == np.array(labels))\n",
    "\n",
    "# test_model(model_ft, loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x1080 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def draw3(hist310, hist110, hist510, hist305, hist315, f1_310, f1_110, f1_510, f1_305, f1_315, num_epochs):\n",
    "    # tex\n",
    "    plt.rc('text', usetex=True)\n",
    "    plt.rc('font', family='serif')\n",
    "    x = range(num_epochs)\n",
    "\n",
    "    plt.figure(figsize=(25, 15))\n",
    "\n",
    "    plt.subplot(321)\n",
    "    plt.plot(x, hist310['train'], 'r', label = 'train')\n",
    "    plt.plot(x, hist310['val'], 'g', label = 'val')\n",
    "    plt.plot(x, hist310['test'], 'b', label = 'test')\n",
    "    # plt.xlabel('epoch', fontsize=30)\n",
    "    plt.ylabel('Accuracy', fontsize=30)\n",
    "    plt.tick_params(labelsize=30)\n",
    "    plt.legend(fontsize=30)\n",
    "    \n",
    "    plt.subplot(322)\n",
    "    plt.plot(x, f1_310['train'], 'r', label = 'train')\n",
    "    plt.plot(x, f1_310['val'], 'g', label = 'val')\n",
    "    plt.plot(x, f1_310['test'], 'b', label = 'test')\n",
    "    # plt.xlabel('epoch', fontsize=30)\n",
    "    plt.ylabel('macro F1-score', fontsize=30)\n",
    "    plt.tick_params(labelsize=30)\n",
    "    plt.legend(fontsize=30)\n",
    "\n",
    "    plt.subplot(323)\n",
    "    plt.plot(x, hist310['test'], 'r', label = '3 layers')\n",
    "    plt.plot(x, hist110['test'], 'g', label = '1 layer')\n",
    "    plt.plot(x, hist510['test'], 'b', label = '5 layers')\n",
    "    # plt.xlabel('epoch', fontsize=30)\n",
    "    plt.ylabel('Accuracy', fontsize=30)\n",
    "    plt.tick_params(labelsize=30)\n",
    "    plt.legend(fontsize=30)\n",
    "    \n",
    "    plt.subplot(324)\n",
    "    plt.plot(x, f1_310['test'], 'r', label = '3 layers')\n",
    "    plt.plot(x, f1_110['test'], 'g', label = '1 layer')\n",
    "    plt.plot(x, f1_510['test'], 'b', label = '5 layers')\n",
    "    # plt.xlabel('epoch', fontsize=30)\n",
    "    plt.ylabel('macro F1-score', fontsize=30)\n",
    "    plt.tick_params(labelsize=30)\n",
    "    plt.legend(fontsize=30)\n",
    "    \n",
    "    plt.subplot(325)\n",
    "    plt.plot(x, hist310['test'], 'r', label = 'hidden num = 10')\n",
    "    plt.plot(x, hist305['test'], 'g', label = 'hidden num = 5')\n",
    "    plt.plot(x, hist315['test'], 'b', label = 'hidden num = 15')\n",
    "    plt.xlabel('epoch', fontsize=30)\n",
    "    plt.ylabel('Accuracy', fontsize=30)\n",
    "    plt.tick_params(labelsize=30)\n",
    "    plt.legend(fontsize=30)\n",
    "    \n",
    "    plt.subplot(326)\n",
    "    plt.plot(x, f1_310['test'], 'r', label = 'hidden num = 10')\n",
    "    plt.plot(x, f1_305['test'], 'g', label = 'hidden num = 5')\n",
    "    plt.plot(x, f1_315['test'], 'b', label = 'hidden num = 15')\n",
    "    plt.xlabel('epoch', fontsize=30)\n",
    "    plt.ylabel('macro F1-score', fontsize=30)\n",
    "    plt.tick_params(labelsize=30)\n",
    "    plt.legend(fontsize=30)   \n",
    "    \n",
    "draw3(hist310, hist110, hist510, hist305, hist315, f1_310, f1_110, f1_510, f1_305, f1_315, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x1080 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw3(hist310r, hist110r, hist510r, hist305r, hist315r, f1_310r, f1_110r, f1_510r, f1_305r, f1_315r, num_epochs_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_list = [hist310, hist110, hist510, hist305, hist315, f1_310, f1_110, f1_510, f1_305, f1_315]\n",
    "random_list = [hist310r, hist110r, hist510r, hist305r, hist315r, f1_310r, f1_110r, f1_510r, f1_305r, f1_315r]\n",
    "\n",
    "def all_f1(data_list):\n",
    "#     data_list.cpu()\n",
    "    max_list = []\n",
    "    for j,i in enumerate(data_list[5:]):\n",
    "        f1_max = np.mean(i['test'][-10:])\n",
    "#         print(np.array(data_list[j]['test'])[-5:])\n",
    "        acc_max = np.mean(np.array(data_list[j]['test'])[-10:])\n",
    "        max_list.append([f1_max, acc_max])\n",
    "#         f1_max = np.max(i['test'])\n",
    "#         loc = np.where(i['test'] == f1_max)\n",
    "#         acc_max = np.max(np.array(data_list[j]['test'])[loc])\n",
    "#         max_list.append([f1_max, acc_max])\n",
    "    return np.array(max_list)\n",
    "\n",
    "iris_best = all_f1(iris_list)\n",
    "# random_best = all_f1(random_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def draw_bar(data_list, num_epochs = 5):\n",
    "    # tex\n",
    "    plt.rc('text', usetex=True)\n",
    "    plt.rc('font', family='serif')\n",
    "    x = range(num_epochs)\n",
    "\n",
    "    plt.figure(figsize=(25, 10))\n",
    "\n",
    "    plt.subplot(121)\n",
    "    plt.bar(range(5), data_list[:,0], width=0.7, color='dodgerblue', alpha=0.8)      # \n",
    "    plt.xticks(range(5), ['3*10', '1*10', '5*10', '3*5', '3*15'])\n",
    "    plt.ylim(0.5,1)\n",
    "    plt.xlabel(\"model\", fontsize=30)\n",
    "    plt.ylabel(\"macro F1-score\", fontsize=30)\n",
    "    plt.tick_params(labelsize=30)\n",
    "    for x, y in enumerate(data_list[:,0]):\n",
    "        plt.text(x -0.3, y + 0.01, '%.4f' % y, fontsize=30)\n",
    "\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.bar(range(5), data_list[:,1], width=0.7, color='limegreen', alpha=0.8)      # \n",
    "    plt.xticks(range(5), ['3*10', '1*10', '5*10', '3*5', '3*15'])\n",
    "    plt.ylim(0.5,1)\n",
    "    plt.xlabel(\"model\", fontsize=30)\n",
    "    plt.ylabel(\"Accuracy\", fontsize=30)\n",
    "    plt.tick_params(labelsize=30)\n",
    "    for x, y in enumerate(data_list[:,1]):\n",
    "        plt.text(x -0.3, y + 0.01, '%.4f' % y, fontsize=30)\n",
    "\n",
    "draw_bar(iris_best)\n",
    "draw_bar(random_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
